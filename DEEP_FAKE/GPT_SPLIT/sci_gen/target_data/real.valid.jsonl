{"original_text": "In this paper, we focus on the meta distribution for the cache-enabled networks where the locations of base stations (BSs) are modeled as Poisson point process (PPP). Under the random caching framework, we derive the moments of the conditional successful transmission probability (STP), the exact meta distribution and its beta approximation by utilizing stochastic geometry. The closed-form expression of the mean local delay is also derived. We consider the maximization of the STP and the minimization of the mean local delay by optimizing the caching probability and the BS active probability, respectively. For the former, a convex optimization problem is formulated and the optimal caching probability and BS active probability are achieved. Moreover, most popular caching (MPC) is proved to optimal under the constraint that the mean local delay is finite. For the latter, a non-convex optimization problem is formulated and an iterative algorithm is proposed to obtain the optimal solution. The backhaul delay has a significant influence on the caching strategy. MPC is proved to be optimal when the backhaul delay is relatively low and the uniform caching (UC) is the optimal caching strategy when the backhaul delay is very large. Finally, the numerical results reveal the effect of the key network parameters on the cache-enabled networks in terms of STP, variance, meta distribution and mean local delay.", "text_perturb": "In this report , we focus on the meta distribution for the cache-enabled networks where the locations of base stations ( BSs ) are modeled as Poisson point process ( PPP ). Under the random caching framework , we derive the instant of the conditional successful transmission probability ( STP ) , the exact meta distribution and its beta approximation by utilizing stochastic geometry. The closed-form expression of the mean local delay constitute also derived. We consider the maximization of the stp and the minimization of the mean local delay by optimizing the caching probability and the BS active probability , respectively. For the former , a convex optimization problem follow formulated and the optimal caching probability and BS active probability are achieved. Moreover , most popular caching ( MPC ) equal proved to optimal under the constraint that the mean local delay equal finite. For the latter , a non-convex optimization problem is formulated and an iterative algorithm is proposed to obtain the optimal resolution. The backhaul delay take a significant influence on the caching strategy. MPC is proved to be optimal when the backhaul delay is relatively low and the uniform caching ( UC ) is the optimal caching strategy when the backhaul delay is really large. Finally , the numerical results reveal the effect of the key network parameters on the cache-enabled networks in terms of STP , variance , meta distribution and mean local time lag. ", "label": 1}
{"original_text": "One significant challenge in the job scheduling of computing clusters for the development of deep learning algorithms is the efficient scheduling of trial-and-error (TE) job, the type of job in which the users seek to conduct small-scale experiments while monitoring their processes. Unfortunately, the existing job schedulers to date do not feature well-balanced scheduling for the mixture of TE jobs and best-effort (BE) jobs, or they can handle the mixture in limited situations at most. To fill in this niche, we propose an algorithm that can significantly reduce the latency of TE jobs in versatile situations without greatly elongating the slowdown of the BE jobs. Our algorithm efficiently schedules both TE and BE jobs by selectively preempting the BE jobs that can be, when the time comes, resumed without much delay. In our simulation study with synthetic and real workloads, we were able to reduce the 95th percentile of the slowdown rates for the TE jobs in the standard FIFO strategy by 96.6, while compromising the median of the BE slowdown rates by only 18.0 and the 95th percentile by only 23.9.", "text_perturb": "One significant challenge in the job scheduling of computing clusters for the development of deep learning algorithms equal the efficient scheduling of trial-and-error ( TE ) job , the type of job in which the users seek to conduct small-scale experiments while monitoring their processes. Unfortunately , the existing job schedulers to date do not feature well-balanced scheduling for the mix of TE jobs and best-effort ( BE ) jobs , or they can handle the mix in limited situations at most. To fill in this niche , we project an algorithm that can significantly reduce the latency of TE jobs in versatile situations without greatly elongating the slowdown of the BE jobs. Our algorithm efficiently schedules both TE and BE jobs by selectively preempting the BE jobs that can be , when the time comes , take up without much delay. In our simulation study with synthetic and real workloads , we were able to reduce the 95th percentile of the slowdown rates for the te jobs in the standard FIFO strategy by 96. 6 , while compromising the median of the glucinium slowdown rates by only 18. 0 and the 95th centile by only 23. 9. ", "label": 1}
{"original_text": "The Morton- or z -curve is one example for a space filling curve: Given a level of refinement L N 0, it maps the interval [ 0, 2 d L) Z one-to-one to a set of d -dimensional cubes of edge length 2 - L that form a subdivision of the unit cube. Similar curves have been proposed for triangular and tetrahedral unit domains. In contrast to the Hilbert curve that is continuous, the Morton-type curves produce jumps. We prove that any contiguous subinterval of the curve divides the domain into a bounded number of face-connected subdomains. For the hypercube case in arbitrary dimension, the subdomains are star-shaped and the bound is indeed two. For the simplicial case in dimensions 2 and 3, the bound is proportional to the depth of refinement L. We supplement the paper with theoretical and computational studies on the frequency of jumps for a quantitative assessment.", "text_perturb": "The Morton- or z -curve is one example for a space filling curve : Given a level of refinement L N 0 , it maps the interval [ 0 , 2 d L ) Z one-to-one to a set of d -dimensional cubes of sharpness length 2 - L that form a subdivision of the unit cube. Similar curves birth been proposed for triangular and tetrahedral unit domains. In contrast to the Hilbert curve that is continuous , the Morton-type curves develop jumps. We prove that any contiguous subinterval of the curve divides the domain into a delimited number of face-connected subdomains. For the hypercube case in arbitrary dimension , the subdomains are star shaped and the bound is indeed two. For the simplicial case in attribute 2 and 3 , the bound is proportional to the depth of refinement L. We supplement the paper with theoretical and computational studies on the frequency of jumps for a quantitative appraisal. ", "label": 1}
{"original_text": "Large number of weights in deep neural networks makes the models difficult to be deployed in low memory environments such as, mobile phones, IOT edge devices as well as \"inferencing as a service\" environments on cloud. Prior work has considered reduction in the size of the models, through compression techniques like pruning, quantization, Huffman encoding etc. However, efficient inferencing using the compressed models has received little attention, specially with the Huffman encoding in place. In this paper, we propose efficient parallel algorithms for inferencing of single image and batches, under various memory constraints. Our experimental results show that our approach of using variable batch size for inferencing achieves 15-25 performance improvement in the inference throughput for AlexNet, while maintaining memory and latency constraints.", "text_perturb": "Large number of weights in deep neural networks makes the models hard to be deployed in low memory environments such as , mobile phones , IOT edge devices as well as `` inferencing as a service '' environments on cloud. Prior work has considered reducing in the size of the models , through compression techniques like pruning , quantization , Huffman encoding etc. However , efficient inferencing using the compressed models has received little attention , specially with the Huffman encoding in office. In this paper , we propose efficient parallel algorithms for inferencing of undivided image and batches , under various memory constraints. Our experimental results show that our approach of using variable batch size for inferencing achieves 15-25 performance improvement in the inference throughput for AlexNet , while maintaining memory and latency constraint. ", "label": 1}
{"original_text": "Several variants of stochastic gradient descent (SGD) have been proposed to improve the learning effectiveness and efficiency when training deep neural networks, among which some recent influential attempts would like to adaptively control the parameter-wise learning rate (e.g., Adam and RMSProp). Although they show a large improvement in convergence speed, most adaptive learning rate methods suffer from compromised generalization compared with SGD. In this paper, we proposed an Adaptive Gradient Method with Resilience and Momentum (AdaRem), motivated by the observation that the oscillations of network parameters slow the training, and give a theoretical proof of convergence. For each parameter, AdaRem adjusts the parameter-wise learning rate according to whether the direction of one parameter changes in the past is aligned with the direction of the current gradient, and thus encourages long-term consistent parameter updating with much fewer oscillations. Comprehensive experiments have been conducted to verify the effectiveness of AdaRem when training various models on a large-scale image recognition dataset, i.e., ImageNet, which also demonstrate that our method outperforms previous adaptive learning rate-based algorithms in terms of the training speed and the test error, respectively.", "text_perturb": "Several variants of stochastic gradient descent ( SGD ) have been proposed to improve the learning effectiveness and efficiency when training deep neural networks , among which some recent influential attempts would care to adaptively control the parameter-wise learning rate ( e. thou. , Adam and RMSProp ). Although they show a large improvement in convergence speed , most adaptive learning rate methods suffer from compromised generalization compare with SGD. In this newspaper , we proposed an Adaptive Gradient Method with Resilience and Momentum ( AdaRem ) , motivated by the observation that the oscillations of network parameters slow the training , and give a theoretical proof of convergence. For each parameter , AdaRem adjusts the parameter-wise learning pace according to whether the direction of one parameter changes in the past is aligned with the direction of the current gradient , and thus encourages long-term consistent parameter updating with much fewer oscillations. Comprehensive experiments have been conducted to verify the effectiveness of AdaRem when training diverse models on a large-scale image recognition dataset , i. due east. , ImageNet , which too demonstrate that our method outperforms previous adaptive learning rate-based algorithms in terms of the training speed and the test error , respectively. ", "label": 1}
{"original_text": "Abstract Geometrical Computation as a new model of computation is the counterpart of Cellular Automata that has Turing computing ability. In this paper we provide an algorithm to simulate Alternating Turing Machine in the context of Signal Machine using techniques adopted from the features of Signal Machine to set up and manage the copiesbranches of Alternating Turing Machine. We show that our algorithm can simulate Alternating Turing Machine in Signal Machine as same functionality as classic family of Turing Machines. Time complexity of the algorithm is linear as ordinary simulated Turing Machines. Depending on the computation tree space complexity is exponential order of d, where d is the depth of the computation tree.", "text_perturb": "Abstract Geometrical Computation as a new model of computation is the counterpart of Cellular Automata that feature Turing computing ability. In this paper we provide an algorithm to simulate Alternating Turing Machine in the context of signal Machine using techniques adopted from the features of signal Machine to set up and manage the copiesbranches of Alternating Turing Machine. We show that our algorithm terminate simulate Alternating Turing Machine in Signal Machine as same functionality as classic family of Turing Machines. Time complexity of the algorithm is linear as ordinary simulated alan mathison turing Machines. Depending on the computation tree space complexity is exponential order of cholecalciferol , where cholecalciferol is the depth of the computation tree. ", "label": 1}
{"original_text": "We describe a simple approach to semantic parsing based on a tensor product kernel. We extract two feature vectors: one for the query and one for each candidate logical form. We then train a clasifier using the tensor product of the two vectors. Using very simple features for both, our system achieves an average F1 score of 40.1 on the WebQuestions dataset. This is comparable to more complex systems but is simpler to implement and runs faster.", "text_perturb": "We describe a simple approach to semantic parsing base on a tensor product kernel. We extract two feature vectors : one for the query and one for each candidate logical course. We then coach a clasifier using the tensor product of the two vectors. Using very simple features for both , our system achieves an average F1 mark of 40. 1 on the WebQuestions dataset. This cost comparable to more complex systems but cost simpler to implement and runs faster. ", "label": 1}
{"original_text": "With the increasing penetration of renewable energy resources, power systems face new challenges in maintaining power balance and the nominal frequency. This paper studies load control to handle these challenges. In particular, a fully distributed automatic load control (ALC) algorithm, which only needs local measurement and local communication, is proposed. We prove that the load control algorithm globally converges to an optimal operating point which minimizes the total disutility of users, restores the nominal frequency and the scheduled tie-line power flows, and respects the load capacity limits and the thermal constraints of transmission lines. It is further shown that the asymptotic convergence still holds even when inaccurate system parameters are used in the control algorithm. In addition, the global exponential convergence of the reduced ALC algorithm without considering the capacity limits is proved and leveraged to study the dynamical tracking performance and robustness of the algorithm. Lastly, the effectiveness, optimality, and robustness of the proposed algorithm are demonstrated via numerical simulations.", "text_perturb": "With the increase penetration of renewable energy resources , power systems face new challenges in maintaining power balance and the nominal frequency. This paper studies lade control to handle these challenges. In particular , a fully distributed automatic load control ( ALC ) algorithmic rule , which only needs local measurement and local communication , is proposed. We try out that the load control algorithm globally converges to an optimal operating point which minimizes the total disutility of users , restores the nominal frequency and the scheduled tie-line power flows , and respects the load capacity limits and the thermal constraints of transmission lines. It is further shown that the asymptotic convergence still holds even when inaccurate system parameters are used in the control algorithmic program. In addition , the global exponential convergence of the reduced ALC algorithm without regard the capacity limits is proved and leveraged to study the dynamical tracking performance and robustness of the algorithm. lastly , the effectiveness , optimality , and robustness of the proposed algorithm are demonstrated via numerical simulations. ", "label": 1}
{"original_text": "We propose a new global entity disambiguation (ED) model based on contextualized embeddings of words and entities. Our model is based on a bidirectional transformer encoder (i.e., BERT) and produces contextualized embeddings for words and entities in the input text. The model is trained using a new masked entity prediction task that aims to train the model by predicting randomly masked entities in entity-annotated texts obtained from Wikipedia. We further extend the model by solving ED as a sequential decision task to capture global contextual information. We evaluate our model using six standard ED datasets and achieve new state-of-the-art results on all but one dataset.", "text_perturb": "We propose a new global entity disambiguation ( ED ) model based on contextualized embeddings of words and entity. Our model is establish on a bidirectional transformer encoder ( i. tocopherol. , BERT ) and produces contextualized embeddings for words and entities in the input textual matter. The role model is trained using a new masked entity prediction task that aims to train the role model by predicting randomly masked entities in entity-annotated texts obtained from Wikipedia. We further extend the model by solving ed as a sequential decision task to capture global contextual information. We assess our model using six standard ED datasets and achieve new state-of-the-art results on all but one dataset. ", "label": 1}
{"original_text": "Underwater imagery has enabled numerous civilian applications in various domains, ranging from academia to industry, and from industrial surveillance and maintenance to environmental protection and behavior of marine creatures studies. The accumulation of litter and plastic debris at the seafloor and the bottom of rivers are extremely harmful for the aquatic life. We propose a solution for monitoring this problem using a team of Autonomous Underwater Vehicles (AUVs) to exchange the recorded video in order to reconstruct the map of regions of interest. However, underwater video transmission is a challenge in the harsh environment in which radio-frequency waves are absorbed for distances above a few tens of meters, optical waves require narrow laser beams and suffer from scattering and ocean wave motion, and acoustic waves - while long range - provide a very low bandwidth and unreliable channel for communication. In our solution, the scalable coded video of each vehicle is shared in-network with a selected group of receiving vehicles through the underwater acoustic channel. Presented evaluations, including both simulations and experiments, confirm the efficiency and flexibility of the proposed solution using acoustic software-defined modems.", "text_perturb": "Underwater imagery has enabled numerous civilian applications in various domains , ranging from academia to diligence , and from industrial surveillance and maintenance to environmental protection and behavior of marine creatures studies. The assemblage of litter and plastic debris at the seafloor and the bottom of rivers are extremely harmful for the aquatic life. We propose a solution for monitoring this problem using a team of Autonomous Underwater Vehicles ( AUVs ) to exchange the recorded video in order to remodel the map of regions of interest. However , underwater video transmission is a challenge in the harsh environment in which radio-frequency waves are absorbed for aloofness above a few tens of meters , optical waves require narrow laser beams and suffer from scattering and ocean wave motion , and acoustic waves - while long range - provide a very low bandwidth and unreliable channel for communication. In our solution , the scalable coded video of each vehicle is partake in-network with a selected group of receiving vehicles through the underwater acoustic channel. Presented evaluations , including both simulations and experiments , affirm the efficiency and flexibility of the proposed solution using acoustic software-defined modems. ", "label": 1}
{"original_text": "Given only data generated by a standard confounding graph with unobserved confounder, the Average Treatment Effect (ATE) is not identifiable. To estimate the ATE, a practitioner must then either (a) collect deconfounded data; (b) run a clinical trial; or (c) elucidate further properties of the causal graph that might render the ATE identifiable. In this paper, we consider the benefit of incorporating a (large) confounded observational dataset alongside a (small) deconfounded observational dataset when estimating the ATE. Our theoretical results show that the inclusion of confounded data can significantly reduce the quantity of deconfounded data required to estimate the ATE to within a desired accuracy level. Moreover, in some cases - say, genetics - we could imagine retrospectively selecting samples to deconfound. We demonstrate that by strategically selecting these examples based upon the (already observed) treatment and outcome, we can reduce our data dependence further. Our theoretical and empirical results establish that the worst-case relative performance of our approach (vs. a natural benchmark) is bounded while our best-case gains are unbounded. Next, we demonstrate the benefits of selective deconfounding using a large real-world dataset related to genetic mutation in cancer. Finally, we introduce an online version of the problem, proposing two adaptive heuristics.", "text_perturb": "Given only data generated by a standard confounding graph with unobserved confounder , the Average Treatment consequence ( ATE ) is not identifiable. To estimate the ATE , a practitioner must then either ( a ) collect deconfounded data ; ( b ) run a clinical trial ; or ( c ) elucidate farther properties of the causal graph that might render the ATE identifiable. In this paper , we consider the benefit of incorporating a ( large ) confuse observational dataset alongside a ( small ) deconfounded observational dataset when estimating the ATE. Our theoretical results show that the inclusion of confounded data can significantly reduce the quantity of deconfounded data required to estimate the ATE to within a desired truth level. Moreover , in some cases - say , genetics - we could think retrospectively selecting samples to deconfound. We demonstrate that by strategically selecting these examples based upon the ( already observed ) treatment and final result , we can reduce our data dependence further. Our theoretical and empirical outcome establish that the worst-case relative performance of our approach ( vs. a natural bench mark ) is bounded while our best-case gains are unbounded. side by side , we demonstrate the benefits of selective deconfounding using a large real-world dataset related to genetic mutation in cancer. Finally , we introduce an online version of the problem , proposing two adaptive heuristic program. ", "label": 1}
{"original_text": "Wireless communications are vulnerable against radio frequency (RF) jamming which might be caused either intentionally or unintentionally. A particular subset of wireless networks, vehicular ad-hoc networks (VANET) which incorporate a series of safety-critical applications, may be a potential target of RF jamming with detrimental safety effects. To ensure secure communication and defend it against this type of attacks, an accurate detection scheme must be adopted. In this paper we introduce a detection scheme that is based on supervised learning. The machine-learning algorithms, K-Nearest Neighbors (KNN) and Random Forests (RF), utilize a series of features among which is the metric of the variations of relative speed (VRS) between the jammer and the receiver that is passively estimated from the combined value of the useful and the jamming signal at the receiver. To the best of our knowledge, this metric has never been utilized before in a machine-learning detection scheme in the literature. Through offline training and the proposed KNN-VRS, RF-VRS classification algorithms, we are able to efficiently detect various cases of Denial of Service Attacks (DoS) jamming attacks, differentiate them from cases of interference as well as foresee a potential danger successfully and act accordingly.", "text_perturb": "Wireless communications exist vulnerable against radio frequency ( RF ) jamming which might be caused either intentionally or unintentionally. A particular subset of wireless networks , vehicular ad-hoc networks ( VANET ) which incorporate a series of safety-critical applications , may make up a potential target of RF jamming with detrimental safety effects. To ensure secure communication and represent it against this type of attacks , an accurate detection scheme must be adopted. In this paper we inclose a detection scheme that is based on supervised learning. The machine-learning algorithms , K-Nearest Neighbors ( KNN ) and Random Forests ( RF ) , utilize a series of features among which is the metric of the magnetic declination of relative speed ( VRS ) between the jammer and the receiver that is passively estimated from the combined value of the useful and the jamming signal at the receiver. To the best of our knowledge , this metric give birth never been utilized before in a machine-learning detection scheme in the literature. Through offline training and the proposed KNN-VRS , RF-VRS classification algorithms , we are capable to efficiently detect various cases of Denial of Service Attacks ( DoS ) jamming attacks , differentiate them from cases of interference as well as foresee a potential danger successfully and act accordingly. ", "label": 1}
{"original_text": "We introduce a new machine-learning-based approach, which we call the Independent Classifier networks (InClass nets) technique, for the nonparameteric estimation of conditional independence mixture models (CIMMs). We approach the estimation of a CIMM as a multi-class classification problem, since dividing the dataset into different categories naturally leads to the estimation of the mixture model. InClass nets consist of multiple independent classifier neural networks (NNs), each of which handles one of the variates of the CIMM. Fitting the CIMM to the data is performed by simultaneously training the individual NNs using suitable cost functions. The ability of NNs to approximate arbitrary functions makes our technique nonparametric. Further leveraging the power of NNs, we allow the conditionally independent variates of the model to be individually high-dimensional, which is the main advantage of our technique over existing non-machine-learning-based approaches. We derive some new results on the nonparametric identifiability of bivariate CIMMs, in the form of a necessary and a (different) sufficient condition for a bivariate CIMM to be identifiable. We provide a public implementation of InClass nets as a Python package called RainDancesVI and validate our InClass nets technique with several worked out examples. Our method also has applications in unsupervised and semi-supervised classification problems.", "text_perturb": "We introduce a new machine-learning-based approach , which we call the Independent Classifier networks ( InClass nets ) proficiency , for the nonparameteric estimation of conditional independence mixture models ( CIMMs ). We approach the estimation of a CIMM as a multi-class classification problem , since dividing the dataset into dissimilar categories naturally leads to the estimation of the mixture model. InClass nets consist of multiple independent classifier neural networks ( NNs ) , each of which handles one of the variant of the CIMM. Fitting the CIMM to the data is performed by simultaneously training the individual NNs expend suitable cost functions. The power of NNs to approximate arbitrary functions makes our technique nonparametric. Further leveraging the power of NNs , we allow the conditionally independent variates of the model to be severally high-dimensional , which is the main advantage of our technique over existing non-machine-learning-based approaches. We derive some new results on the nonparametric identifiability of bivariate CIMMs , in the figure of a necessary and a ( different ) sufficient condition for a bivariate CIMM to be identifiable. We provide a public implementation of InClass nets as a Python package bid RainDancesVI and validate our InClass nets technique with several worked out examples. Our method likewise has applications in unsupervised and semi-supervised classification problems. ", "label": 1}
{"original_text": "We present ABSApp, a portable system for weakly-supervised aspect-based sentiment extraction 1 footnote 1 1 footnote 1 A demo video of ABSApp is available at The system is interpretable and user friendly and does not require labeled training data, hence can be rapidly and cost-effectively used across different domains in applied setups. The system flow includes three stages: First, it generates domain-specific aspect and opinion lexicons based on an unlabeled dataset; second, it enables the user to view and edit those lexicons (weak supervision); and finally, it enables the user to select an unlabeled target dataset from the same domain, classify it, and generate an aspect-based sentiment report. ABSApp has been successfully used in a number of real-life use cases, among them movie review analysis and convention impact analysis.", "text_perturb": "We present ABSApp , a portable system for weakly-supervised aspect-based sentiment extraction 1 footnote 1 1 footnote 1 group a demo video of ABSApp is available at The system is interpretable and user friendly and does not require labeled training data , hence can be rapidly and cost-effectively used across different domains in applied setups. The system flow includes three stages : First , it generates domain-specific aspect and opinion lexicons based on an unlabeled dataset ; second , it enables the user to view and edit those lexicons ( weak supervising ) ; and finally , it enables the user to select an unlabeled target dataset from the same domain , classify it , and generate an aspect-based sentiment report. ABSApp has been successfully used in a number of real-life use font , among them movie review analysis and convention impact analysis. ", "label": 1}
{"original_text": "This paper investigates secrecy rate optimization for a multicasting network, in which a transmitter broadcasts the same information to multiple legitimate users in the presence of multiple eavesdroppers. In order to improve the achievable secrecy rates, private jammers are employed to generate interference to confuse the eavesdroppers. These private jammers charge the legitimate transmitter for their jamming services based on the amount of interference received at the eavesdroppers. Therefore, this secrecy rate maximization problem is formulated as a Stackelberg game, in which the private jammers and the transmitter are the leaders and the follower of the game, respectively. A fixed interference price scenario is considered first, in which a closed-form solution is derived for the optimal amount of interference generated by the jammers to maximize the revenue of the legitimate transmitter. Based on this solution, the Stackelberg equilibrium of the proposed game, at which both legitimate transmitter and the private jammers achieve their maximum revenues, is then derived. Simulation results are also provided to validate these theoretical derivations.", "text_perturb": "This paper investigates secrecy rate optimisation for a multicasting network , in which a transmitter broadcasts the same information to multiple legitimate users in the presence of multiple eavesdroppers. In order to improve the achievable secrecy rates , private jammers are utilize to generate interference to confuse the eavesdroppers. These private jammers charge the legitimate transmitter for their jamming services based on the amount of interference take in at the eavesdroppers. Therefore , this secrecy rate maximization problem is formulated as a Stackelberg plot , in which the private jammers and the transmitter are the leaders and the follower of the plot , respectively. A fixed interference price scenario is considered first , in which a closed-form solution is derived for the optimal amount of interference generated by the jammers to maximize the revenue of the legitimate vector. Based on this solution , the Stackelberg equilibrium of the proposed game , at which both legitimate transmitter and the private jammers achieve their maximum revenues , follow then derived. Simulation results are also provided to formalise these theoretical derivations. ", "label": 1}
{"original_text": "Quantum annealing (QA) is a quantum computing algorithm that works on the principle of Adiabatic Quantum Computation (AQC), and it has shown significant computational advantages in solving combinatorial optimization problems such as vehicle routing problems (VRP) when compared to classical algorithms. This paper presents a QA approach for solving a variant VRP known as multi-depot capacitated vehicle routing problem (MDCVRP). This is an NP-hard optimization problem with real-world applications in the fields of transportation, logistics, and supply chain management. We consider heterogeneous depots and vehicles with different capacities. Given a set of heterogeneous depots, the number of vehicles in each depot, heterogeneous depotvehicle capacities, and a set of spatially distributed customer locations, the MDCVRP attempts to identify routes of various vehicles satisfying the capacity constraints such as that all the customers are served. We model MDCVRP as a quadratic unconstrained binary optimization (QUBO) problem, which minimizes the overall distance traveled by all the vehicles across all depots given the capacity constraints. Furthermore, we formulate a QUBO model for dynamic version of MDCVRP known as D-MDCVRP, which involves dynamic rerouting of vehicles to real-time customer requests. We discuss the problem complexity and a solution approach to solving MDCVRP and D-MDCVRP on quantum annealing hardware from D-Wave.", "text_perturb": "Quantum annealing ( QA ) is a quantum computing algorithm that works on the precept of Adiabatic Quantum Computation ( AQC ) , and it has shown significant computational advantages in solving combinatorial optimization problems such as vehicle routing problems ( VRP ) when compared to classical algorithms. This paper presents a QA approach for solving a variant VRP known as multi-depot capacitated fomite routing problem ( MDCVRP ). This is an NP-hard optimization problem with real-world applications programme in the fields of transportation , logistics , and supply chain management. We take heterogeneous depots and vehicles with different capacities. Given a set of heterogeneous depots , the number of vehicles in each depot , heterogeneous depotvehicle capacities , and a set of spatially distributed customer locations , the MDCVRP attempts to identify itinerary of various vehicles satisfying the capacity constraints such as that all the customers are served. We model MDCVRP as a quadratic unconstrained binary optimization ( QUBO ) problem , which minimizes the overall distance jaunt by all the vehicles across all depots given the capacity constraints. Furthermore , we formulate a QUBO modelling for dynamic version of MDCVRP known as D-MDCVRP , which involves dynamic rerouting of vehicles to real-time customer requests. We discuss the problem complexity and a solution approach to solving MDCVRP and D-MDCVRP on quantum anneal hardware from D-Wave. ", "label": 1}
{"original_text": "Abstract: The Fields Medal, often referred as the Nobel Prize of mathematics, is awarded to no more than four mathematician under the age of 40, every four years. In recent years, its conferral has come under scrutiny of math historians, for rewarding the existing elite rather than its original goal of elevating mathematicians from under-represented communities (,). Prior studies of elitism focus on citational practices (,) and sub-fields (,); the structural forces that prevent equitable access remain unclear. Here we show the flow of elite mathematicians between countries and lingo-ethnic identity, using network analysis and natural language processing on 240,000 mathematicians and their advisor-advisee relationships. We found that the Fields Medal helped integrate Japan after WWII, through analysis of the elite circle formed around Fields Medalists. Arabic, African, and East Asian identities remain under-represented at the elite level. Through analysis of inflow and outflow, we rebuts the myth that minority communities create their own barriers to entry. Our results demonstrate concerted efforts by international academic committees, such as prize giving, are a powerful force to give equal access. We anticipate our methodology of academic genealogical analysis can serve as a useful diagnostic for equality within academic fields.", "text_perturb": "Abstract : The Fields Medal , often referred as the Nobel booty of mathematics , is awarded to no more than four mathematician under the age of 40 , every four years. In recent years , its conferral let come under scrutiny of math historians , for rewarding the existing elite rather than its original goal of elevating mathematicians from under-represented communities ( , ). Prior discipline of elitism focus on citational practices ( , ) and sub-fields ( , ) ; the structural forces that prevent equitable access remain unclear. Here we show the stream of elite mathematicians between countries and lingo-ethnic identity , using network analysis and natural language processing on 240,000 mathematicians and their advisor-advisee relationships. We found that the Fields Medal helped integrate Japan after WWII , through analytic thinking of the elite circle formed around Fields Medalists. Arabic , African , and due east Asian identities remain under-represented at the elite level. Through analysis of inflow and leakage , we rebuts the myth that minority communities create their own barriers to entry. Our outcome demonstrate concerted efforts by international academic committees , such as prize giving , are a powerful force to give equal access. We anticipate our methodology of academic genealogic analysis can serve as a useful diagnostic for equality within academic fields. ", "label": 1}
{"original_text": "We introduce a new regularizer in the total variation family that promotes reconstructions with a given Lipschitz constant (which can also vary spatially). We prove regularizing properties of this functional and investigate its connections to total variation and infimal convolution type regularizers TVL p and, in particular, establish topological equivalence. Our numerical experiments show that the proposed regularizer can achieve similar performance as total generalized variation while having the advantage of a very intuitive interpretation of its free parameter, which is just a local estimate of the norm of the gradient. It also provides a natural approach to spatially adaptive regularization.", "text_perturb": "We introduce a new regularizer in the total variation family that push reconstructions with a given Lipschitz constant ( which can also vary spatially ). We prove regularizing properties of this working and investigate its connections to total variation and infimal convolution type regularizers TVL p and , in particular , establish topological equivalence. Our numerical experiments show that the proposed regularizer can achieve similar performance as total generalized variation while having the vantage of a very intuitive interpretation of its free parameter , which is just a local estimate of the norm of the gradient. It as well provides a natural approach to spatially adaptive regularization. ", "label": 1}
{"original_text": "Behavioural economists have shown that people are often averse to inequality and will make choices to avoid unequal outcomes. In this paper, we consider how to allocate indivisible goods fairly so as to minimize inequality. We consider how this interacts with axiomatic properties such as envy-freeness, Pareto efficiency and strategy-proofness. We also consider the computational complexity of computing allocations minimizing inequality. Unfortunately, this is computationally intractable in general so we consider several tractable greedy online mechanisms that minimize inequality. Finally, we run experiments to explore the performance of these methods.", "text_perturb": "Behavioural economists have shown that people are often averse to inequality and will piddle choices to avoid unequal outcomes. In this newspaper , we consider how to allocate indivisible goods fairly so as to minimize inequality. We reckon how this interacts with axiomatic properties such as envy-freeness , Pareto efficiency and strategy-proofness. We also consider the computational complexity of computing allocations understate inequality. Unfortunately , this is computationally intractable in general so we consider several tractable greedy online mechanics that minimize inequality. Finally , we run experiments to explore the operation of these methods. ", "label": 1}
{"original_text": "Twitter is among the most used online platforms for the political communications, due to the concision of its messages (which is particularly suitable for political slogans) and the quick diffusion of messages. Especially when the argument stimulate the emotionality of users, the content on Twitter is shared with extreme speed and thus studying the tweet sentiment if of utmost importance to predict the evolution of the discussions and the register of the relative narratives. In this article, we present a model able to reproduce the dynamics of the sentiments of tweets related to specific topics and periods and to provide a prediction of the sentiment of the future posts based on the observed past. The model is a recent variant of the Polya urn, introduced and studied in, which is characterized by a \"local\" reinforcement, i.e. a reinforcement mechanism mainly based on the most recent observations, and by a random persistent fluctuation of the predictive mean. In particular, this latter feature is capable of capturing the trend fluctuations in the sentiment curve. While the proposed model is extremely general and may be also employed in other contexts, it has been tested on several Twitter data sets and demonstrated greater performances compared to the standard Polya urn model. Moreover, the different performances on different data sets highlight different emotional sensitivities respect to a public event. keywords: Polya urn, reinforcement learning, sentiment analysis, urn model, Twitter.", "text_perturb": "Twitter is among the most used online platforms for the political communications , due to the concision of its messages ( which is particularly suitable for political slogans ) and the agile diffusion of messages. Especially when the argument stimulate the emotionality of users , the content on Twitter is shared with utmost speed and thus studying the tweet sentiment if of utmost importance to predict the evolution of the discussions and the register of the relative narratives. In this clause , we present a model able to reproduce the dynamics of the sentiments of tweets related to specific topics and periods and to provide a prediction of the sentiment of the future posts based on the observed past. The model is a recent variant of the Polya urn , bring out and studied in , which is characterized by a `` local '' reinforcement , i. vitamin e. a reinforcer mechanism mainly based on the most recent observations , and by a random persistent fluctuation of the predictive mean. In particular , this latter feature is capable of fascinate the trend fluctuations in the sentiment curve. While the proposed model is passing general and may be also employed in other contexts , it has been tested on several Twitter data sets and demonstrated greater performances compared to the standard Polya urn model. Moreover , the different performances on different data sets highlight different excited sensitivities respect to a public event. keywords : Polya urn , reinforcement learning , sentiment analytic thinking , urn model , Twitter. ", "label": 1}
{"original_text": "Advances in deep neural networks (DNN) greatly bolster real-time detection of anomalous IoT data. However, IoT devices can barely afford complex DNN models due to limited computational power and energy supply. While one can offload anomaly detection tasks to the cloud, it incurs long delay and requires large bandwidth when thousands of IoT devices stream data to the cloud concurrently. In this paper, we propose an adaptive anomaly detection approach for hierarchical edge computing (HEC) systems to solve this problem. Specifically, we first construct three anomaly detection DNN models of increasing complexity, and associate them with the three layers of HEC from bottom to top, i.e., IoT devices, edge servers, and cloud. Then, we design an adaptive scheme to select one of the models based on the contextual information extracted from input data, to perform anomaly detection. The selection is formulated as a contextual bandit problem and is characterized by a single-step Markov decision process, with an objective of achieving high detection accuracy and low detection delay simultaneously. We evaluate our proposed approach using a real IoT dataset, and demonstrate that it reduces detection delay by 84 while maintaining almost the same accuracy as compared to offloading detection tasks to the cloud. In addition, our evaluation also shows that it outperforms other baseline schemes.", "text_perturb": "Advances in bass neural networks ( DNN ) greatly bolster real-time detection of anomalous IoT data. However , IoT devices can hardly afford complex DNN models due to limited computational power and energy supply. While one can offload anomaly detection tasks to the swarm , it incurs long delay and requires large bandwidth when thousands of IoT devices stream data to the swarm concurrently. In this paper , we propose an adaptive anomaly detection approach for hierarchical border computing ( HEC ) systems to solve this problem. Specifically , we first construct three anomaly spying DNN models of increasing complexity , and associate them with the three layers of HEC from bottom to top , i. east. , IoT devices , boundary servers , and cloud. Then , we design an adaptive scheme to select one of the models based on the contextual information extracted from input data , to do anomaly detection. The selection is formulated as a contextual bandit problem and is characterize by a single-step Markov decision process , with an objective of achieving high detection accuracy and low detection delay simultaneously. We evaluate our proposed approach using a real IoT dataset , and demonstrate that it bring down detection delay by 84 while maintaining almost the same accuracy as compared to offloading detection tasks to the cloud. In addition , our evaluation as well shows that it outperforms other baseline schemes. ", "label": 1}
{"original_text": "In human-in-the-loop machine learning, the user provides information beyond that in the training data. Many algorithms and user interfaces have been designed to optimize and facilitate this human-machine interaction; however, fewer studies have addressed the potential defects the designs can cause. Effective interaction often requires exposing the user to the training data or its statistics. The design of the system is then critical, as this can lead to double use of data and overfitting, if the user reinforces noisy patterns in the data. We propose a user modelling methodology, by assuming simple rational behaviour, to correct the problem. We show, in a user study with 48 participants, that the method improves predictive performance in a sparse linear regression sentiment analysis task, where graded user knowledge on feature relevance is elicited. We believe that the key idea of inferring user knowledge with probabilistic user models has general applicability in guarding against overfitting and improving interactive machine learning.", "text_perturb": "In human-in-the-loop machine learning , the user bring home the bacon information beyond that in the training data. Many algorithms and user interfaces have been designed to optimize and facilitate this human-machine interaction ; however , fewer studies have deal the potential defects the designs can cause. Effective interaction often expect exposing the user to the training data or its statistics. The design of the system is then critical , as this can lead to double use of data and overfitting , if the user reward noisy patterns in the data. We propose a user modelling methodology , by assuming simple rational deportment , to correct the problem. We show , in a user study with 48 participants , that the method improves predictive performance in a sparse linear regression toward the mean sentiment analysis task , where graded user knowledge on feature relevance is elicited. We believe that the key idea of inferring user knowledge with probabilistic user models has general applicability in guarding against overfitting and improving interactive simple machine learning. ", "label": 1}
{"original_text": "We propose a novel regularization-based continual learning method, dubbed as Adaptive Group Sparsity based Continual Learning (AGS-CL), using two group sparsity-based penalties. Our method selectively employs the two penalties when learning each node based its the importance, which is adaptively updated after learning each new task. By utilizing the proximal gradient descent method for learning, the exact sparsity and freezing of the model is guaranteed, and thus, the learner can explicitly control the model capacity as the learning continues. Furthermore, as a critical detail, we re-initialize the weights associated with unimportant nodes after learning each task in order to prevent the negative transfer that causes the catastrophic forgetting and facilitate efficient learning of new tasks. Throughout the extensive experimental results, we show that our AGS-CL uses much less additional memory space for storing the regularization parameters, and it significantly outperforms several state-of-the-art baselines on representative continual learning benchmarks for both supervised and reinforcement learning tasks.", "text_perturb": "We propose a novel regularization-based continual learning method acting , dubbed as Adaptive Group Sparsity based Continual Learning ( AGS-CL ) , using two group sparsity-based penalties. Our method selectively employs the two penalties when learning each thickening based its the importance , which is adaptively updated after learning each new task. By utilizing the proximal gradient descent method for learning , the exact sparsity and freezing of the model is guaranteed , and thus , the learner terminate explicitly control the model capacity as the learning continues. Furthermore , as a critical detail , we re-initialize the weights link up with unimportant nodes after learning each task in order to prevent the negative transfer that causes the catastrophic forgetting and facilitate efficient learning of new tasks. Throughout the extensive experimental results , we show that our AGS-CL uses much less additional memory space for storing the regularization parameters , and it significantly outperforms several state-of-the-art baselines on representative continual erudition benchmarks for both supervised and reinforcement erudition tasks. ", "label": 1}
{"original_text": "We present a full reference, perceptual image metric based on VGG-16, an artificial neural network trained on object classification. We fit the metric to a new database based on 140k unique images annotated with ground truth by human raters who received minimal instruction. The resulting metric shows competitive performance on TID 2013, a database widely used to assess image quality assessments methods. More interestingly, it shows strong responses to objects potentially carrying semantic relevance such as faces and text, which we demonstrate using a visualization technique and ablation experiments. In effect, the metric appears to model a higher influence of semantic context on judgments, which we observe particularly in untrained raters. As the vast majority of users of image processing systems are unfamiliar with Image Quality Assessment (IQA) tasks, these findings may have significant impact on real-world applications of perceptual metrics.", "text_perturb": "We show a full reference , perceptual image metric based on VGG-16 , an artificial neural network trained on object classification. We fit the metric to a new database ground on 140k unique images annotated with ground truth by human raters who received minimal instruction. The resulting metric shows competitive performance on TID 2013 , a database widely use to assess image quality assessments methods. More interestingly , it present strong responses to objects potentially carrying semantic relevance such as faces and text , which we demonstrate using a visualization technique and ablation experiments. In effect , the metric appears to model a higher influence of semantic context on judgments , which we observe specially in untrained raters. As the vast absolute majority of users of image processing systems are unfamiliar with Image Quality Assessment ( IQA ) tasks , these findings may have significant impact on real-world applications of perceptual metrics. ", "label": 1}
{"original_text": "In this paper, we study the waveform design problem for a single-input single-output (SISO) radio-frequency (RF) wireless power transfer (WPT) system in frequency-selective channels. First, based on the actual non-linear current-voltage model of the diode at the energy receiver, we derive a semi-closed-form expression for the deliverable DC voltage in terms of the incident RF signal and hence obtain the average harvested power. Next, by adopting a multisine waveform structure for the transmit signal of the energy transmitter, we jointly design the multisine signal amplitudes and phases over all frequency tones according to the channel state information (CSI) to maximize the deliverable DC voltage or harvested power. Although our formulated problem is non-convex and difficult to solve, we propose two suboptimal solutions to it, based on the frequency-domain maximal ratio transmission (MRT) principle and the sequential convex optimization (SCP) technique, respectively. Using various simulations, the performance gain of our solutions over the existing waveform designs is shown.", "text_perturb": "In this paper , we analyse the waveform design problem for a single-input single-output ( SISO ) radio-frequency ( RF ) wireless power transfer ( WPT ) system in frequency-selective channels. First , based on the actual non-linear current-voltage model of the diode at the energy receiver , we deduct a semi-closed-form expression for the deliverable DC voltage in terms of the incident RF signal and hence obtain the average harvested power. Next , by adopting a multisine waveform bodily structure for the transmit signal of the energy transmitter , we jointly design the multisine signal amplitudes and phases over all frequency tones according to the channel state information ( CSI ) to maximize the deliverable DC voltage or harvested power. Although our contrive problem is non-convex and difficult to solve , we propose two suboptimal solutions to it , based on the frequency-domain maximal ratio transmission ( MRT ) principle and the sequential convex optimization ( SCP ) technique , respectively. employ various simulations , the performance gain of our solutions over the existing waveform designs is shown. ", "label": 1}
{"original_text": "In this paper, we report the results of our participation in the TREC-COVID challenge. To meet the challenge of building a search engine for rapidly evolving biomedical collection, we propose a simple yet effective weighted hierarchical rank fusion approach, that ensembles together 102 runs from (a) lexical and semantic retrieval systems, (b) pre-trained and fine-tuned BERT rankers, and (c) relevance feedback runs. Our ablation studies demonstrate the contributions of each of these systems to the overall ensemble. The submitted ensemble runs achieved state-of-the-art performance in rounds 4 and 5 of the TREC-COVID challenge.", "text_perturb": "In this report , we report the results of our participation in the TREC-COVID challenge. To meet the challenge of building a search engine for rapidly evolving biomedical collection , we propose a simple yet effective weighted hierarchical rank fusion access , that ensembles together 102 runs from ( a ) lexical and semantic retrieval systems , ( b ) pre-trained and fine-tuned BERT rankers , and ( c ) relevance feedback runs. Our ablation discipline demonstrate the contributions of each of these systems to the overall ensemble. The submitted ensemble outpouring achieved state-of-the-art performance in rounds 4 and 5 of the TREC-COVID challenge. ", "label": 1}
{"original_text": "It was recently shown that complex cepstrum can be effectively used for glottal flow estimation by separating the causal and anticausal components of speech. In order to guarantee a correct estimation, some constraints on the window have been derived. Among these, the window has to be synchronized on a Glottal Closure Instant. This paper proposes an extension of the complex cepstrum-based decomposition by incorporating a chirp analysis. The resulting method is shown to give a reliable estimation of the glottal flow wherever the window is located. This technique is then suited for its integration in usual speech processing systems, which generally operate in an asynchronous way. Besides its potential for automatic voice quality analysis is highlighted.", "text_perturb": "It was recently shown that complex cepstrum can be efficaciously used for glottal flow estimation by separating the causal and anticausal components of speech. In order to guarantee a correct estimation , some restraint on the window have been derived. Among these , the window has to be synchronized on a Glottal Closure instant. This paper proposes an extension of the complex cepstrum-based decomposition by incorporating a chirp psychoanalysis. The resulting method is shown to give a reliable estimation of the glottal flowing wherever the window is located. This technique is and so suited for its integration in usual speech processing systems , which generally operate in an asynchronous way. Besides its potential for automatonlike voice quality analysis is highlighted. ", "label": 1}
{"original_text": "In this paper we present a novel rule-based approach for Runtime Verification of FLTL properties over finite but expanding traces. Our system exploits Horn clauses in implication form and relies on a forward chaining-based monitoring algorithm. This approach avoids the branching structure and exponential complexity typical of tableaux-based formulations, creating monitors with a single state and a fixed number of rules. This allows for a fast and scalable tool for Runtime Verification: we present the technical details together with a working implementation.", "text_perturb": "In this paper we present a novel rule-based approach for Runtime Verification of FLTL dimension over finite but expanding traces. Our system exploits automobile horn clauses in implication form and relies on a forward chaining-based monitoring algorithm. This approach avoids the branching structure and exponential complexity typical of tableaux-based formulations , creating monitors with a single state and a fixed number of prescript. This tolerate for a fast and scalable tool for Runtime Verification : we present the technical details together with a working implementation. ", "label": 1}
{"original_text": "In cryptocurrencies, transaction fees are typically exclusively paid in the native platform currency. This restriction causes a wide range of challenges, such as deteriorated user experience, mandatory rent payments by decentralized applications, and blockchain community rivalries (e.g., coinism). Ideally, in a truly permissionless blockchain, transaction fees should be payable in any other cryptocurrency via so-called metatransactions. In this paper, we formalize metatransactions, review existing ideas, and describe novel metatransaction design approaches. Under the assumption of sufficient market liquidity, we argue that metatransactions do not lower the security of cryptocurrency platforms. However, without changing the underlying blockchain, metatransaction designs typically increase transaction costs and reduce the blockchain transaction throughput.", "text_perturb": "In cryptocurrencies , transaction fees are typically exclusively paid in the native political platform currency. This confinement causes a wide range of challenges , such as deteriorated user experience , mandatory rent payments by decentralized applications , and blockchain community rivalries ( e. gigabyte. , coinism ). Ideally , in a truly permissionless blockchain , transaction fees should be payable in any former cryptocurrency via so-called metatransactions. In this paper , we formalize metatransactions , review existing ideas , and key novel metatransaction design approaches. Under the assumption of sufficient market liquidity , we argue that metatransactions do not lower the security department of cryptocurrency platforms. However , without changing the underlying blockchain , metatransaction designs typically increase dealings costs and reduce the blockchain dealings throughput. ", "label": 1}
{"original_text": "Anomaly detection is a challenging problem in intelligent video surveillance. Most existing methods are computation-consuming, which cannot satisfy the real-time requirement. In this paper, we propose a real-time anomaly detection framework with low computational complexity and high efficiency. A new feature, named Histogram of Magnitude Optical Flow (HMOF), is proposed to capture the motion of video patches. Compared with existing feature descriptors, HMOF is more sensitive to motion magnitude and more efficient to distinguish anomaly information. The HMOF features are computed for foreground patches, and are reconstructed by the auto-encoder for better clustering. Then, we use Gaussian Mixture Model (GMM) Classifiers to distinguish anomalies from normal activities in videos. Experimental results show that our framework outperforms state-of-the-art methods, and can reliably detect anomalies in real-time.", "text_perturb": "Anomaly detection is a gainsay problem in intelligent video surveillance. Most existing methods are computation-consuming , which can not satisfy the real-time requisite. In this paper , we propose a real time anomaly detection framework with low computational complexity and high efficiency. A new feature , named histogram of Magnitude Optical Flow ( HMOF ) , is proposed to capture the motion of video patches. Compared with exist feature descriptors , HMOF is more sensitive to motion magnitude and more efficient to distinguish anomaly information. The HMOF features are computed for foreground patches , and are reconstructed by the auto-encoder for better clump. Then , we use gaussian Mixture Model ( GMM ) Classifiers to distinguish anomalies from normal activities in videos. Experimental upshot show that our framework outperforms state-of-the-art methods , and can reliably detect anomalies in real-time. ", "label": 1}
{"original_text": "In this paper we provide nearly linear time algorithms for several problems closely associated with the classic Perron-Frobenius theorem, including computing Perron vectors, i.e. entrywise non-negative eigenvectors of non-negative matrices, and solving linear systems in asymmetric M-matrices, a generalization of Laplacian systems. The running times of our algorithms depend nearly linearly on the input size and polylogarithmically on the desired accuracy and problem condition number. Leveraging these results we also provide improved running times for a broader range of problems including computing random walk-based graph kernels, computing Katz centrality, and more. The running times of our algorithms improve upon previously known results which either depended polynomially on the condition number of the problem, required quadratic time, or only applied to special cases. We obtain these results by providing new iterative methods for reducing these problems to solving linear systems in Row-Column Diagonally Dominant (RCDD) matrices. Our methods are related to the classic shift-and-invert preconditioning technique for eigenvector computation and constitute the first alternative to the result in Cohen et al. (2016) for reducing stationary distribution computation and solving directed Laplacian systems to solving RCDD systems.", "text_perturb": "In this paper we provide nearly linear time algorithms for several problem closely associated with the classic Perron-Frobenius theorem , including computing Perron vectors , i. east. entrywise non-negative eigenvectors of non-negative matrices , and solving additive systems in asymmetric M-matrices , a generalization of Laplacian systems. The running times of our algorithms depend nearly linearly on the input size and polylogarithmically on the desired truth and problem condition number. Leveraging these results we also provide improved running times for a broader range of problems including figure random walk-based graph kernels , figure Katz centrality , and more. The running times of our algorithms improve upon previously known results which either depended polynomially on the condition number of the trouble , required quadratic time , or only applied to special cases. We find these results by providing new iterative methods for reducing these problems to solving linear systems in Row-Column Diagonally Dominant ( RCDD ) matrices. Our methods are related to the classic shift-and-invert preconditioning proficiency for eigenvector computation and constitute the first alternative to the result in Cohen et al. ( 2016 ) for reducing stationary distribution computation and solving directed Laplacian system to solving RCDD system. ", "label": 1}
{"original_text": "It is well-established that many iterative sparse reconstruction algorithms can be unrolled to yield a learnable neural network for improved empirical performance. A prime example is learned ISTA (LISTA) where weights, step sizes and thresholds are learned from training data. Recently, Analytic LISTA (ALISTA) has been introduced, combining the strong empirical performance of a fully learned approach like LISTA, while retaining theoretical guarantees of classical compressed sensing algorithms and significantly reducing the number of parameters to learn. However, these parameters are trained to work in expectation, often leading to suboptimal reconstruction of individual targets. In this work we therefore introduce Neurally Augmented ALISTA, in which an LSTM network is used to compute step sizes and thresholds individually for each target vector during reconstruction. This adaptive approach is theoretically motivated by revisiting the recovery guarantees of ALISTA. We show that our approach further improves empirical performance in sparse reconstruction, in particular outperforming existing algorithms by an increasing margin as the compression ratio becomes more challenging.", "text_perturb": "It is well-established that many iterative sparse reconstruction algorithms can be unfurl to yield a learnable neural network for improved empirical performance. A prime example is learned ISTA ( LISTA ) where weights , step size of it and thresholds are learned from training data. Recently , Analytic LISTA ( ALISTA ) has been introduced , combining the strong empirical performance of a fully learned approach like LISTA , while retaining theoretical guarantees of classical compressed sensing algorithm and significantly reducing the number of parameters to learn. However , these parameters are trained to work in anticipation , often leading to suboptimal reconstruction of individual targets. In this work we therefore introduce Neurally Augmented ALISTA , in which an LSTM network is used to compute step sizes and limen individually for each target vector during reconstruction. This adaptive approach is theoretically motivated by revisiting the retrieval guarantees of ALISTA. We show that our approach further improves empirical performance in sparse reconstruction , in particular outstrip existing algorithms by an increasing margin as the compression ratio becomes more challenging. ", "label": 1}
{"original_text": "We show how Markov mixed membership models (MMMM) can be used to predict the degradation of assets. We model the degradation path of individual assets, to predict overall failure rates. Instead of a separate distribution for each hidden state, we use hierarchical mixtures of distributions in the exponential family. In our approach the observation distribution of the states is a finite mixture distribution of a small set of (simpler) distributions shared across all states. Using tied-mixture observation distributions offers several advantages. The mixtures act as a regularization for typically very sparse problems, and they reduce the computational effort for the learning algorithm since there are fewer distributions to be found. Using shared mixtures enables sharing of statistical strength between the Markov states and thus transfer learning. We determine for individual assets the trade-off between the risk of failure and extended operating hours by combining a MMMM with a partially observable Markov decision process (POMDP) to dynamically optimize the policy for when and how to maintain the asset.", "text_perturb": "We show how Markov mixed membership models ( MMMM ) can be used to predict the degradation of plus. We sit the degradation path of individual assets , to predict overall failure rates. Instead of a separate distribution for each out of sight state , we use hierarchical mixtures of distributions in the exponential family. In our approach the observation distribution of the states is a finite mixture distribution of a diminished set of ( simpler ) distributions shared across all states. Using tied-mixture observation distributions offers several advantages. The mixtures act as a regularization for typically very sparse problems , and they reduce the computational effort for the learnedness algorithm since there are fewer distributions to be found. Using shared mixtures enables sharing of statistical strength between the Markov states and thus transfer learn. We determine for individual assets the trade-off between the risk of loser and extended operating hours by combining a MMMM with a partially observable Markov decision process ( POMDP ) to dynamically optimize the policy for when and how to maintain the asset. ", "label": 1}
{"original_text": "Path checking, the special case of the model checking problem where the model under consideration is a single path, plays an important role in monitoring, testing, and verification. We prove that for linear-time temporal logic (LTL), path checking can be efficiently parallelized. In addition to the core logic, we consider the extensions of LTL with bounded-future (BLTL) and past-time (LTLPast) operators. Even though both extensions improve the succinctness of the logic exponentially, path checking remains efficiently parallelizable: Our algorithm for LTL, LTLPast, and BLTLPast is in AC 1 (logDCFL) NC.", "text_perturb": "Path checking , the special case of the model checking job where the model under consideration is a single path , plays an important role in monitoring , testing , and verification. We prove that for linear-time temporal logic ( LTL ) , path checking tin be efficiently parallelized. In addition to the core logic , we consider the annex of LTL with bounded-future ( BLTL ) and past-time ( LTLPast ) operators. Even though both extensions improve the succinctness of the logic exponentially , path checking remains efficiently parallelizable : Our algorithm for LTL , LTLPast , and BLTLPast is in alternating current 1 ( logDCFL ) NC. ", "label": 1}
{"original_text": "We consider the property of unique parallel decomposition modulo branching and weak bisimilarity. First, we show that infinite behaviours may fail to have parallel decompositions at all. Then, we prove that totally normed behaviours always have parallel decompositions, but that these are not necessarily unique. Finally, we establish that weakly bounded behaviours have unique parallel decompositions. We derive the latter result from a general theorem about unique decompositions in partial commutative monoids.", "text_perturb": "We consider the prop of unique parallel decomposition modulo branching and weak bisimilarity. firstly , we show that infinite behaviours may fail to have parallel decompositions at all. Then , we prove that totally normed behaviours always have parallel decompositions , but that these be not necessarily unique. Finally , we establish that weakly bounded behaviours have unparalleled parallel decompositions. We derive the latter result from a general theorem about unique decay in partial commutative monoids. ", "label": 1}
{"original_text": "Context:The volume of data generated by astronomical surveys is growing rapidly. Traditional analysis techniques in spectroscopy either demand intensive human interaction or are computationally expensive. In this scenario, machine learning, and unsupervised clustering algorithms in particular, offer interesting alternatives. The Apache Point Observatory Galactic Evolution Experiment (APOGEE) offers a vast data set of near-infrared stellar spectra, which is perfect for testing such alternatives. Aims:Our research applies an unsupervised classification scheme based on K -means to the massive APOGEE data set. We explore whether the data are amenable to classification into discrete classes. Methods:We apply the K -means algorithm to 153,847 high resolution spectra (R 22, 500). We discuss the main virtues and weaknesses of the algorithm, as well as our choice of parameters. Results:We show that a classification based on normalised spectra captures the variations in stellar atmospheric parameters, chemical abundances, and rotational velocity, among other factors. The algorithm is able to separate the bulge and halo populations, and distinguish dwarfs, sub-giants, RC, and RGB stars. However, a discrete classification in flux space does not result in a neat organisation in the parameters' space. Furthermore, the lack of obvious groups in flux space causes the results to be fairly sensitive to the initialisation, and disrupts the efficiency of commonly-used methods to select the optimal number of clusters. Our classification is publicly available, including extensive online material associated with the APOGEE Data Release 12 (DR12). Conclusions:Our description of the APOGEE database can help greatly with the identification of specific types of targets for various applications. We find a lack of obvious groups in flux space, and identify limitations of the K -means algorithm in dealing with this kind of data.", "text_perturb": "Context : The volume of data generated by astronomical view is growing rapidly. Traditional analysis techniques in spectroscopy either need intensive human interaction or are computationally expensive. In this scenario , car learning , and unsupervised clustering algorithms in particular , offer interesting alternatives. The Apache Point Observatory Galactic Evolution experimentation ( APOGEE ) offers a vast data set of near-infrared stellar spectra , which is perfect for testing such alternatives. Aims : Our inquiry applies an unsupervised classification scheme based on K -means to the massive APOGEE data set. We explore whether the data are amenable to classification into discrete form. Methods : We apply the K -means algorithm to 153,847 gamey resolution spectra ( R 22 , 500 ). We discuss the main virtue and weaknesses of the algorithm , as well as our choice of parameters. final result : We show that a classification based on normalised spectra captures the variations in stellar atmospheric parameters , chemical abundances , and rotational velocity , among other factors. The algorithm is able to separate the bulge and doughnut populations , and distinguish dwarfs , sub-giants , RC , and RGB stars. However , a discrete classification in flux space does not result in a neat organization in the parameters ' space. Furthermore , the lack of obvious groups in flux space causes the results to be fairly sensitive to the initialization , and disrupts the efficiency of commonly-used methods to select the optimal number of clusters. Our classification is publicly available , including extensive online material associated with the apogee Data Release 12 ( DR12 ). Conclusions : Our description of the APOGEE database terminate help greatly with the identification of specific types of targets for various applications. We find a lack of obvious groups in flux space , and identify restriction of the K -means algorithm in dealing with this kind of data. ", "label": 1}
{"original_text": "This paper presents models for transforming standard reversible circuits into Linear Nearest Neighbor (LNN) architecture without inserting SWAP gates. Templates to optimize the transformed LNN circuits are proposed. All minimal LNN circuits for all 3-qubit functions have been generated to serve as benchmarks to evaluate heuristic optimization algorithms. The minimal results generated are compared with optimized LNN circuits obtained from the post synthesis algorithm - template matching with LNN templates. Experiments show that the suggested synthesis flow significantly improves the quantum cost of circuits.", "text_perturb": "This paper presents models for transforming standard reversible circle into Linear Nearest Neighbor ( LNN ) architecture without inserting SWAP gates. Templates to optimise the transformed LNN circuits are proposed. All minimal LNN circuits for all 3-qubit affair have been generated to serve as benchmarks to evaluate heuristic optimization algorithms. The minimal results generated are compared with optimized LNN circuits obtained from the post deductive reasoning algorithm - template matching with LNN templates. Experiments show that the suggested deductive reasoning flow significantly improves the quantum cost of circuits. ", "label": 1}
{"original_text": "We extend the Deep Image Prior (DIP) framework to one-dimensional signals. DIP is using a randomly initialized convolutional neural network (CNN) to solve linear inverse problems by optimizing over weights to fit the observed measurements. Our main finding is that properly tuned one-dimensional convolutional architectures provide an excellent Deep Image Prior for various types of temporal signals including audio, biological signals, and sensor measurements. We show that our network can be used in a variety of recovery tasks including missing value imputation, blind denoising, and compressed sensing from random Gaussian projections. The key challenge is how to avoid overfitting by carefully tuning early stopping, total variation, and weight decay regularization. Our method requires up to 4 times fewer measurements than Lasso and outperforms NLM-VAMP for random Gaussian measurements on audio signals, has similar imputation performance to a Kalman state-space model on a variety of data, and outperforms wavelet filtering in removing additive noise from air-quality sensor readings.", "text_perturb": "We exsert the Deep Image Prior ( DIP ) framework to one-dimensional signals. DIP is using a randomly initialized convolutional neural network ( CNN ) to solve linear inverse problems by optimizing over weights to fit the ascertained measurements. Our main finding is that properly tuned one-dimensional convolutional architectures provide an excellent Deep Image Prior for various types of temporal signals including audio , biological signals , and sensing element measurements. We show that our network can be used in a variety of recovery tasks including missing note value imputation , blind denoising , and compressed sensing from random Gaussian projections. The key challenge is how to avoid overfitting by carefully tuning early stopping , total variant , and weight decay regularization. Our method requires up to 4 times fewer measurements than Lasso and outperforms NLM-VAMP for random Gaussian measurements on audio signals , suffer similar imputation performance to a Kalman state-space model on a variety of data , and outperforms wavelet filtering in removing additive noise from air-quality sensor readings. ", "label": 1}
{"original_text": "At the core of any inference procedure in deep neural networks are dot product operations, which are the component that require the highest computational resources. For instance, deep neural networks such as VGG-16 require up to 15 giga-operations in order to perform the dot products present in a single forward pass, which results in significant energy consumption and therefore limit their use in resource-limited environments, e.g., on embedded devices or smartphones. A common approach to reduce the cost of inference is to reduce its memory complexity by lowering the entropy of the weight matrices of the neural network, e.g., by pruning and quantizing their elements. However, the quantized weight matrices are then usually represented either by a dense or sparse matrix storage format, whose associated dot product complexity is not bounded by the entropy of the matrix. This means that the associated inference complexity ultimately depends on the implicit statistical assumptions that these matrix representations make about the weight distribution, which can be in many cases suboptimal. In this paper we address this issue and present new efficient representations for matrices with low entropy statistics. These new matrix formats have the novel property that their memory and algorithmic complexity are implicitly bounded by the entropy of the matrix, consequently implying that they are guaranteed to become more efficient as the entropy of the matrix is being reduced. In our experiments we show that performing the dot product under these new matrix formats can indeed be more energy and time efficient under practically relevant assumptions. For instance, we are able to attain up to x42 compression ratios, x5 speed ups and x90 energy savings when we convert in a lossless manner the weight matrices of state-of-the-art networks such as AlexNet, VGG-16, ResNet152 and DenseNet into the new matrix formats and benchmark their respective dot product operation.", "text_perturb": "At the core of any inference procedure in deep neural networks follow dot product operations , which follow the component that require the highest computational resources. For instance , deep neural networks such as VGG-16 require up to 15 giga-operations in order to perform the dot products present in a single forward pass , which results in significant energy ingestion and therefore limit their use in resource-limited environments , e. universal gravitational constant. , on embedded twist or smartphones. A common approach to reduce the cost of inference is to reduce its store complexity by lowering the entropy of the weight matrices of the neural network , e. yard. , by pruning and quantizing their factor. However , the quantized weight matrices are and then usually represented either by a dense or sparse matrix storage format , whose associated dot product complexity is not bounded by the entropy of the matrix. This means that the associated inference complexity ultimately depends on the unquestioning statistical assumptions that these matrix representations make about the weight distribution , which can be in many cases suboptimal. In this paper we address this issue and present new efficient representations for matrices with dispirited entropy statistics. These new matrix formats have the novel property that their memory and algorithmic complexity are implicitly bounded by the entropy of the matrix , consequently inculpate that they are guaranteed to become more efficient as the entropy of the matrix is being reduced. In our experiments we show that performing the dot product under these new matrix formats can indeed be more energy and sentence efficient under practically relevant assumptions. For instance , we follow able to attain up to x42 compression ratios , x5 speed ups and x90 energy savings when we convert in a lossless manner the weight matrices of state-of-the-art networks such as AlexNet , VGG-16 , ResNet152 and DenseNet into the new matrix formats and benchmark their respective dot product operation. ", "label": 1}
{"original_text": "This chapter provides a comprehensive survey of the researches and motivations for hardware implementation of reservoir computing (RC) on neuromorphic electronic systems. Due to its computational efficiency and the fact that training amounts to a simple linear regression, both spiking and non-spiking implementations of reservoir computing on neuromorphic hardware have been developed. Here, a review of these experimental studies is provided to illustrate the progress in this area and to address the technical challenges which arise from this specific hardware implementation. Moreover, to deal with challenges of computation on such unconventional substrates, several lines of potential solutions are presented based on advances in other computational approaches in machine learning.", "text_perturb": "This chapter provides a comprehensive sketch of the researches and motivations for hardware implementation of reservoir computing ( RC ) on neuromorphic electronic systems. Due to its computational efficiency and the fact that training amounts to a simple linear retroversion , both spiking and non-spiking implementations of reservoir computing on neuromorphic hardware have been developed. Here , a review of these experimental studies is supply to illustrate the progress in this area and to address the technical challenges which arise from this specific hardware implementation. Moreover , to deal with challenges of computation on such improper substrates , several lines of potential solutions are presented based on advances in other computational approaches in machine learning. ", "label": 1}
{"original_text": "Existing source-code-generating tools such as Lex and Yacc suffer from practical inconveniences because they use disembodied code to implement actions. To prevent this problem, such tools could generate closed functors that are then instantiated by the programmer with appropriate action code. This results in all code being type checked in its appropriate context, and it assists the type checker in localizing errors correctly. We have implemented a lexer generator and parser generator based on this technique for Standard ML, OCaml, and Haskell.", "text_perturb": "Existing source-code-generating tool such as Lex and Yacc suffer from practical inconveniences because they use disembodied code to implement actions. To keep this problem , such tools could generate closed functors that are then instantiated by the programmer with appropriate action code. This effect in all code being type checked in its appropriate context , and it assists the type checker in localizing errors correctly. We have implemented a lexer generator and parser generator based on this technique for Standard mil , OCaml , and Haskell. ", "label": 1}
{"original_text": "Crowds can often make better decisions than individuals or small groups of experts by leveraging their ability to aggregate diverse information. Question answering sites, such as Stack Exchange, rely on the \"wisdom of crowds\" effect to identify the best answers to questions asked by users. We analyze data from 250 communities on the Stack Exchange network to pinpoint factors affecting which answers are chosen as the best answers. Our results suggest that, rather than evaluate all available answers to a question, users rely on simple cognitive heuristics to choose an answer to vote for or accept. These cognitive heuristics are linked to an answer's salience, such as the order in which it is listed and how much screen space it occupies. While askers appear to depend more on heuristics, compared to voting users, when choosing an answer to accept as the most helpful one, voters use acceptance itself as a heuristic: they are more likely to choose the answer after it is accepted than before that very same answer was accepted. These heuristics become more important in explaining and predicting behavior as the number of available answers increases. Our findings suggest that crowd judgments may become less reliable as the number of answers grow.", "text_perturb": "crowd can often make better decisions than individuals or small groups of experts by leveraging their ability to aggregate diverse information. Question answering sites , such as raft Exchange , rely on the `` wisdom of crowds '' effect to identify the best answers to questions asked by users. We analyze data from 250 communities on the mountain Exchange network to pinpoint factors affecting which answers are chosen as the best answers. Our results suggest that , rather than evaluate all useable answers to a question , users rely on simple cognitive heuristics to choose an answer to vote for or accept. These cognitive heuristics are linked to an answer 's salience , such as the order in which it is listed and how much screen infinite it occupies. While askers appear to depend more on heuristics , compared to voting substance abuser , when choosing an answer to accept as the most helpful one , voters use acceptance itself as a heuristic : they are more likely to choose the answer after it is accepted than before that very same answer was accepted. These heuristics become more important in explaining and predicting behavior as the number of available reply increases. Our findings suggest that crowd judgments may become less dependable as the number of answers grow. ", "label": 1}
{"original_text": "In the planar range skyline reporting problem, the goal is to store a set P of n 2D points in a structure such that, given a query rectangle Q x [ a 1, a 2 ] [ b 1, b 2 ], the maxima (a.k.a. skyline) of P Q can be reported efficiently. The query is 3-sided if an edge of Q is grounded, giving rise to two variants: top-open (b 2) and left-open (a 1 (symmetrically bottom-open and right-open) queries. This paper presents comprehensive results in external memory under the O (n B) space budget (B is the block size), covering both the static and dynamic settings: 1st item For static P, we give structures that answer top-open queries in O (log B n k B), O (log log B U k B), and O (1 k B) IOs when the universe is R 2, a x U U grid, and a rank space grid [ O (n) ] 2, respectively (where k is the number of reported points). The query complexity is optimal in all cases. 2nd item We show that the left-open case is harder, such that any linear-size structure must incur O n B) k B) IOs to answer a query. In fact, this case turns out to be just as difficult as the general 4-sided queries, for which we provide a static structure with the optimal query cost O n B) k B). 3rd item We present a dynamic structure that supports top-open queries in O (log 2 B (n B) k B - 1) IOs, and updates in O (log 2 B (n B IOs, for any satisfying 0 1. This result also leads to a dynamic structure for 4-sided queries with optimal query cost O n B) k B), and amortized update cost O (log (n B. As a contribution of independent interest, we propose an IO-efficient version of the fundamental structure priority queue with attrition (PQA). Our PQA supports FindMin, DeleteMin, and InsertAndAttrite all in O (1) worst case IOs, and O (1 B) amortized IOs per operation. Furthermore, it allows the additional CatenateAndAttrite operation that merges two PQAs in O (1) worst case and O (1 B) amortized IOs. The last operation is a non-trivial extension to the classic PQA of Sundar, even in internal memory.", "text_perturb": "In the planar range sensible horizon reporting problem , the goal is to store a set P of n 2D points in a structure such that , given a query rectangle Q x [ a 1 , a 2 ] [ b 1 , b 2 ] , the maxima ( a. one thousand. a. skyline ) of P Q tin be reported efficiently. The query follow 3-sided if an edge of Q follow grounded , giving rise to two variants : top-open ( b 2 ) and left-open ( a 1 ( symmetrically bottom-open and right-open ) queries. This paper presents comprehensive results in external memory under the O ( n B ) space budget ( B is the block size ) , covering both the static and dynamic settings : 1st item For static P , we give structures that answer top-open queries in O ( log B n k B ) , O ( log log B u k B ) , and O ( 1 k B ) IOs when the universe is R 2 , a x u u grid , and a rank space grid [ O ( n ) ] 2 , respectively ( where k is the number of reported points ). The interrogation complexity is optimal in all cases. 2nd item We show that the left-open case is knockout , such that any linear-size structure must incur O n B ) k B ) IOs to answer a query. In fact , this case turns out to be just as difficult as the general 4-sided queries , for which we provide a stable structure with the optimal query cost O n B ) k B ). 3rd point We present a dynamic structure that supports top-open queries in O ( log 2 B ( n B ) k B - 1 ) IOs , and updates in O ( log 2 B ( n B IOs , for any satisfying 0 1. This result too leads to a dynamic structure for 4-sided queries with optimal query cost O n B ) k B ) , and amortized update cost O ( log ( n B. As a contribution of independent interest , we advise an IO-efficient version of the fundamental structure priority queue with attrition ( PQA ). Our PQA supports FindMin , DeleteMin , and InsertAndAttrite all in O ( 1 ) defective case IOs , and O ( 1 B ) amortized IOs per operation. moreover , it allows the additional CatenateAndAttrite operation that merges two PQAs in O ( 1 ) worst case and O ( 1 B ) amortized IOs. The last operation is a non-trivial filename extension to the classic PQA of Sundar , even in internal memory. ", "label": 1}
{"original_text": "Convolutional Neural Networks (CNNs) have been successfully applied for relative camera pose estimation from labeled image-pair data, without requiring any hand-engineered features, camera intrinsic parameters or depth information. The trained CNN can be utilized for performing pose based visual servo control (PBVS). One of the ways to improve the quality of visual servo output is to improve the accuracy of the CNN for estimating the relative pose estimation. With a given state-of-the-art CNN for relative pose regression, how can we achieve an improved performance for visual servo control? In this paper, we explore switching of CNNs to improve the precision of visual servo control. The idea of switching a CNN is due to the fact that the dataset for training a relative camera pose regressor for visual servo control must contain variations in relative pose ranging from a very small scale to eventually a larger scale. We found that, training two different instances of the CNN, one for large-scale-displacements (LSD) and another for small-scale-displacements (SSD) and switching them during the visual servo execution yields better results than training a single CNN with the combined LSDSSD data. However, it causes extra storage overhead and switching decision is taken by a manually set threshold which may not be optimal for all the scenes. To eliminate these drawbacks, we propose an efficient switching strategy based on model agnostic meta learning (MAML) algorithm. In this, a single model is trained to learn parameters which are simultaneously good for multiple tasks, namely a binary classification for switching decision, a 6DOF pose regression for LSD data and also a 6DOF pose regression for SSD data. The proposed approach performs far better than the naive approach, while storage and run-time overheads are almost negligible.", "text_perturb": "Convolutional Neural Networks ( CNNs ) have live successfully applied for relative camera pose estimation from labeled image-pair data , without requiring any hand-engineered features , camera intrinsic parameters or depth information. The trained CNN can be apply for performing pose based visual servo control ( PBVS ). One of the ways to improve the quality of visual servo output is to improve the accuracy of the CNN for estimating the relative affectation estimation. With a make state-of-the-art CNN for relative pose regression , how can we achieve an improved performance for visual servo control ? In this paper , we explore switching of CNNs to improve the precision of visual servo control. The idea of switching a CNN is due to the fact that the dataset for training a relative camera mannerism regressor for visual servo control must contain variations in relative mannerism ranging from a very small scale to eventually a larger scale. We found that , training two different instances of the CNN , one for large-scale-displacements ( lsd ) and another for small-scale-displacements ( SSD ) and switching them during the visual servo execution yields better results than training a single CNN with the combined LSDSSD data. However , it causes extra storage overhead and switching decision is learn by a manually set threshold which may not be optimal for all the scenes. To eliminate these drawbacks , we propose an efficient switching strategy found on model agnostic meta learning ( MAML ) algorithm. In this , a single model is trained to learn parameters which are simultaneously good for multiple tasks , namely a binary classification for switching decision , a 6DOF pose infantile fixation for LSD data and also a 6DOF pose infantile fixation for SSD data. The proposed approach performs far better than the uninitiate approach , while storage and run-time overheads are almost negligible. ", "label": 1}
{"original_text": "The increase in the world's population and rising standards of living is leading to an ever-increasing number of vehicles on the roads, and with it ever-increasing difficulties in traffic management. This traffic management in transport networks can be clearly optimized by using information and communication technologies referred as Intelligent Transport Systems (ITS). This management problem is usually reformulated as finding the shortest path in a time varying random graph. In this article, an online shortest path computation using stochastic gradient descent is proposed. This routing algorithm for ITS traffic management is based on the online Frank-Wolfe approach. Our improvement enables to find a confidence interval for the shortest path, by using the stochastic gradient algorithm for approximate Bayesian inference. The theory required to understand our approach is provided, as well as the implementation details.", "text_perturb": "The increase in the world 's population and rising standards of living is leading to an ever-increasing identification number of vehicles on the roads , and with it ever-increasing difficulties in traffic management. This traffic management in transport networks can be clearly optimized by practice information and communication technologies referred as Intelligent Transport Systems ( ITS ). This management problem is usually reformulated as finding the shortest way in a time varying random graph. In this article , an online shortest path computation using stochastic slope descent is proposed. This routing algorithm for ITS traffic management be based on the online Frank-Wolfe approach. Our improvement enables to find a confidence interval for the shortest path , by employ the stochastic gradient algorithm for approximate Bayesian inference. The possibility required to understand our approach is provided , as well as the implementation details. ", "label": 1}
{"original_text": "Facial attribute analysis has received considerable attention when deep learning techniques made remarkable breakthroughs in this field over the past few years. Deep learning based facial attribute analysis consists of two basic sub-issues: facial attribute estimation (FAE), which recognizes whether facial attributes are present in given images, and facial attribute manipulation (FAM), which synthesizes or removes desired facial attributes. In this paper, we provide a comprehensive survey of deep facial attribute analysis from the perspectives of both estimation and manipulation. First, we summarize a general pipeline that deep facial attribute analysis follows, which comprises two stages: data preprocessing and model construction. Additionally, we introduce the underlying theories of this two-stage pipeline for both FAE and FAM. Second, the datasets and performance metrics commonly used in facial attribute analysis are presented. Third, we create a taxonomy of state-of-the-art methods and review deep FAE and FAM algorithms in detail. Furthermore, several additional facial attribute related issues are introduced, as well as relevant real-world applications. Finally, we discuss possible challenges and promising future research directions.", "text_perturb": "Facial attribute analysis has received considerable attention when deep learning techniques made remarkable breakthroughs in this field over the past few old age. Deep learning based facial attribute analysis consists of two basic sub-issues : facial attribute estimation ( fae ) , which recognizes whether facial attributes are present in given images , and facial attribute manipulation ( FAM ) , which synthesizes or removes desired facial attributes. In this paper , we provide a comprehensive survey of abstruse facial attribute analysis from the perspectives of both estimation and manipulation. First , we summarize a general pipeline that recondite facial attribute analysis follows , which comprises two stages : data preprocessing and model construction. Additionally , we introduce the rudimentary theories of this two-stage pipeline for both FAE and FAM. Second , the datasets and performance metrics commonly used in facial dimension analysis are presented. Third , we create a taxonomy of state-of-the-art methods and refresh deep FAE and FAM algorithms in detail. Furthermore , several additional facial attribute related issues are introduced , equally well as relevant real-world applications. eventually , we discuss possible challenges and promising future research directions. ", "label": 1}
{"original_text": "Under successive cancellation (SC) decoding, polar codes are inferior to other codes of similar blocklength in terms of frame error rate. While more sophisticated decoding algorithms such as list- or stack-decoding partially mitigate this performance loss, they suffer from an increase in complexity. In this paper, we describe a new flavor of the SC decoder, called the SC flip decoder. Our algorithm preserves the low memory requirements of the basic SC decoder and adjusts the required decoding effort to the signal quality. In the waterfall region, its average computational complexity is almost as low as that of the SC decoder.", "text_perturb": "Under successive cancellation ( SC ) decoding , polar codes are inferior to other codes of similar blocklength in terms of frame misplay rate. While more sophisticated decoding algorithmic rule such as list- or stack-decoding partially mitigate this performance loss , they suffer from an increase in complexity. In this paper , we describe a new flavor of the SC decoder , called the SC somersault decoder. Our algorithm preserves the low memory necessity of the basic SC decoder and adjusts the required decoding effort to the signal quality. In the waterfall region , its average computational complexity is almost as low as that of the security council decoder. ", "label": 1}
{"original_text": "We consider the paradigm of a black box AI system that makes life-critical decisions. We propose an \"arguing machines\" framework that pairs the primary AI system with a secondary one that is independently trained to perform the same task. We show that disagreement between the two systems, without any knowledge of underlying system design or operation, is sufficient to arbitrarily improve the accuracy of the overall decision pipeline given human supervision over disagreements. We demonstrate this system in two applications: (1) an illustrative example of image classification and (2) on large-scale real-world semi-autonomous driving data. For the first application, we apply this framework to image classification achieving a reduction from 8.0 to 2.8 top-5 error on ImageNet. For the second application, we apply this framework to Tesla Autopilot and demonstrate the ability to predict 90.4 of system disengagements that were labeled by human annotators as challenging and needing human supervision.", "text_perturb": "We consider the paradigm of a black box AI arrangement that makes life-critical decisions. We propose an `` arguing machines '' framework that pairs the primary AI system of rules with a secondary one that is independently trained to perform the same task. We show that disagreement between the two systems , without any knowledge of underlie system design or operation , is sufficient to arbitrarily improve the accuracy of the overall decision pipeline given human supervision over disagreements. We demonstrate this system in two applications : ( 1 ) an illustrative example of image compartmentalisation and ( 2 ) on large-scale real-world semi-autonomous driving data. For the first application , we apply this framework to image compartmentalization achieving a reduction from 8. 0 to 2. 8 top-5 fault on ImageNet. For the second application , we apply this framework to Tesla Autopilot and demo the ability to predict 90. 4 of system detachment that were labeled by human annotators as challenging and needing human supervision. ", "label": 1}
{"original_text": "We introduce a model of one-way language acceptors (a variant of a checking stack automaton) and show the following decidability properties: 1. item 1 1 item 1 The deterministic version has a decidable membership problem but has an undecidable emptiness problem. 2. item 2 2 item 2 The nondeterministic version has an undecidable membership problem and emptiness problem. There are many models of accepting devices for which there is no difference with these problems between deterministic and nondeterministic versions, i.e., the membership problem for both versions are either decidable or undecidable, and the same holds for the emptiness problem. As far as we know, the model we introduce above is the first one-way model to exhibit properties (1) and (2). We define another family of one-way acceptors where the nondeterministic version has an undecidable emptiness problem, but the deterministic version has a decidable emptiness problem. We also know of no other model with this property in the literature. We also investigate decidability properties of other variations of checking stack automata (e.g., allowing multiple stacks, two-way input, etc.). Surprisingly, two-way deterministic machines with multiple checking stacks and multiple reversal-bounded counters are shown to have a decidable membership problem, a very general model with this property.", "text_perturb": "We introduce a model of one-way language acceptors ( a variant of a checking good deal automaton ) and show the following decidability properties : 1. detail 1 1 detail 1 The deterministic version has a decidable membership problem but has an undecidable emptiness problem. 2. item 2 2 item 2 The nondeterministic adaptation has an undecidable membership problem and emptiness problem. There are many models of accepting twist for which there is no difference with these problems between deterministic and nondeterministic versions , i. due east. , the membership problem for both versions are either decidable or undecidable , and the like holds for the emptiness problem. As far as we know , the manakin we introduce above is the first one-way manakin to exhibit properties ( 1 ) and ( 2 ). We set another family of one-way acceptors where the nondeterministic version has an undecidable emptiness problem , but the deterministic version has a decidable emptiness problem. We also sleep together of no other model with this property in the literature. We also investigate decidability properties of other variations of checking stack automaton ( e. gee. , provide multiple stacks , two-way input , etc. ). Surprisingly , two-way deterministic machines with multiple checking stacks and multiple reversal-bounded retort are shown to have a decidable membership problem , a very general model with this property. ", "label": 1}
{"original_text": "3-D image registration, which involves aligning two or more images, is a critical step in a variety of medical applications from diagnosis to therapy. Image registration is commonly performed by optimizing an image matching metric as a cost function. However, this task is challenging due to the non-convex nature of the matching metric over the plausible registration parameter space and insufficient approaches for a robust optimization. As a result, current approaches are often customized to a specific problem and sensitive to image quality and artifacts. In this paper, we propose a completely different approach to image registration, inspired by how experts perform the task. We first cast the image registration problem as a \"strategy learning\" process, where the goal is to find the best sequence of motion actions (e.g. up, down, etc.) that yields image alignment. Within this approach, an artificial agent is learned, modeled using deep convolutional neural networks, with 3D raw image data as the input, and the next optimal action as the output. To cope with the dimensionality of the problem, we propose a greedy supervised approach for an end-to-end training, coupled with attention-driven hierarchical strategy. The resulting registration approach inherently encodes both a data-driven matching metric and an optimal registration strategy (policy). We demonstrate, on two 3-D3-D medical image registration examples with drastically different nature of challenges, that the artificial agent outperforms several state-of-art registration methods by a large margin in terms of both accuracy and robustness.", "text_perturb": "3-D image registration , which involves aligning two or more images , is a critical step in a multifariousness of medical applications from diagnosis to therapy. Image registration is commonly performed by optimizing an simulacrum matching metric as a cost function. However , this task is challenging due to the non-convex nature of the matching metric over the plausible registration parameter space and deficient approaches for a robust optimization. As a result , current approaches are often customized to a particular problem and sensitive to image quality and artifacts. In this paper , we propose a completely different approach to image registration , inspired by how experts perform the chore. We first cast the image registration problem as a `` strategy learning '' process , where the destination is to find the best sequence of motion actions ( e. one thousand. upwardly , down , etc. ) that yields look alike alignment. Within this approach , an artificial agent is learned , pose using deep convolutional neural networks , with 3D raw image data as the input , and the next optimal action as the output. To cope with the dimensionality of the problem , we aim a greedy supervised approach for an end-to-end training , coupled with attention-driven hierarchical strategy. The result registration approach inherently encodes both a data-driven matching metric and an optimal registration strategy ( policy ). We demonstrate , on two 3-D3-D medical image registration examples with drastically different nature of challenges , that the artificial agent outperforms several state-of-art registration methods by a large margin in terms of both truth and robustness. ", "label": 1}
{"original_text": "This paper describes the Amobee sentiment analysis system, adapted to compete in SemEval 2017 task 4. The system consists of two parts: a supervised training of RNN models based on a Twitter sentiment treebank, and the use of feedforward NN, Naive Bayes and logistic regression classifiers to produce predictions for the different sub-tasks. The algorithm reached the 3rd place on the 5-label classification task (sub-task C).", "text_perturb": "This paper describes the Amobee sentiment analysis system , adjust to compete in SemEval 2017 task 4. The system consists of two component part : a supervised training of RNN models based on a Twitter sentiment treebank , and the use of feedforward NN , Naive Bayes and logistic regression classifiers to produce predictions for the different sub-tasks. The algorithm reached the 3rd space on the 5-label classification task ( sub-task C ). ", "label": 1}
{"original_text": "The paper deals with the problem of deciding if two finite-dimensional linear subspaces over an arbitrary field are identical up to a permutation of the coordinates. This problem is referred to as the permutation code equivalence. We show that given access to a subroutine that decides if two weighted undirected graphs are isomorphic, one may deterministically decide the permutation code equivalence provided that the underlying vector spaces intersect trivially with their orthogonal complement with respect to an arbitrary inner product. Such a class of vector spaces is usually called linear codes with trivial hulls. The reduction is efficient because it essentially boils down to computing the inverse of a square matrix of order the length of the involved codes. Experimental results obtained with randomly drawn binary codes having trivial hulls show that permutation code equivalence can be decided in a few minutes for lengths up to 50, 000.", "text_perturb": "The theme deals with the problem of deciding if two finite-dimensional linear subspaces over an arbitrary field are identical up to a permutation of the coordinates. This problem is referred to as the permutation computer code equivalence. We show that given access to a subroutine that decides if two weighted aimless graphs are isomorphic , one may deterministically decide the permutation code equivalence provided that the underlying vector spaces intersect trivially with their orthogonal complement with respect to an arbitrary inner product. Such a class of vector spaces represent usually called linear codes with trivial hulls. The reduction is efficient because it essentially boils down to computing the inverse of a square ground substance of order the length of the involved codes. Experimental upshot obtained with randomly drawn binary codes having trivial hulls show that permutation code equivalence can be decided in a few minutes for lengths up to 50 , 000. ", "label": 1}
{"original_text": "Physics-Informed Neural Networks (PINNs) have emerged recently as a promising application of deep neural networks to the numerical solution of nonlinear partial differential equations (PDEs). However, the original PINN algorithm is known to suffer from stability and accuracy problems in cases where the solution has sharp spatio-temporal transitions. These \"stiff\" PDEs require an unreasonably large number of collocation points to be solved accurately. It has been recognized that adaptive procedures are needed to force the neural network to fit accurately the stubborn spots in the solution of stiff PDEs. To accomplish this, previous approaches have used fixed weights hard-coded over regions of the solution deemed to be important. In this paper, we propose a fundamentally new method to train PINNs adaptively, where the adaptation weights are fully trainable, so the neural network learns by itself which regions of the solution are difficult and is forced to focus on them, which is reminiscent of soft multiplicative-mask attention mechanism used in computer vision. The basic idea behind these Self-Adaptive PINNs is to make the weights increase where the corresponding loss is higher, which is accomplished by training the network to simultaneously minimize the losses and maximize the weights, i.e., to find a saddle point in the cost surface. We show that this is formally equivalent to solving a PDE-constrained optimization problem using a penalty-based method, though in a way where the monotonically-nondecreasing penalty coefficients are trainable. Numerical experiments with an Allen-Cahn \"stiff\" PDE, the Self-Adaptive PINN outperformed other state-of-the-art PINN algorithms in L2 error by a wide margin, while using a smaller number of training epochs. An Appendix contains additional results with Burger's and Helmholtz PDEs, which confirmed the trends observed in the Allen-Cahn experiments.", "text_perturb": "Physics-Informed Neural Networks ( PINNs ) have emerged recently as a promising lotion of deep neural networks to the numerical solution of nonlinear partial differential equations ( PDEs ). However , the original PINN algorithm is lie with to suffer from stability and accuracy problems in cases where the solution has sharp spatio-temporal transitions. These `` stiff '' PDEs require an unreasonably large number of apposition points to be solved accurately. It have been recognized that adaptive procedures are needed to force the neural network to fit accurately the stubborn spots in the solution of stiff PDEs. To accomplish this , previous approaches have used repair weights hard-coded over regions of the solution deemed to be important. In this paper , we propose a fundamentally new method to train PINNs adaptively , where the adaptation weights are fully trainable , so the neural network learns by itself which regions of the solution are difficult and is forced to focus on them , which is reminiscent of mild multiplicative-mask attention mechanism used in computer vision. The basic idea behind these Self-Adaptive PINNs is to make the free weight increase where the corresponding loss is higher , which is accomplished by training the network to simultaneously minimize the losses and maximize the free weight , i. tocopherol. , to find a saddle point in the cost earths surface. We show that this is formally equivalent to lick a PDE-constrained optimization problem using a penalty-based method , though in a way where the monotonically-nondecreasing penalty coefficients are trainable. Numerical experiments with an Allen-Cahn `` stiff '' PDE , the Self-Adaptive PINN outperformed other state-of-the-art PINN algorithms in L2 error by a wide margin , while using a smaller number of grooming epochs. An Appendix contains additional results with Burger 's and Helmholtz PDEs , which substantiate the trends observed in the Allen-Cahn experiments. ", "label": 1}
{"original_text": "Low-light image enhancement is generally regarded as a challenging task in image processing, especially for the complex visual tasks at night or weakly illuminated. In order to reduce the blurs or noises on the low-light images, a large number of papers have contributed to applying different technologies. Regretfully, most of them had served little purposes in coping with the extremely poor illumination parts of images or test in practice. In this work, the authors propose a novel approach for processing low-light images based on the Retinex theory and generative adversarial network (GAN), which is composed of the decomposition part for splitting the image into illumination image and reflected image, and the enhancement part for generating high-quality image. Such a discriminative network is expected to make the generated image clearer. Couples of experiments have been implemented under the circumstance of different lighting strength on the basis of Converted See-In-the-Dark (CSID) datasets, and the satisfactory results have been achieved with exceeding expectation that much encourages the authors. In a word, the proposed GAN-based network and employed Retinex theory in this work have proven to be effective in dealing with the low-light image enhancement problems, which will benefit the image processing with no doubt.", "text_perturb": "Low-light prototype enhancement is generally regarded as a challenging task in prototype processing , especially for the complex visual tasks at night or weakly illuminated. In order to reduce the blurs or noises on the low-light images , a large number of papers induce contributed to applying different technologies. Regretfully , most of them had process little purposes in coping with the extremely poor illumination parts of images or test in practice. In this work , the authors propose a novel approach for processing low-light images free base on the Retinex theory and generative adversarial network ( GAN ) , which is composed of the decomposition part for splitting the image into illumination image and reflected image , and the enhancement part for generating high-quality image. Such a discriminative network is require to make the generated image clearer. Couples of experiments have follow implemented under the circumstance of different lighting strength on the basis of Converted See-In-the-Dark ( CSID ) datasets , and the satisfactory results have follow achieved with exceeding expectation that much encourages the authors. In a word , the proposed GAN-based network and employed Retinex theory in this work have proven to be effective in dealing with the low-light image enhancement problems , which will benefit the image processing with no question. ", "label": 1}
{"original_text": "We propose Monte Carlo methods to estimate the partition function of the two-dimensional Ising model in the presence of an external magnetic field. The estimation is done in the dual of the Forney factor graph representing the model. The proposed methods can efficiently compute an estimate of the partition function in a wide range of model parameters. As an example, we consider models that are in a strong external field.", "text_perturb": "We propose Monte Carlo methods to estimate the partition function of the two-dimensional Ising model in the presence of an external magnetic orbit. The estimation cost done in the dual of the Forney factor graph representing the model. The offer methods can efficiently compute an estimate of the partition function in a wide range of model parameters. As an example , we turn over models that are in a strong external field. ", "label": 1}
{"original_text": "TimeML is an XML-based schema for annotating temporal information over discourse. The standard has been used to annotate a variety of resources and is followed by a number of tools, the creation of which constitute hundreds of thousands of man-hours of research work. However, the current state of resources is such that many are not valid, or do not produce valid output, or contain ambiguous or custom additions and removals. Difficulties arising from these variances were highlighted in the TempEval-3 exercise, which included its own extra stipulations over conventional TimeML as a response. To unify the state of current resources, and to make progress toward easy adoption of its current incarnation ISO-TimeML, this paper introduces TimeML-strict: a valid, unambiguous, and easy-to-process subset of TimeML. We also introduce three resources - a schema for TimeML-strict; a validator tool for TimeML-strict, so that one may ensure documents are in the correct form; and a repair tool that corrects common invalidating errors and adds disambiguating markup in order to convert documents from the laxer TimeML standard to TimeML-strict.", "text_perturb": "TimeML is an XML-based outline for annotating temporal information over discourse. The standard has been used to gloss a variety of resources and is followed by a number of tools , the creation of which constitute hundreds of thousands of man-hours of research work. However , the current state of resources is such that many are not valid , or do not bring forth valid output , or contain ambiguous or custom additions and removals. Difficulties rise up from these variances were highlighted in the TempEval-3 exercise , which included its own extra stipulations over conventional TimeML as a response. To unify the state of current resource , and to make progress toward easy adoption of its current incarnation ISO-TimeML , this paper introduces TimeML-strict : a valid , unambiguous , and easy-to-process subset of TimeML. We also introduce three resource - a schema for TimeML-strict ; a validator tool for TimeML-strict , so that one may ensure documents are in the correct form ; and a repair tool that corrects common invalidating errors and adds disambiguating markup in order to convert documents from the laxer TimeML standard to TimeML-strict. ", "label": 1}
{"original_text": "The g 2 norm of a real x m n matrix A is the minimum number t such that the column vectors of A are contained in a 0 -centered ellipsoid E R m which in turn is contained in the hypercube [ - t, t ] m. We prove that this classical quantity approximates the hereditary discrepancy herdisc A as follows: g 2 (A) O (log m) herdisc A and herdisc A O (log m) g 2 (A). Since g 2 is polynomial-time computable, this gives a polynomial-time approximation algorithm for hereditary discrepancy. Both inequalities are shown to be asymptotically tight. We then demonstrate on several examples the power of the g 2 norm as a tool for proving lower and upper bounds in discrepancy theory. Most notably, we prove a new lower bound of O (log - d 1 n) for the d -dimensional Tusnady problem, asking for the combinatorial discrepancy of an n -point set in R d with respect to axis-parallel boxes. For d 2, this improves the previous best lower bound, which was of order approximately log d 1) 2 n, and it comes close to the best known upper bound of O (log d 1 2 n), for which we also obtain a new, very simple proof.", "text_perturb": "The g 2 norm of a real x m n matrix A is the minimum number deoxythymidine monophosphate such that the column vectors of A are contained in a 0 -centered ellipsoid E R m which in turn is contained in the hypercube [ - deoxythymidine monophosphate , t ] m. We prove that this classical quantity guess the hereditary discrepancy herdisc A as follows : g 2 ( A ) O ( log m ) herdisc A and herdisc A O ( log m ) g 2 ( A ). Since g 2 constitute polynomial-time computable , this gives a polynomial-time approximation algorithm for hereditary discrepancy. Both inequalities are shown to be asymptotically stiff. We then demonstrate on several examples the power of the g 2 norm as a tool for proving lower and upper bounds in divergence theory. most notably , we prove a new lower bound of O ( log - d 1 n ) for the d -dimensional Tusnady problem , asking for the combinatorial discrepancy of an n -point set in R d with respect to axis-parallel boxes. For d 2 , this improves the previous best lower bound , which be of order approximately log d 1 ) 2 n , and it comes close to the best known upper bound of O ( log d 1 2 n ) , for which we also obtain a new , very simple proof. ", "label": 1}
{"original_text": "Despite a decade of active research, there is a marked lack in clone detectors that scale to very large repositories of source code, in particular for detecting near-miss clones where significant editing activities may take place in the cloned code. We present SourcererCC, a token-based clone detector that targets three clone types, and exploits an index to achieve scalability to large inter-project repositories using a standard workstation. SourcererCC uses an optimized inverted-index to quickly query the potential clones of a given code block. Filtering heuristics based on token ordering are used to significantly reduce the size of the index, the number of code-block comparisons needed to detect the clones, as well as the number of required token-comparisons needed to judge a potential clone. We evaluate the scalability, execution time, recall and precision of SourcererCC, and compare it to four publicly available and state-of-the-art tools. To measure recall, we use two recent benchmarks, (1) a large benchmark of real clones, BigCloneBench, and (2) a MutationInjection-based framework of thousands of fine-grained artificial clones. We find SourcererCC has both high recall and precision, and is able to scale to a large inter-project repository (250MLOC) using a standard workstation.", "text_perturb": "Despite a decade of active research , there is a marked lack in clone detectors that scale to very large repositories of rootage code , in particular for detecting near-miss clones where significant editing activities may take place in the cloned code. We present SourcererCC , a token-based clone detector that aim three clone types , and exploits an index to achieve scalability to large inter-project repositories using a standard workstation. SourcererCC uses an optimized inverted-index to quickly query the potential clones of a dedicate code block. Filtering heuristics based on token ordering are used to importantly reduce the size of the index , the number of code-block comparisons needed to detect the clones , as well as the number of required token-comparisons needed to judge a potential clone. We evaluate the scalability , murder time , recall and precision of SourcererCC , and compare it to four publicly available and state-of-the-art tools. To mensurate recall , we use two recent benchmarks , ( 1 ) a large benchmark of real clones , BigCloneBench , and ( 2 ) a MutationInjection-based framework of thousands of fine-grained artificial clones. We find SourcererCC feature both high recall and precision , and is able to scale to a large inter-project repository ( 250MLOC ) using a standard workstation. ", "label": 1}
{"original_text": "A track layout of a graph consists of a vertex coloring and a total order of each color class, such that no two edges cross between any two color classes. The track number of a graph is the minimum number of colors required by a track layout of the graph. This paper improves lower and upper bounds on the track number of several families of planar graphs. We prove that every planar graph has track number at most 225 and every planar 3 -tree has track number at most 25. Then we show that there exist outerplanar graphs whose track number is 5, which leads to the best known lower bound of 8 for planar graphs. Finally, we investigate leveled planar graphs and tighten bounds on the track number of weakly leveled graphs, Halin graphs, and X-trees.", "text_perturb": "A track layout of a graph consists of a vertex coloring and a total order of each color class , such that no two edges cross between any two color course of study. The track number of a graphical record is the minimum number of colors required by a track layout of the graphical record. This paper improves lower and upper bounds on the track number of several families of planar graph. We prove that every planar graph has chase number at most 225 and every planar 3 -tree has chase number at most 25. Then we show that there exist outerplanar graphs whose track number constitute 5 , which leads to the best known lower bound of 8 for planar graphs. Finally , we investigate leveled planar graph and tighten bounds on the track number of weakly leveled graph , Halin graph , and X-trees. ", "label": 1}
{"original_text": "All traditional methods of computing shortest paths depend upon edge-relaxation where the cost of reaching a vertex from a source vertex is possibly decreased if that edge is used. We introduce a method which maintains lower bounds as well as upper bounds for reaching a vertex. This method enables one to find the optimal cost for multiple vertices in one iteration and thereby reduces the sequential bottleneck in Dijkstra's algorithm. We present four algorithms in this paper - S P 1, S P 2, S P 3 and S P 4. S P 1 and S P 2 reduce the number of heap operations in Dijkstra's algorithm. For directed acyclic graphs, or directed unweighted graphs they have the optimal complexity of O (e) where e is the number of edges in the graph which is better than that of Dijkstra's algorithm. For general graphs, their worst case complexity matches that of Dijkstra's algorithm for a sequential implementation but allows for greater parallelism. Algorithms S P 3 and S P 4 allow for even more parallelism but with higher work complexity. Algorithm S P 3 requires O (n e (max (log n, D work where n is the number of vertices and D is the maximum in-degree of a node. Algorithm S P 4 has the most parallelism. It requires O (n e) work. These algorithms generalize the work by Crauser, Mehlhorn, Meyer, and Sanders on parallelizing Dijkstra's algorithm.", "text_perturb": "All traditional methods of compute shortest paths depend upon edge-relaxation where the cost of reaching a vertex from a source vertex is possibly decreased if that edge is used. We introduce a method acting which maintains lower bounds as well as upper bounds for reaching a vertex. This method enables one to find the optimal cost for multiple vertices in one iteration and thereby reduces the sequential chokepoint in Dijkstra 's algorithm. We present four algorithms in this composition - S P 1 , S P 2 , S P 3 and S P 4. S P 1 and S P 2 reduce the numeral of heap operations in Dijkstra 's algorithm. For directed acyclic graphs , or directed unweighted graphs they have the optimal complexity of O ( e ) where e is the number of edges in the graphical record which is better than that of Dijkstra 's algorithm. For general graphs , their worst case complexity matches that of Dijkstra 's algorithm for a sequential implementation but permit for greater parallelism. algorithm S P 3 and S P 4 allow for even more parallelism but with higher work complexity. Algorithm reciprocal ohm P 3 requires O ( n e ( max ( log n , D work where n is the number of vertices and D is the maximum in-degree of a node. Algorithm S P 4 throw the most parallelism. It requires O ( n e ) body of work. These algorithms vulgarize the work by Crauser , Mehlhorn , Meyer , and Sanders on parallelizing Dijkstra 's algorithm. ", "label": 1}
{"original_text": "Analysis of opinion dynamics in social networks plays an important role in today's life. For applications such as predicting users' political preference, it is particularly important to be able to analyze the dynamics of competing opinions. While observing the evolution of polar opinions of a social network's users over time, can we tell when the network \"behaved\" abnormally? Furthermore, can we predict how the opinions of the users will change in the future? Do opinions evolve according to existing network opinion dynamics models? To answer such questions, it is not sufficient to study individual user behavior, since opinions can spread far beyond users' egonets. We need a method to analyze opinion dynamics of all network users simultaneously and capture the effect of individuals' behavior on the global evolution pattern of the social network. In this work, we introduce Social Network Distance (SND) - a distance measure that quantifies the \"cost\" of evolution of one snapshot of a social network into another snapshot under various models of polar opinion propagation. SND has a rich semantics of a transportation problem, yet, is computable in time linear in the number of users, which makes SND applicable to the analysis of large-scale online social networks. In our experiments with synthetic and real-world Twitter data, we demonstrate the utility of our distance measure for anomalous event detection. It achieves a true positive rate of 0.83, twice as high as that of alternatives. When employed for opinion prediction in Twitter, our method's accuracy is 75.63, which is 7.5 higher than that of the next best method. Code:", "text_perturb": "Analysis of opinion dynamics in social networks make for an important role in today 's life. For practical application such as predicting users ' political preference , it is particularly important to be able to analyze the dynamics of competing opinions. While observing the evolution of polar opinions of a social network 's substance abuser over time , can we tell when the network `` behaved '' abnormally ? Furthermore , can we predict how the opinions of the substance abuser will change in the future ? Do opinions evolve according to existing network opinion dynamics models ? To answer such questions , it is not sufficient to study individual user behavior , since opinions can spread far beyond substance abuser ' egonets. We need a method to analyze opinion dynamics of all network users simultaneously and capture the effect of individuals ' behavior on the planetary evolution pattern of the social network. In this work , we introduce Social Network Distance ( SND ) - a distance measure that quantifies the `` cost '' of evolution of one snapshot of a social web into another snapshot under various models of polar opinion propagation. SND has a rich semantics of a transportation problem , yet , is computable in time linear in the number of users , which makes SND applicable to the analysis of large-scale online societal networks. In our experiments with synthetic and real-world Twitter data , we demonstrate the public service corporation of our distance measure for anomalous event detection. It achieves a on key positive rate of 0. 83 , twice as high as that of alternative. When employed for opinion prediction in chirrup , our method 's accuracy is 75. 63 , which follow 7. 5 higher than that of the next best method acting. code :", "label": 1}
{"original_text": "We show that given a 3-colorable graph, it is NP -hard to find a 3-coloring with (16 17 eps) of the edges bichromatic. In a related result, we show that given a satisfiable instance of the 2 -to- 1 Label Cover problem, it is NP -hard to find a (23 24 eps) -satisfying assignment.", "text_perturb": "We show that given a 3-colorable graph , it is NP -hard to find oneself a 3-coloring with ( 16 17 eps ) of the edges bichromatic. In a related result , we show that given a satisfiable instance of the 2 -to- 1 Label Cover problem , it is nurse practitioner -hard to find a ( 23 24 eps ) -satisfying assignment. ", "label": 1}
{"original_text": "This paper presents the link availability probability. We evaluate and compare the link availability probability for routing protocols; Ad hoc On-demand Distance vector (AODV), Dynamic Source Routing (DSR) and Fisheye State Routing (FSR) for different number of connections and node density. A novel contribution of this work is enhancement in existing parameters of routing protocols; AODV, DSR and FSR as MOD-AODV, MOD-DSR and MOD-FSR. From the results, we observe that MOD-DSR and DSR outperform MOD-AODV, AODV, MOD-OLSR and OLSR in terms of Packet Delivery Ratio (PDR), Average End-to End Delay (AE2ED), link availability probability at the cost of high value of Normalized Routing Overhead (NRO).", "text_perturb": "This paper presents the linkup availability probability. We evaluate and compare the inter group communication availability probability for routing protocols ; Ad hoc On-demand Distance vector ( AODV ) , Dynamic Source Routing ( DSR ) and Fisheye State Routing ( FSR ) for different number of connections and node density. A novel contribution of this work is enhancement in subsist parameters of routing protocols ; AODV , DSR and FSR as MOD-AODV , MOD-DSR and MOD-FSR. From the results , we observe that MOD-DSR and DSR outperform MOD-AODV , AODV , MOD-OLSR and OLSR in terms of Packet Delivery ratio ( PDR ) , Average End-to End Delay ( AE2ED ) , link availability probability at the cost of high value of Normalized Routing Overhead ( NRO ). ", "label": 1}
{"original_text": "While it has become common to perform automated translations on natural language, performing translations between different representations of mathematical formulae has thus far not been possible. We implemented the first translator for mathematical formulae based on recursive neural networks. We chose recursive neural networks because mathematical formulae inherently include a structural encoding. In our implementation, we developed new techniques and topologies for recursive tree-to-tree neural networks based on multi-variate multi-valued Long Short-Term Memory cells. We propose a novel approach for mini-batch training that utilizes clustering and tree traversal. We evaluate our translator and analyze the behavior of our proposed topologies and techniques based on a translation from generic LaTeX to the semantic LaTeX notation. We use the semantic LaTeX notation from the Digital Library for Mathematical Formulae and the Digital Repository for Mathematical Formulae at the National Institute for Standards and Technology. We find that a simple heuristics-based clustering algorithm outperforms the conventional clustering algorithms on the task of clustering binary trees of mathematical formulae with respect to their topology. Furthermore, we find a mask for the loss function, which can prevent the neural network from finding a local minimum of the loss function. Given our preliminary results, a complete translation from formula to formula is not yet possible. However, we achieved a prediction accuracy of 47.05 for predicting symbols at the correct position and an accuracy of 92.3 when ignoring the predicted position. Concluding, our work advances the field of recursive neural networks by improving the training speed and quality of training. In the future, we will work towards a complete translation allowing a machine-interpretation of LaTeX formulae.", "text_perturb": "While it has become common to perform machine driven translations on natural language , performing translations between different representations of mathematical formulae has thus far not been possible. We implemented the first transcriber for mathematical formulae based on recursive neural networks. We chose recursive neural networks because mathematical formulae inherently include a structural encryption. In our implementation , we developed new techniques and topologies for recursive tree-to-tree neural networks based on multi-variate multivalent Long Short-Term Memory cells. We propose a novel approach for mini-batch training that utilize clustering and tree traversal. We evaluate our translator and analyze the behavior of our proposed topologies and techniques based on a translation from generic latex paint to the semantic latex paint notation. We use the semantic LaTeX notation from the Digital Library for Mathematical formula and the Digital Repository for Mathematical formula at the National Institute for Standards and Technology. We find that a simple heuristics-based clustering algorithm outperforms the conventional clustering algorithms on the task of clustering binary trees of numerical formulae with respect to their topology. Furthermore , we find a mask for the going function , which can prevent the neural network from finding a local minimum of the going function. Given our preliminary results , a all over translation from formula to formula is not yet possible. withal , we achieved a prediction accuracy of 47. 05 for predicting symbols at the correct emplacement and an accuracy of 92. 3 when ignoring the predicted position. Concluding , our work advances the field of recursive nervous networks by improving the training speed and quality of training. In the future tense , we will work towards a complete translation allowing a machine-interpretation of LaTeX formulae. ", "label": 1}
{"original_text": "Fashion attribute classification is of great importance to many high-level tasks such as fashion item search, fashion trend analysis, fashion recommendation, etc. The task is challenging due to the extremely imbalanced data distribution, particularly the attributes with only a few positive samples. In this paper, we introduce a hard-aware pipeline to make full use of \"hard\" samplesattributes. We first propose Hard-Aware BackPropagation (HABP) to efficiently and adaptively focus on training \"hard\" data. Then for the identified hard labels, we propose to synthesize more complementary samples for training. To stabilize training, we extend semi-supervised GAN by directly deactivating outputs for synthetic complementary samples (Deact). In general, our method is more effective in addressing \"hard\" cases. HABP weights more on \"hard\" samples. For \"hard\" attributes with insufficient training data, Deact brings more stable synthetic samples for training and further improve the performance. Our method is verified on large scale fashion dataset, outperforming other state-of-the-art without any additional supervisions.", "text_perturb": "Fashion attribute classification is of great importance to many high-level tasks such as fashion detail search , fashion trend analysis , fashion recommendation , etc. The task is challenging due to the extremely imbalanced data dispersion , particularly the attributes with only a few positive samples. In this paper , we introduce a hard-aware pipeline to ca ca full use of `` hard '' samplesattributes. We first propose Hard-Aware BackPropagation ( HABP ) to expeditiously and adaptively focus on training `` hard '' data. Then for the identified hard label , we propose to synthesize more complementary samples for training. To stabilize training , we extend semi-supervised GAN by at once deactivating outputs for synthetic complementary samples ( Deact ). In universal , our method is more effective in addressing `` hard '' cases. HABP system of weights more on `` hard '' samples. For `` hard '' attributes with insufficient training datum , Deact brings more stable synthetic samples for training and further improve the performance. Our method is verified on large scale fashion dataset , outperforming other state-of-the-art without any additional supervision. ", "label": 1}
{"original_text": "This paper presents an efficient parallel Adaptive Inverse Distance Weighting (AIDW) interpolation algorithm on modern Graphics Processing Unit (GPU). The presented algorithm is an improvement of our previous GPU-accelerated AIDW algorithm by adopting fast k - N earest N eighbors (k NN) search. In AIDW, it needs to find several nearest neighboring data points for each interpolated point to adaptively determine the power parameter; and then the desired prediction value of the interpolated point is obtained by weighted interpolating using the power parameter. In this work, we develop a fast k NN search approach based on the space-partitioning data structure, even grid, to improve the previous GPU-accelerated AIDW algorithm. The improved algorithm is composed of the stages of k NN search and weighted interpolating. To evaluate the performance of the improved algorithm, we perform five groups of experimental tests. Experimental results show that: (1) the improved algorithm can achieve a speedup of up to 1017 over the corresponding serial algorithm; (2) the improved algorithm is at least two times faster than our previous GPU-accelerated AIDW algorithm; and (3) the utilization of fast k NN search can significantly improve the computational efficiency of the entire GPU-accelerated AIDW algorithm.", "text_perturb": "This paper presents an efficient parallel Adaptive Inverse Distance Weighting ( AIDW ) interpolation algorithm on innovative Graphics Processing Unit ( GPU ). The presented algorithm is an improvement of our previous GPU-accelerated AIDW algorithm by adopting fast k - N earest N eighbors ( k NN ) lookup. In AIDW , it needs to find several nearest neighboring data points for each interpolated point to adaptively determine the power parameter ; and then the desired prediction value of the interpolated point is obtained by leaden interpolating using the power parameter. In this work , we develop a fast m NN search approach based on the space-partitioning data structure , even grid , to improve the previous GPU-accelerated AIDW algorithm. The improved algorithm is composed of the stages of k NN hunt and weighted interpolating. To valuate the performance of the improved algorithm , we perform five groups of experimental tests. Experimental results show that : ( 1 ) the improved algorithm can achieve a speedup of up to 1017 over the corresponding serial algorithm ; ( 2 ) the improved algorithm is at least two metre faster than our previous GPU-accelerated AIDW algorithm ; and ( 3 ) the utilization of fast k NN search can significantly improve the computational efficiency of the entire GPU-accelerated AIDW algorithm. ", "label": 1}
{"original_text": "Generative adversarial network (GAN) has greatly improved the quality of unsupervised image generation. Previous GAN-based methods often require a large amount of high-quality training data while producing a small number (e.g. , tens) of classes. This work aims to scale up GANs to thousands of classes meanwhile reducing the use of high-quality data in training. We propose an image generation method based on conditional transferring features, which can capture pixel-level semantic changes when transforming low-quality images into high-quality ones. Moreover, self-supervision learning is integrated into our GAN architecture to provide more label-free semantic supervisory information observed from the training data. As such, training our GAN architecture requires much fewer high-quality images with a small number of additional low-quality images. The experiments on CIFAR-10 and STL-10 show that even removing 30 high-quality images from the training set, our method can still outperform previous ones. The scalability on object classes has been experimentally validated: our method with 30 fewer high-quality images obtains the best quality in generating 1,000 ImageNet classes, as well as generating all 3,755 classes of CASIA-HWDB1.0 Chinese handwriting characters.", "text_perturb": "Generative adversarial electronic network ( GAN ) has greatly improved the quality of unsupervised image generation. Previous GAN-based methods much require a large amount of high-quality training data while producing a small number ( e. gram. , tens ) of form. This work aims to scale up GANs to thousands of classes meanwhile reducing the use of high-quality information in training. We propose an image generation method based on conditional transferring features , which can capture pixel-level semantic changes when transforming low-quality images into high-quality single. Moreover , self-supervision learning is integrated into our GAN architecture to provide more label-free semantic supervisory selective information observed from the training data. As such , training our GAN architecture postulate much fewer high-quality images with a small number of additional low-quality images. The experiment on CIFAR-10 and STL-10 show that even removing 30 high-quality images from the training set , our method can still outperform previous ones. The scalability on object classes has cost experimentally validated : our method with 30 fewer high-quality images obtains the best quality in generating 1,000 ImageNet classes , as well as generating all 3,755 classes of CASIA-HWDB1. 0 Chinese handwrite characters. ", "label": 1}
{"original_text": "Exploring the interference-emitting friendly jammers to protect the sensitive communications in the presence of eavesdroppers has increasingly being investigated in literature. In parallel, scavenging energy from abient radio signals for energy-constrained devices, namely wireless energy harvesting (WEH), has also drawn significant attention. Without relying on external energy supply, the wireless-powered friendly jammer by WEH from legitimate wireless devices is an effective approach to prolong their lifetime and gain the flexibility in deployments. This paper studies the online optimization of the placement and WEH of a set of friendly jammers in a geographic location with the energy-efficiency (EE) consideration. We adopt a simple \"time switching\" protocol where power transfer and jammer-assisted secure communications occur in different time blocks when WEH requests are launched. Our scheme has the following important advantages: 1) The proposed online jammers placement and interfering power allocation to attack eavesdroppers is the first distributed and scalable solutions within any specified geographic region; 2) We model the WEH for jammers as a JAM-NET lifetime maximization problem, where online scheduling algorithms with heterogeneous energy demands of each jammer (from energy sources) are designed; 3) Under our model, the problem of placing a minimum number of jammers with distance-based power assignments is NP-hard, and near optimal PTAS approximation algorithms are provided; 4) When durations of the eavesdropping and legitimate communicating are available and the scenario is extended to the multi-channels setting, our results are strengthened to see further improved EE and reduced number of jammers. Simulations back up our theory.", "text_perturb": "Exploring the interference-emitting friendly jammers to protect the sensitive communications in the presence of eavesdroppers has more and more being investigated in literature. In parallel , scavenging energy from abient radio signals for energy-constrained devices , namely wireless energy harvesting ( WEH ) , own also drawn significant attention. Without relying on extraneous energy supply , the wireless-powered friendly jammer by WEH from legitimate wireless devices is an effective approach to prolong their lifetime and gain the flexibility in deployments. This paper studies the on line optimization of the placement and WEH of a set of friendly jammers in a geographic location with the energy-efficiency ( EE ) consideration. We adopt a simple `` time switching '' protocol where tycoon transfer and jammer-assisted secure communications occur in different time blocks when WEH requests are launched. Our scheme has the following important advantages : 1 ) The proposed online jammers placement and interfering power allocation to attack eavesdroppers is the first distributed and scalable solutions within any specified geographic region ; 2 ) We model the WEH for jammers as a JAM-NET lifetime maximization job , where online scheduling algorithms with heterogeneous energy demands of each jammer ( from energy sources ) are designed ; 3 ) Under our model , the job of placing a minimum number of jammers with distance-based power assignments is NP-hard , and near optimal PTAS approximation algorithms are provided ; 4 ) When durations of the eavesdropping and legitimate communicating are available and the scenario is extended to the multi-channels setting , our results are strengthened to see further improved EE and reduced number of jammers. Simulations second up our theory. ", "label": 1}
{"original_text": "Dense subgraph discovery is a key primitive in many graph mining applications, such as detecting communities in social networks and mining gene correlation from biological data. Most studies on dense subgraph mining only deal with one graph. However, in many applications, we have more than one graph describing relations among a same group of entities. In this paper, given two graphs sharing the same set of vertices, we investigate the problem of detecting subgraphs that contrast the most with respect to density. We call such subgraphs Density Contrast Subgraphs, or DCS in short. Two widely used graph density measures, average degree and graph affinity, are considered. For both density measures, mining DCS is equivalent to mining the densest subgraph from a \"difference\" graph, which may have both positive and negative edge weights. Due to the existence of negative edge weights, existing dense subgraph detection algorithms cannot identify the subgraph we need. We prove the computational hardness of mining DCS under the two graph density measures and develop efficient algorithms to find DCS. We also conduct extensive experiments on several real-world datasets to evaluate our algorithms. The experimental results show that our algorithms are both effective and efficient.", "text_perturb": "Dense subgraph discovery is a key primitive in many graph mining applications , such as detecting communities in social mesh and mining gene correlation from biological data. Most studies on dense subgraph mining alone deal with one graph. However , in many applications , we have more than one graph line relations among a same group of entities. In this paper , given two graphs sharing the same set of peak , we investigate the problem of detecting subgraphs that contrast the most with respect to density. We foretell such subgraphs Density Contrast Subgraphs , or DCS in short. Two widely used graph density measurement , average degree and graph affinity , are considered. For both density measures , mining DCS is equivalent to mining the densest subgraph from a `` difference '' graph , which may have both positive and negative sharpness weights. Due to the existence of disconfirming edge weights , existing dense subgraph detection algorithms can not identify the subgraph we need. We prove the computational hardness of mine DCS under the two graph density measures and develop efficient algorithms to find DCS. We also lead extensive experiments on several real-world datasets to evaluate our algorithms. The data based results show that our algorithms are both effective and efficient. ", "label": 1}
{"original_text": "We propose a solution to a time-varying variant of Markov Decision Processes which can be used to address decision-theoretic planning problems for autonomous systems operating in unstructured outdoor environments. We explore the time variability property of the planning stochasticity and investigate the state reachability, based on which we then develop an efficient iterative method that offers a good trade-off between solution optimality and time complexity. The reachability space is constructed by analyzing the means and variances of states' reaching time in the future. We validate our algorithm through extensive simulations using ocean data, and the results show that our method achieves a great performance in terms of both solution quality and computing time.", "text_perturb": "We propose a solution to a time-varying variant of Markov Decision outgrowth which can be used to address decision-theoretic planning problems for autonomous systems operating in unstructured outdoor environments. We explore the time variability property of the planning stochasticity and investigate the state reachability , based on which we so develop an efficient iterative method that offers a good trade-off between solution optimality and time complexity. The reachability space is constructed by psychoanalyse the means and variances of states ' reaching time in the future. We validate our algorithm through extensive simulations using ocean data , and the results show that our method achieves a great performance in terms of both solution quality and computing prison term. ", "label": 1}
{"original_text": "The Smoothed Finite Element Method (S-FEM) proposed by Liu G.R. can achieve more accurate results than the conventional FEM. Currently, much commercial software and many open-source packages have been developed to analyze various science and engineering problems using the FEM. However, there is little work focusing on designing and developing software or packages for the S-FEM. In this paper, we design and implement an open-source package of the parallel S-FEM for elastic problems by utilizing the Julia language on multi-core CPU. The Julia language is a fast, easy-to-use, and open-source programming language that was originally designed for high-performance computing. We term our package as juSFEM. To the best of the authors' knowledge, juSFEM is the first package of parallel S-FEM developed with the Julia language. To verify the correctness and evaluate the efficiency of juSFEM, two groups of benchmark tests are conducted. The benchmark results show that (1) juSFEM can achieve accurate results when compared to commercial FEM software ABAQUS, and (2) juSFEM only requires 543 seconds to calculate the displacements of a 3D elastic cantilever beam model which is composed of approximately 2 million tetrahedral elements, while in contrast the commercial FEM software needs 930 seconds for the same calculation model; (3) the parallel juSFEM executed on the 24-core CPU is approximately 20 x faster than the corresponding serial version. Moreover, the structure and function of juSFEM are easily modularized, and the code in juSFEM is clear and readable, which is convenient for further development.", "text_perturb": "The Smoothed Finite Element method acting ( S-FEM ) proposed by Liu G. r. put up achieve more accurate results than the conventional FEM. Currently , much commercial package and many open-source packages have been developed to analyze various science and engineering problems using the FEM. nonetheless , there is little work focusing on designing and developing software or packages for the S-FEM. In this paper , we design and implement an open source package of the parallel S-FEM for elastic problems by utilizing the Julia language on multi-core CPU. The Julia language equal a fast , easy-to-use , and open-source programming language that was originally designed for high-performance computing. We term our software system as juSFEM. To the best of the authors ' noesis , juSFEM is the first package of parallel S-FEM developed with the Julia language. To verify the correctness and evaluate the efficiency of juSFEM , two groups of benchmark tests are deport. The benchmark results show that ( 1 ) juSFEM can achieve accurate results when compared to commercial FEM software ABAQUS , and ( 2 ) juSFEM only requires 543 seconds to calculate the displacements of a 3D elastic cantilever electron beam model which is composed of approximately 2 million tetrahedral elements , while in contrast the commercial FEM software needs 930 seconds for the same calculation model ; ( 3 ) the parallel juSFEM executed on the 24-core CPU is approximately 20 x faster than the corresponding serial version. Moreover , the structure and function of juSFEM are easily modularized , and the computer code in juSFEM is clear and readable , which is convenient for further development. ", "label": 1}
{"original_text": "We present a multi-query recovery policy for a hybrid system with goal limit cycle. The sample trajectories and the hybrid limit cycle of the dynamical system are stabilized using locally valid Time Varying LQR controller policies which probabilistically cover a bounded region of state space. The original LQR Tree algorithm builds such trees for non-linear static and non-hybrid systems like a pendulum or a cart-pole. We leverage the idea of LQR trees to plan with a continuous control set, unlike methods that rely on discretization like dynamic programming to plan for hybrid dynamical systems where it is hard to capture the exact event of discrete transition. We test the algorithm on a compass gait model by stabilizing a dynamic walking hybrid limit cycle with point foot contact from random initial conditions. We show results from the simulation where the system comes back to a stable behavior with initial position or velocity perturbation and noise.", "text_perturb": "We present a multi-query recovery policy for a hybrid organisation with goal limit cycle. The sample distribution trajectories and the hybrid limit cycle of the dynamical system are stabilized using locally valid Time Varying LQR controller policies which probabilistically cover a bounded region of state space. The original LQR Tree algorithm body build such trees for non-linear static and non-hybrid systems like a pendulum or a cart-pole. We leverage the idea of LQR trees to plan with a continuous control set , unlike methods that rely on discretization like dynamic computer programing to plan for hybrid dynamical systems where it is hard to capture the exact event of discrete transition. We test the algorithm on a compass gait model by stabilizing a dynamic walking hybrid bound cycle with point foot contact from random initial conditions. We show termination from the simulation where the system comes back to a stable behavior with initial position or velocity perturbation and noise. ", "label": 1}
{"original_text": "Graph neural networks (GNNs) are powerful machine learning models for various graph learning tasks. Recently, the limitations of the expressive power of various GNN models have been revealed. For example, GNNs cannot distinguish some non-isomorphic graphs (,) and they cannot learn efficient graph algorithms (,), and several GNN models have been proposed to overcome these limitations. In this paper, we demonstrate that GNNs become powerful just by adding a random feature to each node. We prove that the random features enable GNNs to learn almost optimal polynomial-time approximation algorithms for the minimum dominating set problem and maximum matching problem in terms of the approximation ratio. The main advantage of our method is that it can be combined with off-the-shelf GNN models with slight modifications. Through experiments, we show that the addition of random features enables GNNs to solve various problems that normal GNNs, including GCNs and GINs, cannot solve.", "text_perturb": "Graph neural networks ( GNNs ) are powerful machine scholarship models for various graph learning tasks. Recently , the limitation of the expressive power of various GNN models have been revealed. For example , GNNs can not distinguish some non-isomorphic graphs ( , ) and they can not watch efficient graph algorithms ( , ) , and several GNN models have been proposed to overcome these limitations. In this paper , we demonstrate that GNNs become hefty just by adding a random feature to each node. We prove that the random features enable GNNs to learn almost optimal polynomial-time bringing close together algorithms for the minimum dominating set problem and maximum matching problem in terms of the bringing close together ratio. The main advantage of our method cost that it can be combined with off-the-shelf GNN models with slight modifications. Through experiments , we show that the addition of random features enables GNNs to solve various problems that normal GNNs , including GCNs and GINs , send away not solve. ", "label": 1}
{"original_text": "This paper proposes a particle volume reconstruction directly from an in-line hologram using a deep neural network. Digital holographic volume reconstruction conventionally uses multiple diffraction calculations to obtain sectional reconstructed images from an in-line hologram, followed by detection of the lateral and axial positions, and the sizes of particles by using focus metrics. However, the axial resolution is limited by the numerical aperture of the optical system, and the processes are time-consuming. The method proposed here can simultaneously detect the lateral and axial positions, and the particle sizes via a deep neural network (DNN). We numerically investigated the performance of the DNN in terms of the errors in the detected positions and sizes. The calculation time is faster than conventional diffracted-based approaches.", "text_perturb": "This paper proposes a particle volume reconstruction directly from an in-line holograph using a deep neural network. Digital holographic volume reconstruction conventionally uses multiple diffraction calculations to obtain sectional reconstructed images from an in-line hologram , followed by detection of the lateral and axial positions , and the sizing of particles by using focus metrics. However , the axial resolution is limited by the numerical aperture of the optical system , and the processes personify time-consuming. The method proposed here can simultaneously detect the lateral and axial lieu , and the particle sizes via a deep neural network ( DNN ). We numerically investigated the performance of the DNN in terms of the errors in the detected positions and size. The calculation time is faster than conventional diffracted-based approaches. ", "label": 1}
{"original_text": "Event-specific concepts are the semantic concepts specifically designed for the events of interest, which can be used as a mid-level representation of complex events in videos. Existing methods only focus on defining event-specific concepts for a small number of pre-defined events, but cannot handle novel unseen events. This motivates us to build a large scale event-specific concept library that covers as many real-world events and their concepts as possible. Specifically, we choose WikiHow, an online forum containing a large number of how-to articles on human daily life events. We perform a coarse-to-fine event discovery process and discover 500 events from WikiHow articles. Then we use each event name as query to search YouTube and discover event-specific concepts from the tags of returned videos. After an automatic filter process, we end up with 95, 321 videos and 4, 490 concepts. We train a Convolutional Neural Network (CNN) model on the 95, 321 videos over the 500 events, and use the model to extract deep learning feature from video content. With the learned deep learning feature, we train 4, 490 binary SVM classifiers as the event-specific concept library. The concepts and events are further organized in a hierarchical structure defined by WikiHow, and the resultant concept library is called EventNet. Finally, the EventNet concept library is used to generate concept based representation of event videos. To the best of our knowledge, EventNet represents the first video event ontology that organizes events and their concepts into a semantic structure. It offers great potential for event retrieval and browsing. Extensive experiments over the zero-shot event retrieval task when no training samples are available show that the proposed EventNet concept library consistently and significantly outperforms the state-of-the-art (such as the 20 K ImageNet concepts trained with CNN) by a large margin up to 207. We will also show that EventNet structure can help users find relevant concepts for novel event queries that cannot be well handled by conventional text based semantic analysis alone. The unique two-step approach of first applying event detection models followed by detection of event-specific concepts also provides great potential to improve the efficiency and accuracy of Event Recounting since only a very small number of event-specific concept classifiers need to be fired after event detection.", "text_perturb": "Event-specific concepts are the semantic concepts specifically designed for the event of interest , which can be used as a mid-level representation of complex event in videos. Existing methods only focus on defining event-specific concepts for a small number of pre-defined events , but can not handle novel unobserved events. This incite us to build a large scale event-specific concept library that covers as many real-world events and their concepts as possible. specifically , we choose WikiHow , an online forum containing a large number of how-to articles on human daily life events. We perform a coarse-to-fine result discovery process and discover 500 events from WikiHow articles. Then we use each event epithet as query to search YouTube and discover event-specific concepts from the tags of returned videos. After an reflex filter process , we end up with 95 , 321 videos and 4 , 490 concepts. We train a Convolutional Neural Network ( CNN ) model on the 95 , 321 videos over the 500 events , and use the model to educe deep learning feature from video content. With the learned inscrutable learning feature , we train 4 , 490 binary SVM classifiers as the event-specific concept library. The concepts and outcome are further organized in a hierarchical structure defined by WikiHow , and the resultant concept library is called EventNet. finally , the EventNet concept library is used to generate concept based representation of event videos. To the best of our knowledge , EventNet represents the first video event ontology that organizes result and their concepts into a semantic structure. It offers great potential for event retrieval and browse. Extensive experiments over the zero-shot event retrieval task when no training samples are available show that the proposed EventNet conception library consistently and significantly outperforms the state-of-the-art ( such as the 20 K ImageNet concepts trained with CNN ) by a large margin up to 207. We will also show that EventNet structure can help users find relevant concepts for refreshing event queries that can not be well handled by conventional text based semantic analysis alone. The unique two-step approach of first applying outcome detection models followed by detection of event-specific concepts also provides great potential to improve the efficiency and accuracy of Event Recounting since only a very small number of event-specific concept classifiers need to be fired after outcome detection. ", "label": 1}
{"original_text": "Combinatorial games are widely used in finite model theory, constraint satisfaction, modal logic and concurrency theory to characterize logical equivalences between structures. In particular, Ehrenfeucht-Fraisse games, pebble games, and bisimulation games play a central role. We show how each of these types of games can be described in terms of an indexed family of comonads on the category of relational structures and homomorphisms. The index k is a resource parameter which bounds the degree of access to the underlying structure. The coKleisli categories for these comonads can be used to give syntax-free characterizations of a wide range of important logical equivalences. Moreover, the coalgebras for these indexed comonads can be used to characterize key combinatorial parameters: tree-depth for the Ehrenfeucht-Fraisse comonad, tree-width for the pebbling comonad, and synchronization-tree depth for the modal unfolding comonad. These results pave the way for systematic connections between two major branches of the field of logic in computer science which hitherto have been almost disjoint: categorical semantics, and finite and algorithmic model theory.", "text_perturb": "Combinatorial games are widely used in finite model theory , constraint satisfaction , modal logic and concurrency theory to characterise logical equivalences between structures. In particular , Ehrenfeucht-Fraisse games , pebble games , and bisimulation games play a central function. We show how each of these types of games can be described in terms of an indexed family of comonads on the category of relational structures and homomorphism. The index k is a resource parametric quantity which bounds the degree of access to the underlying structure. The coKleisli categories for these comonads can be used to give syntax-free characterizations of a wide mountain chain of important logical equivalences. Moreover , the coalgebras for these indexed comonads can be apply to characterize key combinatorial parameters : tree-depth for the Ehrenfeucht-Fraisse comonad , tree-width for the pebbling comonad , and synchronization-tree depth for the modal unfolding comonad. These results pave the way for systematic connections between two major branches of the field of logic in computer science which hitherto have been nigh disjoint : categorical semantics , and finite and algorithmic model theory. ", "label": 1}
{"original_text": "Many predicted structured objects (e.g., sequences, matchings, trees) are evaluated using the F-score, alignment error rate (AER), or other multivariate performance measures. Since inductively optimizing these measures using training data is typically computationally difficult, empirical risk minimization of surrogate losses is employed, using, e.g., the hinge loss for (structured) support vector machines. These approximations often introduce a mismatch between the learner's objective and the desired application performance, leading to inconsistency. We take a different approach: adversarially approximate training data while optimizing the exact F-score or AER. Structured predictions under this formulation result from solving zero-sum games between a predictor seeking the best performance and an adversary seeking the worst while required to (approximately) match certain structured properties of the training data. We explore this approach for word alignment (AER evaluation) and named entity recognition (F-score evaluation) with linear-chain constraints.", "text_perturb": "Many predicted structured object ( e. . , sequences , matchings , trees ) are evaluated using the F-score , alignment error rate ( AER ) , or other multivariate operation measures. Since inductively optimizing these measures using training data is typically computationally difficult , empirical risk minimization of surrogate losses is employed , using , eastward. gm. , the hinge loss for ( structured ) support vector car. These approximations often introduce a mismatch between the learner 's documentary and the desired application performance , leading to inconsistency. We take a different access : adversarially approximate training data while optimizing the exact F-score or AER. Structured predictions under this formulation result from solving zero-sum games between a predictor seeking the best performance and an adversary seeking the worst while required to ( roughly ) match certain structured properties of the training data. We explore this approach for word alinement ( AER evaluation ) and named entity recognition ( F-score evaluation ) with linear-chain constraints. ", "label": 1}
{"original_text": "Federated Learning (FL), arising as a novel secure learning paradigm, has received notable attention from the public. In each round of synchronous FL training, only a fraction of available clients are chosen to participate and the selection of which might have a direct or indirect effect on the training efficiency, as well as the final model performance. In this paper, we investigate the client selection problem under a volatile context, in which the local training of heterogeneous clients is likely to fail due to various kinds of reasons and in different levels of frequency. Intuitively, too much training failure might potentially reduce the training efficiency and therefore should be regulated through proper selection of clients. Being inspired, effective participation under a deadline-based aggregation mechanism is modeled as the objective function in our problem model, and the fairness degree, another critical factor that might influence the training performance, is covered as an expected constraint. For an efficient settlement for the proposed selection problem, we propose E3CS, a stochastic client selection scheme on the basis of an adversarial bandit solution and we further corroborate its effectiveness by conducting real data-based experiments. According to the experimental results, under a proper setting, our proposed selection scheme is able to achieve at least 20 percent and up to 50 percent of acceleration to a fixed model accuracy while maintaining the same level of final model accuracy, in comparison to the vanilla selection scheme in FL.", "text_perturb": "Federated Learning ( FL ) , arising as a novel secure learning paradigm , has received notable attention from the world. In each round of synchronous FL training , only a fraction of available clients are chosen to participate and the selection of which might have a direct or indirect effect on the training efficiency , as well as the last model performance. In this paper , we investigate the client selection problem under a volatile context , in which the local training of heterogeneous clients is likely to fail due to versatile kinds of reasons and in different levels of frequency. Intuitively , too much training failure might potentially deoxidise the training efficiency and therefore should be regulated through proper selection of clients. Being inspire , effective participation under a deadline-based aggregation mechanism is modeled as the objective function in our problem model , and the fairness degree , another critical factor that might influence the training performance , is covered as an expected constraint. For an effective settlement for the proposed selection problem , we propose E3CS , a stochastic client selection scheme on the basis of an adversarial bandit solution and we further corroborate its effectiveness by conducting real data-based experiments. According to the experimental results , under a proper setting , our proposed selection scheme is able to achieve at least 20 percent and up to 50 percent of acceleration to a fixed model accuracy while maintaining the same level of concluding model accuracy , in comparison to the vanilla selection scheme in FL. ", "label": 1}
{"original_text": "Huge amounts of digital videos are being produced and broadcast every day, leading to giant media archives. Effective techniques are needed to make such data accessible further. Automatic meta-data labelling of broadcast media is an essential task for multimedia indexing, where it is standard to use multi-modal input for such purposes. This paper describes a novel method for automatic detection of media genre and show identities using acoustic features, textual features or a combination thereof. Furthermore the inclusion of available meta-data, such as time of broadcast, is shown to lead to very high performance. Latent Dirichlet Allocation is used to model both acoustics and text, yielding fixed dimensional representations of media recordings that can then be used in Support Vector Machines based classification. Experiments are conducted on more than 1200 hours of TV broadcasts from the British Broadcasting Corporation (BBC), where the task is to categorise the broadcasts into 8 genres or 133 show identities. On a 200-hour test set, accuracies of 98.6 and 85.7 were achieved for genre and show identification respectively, using a combination of acoustic and textual features with meta-data.", "text_perturb": "Huge amounts of digital videos personify being produced and broadcast every day , leading to giant media archives. Effective techniques are necessitate to make such data accessible further. Automatic meta-data labelling of broadcast media is an essential task for multimedia indexing , where it is standard to use multi-modal input for such function. This paper describes a novel method for automatic detection of media genre and show identities using acoustical features , textual features or a combination thereof. Furthermore the inclusion of available meta-data , such as time of broadcast , is shown to lead to very high pitched performance. Latent Dirichlet Allocation is used to model both acoustics and text , yielding fixed dimensional mental representation of media recordings that can then be used in Support Vector Machines based classification. Experiments are conducted on more than 1200 hours of TV broadcasts from the British Broadcasting Corporation ( BBC ) , where the project is to categorise the broadcasts into 8 genres or 133 show identities. On a 200-hour test set , accuracy of 98. 6 and 85. 7 were achieved for genre and show identification respectively , using a combination of acoustic and textual feature with meta-data. ", "label": 1}
{"original_text": "The ABSTRACT is to be in fully-justified italicized text, at the top of the left-hand column, below the author and affiliation information. Use the word \"Abstract\" as the title, in 12-point Times, boldface type, centered relative to the column, initially capitalized. The abstract is to be in 10-point, single-spaced type. Leave two blank lines after the Abstract, then begin the main text. Look at previous CVPR abstracts to get a feel for style and length.", "text_perturb": "The ABSTRACT is to be in fully-justified italicized text , at the top of the left-hand column , below the writer and affiliation information. Use the word `` Abstract '' as the title , in 12-point Times , boldface type , centre relative to the column , initially capitalized. The precis is to be in 10-point , single-spaced type. Leave two clean lines after the Abstract , then begin the main text. Look at previous CVPR abstracts to get a spirit for style and length. ", "label": 1}
{"original_text": "In machine learning, asynchronous parallel stochastic gradient descent (APSGD) is broadly used to speed up the training process through multi-workers. Meanwhile, the time delay of stale gradients in asynchronous algorithms is generally proportional to the total number of workers, which brings additional deviation from the accurate gradient due to using delayed gradients. This may have a negative influence on the convergence of the algorithm. One may ask: How many workers can we use at most to achieve a good convergence and the linear speedup? In this paper, we consider the second-order convergence of asynchronous algorithms in non-convex optimization. We investigate the behaviors of APSGD with consistent read near strictly saddle points and provide a theoretical guarantee that if the total number of workers is bounded by O (K 1 3 M - 1 3) (K is the total steps and M is the mini-batch size), APSGD will converge to good stationary points (f (x), 2 f (x) - I, 2 O (1 M K and the linear speedup is achieved. Our works give the first theoretical guarantee on the second-order convergence for asynchronous algorithms. The technique we provide can be generalized to analyze other types of asynchronous algorithms to understand the behaviors of asynchronous algorithms in distributed asynchronous parallel training.", "text_perturb": "In machine learning , asynchronous parallel stochastic gradient descent ( APSGD ) live broadly used to speed up the training process through multi-workers. Meanwhile , the time delay of stale gradient in asynchronous algorithms is generally proportional to the total number of workers , which brings additional deviation from the accurate gradient due to using delayed gradient. This may have a electronegative influence on the convergence of the algorithm. One may ask : How many workers can we use at most to achieve a good convergence and the linear acceleration ? In this paper , we consider the second-order convergence of asynchronous algorithms in non-convex optimization. We investigate the behaviors of APSGD with consistent read near strictly saddle points and provide a theoretical guarantee that if the total number of workers is bounded by O ( K 1 3 M - 1 3 ) ( K is the total steps and M is the mini-batch size ) , APSGD will converge to beneficial stationary points ( f ( x ) , 2 f ( x ) - I , 2 O ( 1 M K and the linear speedup is achieved. Our works give the first theoretical warrant on the second-order convergence for asynchronous algorithms. The technique we provide can be generalized to analyze other character of asynchronous algorithms to understand the behaviors of asynchronous algorithms in distributed asynchronous parallel training. ", "label": 1}
{"original_text": "This paper proposes a feedback linearising law for single-track dynamic models, allowing the design of a trajectory tracking controller exploiting linear control theory. The main characteristics of this algorithm are its simplicity, its independence from any vehicle model parameter, apart from the position of the center of mass, and its robustness. In particular, a numerical bifurcation analysis demonstrates that, for physically meaningful values of the center of mass deviation, the equilibrium is structurally asymptotically stable. Experimental results, concerning the linearising law and its application as inner loop of a trajectory tracking controller, are also presented, confirming the effectiveness of the proposal.", "text_perturb": "This newspaper publisher proposes a feedback linearising law for single-track dynamic models , allowing the design of a trajectory tracking controller exploiting linear control theory. The main characteristics of this algorithm make up its simplicity , its independence from any vehicle model parameter , apart from the position of the center of mass , and its robustness. In especial , a numerical bifurcation analysis demonstrates that , for physically meaningful values of the center of mass deviation , the equilibrium is structurally asymptotically stable. Experimental results , concerning the linearising law and its application as inner closed circuit of a trajectory tracking controller , are also presented , confirming the effectiveness of the proposal. ", "label": 1}
{"original_text": "We consider infinitely repeated games with vector losses discounted over time. We characterize the set of minimal upper bounds on expected losses that a player can simultaneously guarantee across the different dimensions. Specifically, we show that this set is the fixed point of a set-valued dynamic programming operator. This approach also characterizes the strategies that achieve these bounds. These optimal strategies are shown to be independent of the player's own past actions and stationary relative to a compact state space obtained by parameterizing the set of the minimal bounds. We also present a computational procedure to approximate this set and the optimal strategies. We discuss two applications of our results: 1) characterization of the optimal strategy of the uninformed player in zero-sum discounted repeated games with incomplete information on one side; 2) characterization of the minmax optimal regret and the regret-optimal strategy in repeated games with discounted losses. Our approximation procedure can be used to compute approximately optimal strategies in both these applications. We illustrate this procedure by computing approximately regret-optimal strategies for the problem of prediction using expert advice from two and three experts under {0, 1 } - losses. Our numerical evaluations demonstrate improved performance over existing algorithms for this problem.", "text_perturb": "We consider infinitely repeated biz with vector losses discounted over time. We characterize the set of minimal upper bounds on expected losses that a participant can simultaneously guarantee across the different dimensions. Specifically , we show that this set is the fixed point of a set-valued dynamical programming operator. This approach as well characterizes the strategies that achieve these bounds. These optimal strategies are shown to be independent of the player 's own yesteryear actions and stationary relative to a compact state space obtained by parameterizing the set of the minimal bounds. We also exhibit a computational procedure to approximate this set and the optimal strategies. We discuss two applications of our results : 1 ) characterisation of the optimal strategy of the uninformed player in zero-sum discounted repeated games with incomplete information on one side ; 2 ) characterisation of the minmax optimal regret and the regret-optimal strategy in repeated games with discounted losses. Our approximation procedure can be used to compute approximately optimal strategy in both these applications. We illustrate this procedure by computing around regret-optimal strategies for the problem of prediction using expert advice from two and three experts under { 0 , 1 } - losses. Our numerical evaluations demonstrate improve performance over existing algorithms for this problem. ", "label": 1}
{"original_text": "With the widespread use of smartphones as recording devices and the massive growth in bandwidth, the number and volume of video collections has increased significantly in the last years. This poses novel challenges to the management of these large-scale video data and especially to the analysis of and retrieval from such video collections. At the same time, existing video datasets used for research and experimentation are either not large enough to represent current collections or do not reflect the properties of video commonly found on the Internet in terms of content, length, or resolution. In this paper, we introduce the Vimeo Creative Commons Collection, in short V3C, a collection of 28'450 videos (with overall length of about 3'800 hours) published under creative commons license on Vimeo. V3C comes with a shot segmentation for each video, together with the resulting keyframes in original as well as reduced resolution and additional metadata. It is intended to be used from 2019 at the International large-scale TREC Video Retrieval Evaluation campaign (TRECVid).", "text_perturb": "With the far flung use of smartphones as recording devices and the massive growth in bandwidth , the number and volume of video collections has increased significantly in the last years. This poses novel challenge to the management of these large-scale video data and especially to the analysis of and retrieval from such video collections. At the same time , existing video datasets used for research and experimentation are either not large enough to represent current collections or do not reflect the properties of video commonly found on the net in terms of content , length , or resolution. In this paper , we introduce the Vimeo Creative Commons Collection , in short V3C , a collection of 28'450 videos ( with overall length of about 3'800 hours ) bring out under creative commons license on Vimeo. V3C comes with a shot segmentation for each video , together with the lead keyframes in original as well as reduced resolution and additional metadata. It is intended to be use from 2019 at the International large-scale TREC Video Retrieval Evaluation campaign ( TRECVid ). ", "label": 1}
{"original_text": "In the past few years, the growth of e-commerce and digital marketing in Vietnam has generated a huge volume of opinionated data. Analyzing those data would provide enterprises with insight for better business decisions. In this work, as part of the Advosights project, we study sentiment analysis of product reviews in Vietnamese. The final solution is based on Self-attention neural networks, a flexible architecture for text classification task with about 90.16 of accuracy in 0.0124 second, a very fast inference time.", "text_perturb": "In the past few years , the ontogeny of e-commerce and digital marketing in Vietnam has generated a huge volume of opinionated data. Analyzing those data would provide enterprises with insight for well business decisions. In this work , as part of the Advosights labor , we study sentiment analysis of product reviews in Vietnamese. The final solution is based on Self-attention neural network , a flexible architecture for text classification task with about 90. 16 of truth in 0. 0124 second , a very fast inference fourth dimension. ", "label": 1}
{"original_text": "End-to-end (E2E) systems have played a more and more important role in automatic speech recognition (ASR) and achieved great performance. However, E2E systems recognize output word sequences directly with the input acoustic feature, which can only be trained on limited acoustic data. The extra text data is widely used to improve the results of traditional artificial neural network-hidden Markov model (ANN-HMM) hybrid systems. The involving of extra text data to standard E2E ASR systems may break the E2E property during decoding. In this paper, a novel modular E2E ASR system is proposed. The modular E2E ASR system consists of two parts: an acoustic-to-phoneme (A2P) model and a phoneme-to-word (P2W) model. The A2P model is trained on acoustic data, while extra data including large scale text data can be used to train the P2W model. This additional data enables the modular E2E ASR system to model not only the acoustic part but also the language part. During the decoding phase, the two models will be integrated and act as a standard acoustic-to-word (A2W) model. In other words, the proposed modular E2E ASR system can be easily trained with extra text data and decoded in the same way as a standard E2E ASR system. Experimental results on the Switchboard corpus show that the modular E2E model achieves better word error rate (WER) than standard A2W models.", "text_perturb": "End-to-end ( E2E ) systems have played a more and more important role in automatic speech recognition ( ASR ) and reach great performance. However , E2E systems recognize output word sequences directly with the input acoustical feature , which can only be trained on limited acoustical data. The extra text data embody widely used to improve the results of traditional artificial neural network-hidden Markov model ( ANN-HMM ) hybrid systems. The involving of extra text information to standard E2E ASR systems may break the E2E property during decoding. In this paper , a novel modular E2E ASR system is propose. The modular E2E ASR system consists of two share : an acoustic-to-phoneme ( A2P ) model and a phoneme-to-word ( P2W ) model. The A2P model follow trained on acoustic data , while extra data including large scale text data can be used to train the P2W model. This additional data enable the modular E2E ASR system to model not only the acoustic part but also the language part. During the decoding phase , the two models bequeath be integrated and act as a standard acoustic-to-word ( A2W ) model. In other words , the proposed modular E2E ASR system can be easily trained with extra text data and decoded in the same manner as a standard E2E ASR system. Experimental solution on the Switchboard corpus show that the modular E2E model achieves better word error rate ( WER ) than standard A2W models. ", "label": 1}
{"original_text": "Importance of visual context in scene understanding tasks is well recognized in the computer vision community. However, to what extent the computer vision models for image classification and semantic segmentation are dependent on the context to make their predictions is unclear. A model overly relying on context will fail when encountering objects in context distributions different from training data and hence it is important to identify these dependencies before we can deploy the models in the real-world. We propose a method to quantify the sensitivity of black-box vision models to visual context by editing images to remove selected objects and measuring the response of the target models. We apply this methodology on two tasks, image classification and semantic segmentation, and discover undesirable dependency between objects and context, for example that \"sidewalk\" segmentation relies heavily on \"cars\" being present in the image. We propose an object removal based data augmentation solution to mitigate this dependency and increase the robustness of classification and segmentation models to contextual variations. Our experiments show that the proposed data augmentation helps these models improve the performance in out-of-context scenarios, while preserving the performance on regular data.", "text_perturb": "Importance of visual context in tantrum understanding tasks is well recognized in the computer vision community. However , to what extent the computer vision models for image compartmentalization and semantic segmentation are dependent on the context to make their predictions is unclear. A model overly relying on context leave fail when encountering objects in context distributions different from training data and hence it is important to identify these dependencies before we can deploy the models in the real-world. We propose a method to quantify the sensitivity of black-box vision models to visual context by editing figure to remove selected objects and measuring the response of the target models. We apply this methodology on two tasks , image classification and semantic segmentation , and discover undesirable dependency between objects and context , for example that `` pavement '' segmentation relies heavily on `` cars '' being present in the image. We propose an object removal based data augmentation solution to mitigate this dependency and increase the robustness of classification and segmentation models to contextual magnetic declination. Our experimentation show that the proposed data augmentation helps these models improve the performance in out-of-context scenarios , while preserving the performance on regular data. ", "label": 1}
{"original_text": "Pedestrian detection algorithms are important components of mobile robots, such as autonomous vehicles, which directly relate to human safety. Performance disparities in these algorithms could translate into disparate impact in the form of biased accident outcomes. To evaluate the need for such concerns, we characterize the age and gender bias in the performance of state-of-the-art pedestrian detection algorithms. Our analysis is based on the INRIA Person Dataset extended with child, adult, male and female labels. We show that all of the 24 top-performing methods of the Caltech Pedestrian Detection Benchmark have higher miss rates on children. The difference is significant and we analyse how it varies with the classifier, features and training data used by the methods. Algorithms were also gender-biased on average but the performance differences were not significant. We discuss the source of the bias, the ethical implications, possible technical solutions and barriers.", "text_perturb": "Pedestrian detection algorithms are authoritative components of mobile robots , such as autonomous vehicles , which directly relate to human safety. Performance disparities in these algorithms could translate into disparate shock in the form of biased accident outcomes. To evaluate the need for such concerns , we characterize the age and gender preconception in the performance of state-of-the-art pedestrian detection algorithms. Our analysis is based on the INRIA individual Dataset extended with child , adult , male and female labels. We show that all of the 24 top-performing methods of the Caltech Pedestrian Detection Benchmark have higher miss rates on child. The difference represent significant and we analyse how it varies with the classifier , features and training data used by the methods. Algorithms were also gender-biased on average but the performance remainder were not significant. We discuss the source of the bias , the ethical implications , potential technical solutions and barriers. ", "label": 1}
{"original_text": "Neural networks are surprisingly good at interpolating and perform remarkably well when the training set examples resemble those in the test set. However, they are often unable to extrapolate patterns beyond the seen data, even when the abstractions required for such patterns are simple. In this paper, we first review the notion of extrapolation, why it is important, and how one could hope to tackle it. We then focus on a specific type of extrapolation, which is especially useful for natural language processing: generalization to sequences longer than those seen during training. We hypothesize that models with a separate content- and location-based attention are more likely to extrapolate than those with common attention mechanisms. We empirically support our claim for recurrent seq2seq models with our proposed attention on variants of the Lookup Table task. This sheds light on some striking failures of neural models for sequences and on possible methods to approaching such issues.", "text_perturb": "Neural networks are surprisingly good at interpolating and perform remarkably well when the training set examples resemble those in the test solidification. However , they are often unable to extrapolate patterns beyond the seen information , even when the abstractions required for such patterns are simple. In this composition , we first review the notion of extrapolation , why it is important , and how one could hope to tackle it. We then focus on a specific type of extrapolation , which is especially useful for natural language processing : generalization to sequences longer than those image during training. We hypothesize that models with a separate content- and location-based care are more likely to extrapolate than those with common care mechanisms. We empirically support our claim for recurrent seq2seq models with our proposed attention on random variable of the Lookup Table task. This sheds light on some striking failures of neural poser for sequences and on possible methods to approaching such issues. ", "label": 1}
{"original_text": "We present a local routing algorithm which guarantees delivery in all connected graphs embedded on a known surface of genus g. The algorithm transports O (g log n) memory and finishes in time O (g 2 n 2), where n is the size of the graph. It requires access to a homology basis for the surface. This algorithm, GFR, may be viewed as a suitable generalization of Face Routing (FR), the well-known algorithm for plane graphs, which we previously showed does not guarantee delivery in graphs embedded on positive genus surfaces. The problem for such surfaces is the potential presence of homologically non-trivial closed walks which may be traversed by the right-hand rule. We use an interesting mathematical property of homology bases (proven in Lemma) to show that such walks will not impede GFR. FR is at the base of most routing algorithms used in modern (2D) ad hoc networks: these algorithms all involve additional local techniques to deal with edge-crossings so FR may be applied. GFR should be viewed in the same light, as a base algorithm which could for example be tailored to sensor networks on surfaces in 3D. Currently there are no known efficient local, logarithmic memory algorithms for 3D ad hoc networks. From a theoretical point of view our work suggests that the efficiency advantages from which FR benefits are related to the codimension one nature of an embedded graph in a surface rather than the flatness of that surface (planarity).", "text_perturb": "We present a local routing algorithm which guarantees delivery in all connected graph embedded on a known surface of genus g. The algorithm transports O ( g log due north ) memory and finishes in time O ( g 2 n 2 ) , where due north is the size of the graph. It requires admission to a homology basis for the surface. This algorithm , GFR , may equal viewed as a suitable generalization of Face Routing ( FR ) , the well-known algorithm for plane graphs , which we previously showed does not guarantee delivery in graphs embedded on positive genus surfaces. The problem for such surfaces is the potential presence of homologically non-trivial close walks which may be traversed by the right-hand rule. We use an interesting mathematical property of homology bases ( proven in Lemma ) to testify that such walks will not impede GFR. FR is at the base of most routing algorithms used in modern ( 2D ) ad hoc networks : these algorithms all involve additional local techniques to deal with edge-crossings so FR may make up applied. GFR should be viewed in the same light , as a base algorithm which could for example be tailored to sensor networks on open in 3D. presently there are no known efficient local , logarithmic memory algorithms for 3D ad hoc networks. From a theoretical point of view our work suggests that the efficiency advantages from which FR benefits are tie in to the codimension one nature of an embedded graph in a surface rather than the flatness of that surface ( planarity ). ", "label": 1}
{"original_text": "The decision problems on matrices were intensively studied for many decades as matrix products play an essential role in the representation of various computational processes. However, many computational problems for matrix semigroups are inherently difficult to solve even for problems in low dimensions and most matrix semigroup problems become undecidable in general starting from dimension three or four. This paper solves two open problems about the decidability of the vector reachability problem over a finitely generated semigroup of matrices from SL (2, Z) and the point to point reachability (over rational numbers) for fractional linear transformations, where associated matrices are from SL (2, Z). The approach to solving reachability problems is based on the characterization of reachability paths between points which is followed by the translation of numerical problems on matrices into computational and combinatorial problems on words and formal languages. We also give a geometric interpretation of reachability paths and extend the decidability results to matrix products represented by arbitrary labelled directed graphs. Finally, we will use this technique to prove that a special case of the scalar reachability problem is decidable.", "text_perturb": "The decision problems on matrices were intensively studied for many decades as matrix products play an essential character in the representation of various computational processes. However , many computational problems for intercellular substance semigroups are inherently difficult to solve even for problems in low dimensions and most matrix semigroup problems become undecidable in general starting from dimension three or four. This paper solves two open problems about the decidability of the vector reachability problem over a finitely engender semigroup of matrices from SL ( 2 , Z ) and the point to point reachability ( over rational numbers ) for fractional linear transformations , where associated matrices are from SL ( 2 , Z ). The approach to solving reachability problems is based on the characterization of reachability way of life between points which is followed by the translation of numerical problems on matrices into computational and combinatorial problems on words and formal languages. We also give a geometric interpretation of reachability paths and continue the decidability results to matrix products represented by arbitrary labelled directed graphs. eventually , we will use this technique to prove that a special case of the scalar reachability problem is decidable. ", "label": 1}
{"original_text": "Existing techniques for Craig interpolation for the quantifier-free fragment of the theory of arrays are inefficient for computing sequence and tree interpolants: the solver needs to run for every partitioning (A, B) of the interpolation problem to avoid creating A B -mixed terms. We present a new approach using Proof Tree Preserving Interpolation and an array solver based on Weak Equivalence on Arrays. We give an interpolation algorithm for the lemmas produced by the array solver. The computed interpolants have worst-case exponential size for extensionality lemmas and worst-case quadratic size otherwise. We show that these bounds are strict in the sense that there are lemmas with no smaller interpolants. We implemented the algorithm and show that the produced interpolants are useful to prove memory safety for C programs.", "text_perturb": "Existing techniques for Craig interpolation for the quantifier-free fragment of the theory of arrays are ineffective for computing sequence and tree interpolants : the solver needs to run for every partitioning ( A , B ) of the interpolation problem to avoid creating A B -mixed terms. We present a new approach using Proof Tree Preserving insertion and an array solver based on Weak Equivalence on Arrays. We give an interpolation algorithm for the lemmas bring about by the array solver. The computed interpolants have worst-case exponential size for extensionality lemma and worst-case quadratic size otherwise. We show that these bounds are strict in the horse sense that there are lemmas with no smaller interpolants. We implemented the algorithm and show that the produced interpolants are useful to prove memory safety for atomic number  programs. ", "label": 1}
{"original_text": "Multi-target multi-camera tracking (MTMCT) systems track targets across cameras. Due to the continuity of target trajectories, tracking systems usually restrict their data association within a local neighborhood. In single camera tracking, local neighborhood refers to consecutive frames; in multi-camera tracking, it refers to neighboring cameras that the target may appear successively. For similarity estimation, tracking systems often adopt appearance features learned from the re-identification (re-ID) perspective. Different from tracking, re-ID usually does not have access to the trajectory cues that can limit the search space to a local neighborhood. Due to its global matching property, the re-ID perspective requires to learn global appearance features. We argue that the mismatch between the local matching procedure in tracking and the global nature of re-ID appearance features may compromise MTMCT performance. To fit the local matching procedure in MTMCT, in this work, we introduce locality aware appearance metric (LAAM). Specifically, we design an intra-camera metric for single camera tracking, and an inter-camera metric for multi-camera tracking. Both metrics are trained with data pairs sampled from their corresponding local neighborhoods, as opposed to global sampling in the re-ID perspective. We show that the locally learned metrics can be successfully applied on top of several globally learned re-ID features. With the proposed method, we report new state-of-the-art performance on the DukeMTMC dataset, and a substantial improvement on the CityFlow dataset.", "text_perturb": "Multi-target multi-camera tracking ( MTMCT ) systems track targets across cameras. Due to the continuity of quarry trajectories , tracking systems usually restrict their data association within a local neighborhood. In single camera tracking , local neighborhood refers to consecutive frames ; in multi-camera tracking , it refers to neighbor cameras that the target may appear successively. For similarity estimation , tracking systems often adopt appearance features discover from the re-identification ( re-ID ) perspective. Different from tracking , re-ID usually does not have access to the trajectory cues that can determine the search space to a local neighborhood. referable to its global matching property , the re-ID perspective requires to learn global appearance features. We argue that the mismatch between the local matching procedure in tracking and the global nature of re-ID coming into court features may compromise MTMCT performance. To fit the local matching procedure in MTMCT , in this work , we introduce locality mindful appearance metric ( LAAM ). specifically , we design an intra-camera metric for single camera tracking , and an inter-camera metric for multi-camera tracking. Both metrics are trained with data pairs sampled from their corresponding local neck of the woods , as opposed to global sampling in the re-ID perspective. We show that the locally read metrics can be successfully applied on top of several globally read re-ID features. With the proposed method acting , we report new state-of-the-art performance on the DukeMTMC dataset , and a substantial improvement on the CityFlow dataset. ", "label": 1}
{"original_text": "Currently, the visually impaired rely on either a sighted human, guide dog, or white cane to safely navigate. However, the training of guide dogs is extremely expensive, and canes cannot provide essential information regarding the color of traffic lights and direction of crosswalks. In this paper, we propose a deep learning based solution that provides information regarding the traffic light mode and the position of the zebra crossing. Previous solutions that utilize machine learning only provide one piece of information and are mostly binary: only detecting red or green lights. The proposed convolutional neural network, LYTNet, is designed for comprehensiveness, accuracy, and computational efficiency. LYTNet delivers both of the two most important pieces of information for the visually impaired to cross the road. We provide five classes of pedestrian traffic lights rather than the commonly seen three or four, and a direction vector representing the midline of the zebra crossing that is converted from the 2D image plane to real-world positions. We created our own dataset of pedestrian traffic lights containing over 5000 photos taken at hundreds of intersections in Shanghai. The experiments carried out achieve a classification accuracy of 94, average angle error of 6.35deg, with a frame rate of 20 frames per second when testing the network on an iPhone 7 with additional post-processing steps.", "text_perturb": "Currently , the visually impaired rely on either a sighted human being , guide dog , or white cane to safely navigate. However , the training of guide dogs is exceedingly expensive , and canes can not provide essential information regarding the color of traffic lights and direction of crosswalks. In this paper , we propose a deep learning based solution that provides information regarding the dealings light mode and the position of the zebra crossing. Previous solutions that utilize machine learning only provide one piece of information and are by and large binary : only detecting red or green lights. The proposed convolutional neural network , LYTNet , is project for comprehensiveness , accuracy , and computational efficiency. LYTNet delivers both of the two almost important pieces of information for the visually impaired to cross the road. We provide five classes of pedestrian traffic lights rather than the commonly seen three or four , and a direction vector representing the midline of the zebra crossing that is converted from the 2D image carpenters plane to real-world positions. We created our own dataset of prosaic traffic lights containing over 5000 photos taken at hundreds of intersections in Shanghai. The experiments carried out achieve a classification accuracy of 94 , modal angle error of 6. 35deg , with a form rate of 20 frames per second when testing the network on an iPhone 7 with additional post-processing steps. ", "label": 1}
{"original_text": "We initiate the study of indivisible chore allocation for agents with asymmetric shares. The fairness concept we focus on is the weighted natural generalization of maxmin share: WMMS fairness and OWMMS fairness. We first highlight the fact that commonly-used algorithms that work well for the allocation of goods to asymmetric agents, and even for chores to symmetric agents do not provide good approximations for allocation of chores to asymmetric agents under WMMS. As a consequence, we present a novel polynomial-time constant-approximation algorithm, via linear program, for OWMMS. For two special cases: the binary valuation case and the 2-agent case, we provide exact or better constant-approximation algorithms.", "text_perturb": "We initiate the study of indivisible chore allocation for agents with asymmetrical shares. The fairness concept we focus on is the weighted rude generalization of maxmin share : WMMS fairness and OWMMS fairness. We first highlight the fact that commonly-used algorithms that exploit well for the allocation of goods to asymmetric agents , and even for chores to symmetric agents do not provide good approximations for allocation of chores to asymmetric agents under WMMS. As a result , we present a novel polynomial-time constant-approximation algorithm , via linear program , for OWMMS. For two special face : the binary valuation case and the 2-agent case , we provide exact or better constant-approximation algorithms. ", "label": 1}
{"original_text": "This paper establishes theoretical bonafides for implicit concurrent multivariate effect evaluation - implicit concurrency 1 footnote 1 1 footnote 1 for short - a broad and versatile computational learning efficiency thought to underlie general-purpose, non-local, noise-tolerant optimization in genetic algorithms with uniform crossover (UGAs). We demonstrate that implicit concurrency is indeed a form of efficient learning by showing that it can be used to obtain close-to-optimal bounds on the time and queries required to approximately correctly solve a constrained version (k 7, e 1 5) of a recognizable computational learning problem: learning parities with noisy membership queries. We argue that a UGA that treats the noisy membership query oracle as a fitness function can be straightforwardly used to approximately correctly learn the essential attributes in O (log 1.585 n) queries and O (n log 1.585 n) time, where n is the total number of attributes. Our proof relies on an accessible symmetry argument and the use of statistical hypothesis testing to reject a global null hypothesis at the 10 - 100 level of significance. It is, to the best of our knowledge, the first relatively rigorous identification of efficient computational learning in an evolutionary algorithm on a non-trivial learning problem.", "text_perturb": "This paper establishes theoretical bonafides for implicit concurrent multivariate effect evaluation - implicit concurrency 1 footnote 1 1 footnote 1 for short - a broad and versatile computational learnedness efficiency thought to underlie general-purpose , non-local , noise-tolerant optimization in genetic algorithms with uniform crossover ( UGAs ). We demonstrate that implicit concurrency is indeed a form of efficient learning by showing that it can be used to receive close-to-optimal bounds on the time and queries required to approximately correctly solve a constrained version ( k 7 , e 1 5 ) of a recognizable computational learning problem : learning parities with noisy membership queries. We argue that a UGA that treats the noisy membership query oracle as a fitness function can be straightforwardly used to approximately correctly learn the essential attributes in oxygen ( log 1. 585 n ) queries and O ( n logarithm 1. 585 north ) time , where north is the total number of attributes. Our proof relies on an accessible proportion argument and the use of statistical hypothesis testing to reject a global null hypothesis at the 10 - 100 level of significance. It is , to the dear of our knowledge , the first relatively rigorous identification of efficient computational learning in an evolutionary algorithm on a non-trivial learning problem. ", "label": 1}
{"original_text": "Video-based person re-identification matches video clips of people across non-overlapping cameras. Most existing methods tackle this problem by encoding each video frame in its entirety and computing an aggregate representation across all frames. In practice, people are often partially occluded, which can corrupt the extracted features. Instead, we propose a new spatiotemporal attention model that automatically discovers a diverse set of distinctive body parts. This allows useful information to be extracted from all frames without succumbing to occlusions and misalignments. The network learns multiple spatial attention models and employs a diversity regularization term to ensure multiple models do not discover the same body part. Features extracted from local image regions are organized by spatial attention model and are combined using temporal attention. As a result, the network learns latent representations of the face, torso and other body parts using the best available image patches from the entire video sequence. Extensive evaluations on three datasets show that our framework outperforms the state-of-the-art approaches by large margins on multiple metrics.", "text_perturb": "Video-based person re-identification peer video clips of people across non-overlapping cameras. Most existing methods tackle this problem by encoding each video frame in its entirety and computing an aggregate theatrical across all frames. In practice , people are often partially obstruct , which can corrupt the extracted features. Instead , we propose a new spatiotemporal aid model that automatically discovers a diverse set of distinctive body parts. This leave useful information to be extracted from all frames without succumbing to occlusions and misalignments. The network see multiple spatial attention models and employs a diversity regularization term to ensure multiple models do not discover the same body part. Features extracted from local image regions equal organized by spatial attention model and equal combined using temporal attention. As a result , the network learns latent representations of the face , torso and other body parts apply the best available image patches from the entire video sequence. Extensive valuation on three datasets show that our framework outperforms the state-of-the-art approaches by large margins on multiple metrics. ", "label": 1}
{"original_text": "This paper deals with subsampled spectral gradient methods for minimizing finite sums. Subsample function and gradient approximations are employed in order to reduce the overall computational cost of the classical spectral gradient methods. The global convergence is enforced by a nonmonotone line search procedure. Global convergence is proved provided that functions and gradients are approximated with increasing accuracy. R-linear convergence and worst-case iteration complexity is investigated in case of strongly convex objective function. Numerical results on well known binary classification problems are given to show the effectiveness of this framework and analyze the effect of different spectral coefficient approximations arising from the variable sample nature of this procedure. Key words: spectral gradient methods, subsampling strategies, global convergence, nonmonotone line search.", "text_perturb": "This paper deals with subsampled spectral gradient method acting for minimizing finite sums. Subsample function and gradient approximations are employed in order to reduce the overall computational cost of the classical spectral gradient method acting. The global convergence is apply by a nonmonotone line search procedure. Global convergence is establish provided that functions and gradients are approximated with increasing accuracy. R-linear convergence and worst-case iteration complexity live investigated in case of strongly convex objective function. Numerical results on well known binary classification problems are given to show the effectiveness of this framework and analyze the effect of different ghostlike coefficient approximations arising from the variable sample nature of this procedure. Key words : spectral gradient methods , subsampling strategies , global convergence , nonmonotone line hunt. ", "label": 1}
{"original_text": "Current 6D object pose estimation methods usually require a 3D model for each object. These methods also require additional training in order to incorporate new objects. As a result, they are difficult to scale to a large number of objects and cannot be directly applied to unseen objects. We propose a novel framework for 6D pose estimation of unseen objects. We present a network that reconstructs a latent 3D representation of an object using a small number of reference views at inference time. Our network is able to render the latent 3D representation from arbitrary views. Using this neural renderer, we directly optimize for pose given an input image. By training our network with a large number of 3D shapes for reconstruction and rendering, our network generalizes well to unseen objects. We present a new dataset for unseen object pose estimation-MOPED. We evaluate the performance of our method for unseen object pose estimation on MOPED as well as the ModelNet and LINEMOD datasets. Our method performs competitively to supervised methods that are trained on those objects. Code and data will be available at", "text_perturb": "Current 6D object pose estimation methods usually involve a 3D model for each object. These method acting also require additional training in order to incorporate new objects. As a resultant , they are difficult to scale to a large number of objects and can not be directly applied to unseen objects. We nominate a novel framework for 6D pose estimation of unseen objects. We present a network that reconstructs a latent 3D representation of an object using a small number of reference aspect at inference time. Our network is able to render the latent 3D theatrical from arbitrary views. utilise this neural renderer , we directly optimize for pose given an input image. By training our network with a large number of 3D shapes for reconstruction and rendering , our network generalizes well to unobserved objects. We award a new dataset for unseen object pose estimation-MOPED. We judge the performance of our method for unseen object pose estimation on MOPED as well as the ModelNet and LINEMOD datasets. Our method performs competitively to supervised method that are trained on those objects. computer code and data will be available at", "label": 1}
{"original_text": "Under appropriate cooperation protocols and parameter choices, fully decentralized solutions for stochastic optimization have been shown to match the performance of centralized solutions and result in linear speedup (in the number of agents) relative to non-cooperative approaches in the strongly-convex setting. More recently, these results have been extended to the pursuit of first-order stationary points in non-convex environments. In this work, we examine in detail the dependence of second-order convergence guarantees on the spectral properties of the combination policy for non-convex multi agent optimization. We establish linear speedup in saddle-point escape time in the number of agents for symmetric combination policies and study the potential for further improvement by employing asymmetric combination weights. The results imply that a linear speedup can be expected in the pursuit of second-order stationary points, which exclude local maxima as well as strict saddle-points and correspond to local or even global minima in many important learning settings.", "text_perturb": "Under appropriate cooperation protocols and parameter choices , fully decentralized solutions for stochastic optimization have been shown to match the performance of centralized solutions and result in linear speedup ( in the number of agents ) relative to non-cooperative approaches in the strongly-convex scope. to a greater extent recently , these results have been extended to the pursuit of first-order stationary points in non-convex environments. In this work , we examine in detail the dependence of second-order convergence warrantee on the spectral properties of the combination policy for non-convex multi agent optimization. We establish linear speedup in saddle-point escape time in the number of agents for symmetric combination policies and study the potential for further improvement by hire asymmetric combination weights. The results imply that a linear speedup can be expected in the pursuit of second-order stationary points , which exclude local maxima as well as strict saddle-points and correspond to local or yet global minima in many important learning settings. ", "label": 1}
{"original_text": "In this paper, we propose a novel deep convolutional neural network (CNN) -based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyper parameter selection. The starting point of our work is the observation that unrolled iterative methods have the form of a CNN (filtering followed by point-wise non-linearity) when the normal operator (H H, the adjoint of H times H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill-posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a x 512 512 image on the GPU.", "text_perturb": "In this paper , we propose a novel deep convolutional neural network ( CNN ) -based algorithm for solving ill-posed opposite problems. Regularized iterative algorithms have emerged as the standard approaching to ill-posed inverse problems in the past few decades. These methods produce excellent results , but can be challenging to deploy in practice due to ingredient including the high computational cost of the forward and adjoint operators and the difficulty of hyper parameter selection. The starting point of our work embody the observation that unrolled iterative methods have the form of a CNN ( filtering followed by point-wise non-linearity ) when the normal operator ( H H , the adjoint of H times H ) of the forward model embody a convolution. establish on this observation , we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct upending encapsulates the physical model of the system , but leads to artifacts when the problem is ill-posed ; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction ( down to 50 views ) on parallel light beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a ten 512 512 image on the GPU. ", "label": 1}
{"original_text": "We analyze the adversarial examples problem in terms of a model's fault tolerance with respect to its input. Whereas previous work focuses on arbitrarily strict threat models, i.e., -perturbations, we consider arbitrary valid inputs and propose an information-based characteristic for evaluating tolerance to diverse input faults. 1 footnote 1 1 footnote 1 Source available at", "text_perturb": "We analyze the adversarial examples problem in terms of a model 's faulting tolerance with respect to its input. Whereas previous work focuses on every which way strict threat models , i. due east. , -perturbations , we see arbitrary valid inputs and propose an information-based characteristic for evaluating tolerance to diverse input faults. 1 footnote 1 1 footnote 1 Source available at", "label": 1}
{"original_text": "We show that Delaunay triangulations and compressed quadtrees are equivalent structures. More precisely, we give two algorithms: the first computes a compressed quadtree for a planar point set, given the Delaunay triangulation; the second finds the Delaunay triangulation, given a compressed quadtree. Both algorithms run in deterministic linear time on a pointer machine. Our work builds on and extends previous results by Krznaric and Levcopolous and Buchin and Mulzer. Our main tool for the second algorithm is the well-separated pair decomposition (WSPD), a structure that has been used previously to find Euclidean minimum spanning trees in higher dimensions. We show that knowing the WSPD (and a quadtree) suffices to compute a planar Euclidean minimum spanning tree (EMST) in linear time. With the EMST at hand, we can find the Delaunay triangulation in linear time. As a corollary, we obtain deterministic versions of many previous algorithms related to Delaunay triangulations, such as splitting planar Delaunay triangulations, preprocessing imprecise points for faster Delaunay computation, and transdichotomous Delaunay triangulations.", "text_perturb": "We show that Delaunay triangulations and compressed quadtrees constitute equivalent structures. More precisely , we ease up two algorithms : the first computes a compressed quadtree for a planar point set , given the Delaunay triangulation ; the second finds the Delaunay triangulation , given a compressed quadtree. Both algorithms run in deterministic linear sentence on a pointer machine. Our work physique on and extends previous results by Krznaric and Levcopolous and Buchin and Mulzer. Our main tool for the second algorithm is the well-separated pair decomposition ( WSPD ) , a structure that has been used previously to find Euclidean minimum spanning sir herbert beerbohm tree in higher dimensions. We show that knowing the WSPD ( and a quadtree ) suffices to compute a planar Euclidean minimum sweep tree ( EMST ) in linear time. With the EMST at hand , we can find the Delaunay triangulation in elongate time. As a corollary , we obtain deterministic versions of many previous algorithms colligate to Delaunay triangulations , such as splitting planar Delaunay triangulations , preprocessing imprecise points for faster Delaunay computation , and transdichotomous Delaunay triangulations. ", "label": 1}
{"original_text": "This paper presents our methodology and toolbox that allows analyzing the radio access network security of laboratory and commercial 4G and future 5G cellular networks. We leverage a free open-source software suite that implements the LTE UE and eNB enabling real-time signaling using software radio peripherals. We modify the UE software processing stack to act as an LTE packet collection and examination tool. This is possible because of the openness of the 3GPP specifications. Hence, we are able to receive and decode LTE downlink messages for the purpose of analyzing potential security problems of the standard. This paper shows how to rapidly prototype LTE tools and build a software-defined radio access network (RAN) analysis instrument for research and education. Using CSAI, the Cellular RAN Security Analysis Instrument, a researcher can analyze broadcast and paging messages of cellular networks. CSAI is also able to test networks to aid in the identification of vulnerabilities and verify functionality post-remediation. Additionally, we found that it can crash an eNB which motivates equivalent analyses of commercial network equipment and its robustness against denial of service attacks.", "text_perturb": "This paper presents our methodology and toolbox that allows analyzing the radio access network security of laboratory and commercial grade 4G and future 5G cellular networks. We leverage a free open-source software suite that implements the LTE UE and eNB enable real-time signaling using software radio peripherals. We modify the UE software work stack to act as an LTE packet collection and examination tool. This is potential because of the openness of the 3GPP specifications. Hence , we are able to receive and decode LTE downlink messages for the purpose of analyzing potential security trouble of the standard. This paper shows how to speedily prototype LTE tools and build a software-defined radio access network ( RAN ) analysis instrument for research and education. Using CSAI , the Cellular RAN Security Analysis Instrument , a researcher can analyze broadcast and page messages of cellular networks. CSAI is also able to test networks to assist in the identification of vulnerabilities and verify functionality post-remediation. Additionally , we found that it can crash an eNB which motivates equivalent analysis of commercial network equipment and its robustness against denial of service attacks. ", "label": 1}
{"original_text": "Over the last 30 years, researchers have investigated connections between dimension for posets and planarity for graphs. Here we extend this line of research to the structural graph theory parameter tree-width by proving that the dimension of a finite poset is bounded in terms of its height and the tree-width of its cover graph.", "text_perturb": "Over the last 30 years , researchers have investigated connections between dimension for posets and planarity for graph. Here we stretch forth this line of research to the structural graph theory parameter tree-width by proving that the dimension of a finite poset is bounded in terms of its height and the tree-width of its cover graph. ", "label": 1}
{"original_text": "Text-level discourse parsing aims to unmask how two segments (or sentences) in the text are related to each other. We propose the task of Visual Discourse Parsing, which requires understanding discourse relations among scenes in a video. Here we use the term scene to refer to a subset of video frames that can better summarize the video. In order to collect a dataset for learning discourse cues from videos, one needs to manually identify the scenes from a large pool of video frames and then annotate the discourse relations between them. This is clearly a time consuming, expensive and tedious task. In this work, we propose an approach to identify discourse cues from the videos without the need to explicitly identify and annotate the scenes. We also present a novel dataset containing 310 videos and the corresponding discourse cues to evaluate our approach. We believe that many of the multi-discipline Artificial Intelligence problems such as Visual Dialog and Visual Storytelling would greatly benefit from the use of visual discourse cues.", "text_perturb": "Text-level discourse parsing aims to unmask how two segments ( or sentences ) in the text are pertain to each other. We propose the task of Visual Discourse Parsing , which requires understanding discourse relations among tantrum in a video. Here we use the term picture to refer to a subset of video frames that can better summarize the video. In order to collect a dataset for learning discourse cues from videos , one needs to manually identify the scenes from a large pool of video frames and and so annotate the discourse relations between them. This is clearly a metre consuming , expensive and tedious task. In this work , we project an approach to identify discourse cues from the videos without the need to explicitly identify and annotate the scenes. We besides present a novel dataset containing 310 videos and the corresponding discourse cues to evaluate our approach. We believe that many of the multi-discipline Artificial intelligence operation problems such as Visual Dialog and Visual Storytelling would greatly benefit from the use of visual discourse cues. ", "label": 1}
{"original_text": "A new Bayesian state and parameter learning algorithm for multiple target tracking (MTT) models with image observations is proposed. Specifically, a Markov chain Monte Carlo algorithm is designed to sample from the posterior distribution of the unknown number of targets, their birth and death times, states and model parameters, which constitutes the complete solution to the tracking problem. The conventional approach is to pre-process the images to extract point observations and then perform tracking. We model the image generation process directly to avoid potential loss of information when extracting point observations. Numerical examples show that our algorithm has improved tracking performance over commonly used techniques, for both synthetic examples and real florescent microscopy data, especially in the case of dim targets with overlapping illuminated regions.", "text_perturb": "A new Bayesian state and parameter learning algorithmic rule for multiple target tracking ( MTT ) models with image observations is proposed. Specifically , a Markov chain Monte Carlo algorithm is designed to sample from the posterior distribution of the unknown identification number of targets , their birth and death times , states and model parameters , which constitutes the complete solution to the tracking problem. The conventional approach is to pre-process the images to extract point observations and and then perform tracking. We model the image propagation process directly to avoid potential loss of information when extracting point observations. Numerical examples show that our algorithm experience improved tracking performance over commonly used techniques , for both synthetic examples and real florescent microscopy data , especially in the case of dim targets with overlapping illuminated regions. ", "label": 1}
{"original_text": "Convolutional neural networks (CNNs) can be applied to graph similarity matching, in which case they are called graph CNNs. Graph CNNs are attracting increasing attention due to their effectiveness and efficiency. However, the existing convolution approaches focus only on regular data forms and require the transfer of the graph or key node neighborhoods of the graph into the same fixed form. During this transfer process, structural information of the graph can be lost, and some redundant information can be incorporated. To overcome this problem, we propose the disordered graph convolutional neural network (DGCNN) based on the mixed Gaussian model, which extends the CNN by adding a preprocessing layer called the disordered graph convolutional layer (DGCL). The DGCL uses a mixed Gaussian function to realize the mapping between the convolution kernel and the nodes in the neighborhood of the graph. The output of the DGCL is the input of the CNN. We further implement a backward-propagation optimization process of the convolutional layer by which we incorporate the feature-learning model of the irregular node neighborhood structure into the network. Thereafter, the optimization of the convolution kernel becomes part of the neural network learning process. The DGCNN can accept arbitrary scaled and disordered neighborhood graph structures as the receptive fields of CNNs, which reduces information loss during graph transformation. Finally, we perform experiments on multiple standard graph datasets. The results show that the proposed method outperforms the state-of-the-art methods in graph classification and retrieval.", "text_perturb": "Convolutional neuronal networks ( CNNs ) can be applied to graph similarity matching , in which case they are called graph CNNs. Graph CNNs are attracting increasing attention due to their effectivity and efficiency. However , the existing convolution approaches focus only on regular data forms and involve the transfer of the graph or key node neighborhoods of the graph into the same fixed form. During this transfer process , structural information of the graph can be lost , and some extra information can be incorporated. To overcome this problem , we propose the disordered graphical record convolutional neural network ( DGCNN ) based on the mixed Gaussian model , which extends the CNN by adding a preprocessing layer called the disordered graphical record convolutional layer ( DGCL ). The DGCL uses a mixed Gaussian function to make the mapping between the convolution kernel and the nodes in the neighborhood of the graph. The yield of the DGCL is the input of the CNN. We further implement a backward-propagation optimization process of the convolutional layer by which we incorporate the feature-learning model of the irregular thickening neighborhood structure into the network. Thereafter , the optimization of the convolution substance becomes part of the neural network learning process. The DGCNN can accept arbitrary scaled and disordered neighborhood graph structures as the receptive line of business of CNNs , which reduces information loss during graph transformation. at long last , we perform experiments on multiple standard graph datasets. The results show that the proposed method outperforms the state-of-the-art methods in graph compartmentalization and retrieval. ", "label": 1}
{"original_text": "This paper presents a tool for addressing a key component in many algorithms for planning robot trajectories under uncertainty: evaluation of the safety of a robot whose actions are governed by a closed-loop feedback policy near a nominal planned trajectory. We describe an adaptive importance sampling Monte Carlo framework that enables the evaluation of a given control policy for satisfaction of a probabilistic collision avoidance constraint which also provides an associated certificate of accuracy (in the form of a confidence interval). In particular this adaptive technique is well-suited to addressing the complexities of rigid-body collision checking applied to non-linear robot dynamics. As a Monte Carlo method it is amenable to parallelization for computational tractability, and is generally applicable to a wide gamut of simulatable systems, including alternative noise models. Numerical experiments demonstrating the effectiveness of the adaptive importance sampling procedure are presented and discussed.", "text_perturb": "This paper presents a tool for turn to a key component in many algorithms for planning robot trajectories under uncertainty : evaluation of the safety of a robot whose actions are governed by a closed-loop feedback policy near a nominal planned trajectory. We describe an adaptive importance sampling Monte Carlo framework that enable the evaluation of a given control policy for satisfaction of a probabilistic collision avoidance constraint which also provides an associated certificate of accuracy ( in the form of a confidence interval ). In particular this adaptative technique is well-suited to addressing the complexities of rigid-body collision checking applied to non-linear robot dynamics. As a monte Carlo method it is amenable to parallelization for computational tractability , and is generally applicable to a wide gamut of simulatable systems , including alternative noise models. Numerical experiments demonstrating the effectiveness of the adaptive importance sampling procedure are presented and talk about. ", "label": 1}
{"original_text": "Safety remains a central obstacle preventing widespread use of RL in the real world: learning new tasks in uncertain environments requires extensive exploration, but safety requires limiting exploration. We propose Recovery RL, an algorithm which navigates this tradeoff by (1) leveraging offline data to learn about constraint violating zones before policy learning and (2) separating the goals of improving task performance and constraint satisfaction across two policies: a task policy that only optimizes the task reward and a recovery policy that guides the agent to safety when constraint violation is likely. We evaluate Recovery RL on 6 simulation domains, including two contact-rich manipulation tasks and an image-based navigation task, and an image-based obstacle avoidance task on a physical robot. We compare Recovery RL to 5 prior safe RL methods which jointly optimize for task performance and safety via constrained optimization or reward shaping and find that Recovery RL outperforms the next best prior method across all domains. Results suggest that Recovery RL trades off constraint violations and task successes 2 - 80 times more efficiently in simulation domains and 3 times more efficiently in physical experiments. See for videos and supplementary material.", "text_perturb": "Safety remains a central obstacle preventing far flung use of RL in the real world : learning new tasks in uncertain environments requires extensive exploration , but safety requires limiting exploration. We propose Recovery RL , an algorithm which navigates this tradeoff by ( 1 ) leveraging offline data to learn about constraint violating zones before policy learning and ( 2 ) separating the goals of improving task performance and constraint satisfaction across two policies : a task policy that only optimizes the task reward and a recovery policy that conduct the agent to safety when constraint violation is likely. We evaluate Recovery RL on 6 simulation domains , including two contact-rich manipulation tasks and an image-based navigation task , and an image-based obstacle avoidance task on a physical automaton. We compare Recovery RL to 5 prior safe RL methods which jointly optimize for task performance and safety via constrained optimization or reward shaping and find that Recovery RL outperforms the next best prior method acting across all domains. Results suggest that Recovery RL trades off constraint rape and task successes 2 - 80 times more efficiently in simulation domains and 3 times more efficiently in physical experiments. See for videos and supplementary cloth. ", "label": 1}
{"original_text": "We consider the following problem for oriented graphs and digraphs: Given an oriented graph (digraph) G , does it contain an induced subdivision of a prescribed digraph D ? The complexity of this problem depends on D and on whether G must be an oriented graph or is allowed to contain 2-cycles. We give a number of examples of polynomial instances as well as several NP-completeness proofs. Keywords: NP-completeness, induced paths and cycles, linkings, 3-SAT.", "text_perturb": "We consider the following problem for oriented graph and digraphs : Given an oriented graph ( digraph ) G , does it contain an induced subdivision of a prescribed digraph D ? The complexity of this problem depends on D and on whether G must be an oriented graph or is allowed to contain 2-cycles. We give a number of examples of polynomial instances equally well as several NP-completeness proofs. Keywords : NP-completeness , induced paths and cycles , linkings , 3-SAT. ", "label": 1}
{"original_text": "In this paper, we provide a philosophical account of the value of creative systems for individuals and society. We characterize creativity in very broad philosophical terms, encompassing natural, existential, and social creative processes, such as natural evolution and entrepreneurship, and explain why creativity understood in this way is instrumental for advancing human well-being in the long term. We then explain why current mainstream AI tends to be anti-creative, which means that there are moral costs of employing this type of AI in human endeavors, although computational systems that involve creativity are on the rise. In conclusion, there is an argument for ethics to be more hospitable to creativity-enabling AI, which can also be in a trade-off with other values promoted in AI ethics, such as its explainability and accuracy.", "text_perturb": "In this paper , we provide a philosophical account of the note value of creative systems for individuals and society. We characterize creativeness in very broad philosophical terms , encompassing natural , existential , and social creative processes , such as natural evolution and entrepreneurship , and explain why creativeness understood in this way is instrumental for advancing human well-being in the long term. We then explain why current mainstream army intelligence tends to be anti-creative , which means that there are moral costs of employing this type of army intelligence in human endeavors , although computational systems that involve creativity are on the rise. In conclusion , there be an argument for ethics to be more hospitable to creativity-enabling AI , which can also be in a trade-off with other values promoted in AI ethics , such as its explainability and accuracy. ", "label": 1}
{"original_text": "Contrary to the situation with stochastic gradient descent, we argue that when using stochastic methods with variance reduction, such as SDCA, SAG or SVRG, as well as their variants, it could be beneficial to reuse previously used samples instead of fresh samples, even when fresh samples are available. We demonstrate this empirically for SDCA, SAG and SVRG, studying the optimal sample size one should use, and also uncover behavior that suggests running SDCA for an integer number of epochs could be wasteful.", "text_perturb": "Contrary to the situation with stochastic gradient descent , we argue that when using stochastic methods with variance reduction , such as SDCA , SAG or SVRG , as well as their variants , it could be beneficial to reuse previously used sample distribution instead of fresh sample distribution , even when fresh sample distribution are available. We demonstrate this empirically for SDCA , SAG and SVRG , studying the optimal sample size one should use , and also uncover behavior that suggests running SDCA for an integer number of epochs could live wasteful. ", "label": 1}
{"original_text": "We propose a novel approach framed in terms of information theory and entropyto tackle the issue of conspiracy theories propagation. We start with thereport of an event (such as 911 terroristic attack) represented as a series ofindividual strings of information denoted respectively by two-state variableEi-1, i1,..., N. Assigning Ei value to all strings, the initial orderparameter and entropy are determined. Conspiracy theorists comment on thereport, focusing repeatedly on several strings Ek and changing their meaning (from -1 to 1). The reading of the event is turned fuzzy with an increasedentropy value. Beyond some threshold value of entropy, chosen by simplicity toits maximum value, meaning N2 variables with Ei1, doubt prevails in thereading of the event and the chance is created that an alternative theory mightprevail. Therefore, the evolution of the associated entropy is a way to measurethe degree of penetration of a conspiracy theory. Our general framework relieson online content made voluntarily available by crowds of people, in responseto some news or blog articles published by official news agencies. We applydifferent aggregation levels (comment, person, discussion thread) and discussthe associated patterns of entropy change.", "text_perturb": "We propose a fresh approach framed in terms of information theory and entropyto tackle the issue of conspiracy theories propagation. We start with thereport of an event ( such as 911 terroristic attack ) play as a series ofindividual strings of information denoted respectively by two-state variableEi-1 , i1 ,. . . , atomic number . Assigning Ei value to all strings , the initial orderparameter and entropy follow determined. Conspiracy theorist comment on thereport , focusing repeatedly on several strings Ek and changing their meaning ( from -1 to 1 ). The reading of the consequence is turned fuzzy with an increasedentropy value. Beyond some threshold note value of entropy , chosen by simplicity toits maximum note value , meaning N2 variables with Ei1 , doubt prevails in thereading of the event and the chance is created that an alternative theory mightprevail. Therefore , the evolution of the associated randomness is a way to measurethe degree of penetration of a conspiracy theory. Our general framework relieson online content made voluntarily available by crowds of people , in responseto some news or web log articles published by official news agencies. We applydifferent aggregation levels ( comment , person , discussion thread ) and discussthe associated patterns of entropy alteration. ", "label": 1}
{"original_text": "Software defined networking (SDN) has been adopted to enforce the security of large-scale and complex networks because of its programmable, abstract, centralized intelligent control and global and real-time traffic view. However, the current SDN-based security enforcement mechanisms require network managers to fully understand the underlying configurations of network. Facing the increasingly complex and huge SDN networks, we urgently need a novel security policy management mechanism which can be completely transparent to any underlying information. That is it can permit network managers to define upper-level security policies without containing any underlying information of network, and by means of model transformation system, these upper-level security policies can be transformed into their corresponding lower-level policies containing underlying information automatically. Moreover, it should ensure system model updated by the generated lower-level policies can hold all of security properties defined in upper-level policies. Based on these insights, we propose a security policy model transformation and verification approach for SDN in this paper. We first present the formal definition of a security policy model (SPM) which can be used to specify the security policies used in SDN. Then, we propose a model transformation system based on SDN system model and mapping rules, which can enable network managers to convert SPM model into corresponding underlying network configuration policies automatically, i.e., flow table model (FTM). In order to verify SDN system model updated by the generated FTM models can hold the security properties defined in SPM models, we design a security policy verification system based on model checking. Finally, we utilize a comprehensive case to illustrate the feasibility of the proposed approach.", "text_perturb": "Software defined networking ( SDN ) has been adopted to enforce the security of large-scale and complex networks because of its programmable , abstract , centralized intelligent control and global and real-time dealings view. However , the current SDN-based security enforcement mechanisms require network managers to fully understand the underlying conformation of network. Facing the increasingly complex and huge SDN networks , we desperately need a novel security policy management mechanism which can be completely transparent to any underlying information. That is it can permit network managers to define upper-level security policies without containing any fundamental information of network , and by means of model transformation system , these upper-level security policies can be transformed into their corresponding lower-level policies containing fundamental information automatically. furthermore , it should ensure system model updated by the generated lower-level policies can hold all of security properties defined in upper-level policies. Based on these insights , we propose a security policy model transformation and verification attack for SDN in this paper. We first present the formal definition of a security policy model ( SPM ) which can be habituate to specify the security policies habituate in SDN. Then , we propose a model transmutation system based on SDN system model and mapping rules , which can enable network managers to convert SPM model into corresponding underlying network configuration policies automatically , i. eastward. , flow table model ( FTM ). In order to verify SDN system model updated by the generated FTM simulation can hold the security properties defined in SPM simulation , we design a security policy verification system based on model checking. Finally , we utilize a comprehensive case to exemplify the feasibility of the proposed approach. ", "label": 1}
{"original_text": "One long-standing question in epidemiological research is how best to allocate limited amounts of vaccine or similar preventative measures in order to minimize the severity of an epidemic. Much of the literature on the problem of vaccine allocation has focused on influenza epidemics and used mathematical models of epidemic spread to determine the effectiveness of proposed methods. Our work applies computational models of epidemics to the problem of geographically allocating a limited number of vaccines within several Texas counties. We developed a graph-based, stochastic model for epidemics that is based on the SEIR model, and tested vaccine allocation methods based on multiple centrality measures. This approach provides an alternative method for addressing the vaccine allocation problem, which can be combined with more conventional approaches to yield more effective epidemic suppression strategies. We found that allocation methods based on in-degree and inverse betweenness centralities tended to be the most effective at containing epidemics.", "text_perturb": "One long-standing question in epidemiological research is how best to allocate limited amounts of vaccine or similar preventative measures in order to minimize the hardness of an epidemic. Much of the lit on the problem of vaccine allocation has focused on influenza epidemics and used mathematical models of epidemic spread to determine the effectiveness of proposed methods. Our work applies computational models of epidemics to the problem of geographically allocating a limited number of vaccines within several Texas county. We rise a graph-based , stochastic model for epidemics that is based on the SEIR model , and tested vaccine allocation methods based on multiple centrality measures. This approach provides an alternative method for addressing the vaccine allocation problem , which can be combined with more conventional approaches to yield more good epidemic suppression strategies. We found that allocation methods based on in-degree and inverse betweenness centralities tended to be the near effective at containing epidemics. ", "label": 1}
{"original_text": "Internet of Things (IoT) is the next big evolutionary step in the world of internet. The main intention behind the IoT is to enable safer living and risk mitigation on different levels of life. With the advent of IoT botnets, the view towards IoT devices has changed from enabler of enhanced living into Internet of vulnerabilities for cyber criminals. IoT botnets has exposed two different glaring issues, 1) A large number of IoT devices are accessible over public Internet. 2) Security (if considered at all) is often an afterthought in the architecture of many wide spread IoT devices. In this article, we briefly outline the anatomy of the IoT botnets and their basic mode of operations. Some of the major DDoS incidents using IoT botnets in recent times along with the corresponding exploited vulnerabilities will be discussed. We also provide remedies and recommendations to mitigate IoT related cyber risks and briefly illustrate the importance of cyber insurance in the modern connected world.", "text_perturb": "Internet of Things ( IoT ) is the next big evolutionary step in the world of net. The main intention behind the IoT is to enable safer living and risk mitigation on dissimilar levels of life. With the second advent of IoT botnets , the view towards IoT devices has changed from enabler of enhanced living into Internet of vulnerabilities for cyber criminals. IoT botnets has exposed two different glaring issues , 1 ) A large number of IoT devices are accessible over public cyberspace. 2 ) Security ( if see at all ) is often an afterthought in the architecture of many wide spread IoT devices. In this article , we briefly outline the anatomy of the IoT botnets and their basic mode of surgical process. Some of the major DDoS incidents using IoT botnets in recent times along with the corresponding exploited vulnerabilities leave be discussed. We too provide remedies and recommendations to mitigate IoT related cyber risks and briefly illustrate the importance of cyber insurance in the modern connected world. ", "label": 1}
{"original_text": "Lekkerkerker and Boland characterized the minimal forbidden induced subgraphs for the class of interval graphs. We give a linear-time algorithm to find one in any graph that is not an interval graph. Tucker characterized the minimal forbidden submatrices of binary matrices that do not have the consecutive-ones property. We give a linear-time algorithm to find one in any binary matrix that does not have the consecutive-ones property.", "text_perturb": "Lekkerkerker and Boland characterized the minimal forbidden induced subgraphs for the class of interval graphical record. We give a linear-time algorithm to find one in any graph that is not an time interval graph. Tucker characterize the minimal forbidden submatrices of binary matrices that do not have the consecutive-ones property. We give a linear-time algorithm to find one in any binary ground substance that does not have the consecutive-ones property. ", "label": 1}
{"original_text": "Detecting communities has long been popular in the research on networks. It is usually modeled as an unsupervised clustering problem on graphs, based on heuristic assumptions about community characteristics, such as edge density and node homogeneity. In this work, we doubt the universality of these widely adopted assumptions and compare human labeled communities with machine predicted ones obtained via typical mainstream algorithms. Based on supportive results, we argue that communities are defined by their underlying social patterns and unsupervised learning algorithms based on heuristics is incapable of capturing their various forms. Therefore, we propose to inject supervision into community detection through Community Oriented Network Embedding (CONE), which leverages limited ground-truth communities as examples to learn an embedding model aware of the underlying social patterns. Specifically, a deep architecture is developed by combining recurrent neural networks with random-walks on graphs towards capturing social patterns directed by ground-truth communities. Generic clustering algorithms on the embeddings of other nodes produced by the learned model then effectively reveals more communities that share similar social patterns with the ground-truth ones.", "text_perturb": "Detecting community of interests has long been popular in the research on networks. It is usually modeled as an unsupervised clustering problem on graphs , based on heuristic assumptions about community characteristics , such as bound density and node homogeneity. In this employment , we doubt the universality of these widely adopted assumptions and compare human labeled communities with machine predicted ones obtained via typical mainstream algorithms. Based on supportive results , we argue that communities are defined by their underlying societal patterns and unsupervised learning algorithms based on heuristics is incapable of capturing their various forms. Therefore , we propose to inject supervision into community detection through Community Oriented Network Embedding ( CONE ) , which leverages limited ground-truth communities as examples to watch an embedding model aware of the underlying social patterns. Specifically , a deep architecture is developed by combining recurrent neural networks with random-walks on graphs towards capturing social patterns engineer by ground-truth communities. Generic clustering algorithms on the embeddings of other nodes produced by the learned model then effectively reveals more biotic community that share similar social patterns with the ground-truth ones. ", "label": 1}
{"original_text": "The study of multiplicative noise models has a long history in control theory but is re-emerging in the context of complex networked systems and systems with learning-based control. We consider linear system identification with multiplicative noise from multiple state-input trajectory data. We propose exploratory input signals along with a least-squares algorithm to simultaneously estimate nominal system parameters and multiplicative noise covariance matrices. The asymptotic consistency of the least-squares estimator is demonstrated by analyzing first and second moment dynamics of the system. The results are illustrated by numerical simulations.", "text_perturb": "The study of multiplicative noise models has a long history in control theory but is re-emerging in the context of complex networked scheme and scheme with learning-based control. We consider linear system identification with multiplicative noise from multiple state-input trajectory data point. We propose exploratory input signals along with a least-squares algorithm to simultaneously estimate nominal system parameters and multiplicative noise covariance intercellular substance. The asymptotic consistency of the least-squares estimator embody demonstrated by analyzing first and second moment dynamics of the system. The results are illustrated by numerical model. ", "label": 1}
{"original_text": "In this work, we propose a purely geometrical approach for the robust matching of line segments for challenging stereo streams with severe illumination changes or High Dynamic Range (HDR) environments. To that purpose, we exploit the univocal nature of the matching problem, i.e. every observation must be corresponded with a single feature or not corresponded at all. We state the problem as a sparse, convex, l 1 -minimization of the matching vector regularized by the geometric constraints. This formulation allows for the robust tracking of line segments along sequences where traditional appearance-based matching techniques tend to fail due to dynamic changes in illumination conditions. Moreover, the proposed matching algorithm also results in a considerable speed-up of previous state of the art techniques making it suitable for real-time applications such as Visual Odometry (VO). This, of course, comes at expense of a slightly lower number of matches in comparison with appearance-based methods, and also limits its application to continuous video sequences, as it is rather constrained to small pose increments between consecutive frames. We validate the claimed advantages by first evaluating the matching performance in challenging video sequences, and then testing the method in a benchmarked point and line based VO algorithm.", "text_perturb": "In this work , we propose a strictly geometrical approach for the robust matching of line segments for challenging stereo streams with severe illumination changes or High Dynamic Range ( HDR ) environments. To that purpose , we exploit the unambiguous nature of the matching problem , i. tocopherol. every observation must be corresponded with a single feature or non corresponded at all. We province the problem as a sparse , convex , l 1 -minimization of the matching vector regularized by the geometric constraints. This formulation allows for the robust tracking of line segments along sequence where traditional appearance-based matching techniques tend to fail due to dynamic changes in illumination conditions. Moreover , the proposed matching algorithmic rule also results in a considerable speed-up of previous state of the art techniques making it suitable for real-time applications such as Visual Odometry ( VO ). This , of course , comes at expense of a slightly lower telephone number of matches in comparison with appearance-based methods , and also limits its application to continuous video sequences , as it is rather constrained to small pose increments between consecutive frames. We validate the claimed advantages by first evaluating the matching performance in challenging video sequences , and then testing the method in a benchmarked point and line based VO algorithmic rule. ", "label": 1}
{"original_text": "We introduce the new task of Acoustic Question Answering (AQA) to promote research in acoustic reasoning. The AQA task consists of analyzing an acoustic scene composed by a combination of elementary sounds and answering questions that relate the position and properties of these sounds. The kind of relational questions asked, require that the models perform non-trivial reasoning in order to answer correctly. Although similar problems have been extensively studied in the domain of visual reasoning, we are not aware of any previous studies addressing the problem in the acoustic domain. We propose a method for generating the acoustic scenes from elementary sounds and a number of relevant questions for each scene using templates. We also present preliminary results obtained with two models (FiLM and MAC) that have been shown to work for visual reasoning.", "text_perturb": "We introduce the new task of Acoustic interrogation Answering ( AQA ) to promote research in acoustic reasoning. The AQA task consists of examine an acoustic scene composed by a combination of elementary sounds and answering questions that relate the position and properties of these sounds. The kind of relational inquiry asked , require that the models perform non-trivial reasoning in order to answer correctly. Although similar problems have been extensively studied in the domain of visual reasoning , we are not cognisant of any previous studies addressing the problem in the acoustic domain. We propose a method for generating the acoustic scenes from elementary sounds and a issue of relevant questions for each scene using templates. We also present preliminary results obtained with two models ( moving picture and MAC ) that have been shown to work for visual reasoning. ", "label": 1}
{"original_text": "The production of renewable and sustainable energy is one of the most important challenges currently facing mankind. Wind has made an increasing contribution to the world's energy supply mix, but still remains a long way from reaching its full potential. In this paper, we investigate the use of artificial evolution to design vertical-axis wind turbine prototypes that are physically instantiated and evaluated under fan generated wind conditions. Initially a conventional evolutionary algorithm is used to explore the design space of a single wind turbine and later a cooperative coevolutionary algorithm is used to explore the design space of an array of wind turbines. Artificial neural networks are used throughout as surrogate models to assist learning and found to reduce the number of fabrications required to reach a higher aerodynamic efficiency. Unlike in other approaches, such as computational fluid dynamics simulations, no mathematical formulations are used and no model assumptions are made.", "text_perturb": "The production of renewable and sustainable energy is one of the most authoritative challenges currently facing mankind. wind instrument has made an increasing contribution to the world 's energy supply mix , but still remains a long way from reaching its full potential. In this paper , we investigate the use of artificial evolution to design vertical-axis wind turbine prototypes that are physically instantiated and evaluated under fan generated wind status. Initially a conventional evolutionary algorithm is use to explore the design space of a single wind turbine and later a cooperative coevolutionary algorithm is use to explore the design space of an array of wind turbines. Artificial neural networks are used throughout as surrogate models to assist learnedness and found to reduce the number of fabrications required to reach a higher aerodynamic efficiency. Unlike in other approaches , such as computational fluid dynamics simulations , no mathematical formulations are used and no mannequin assumptions are made. ", "label": 1}
{"original_text": "Personalization is important for search engines to improve user experience. Most of the existing work do pure feature engineering and extract a lot of session-style features and then train a ranking model. Here we proposed a novel way to model both long term and short term user behavior using Multi-armed bandit algorithm. Our algorithm can generalize session information across users well, and as an Explore-Exploit style algorithm, it can generalize to new urls and new users well. Experiments show that our algorithm can improve performance over the default ranking and outperforms several popular Multi-armed bandit algorithms.", "text_perturb": "Personalization is important for search engines to improve exploiter experience. Most of the existing work do pure feature engineering and extract a lot of session-style features and so train a ranking model. Here we proposed a novel way to model both farseeing term and short term user behavior using Multi-armed bandit algorithm. Our algorithm sack generalize session information across users well , and as an Explore-Exploit style algorithm , it sack generalize to new urls and new users well. Experiments show that our algorithmic program can improve performance over the default ranking and outperforms several popular Multi-armed bandit algorithms. ", "label": 1}
{"original_text": "Legged robots traversing in confined environments could find their only path is blocked by obstacles. In circumstances where the obstacles are movable, a multilegged robot can manipulate the obstacles using its legs to allow it to continue on its path. We present a method for a hexapod robot to autonomously generate manipulation trajectories for detected obstacles. Using a RGB-D sensor as input, the obstacle is extracted from the environment and filtered to provide key contact points for the manipulation algorithm to calculate a trajectory to move the obstacle out of the path. Experiments on a 30 degree of freedom hexapod robot show the effectiveness of the algorithm in manipulating a range of obstacles in a 3D environment using its front legs.", "text_perturb": "Legged robots traversing in imprisoned environments could find their only path is blocked by obstacles. In circumstances where the obstacles are movable , a multilegged robot can fudge the obstacles using its legs to allow it to continue on its path. We present a method acting for a hexapod robot to autonomously generate manipulation trajectories for detected obstacles. Using a RGB-D sensor as input , the obstacle is extracted from the environment and filtered to offer key contact points for the manipulation algorithm to calculate a trajectory to move the obstacle out of the path. Experiments on a 30 degree of freedom hexapod robot show the effectiveness of the algorithm in manipulating a range of obstacles in a 3D environment utilize its front legs. ", "label": 1}
{"original_text": "This paper advances the design of CTC-based all-neural (or end-to-end) speech recognizers. We propose a novel symbol inventory, and a novel iterated-CTC method in which a second system is used to transform a noisy initial output into a cleaner version. We present a number of stabilization and initialization methods we have found useful in training these networks. We evaluate our system on the commonly used NIST 2000 conversational telephony test set, and significantly exceed the previously published performance of similar systems, both with and without the use of an external language model and decoding technology.", "text_perturb": "This paper advances the design of CTC-based all-neural ( or end-to-end ) manner of speaking recognizers. We propose a novel symbol inventory , and a novel iterated-CTC method in which a second system is used to transform a noisy initial output into a cleaner rendering. We present a number of stabilization and initialization methods we have found useful in groom these networks. We evaluate our system on the commonly used NIST 2000 colloquial telephony test set , and significantly exceed the previously published performance of similar systems , both with and without the use of an external language model and decoding technology. ", "label": 1}
{"original_text": "Interest surrounding cryptocurrencies, digital or virtual currencies that are used as a medium for financial transactions, has grown tremendously in recent years. The anonymity surrounding these currencies makes investors particularly susceptible to fraud - such as \"pump and dump\" scams - where the goal is to artificially inflate the perceived worth of a currency, luring victims into investing before the scammers can sell their holdings. Because of the speed and relative anonymity offered by social platforms such as Twitter and Telegram, social media has become a preferred platform for scammers who wish to spread false hype about the cryptocurrency they are trying to pump. In this work we propose and evaluate a computational approach that can automatically identify pump and dump scams as they unfold by combining information across social media platforms. We also develop a multi-modal approach for predicting whether a particular pump attempt will succeed or not. Finally, we analyze the prevalence of bots in cryptocurrency related tweets, and observe a significant significant presence of bots during the pump attempts.", "text_perturb": "Interest smother cryptocurrencies , digital or virtual currencies that are used as a medium for financial transactions , has grown tremendously in recent years. The anonymity surrounding these currencies makes investors particularly susceptible to put on - such as `` pump and dump '' scams - where the goal is to artificially inflate the perceived worth of a currency , luring victims into investing before the scammers can sell their holdings. Because of the focal ratio and relative anonymity offered by social platforms such as Twitter and Telegram , social media has become a preferred platform for scammers who wish to spread false hype about the cryptocurrency they are trying to pump. In this work we propose and evaluate a computational approach that can automatically identify pump and dump scam as they unfold by combining information across social media platforms. We also develop a multi-modal approach for predicting whether a particular pump attempt will deliver the goods or not. Finally , we analyze the prevalence of bot in cryptocurrency related tweets , and observe a significant significant presence of bot during the pump attempts. ", "label": 1}
{"original_text": "This paper develops an interference aware design for cooperative hybrid automatic repeat request (HARQ) assisted non-orthogonal multiple access (NOMA) scheme for large-scale device-to-device (D2D) networks. Specifically, interference aware rate selection and power allocation are considered to maximize long term average throughput (LTAT) and area spectral efficiency (ASE). The design framework is based on stochastic geometry that jointly accounts for the spatial interference correlation at the NOMA receivers as well as the temporal interference correlation across HARQ transmissions. It is found that ignoring the effect of the aggregate interference, or overlooking the spatial and temporal correlation in interference, highly overestimates the NOMA performance and produces misleading design insights. An interference oblivious selection for the power andor transmission rates leads to violating the network outage constraints. To this end, the results demonstrate the effectiveness of NOMA transmission and manifest the importance of the cooperative HARQ to combat the negative effect of the network aggregate interference. For instance, comparing to the non-cooperative HARQ assisted NOMA, the proposed scheme can yield an outage probability reduction by 32. Furthermore, an interference aware optimal design that maximizes the LTAT given outage constraints leads to 47 throughput improvement over HARQ-assisted orthogonal multiple access (OMA) scheme.", "text_perturb": "This paper develops an interference aware excogitation for cooperative hybrid automatic repeat request ( HARQ ) assisted non-orthogonal multiple access ( NOMA ) scheme for large-scale device-to-device ( D2D ) networks. Specifically , interference aware rate selection and power allocation are considered to maximize farsighted term average throughput ( LTAT ) and area spectral efficiency ( ASE ). The design framework is based on stochastic geometry that jointly accounts for the spatial interference correlation at the NOMA receivers equally well as the temporal interference correlation across HARQ transmissions. It is found that ignoring the effect of the aggregate interference , or overlooking the spatial and temporal correlation coefficient in interference , highly overestimates the NOMA performance and produces misleading design insights. An interference oblivious selection for the power andor transmission rates head to violating the network outage constraints. To this end , the results demonstrate the effectiveness of NOMA transmission and manifest the importance of the cooperative HARQ to combat the negative result of the network aggregate interference. For instance , comparing to the non-cooperative HARQ assisted NOMA , the proposed system can yield an outage probability reduction by 32. Furthermore , an interference aware optimal design that maximizes the LTAT given outage constraints leads to 47 throughput improvement over HARQ-assisted rectangular multiple access ( OMA ) scheme. ", "label": 1}
{"original_text": "We revisit the problem of distributed approximation of functions over multiple-access channels. Contrary to previous works, however, we do not consider the approximation problem itself, but instead we propose a method of incorporating security constraints into a class of approximation schemes to protect against passive eavesdropping. We specifically consider a scenario in which the jamming signal is stronger for the legitimate receiver than it is for the eavesdropper, and we show that in this case jamming techniques are feasible in the sense that they can deteriorate the eavesdropper's signal while not affecting the usefulness of the legitimate receiver's signal. Key ingredients for our scheme are channel resolvability as well as a newly proven result for coding for compound channels with continuous alphabets which is more general than similar results from prior works and may thus be of independent interest.", "text_perturb": "We revisit the problem of distributed approximation of functions over multiple-access duct. Contrary to previous works , however , we do non consider the approximation problem itself , but instead we propose a method of incorporating security constraints into a class of approximation schemes to protect against passive eavesdropping. We specifically consider a scenario in which the jamming signal is stronger for the legitimate receiver than it is for the eavesdropper , and we show that in this case jamming techniques make up feasible in the sense that they can deteriorate the eavesdropper 's signal while not affecting the usefulness of the legitimate receiver 's signal. Key ingredients for our scheme are channel resolvability as well as a newly proven result for coding for compound duct with continuous alphabets which is more general than similar results from prior works and may thus be of independent interest. ", "label": 1}
{"original_text": "Understanding E3 ligase and target substrate interactions are important for cell biology and therapeutic development. However, experimental identification of E3 target relationships is not an easy task due to the labor-intensive nature of the experiments. In this article, a sequence-based E3-target prediction model is proposed for the first time. The proposed framework utilizes composition of k-spaced amino acid pairs (CKSAAP) to learn the relationship between E3 ligases and their target protein. A class separable latent space encoding scheme is also devised that provides a compressed representation of feature space. A thorough ablation study is performed to identify an optimal gap size for CKSAAP and the number of latent variables that can represent the E3-target relationship successfully. The proposed scheme is evaluated on an independent dataset for a variety of standard quantitative measures. In particular, it achieves an average accuracy of 70.63 on an independent dataset. The source code and datasets used in the study are available at the author's GitHub page .", "text_perturb": "Understanding E3 ligase and target substrate interactions are authoritative for cell biology and therapeutic development. However , experimental identification of E3 target relationships is not an easy labor due to the labor-intensive nature of the experiments. In this article , a sequence-based E3-target prevision model is proposed for the first time. The proposed framework utilizes make up of k-spaced amino acid pairs ( CKSAAP ) to learn the relationship between E3 ligases and their target protein. A class separable latent space encoding scheme comprise also devised that provides a compressed representation of feature space. A thorough ablation study is performed to identify an optimal opening size for CKSAAP and the number of latent variables that can represent the E3-target relationship successfully. The proposed scheme is evaluated on an independent dataset for a miscellanea of standard quantitative measures. In particular , it achieve an average accuracy of 70. 63 on an autonomous dataset. The source code and datasets used in the study follow available at the author 's GitHub page. ", "label": 1}
{"original_text": "This paper investigates the physical layer security issue of a device-to-device (D2D) underlaid cellular system with a multi-antenna base station (BS) and a multi-antenna eavesdropper. To investigate the potential of D2D communication in improving network security, the conventional network without D2D users (DUs) is first considered. It is shown that the problem of maximizing the sum secrecy rate (SR) of cellular users (CUs) for this special case can be transformed to an assignment problem and optimally solved. Then, a D2D underlaid network is considered. Since the joint optimization of resource block (RB) allocation, CU-DU matching and power control is a mixed integer programming, the problem is difficult to handle. Hence, the RB assignment process is first conducted by ignoring D2D communication, and an iterative algorithm is then proposed to solve the remaining problem. Simulation results show that the sum SR of CUs can be greatly increased by D2D communication, and compared with the existing schemes, a better secrecy performance can be obtained by the proposed algorithms.", "text_perturb": "This paper investigates the physical layer security issue of a device-to-device ( D2D ) underlaid cellular system with a multi-antenna base of operations station ( BS ) and a multi-antenna eavesdropper. To investigate the potential of D2D communication in improving network security , the ceremonious network without D2D users ( DUs ) is first considered. It is shown that the problem of maximizing the sum secrecy rate ( SR ) of cellular user ( CUs ) for this special case can be transformed to an assignment problem and optimally solved. Then , a D2D underlaid network is considered. Since the joint optimization of resource block ( RB ) apportioning , CU-DU matching and power control is a mixed integer programming , the problem is difficult to handle. Hence , the RB assignment process is first conducted by ignoring D2D communication , and an iterative algorithm is then nominate to solve the remaining problem. Simulation results show that the sum SR of CUs terminate be greatly increased by D2D communication , and compared with the existing schemes , a better secrecy performance terminate be obtained by the proposed algorithms. ", "label": 1}
{"original_text": "Retrieval and content management are assumed to be mutually exclusive. In this paper we suggest that they need not be so. In the usual information retrieval scenario, some information about queries leading to a website (due to 'hits' or 'visits is available to the server administrator of the concerned website. This information can used to better present the content on the website. Further, we suggest that some more information can be shared by the retrieval system with the content provider. This will enable the content provider (any website) to have a more dynamic presentation of the content that is in tune with the query trends, without violating the privacy of the querying user. The result will be a better synchronization between retrieval systems and content providers, with the purpose of improving the user's web search experience. This will also give the content provider a say in this process, given that the content provider is the one who knows much more about the content than the retrieval system. It also means that the content presentation may change in response to a query. In the end, the user will be able to find the relevant content more easily and quickly.", "text_perturb": "Retrieval and contented management are assumed to be mutually exclusive. In this composition we suggest that they need not be so. In the usual information retrieval scenario , some information about queries leading to a website ( due to 'hits ' or 'visits is available to the waiter administrator of the concerned website. This information can used to better present the content on the web site. Further , we suggest that some more information can be shared by the retrieval system with the capacity provider. This will enable the content provider ( any website ) to have a more dynamic presentation of the content that is in strain with the query trends , without violating the privacy of the querying user. The result will be a better synchronization between retrieval systems and contented providers , with the purpose of improving the user 's web search experience. This will also give the content provider a say in this outgrowth , given that the content provider is the one who knows much more about the content than the retrieval system. It also mean that the content presentation may change in response to a query. In the end , the user will be able to find the relevant content more easily and chop chop. ", "label": 1}
{"original_text": "We study approaches to improve fine-grained short answer Question Answering models by integrating coarse-grained data annotated for paragraph-level relevance and show that coarsely annotated data can bring significant performance gains. Experiments demonstrate that the standard multi-task learning approach of sharing representations is not the most effective way to leverage coarse-grained annotations. Instead, we can explicitly model the latent fine-grained short answer variables and optimize the marginal log-likelihood directly or use a newly proposed posterior distillation learning objective. Since these latent-variable methods have explicit access to the relationship between the fine and coarse tasks, they result in significantly larger improvements from coarse supervision.", "text_perturb": "We study approaches to improve fine-grained short answer Question Answering models by mix coarse-grained data annotated for paragraph-level relevance and show that coarsely annotated data can bring significant performance gains. Experiments exhibit that the standard multi-task learning approach of sharing representations is not the most effective way to leverage coarse-grained annotations. Instead , we can explicitly model the latent fine-grained short answer variables and optimize the marginal log-likelihood directly or use a newly proposed posterior distillate learning objective. Since these latent-variable methods have explicit access to the relationship between the fine and coarse tasks , they result in importantly larger improvements from coarse supervision. ", "label": 1}
{"original_text": "Probabilistic models with hierarchical-latent-variable structures provide state-of-the-art results amongst non-autoregressive, unsupervised density-based models. However, the most common approach to training such models based on Variational Autoencoders (VAEs) often fails to leverage deep-latent hierarchies; successful approaches require complex inference and optimisation schemes. Optimal Transport is an alternative, non-likelihood-based framework for training generative models with appealing theoretical properties, in principle allowing easier training convergence between distributions. In this work we propose a novel approach to training models with deep-latent hierarchies based on Optimal Transport, without the need for highly bespoke models and inference networks. We show that our method enables the generative model to fully leverage its deep-latent hierarchy, avoiding the well known \"latent variable collapse\" issue of VAEs; therefore, providing qualitatively better sample generations as well as more interpretable latent representation than the original Wasserstein Autoencoder with Maximum Mean Discrepancy divergence.", "text_perturb": "Probabilistic models with hierarchical-latent-variable construction provide state-of-the-art results amongst non-autoregressive , unsupervised density-based models. However , the most common approach to training such models based on Variational Autoencoders ( VAEs ) much fails to leverage deep-latent hierarchies ; successful approaches require complex inference and optimisation schemes. Optimal Transport is an alternative , non-likelihood-based framework for training generative models with appealing theoretical properties , in principle allowing light training convergence between distributions. In this work we propose a novel approach to training modelling with deep-latent hierarchies based on Optimal Transport , without the need for highly bespoke modelling and inference networks. We show that our method enables the generative model to fully leverage its deep-latent hierarchy , avoiding the well known `` latent variable collapse '' issue of VAEs ; therefore , providing qualitatively better sample generations as well as more interpretable latent representation than the original Wasserstein Autoencoder with Maximum mean value Discrepancy divergence. ", "label": 1}
{"original_text": "Neural program embedding can be helpful in analyzing large software, a task that is challenging for traditional logic-based program analyses due to their limited scalability. A key focus of recent machine-learning advances in this area is on modeling program semantics instead of just syntax. Unfortunately evaluating such advances is not obvious, as program semantics does not lend itself to straightforward metrics. In this paper, we introduce a benchmarking framework called CoSet for standardizing the evaluation of neural program embeddings. CoSet consists of a diverse dataset of programs in source-code format, labeled by human experts according to a number of program properties of interest. A point of novelty is a suite of program transformations included in CoSet. These transformations when applied to the base dataset can simulate natural changes to program code due to optimization and refactoring and can serve as a \"debugging\" tool for classification mistakes. We conducted a pilot study on four prominent models - TreeLSTM, gated graph neural network (GGNN), AST-Path neural network (APNN), and DyPro. We found that CoSet is useful in identifying the strengths and limitations of each model and in pinpointing specific syntactic and semantic characteristics of programs that pose challenges.", "text_perturb": "Neural program embedding can be helpful in analyzing large software package , a task that is challenging for traditional logic-based program analyses due to their limited scalability. A key focus of recent machine-learning advancement in this area is on modeling program semantics instead of just syntax. Unfortunately evaluating such advances is non obvious , as program semantics does non lend itself to straightforward metrics. In this paper , we preface a benchmarking framework called CoSet for standardizing the evaluation of neural program embeddings. CoSet consists of a diverse dataset of programs in source-code format , labeled by human experts accord to a number of program properties of interest. A point of novelty represent a suite of program transformations included in CoSet. These transformations when applied to the base dataset can simulate natural changes to program code imputable to optimization and refactoring and can serve as a `` debugging '' tool for classification mistakes. We conducted a pilot study on four prominent models - TreeLSTM , gated graph neural electronic network ( GGNN ) , AST-Path neural electronic network ( APNN ) , and DyPro. We found that CoSet live useful in identifying the strengths and limitations of each model and in pinpointing specific syntactic and semantic characteristics of programs that pose challenges. ", "label": 1}
{"original_text": "We study multi-player turn-based games played on (potentially infinite) directed graphs. An outcome is assigned to every play of the game. Each player has a preference relation on the set of outcomes which allows him to compare plays. We focus on the recently introduced notion of weak subgame perfect equilibrium (weak SPE). This is a variant of the classical notion of SPE, where players who deviate can only use strategies deviating from their initial strategy in a finite number of histories. Having an SPE in a game implies having a weak SPE but the contrary is generally false. We propose general conditions on the structure of the game graph and on the preference relations of the players that guarantee the existence of a weak SPE, that additionally is finite-memory. From this general result, we derive two large classes of games for which there always exists a weak SPE: (i) the games with a finite-range outcome function, and (I i) the games with a finite underlying graph and a prefix-independent outcome function. For the second class, we identify conditions on the preference relations that guarantee memoryless strategies for the weak SPE.", "text_perturb": "We study multi-player turn-based game played on ( potentially infinite ) directed graphs. An outcome is specify to every play of the game. Each player has a taste relation on the set of outcomes which allows him to compare plays. We focus on the recently introduced notion of weakly subgame perfect equilibrium ( weakly SPE ). This is a variant of the classical notion of SPE , where players who deviate can only use strategy deviating from their initial strategy in a finite number of histories. Having an SPE in a game implies having a weak SPE but the contrary is generally mistaken. We propose universal conditions on the structure of the game graph and on the preference relations of the players that guarantee the existence of a weak SPE , that additionally is finite-memory. From this general result , we derive two large classes of games for which there always exists a weak SPE : ( iodin ) the games with a finite-range outcome function , and ( I i ) the games with a finite underlying graph and a prefix-independent outcome function. For the second class , we identify conditions on the preference relations that ensure memoryless strategies for the weak SPE. ", "label": 1}
{"original_text": "Information cascades are ubiquitous in various social networking web sites. What mechanisms drive information diffuse in the networks? How does the structure and size of the cascades evolve in time? When and which users will adopt a certain message? Approaching these questions can considerably deepen our understanding about information cascades and facilitate various vital applications, including viral marketing, rumor prevention and even link prediction. Most previous works focus only on the final cascade size prediction. Meanwhile, they are always cascade graph dependent methods, which make them towards large cascades prediction and lead to the criticism that cascades may only be predictable after they have already grown large. In this paper, we study a fundamental problem: full-scale cascade dynamics prediction. That is, how to predict when and which users are activated at any time point of a cascading process. Here we propose a unified framework, FScaleCP, to solve the problem. Given history cascades, we first model the local spreading behaviors as a classification problem. Through data-driven learning, we recognize the common patterns by measuring the driving mechanisms of cascade dynamics. After that we present an intuitive asynchronous propagation method for full-scale cascade dynamics prediction by effectively aggregating the local spreading behaviors. Extensive experiments on social network data set suggest that the proposed method performs noticeably better than other state-of-the-art baselines.", "text_perturb": "Information cascades embody ubiquitous in various social networking web sites. What mechanisms drive information diffuse in the meshing ? How does the structure and size of the cascades evolve in time ? When and which users will adopt a certain message ? Approaching these questions can considerably deepen our understanding about information cascades and facilitate various vital applications , including viral marketing , rumor prevention and even link prediction. Most previous works pore only on the final cascade size prediction. Meanwhile , they are always cascade graphical record dependent methods , which make them towards large cascades prediction and lead to the criticism that cascades may only be predictable after they have already grown large. In this paper , we study a fundamental problem : full scale cascade dynamics prediction. That is , how to forecast when and which users are activated at any time point of a cascading process. Here we propose a unified theoretical account , FScaleCP , to solve the problem. Given history cascades , we first model the local spreading behaviors as a classification trouble. Through data-driven learning , we recognize the common patterns by measuring the driving mechanisms of cascade dynamic. After that we present an intuitive asynchronous propagation method for full-scale cascade kinetics prediction by effectively aggregating the local spreading behaviors. Extensive experiments on social network information set suggest that the proposed method performs noticeably better than other state-of-the-art baselines. ", "label": 1}
{"original_text": "Logical models offer a simple but powerful means to understand the complex dynamics of biochemical regulation, without the need to estimate kinetic parameters. However, even simple automata components can lead to collective dynamics that are computationally intractable when aggregated into networks. In previous work we demonstrated that automata network models of biochemical regulation are highly canalizing, whereby many variable states and their groupings are redundant (,). The precise charting and measurement of such canalization simplifies these models, making even very large networks amenable to analysis. Moreover, canalization plays an important role in the control, robustness, modularity and criticality of Boolean network dynamics, especially those used to model biochemical regulation (,). Here we describe a new publicly-available Python package that provides the necessary tools to extract, measure, and visualize canalizing redundancy present in Boolean network models. It extracts the pathways most effective in controlling dynamics in these models, including their effective graph and dynamics canalizing map, as well as other tools to uncover minimum sets of control variables. helveticabold 1 section 1 1 SS1 1 Keywords: Boolean Networks, Automata, Canalization, Python package, biochemical regulation, Logical modeling, Network dynamics, Complex systems", "text_perturb": "Logical models offer a simple but powerful means to understand the complex dynamics of biochemical regulation , without the need to estimate kinetic argument. However , still simple automata components can lead to collective dynamics that are computationally intractable when aggregated into networks. In previous work we demonstrated that automata network models of biochemical regulation are highly canalizing , whereby many variable states and their groupings are surplus ( , ). The precise charting and measuring of such canalization simplifies these models , making even very large networks amenable to analysis. furthermore , canalization plays an important role in the control , robustness , modularity and criticality of Boolean network dynamics , especially those used to model biochemical regulation ( , ). Here we describe a new publicly-available Python package that provides the necessary tools to extract , measure , and visualize canalizing redundance present in Boolean network models. It extracts the pathways most effective in controlling dynamics in these models , including their effective graph and dynamics canalizing map , as well as other tools to unveil minimum sets of control variables. helveticabold 1 section 1 1 SS1 1 Keywords : Boolean meshwork , Automata , Canalization , Python package , biochemical regulation , Logical modeling , Network dynamics , Complex systems", "label": 1}
{"original_text": "We present in this paper a framework which leverages the underlying topology of a data set, in order to produce appropriate coordinate representations. In particular, we show how to construct maps to real and complex projective spaces, given appropriate persistent cohomology classes. An initial map is obtained in two steps: First, the persistent cohomology of a sparse filtration is used to compute systems of transition functions for (real and complex) line bundles over neighborhoods of the data. Next, the transition functions are used to produce explicit classifying maps for the induced bundles. A framework for dimensionality reduction in projective space (Principal Projective Components) is also developed, aimed at decreasing the target dimension of the original map. Several examples are provided as well as theorems addressing choices in the construction.", "text_perturb": "We present in this paper a framework which leverages the underlying network topology of a data set , in order to produce appropriate coordinate representations. In particular , we show how to construct maps to material and complex projective spaces , given appropriate persistent cohomology classes. An initial map is obtained in two steps : First , the persistent cohomology of a sparse filtration is used to compute systems of transition functions for ( real and complex ) cable bundles over neighborhoods of the data. Next , the transition single valued function are used to produce explicit classifying maps for the induced bundles. A fabric for dimensionality reduction in projective space ( Principal Projective Components ) is also developed , aimed at decreasing the target dimension of the original map. various examples are provided as well as theorems addressing choices in the construction. ", "label": 1}
{"original_text": "Sequential computation is well understood but does not scale well with current technology. Within the next decade, systems will contain large numbers of processors with potentially thousands of processors per chip. Despite this, many computational problems exhibit little or no parallelism and many existing formulations are sequential. Therefore, it is essential that highly parallel architectures can support sequential computation by emulating large memories with collections of smaller ones, thus supporting efficient execution of sequential programs or sequential algorithms included as part of parallel programs. This paper presents a novel tiled parallel architecture which can scale to thousands of processors per-chip and can deliver this ability. Provision of an interconnect with scalable low-latency communications is essential for this and the realistic construction of such a system with a high-degree switch and a Clos-based network is presented. Experimental evaluation shows that sequential programs can be executed with only a factor of 2 to 3 slowdown when compared to a conventional sequential machine and that the area is roughly only a factor of two larger. This seems an acceptable price to pay for an architecture that can switch between executing highly parallel programs and sequential programs with large memory requirements.", "text_perturb": "Sequential computation is well understood but fare not scale well with current technology. Within the next decade , systems will contain large numbers of processors with potentially thousands of processors per check. Despite this , many computational problems exhibit little or no parallelism and many existing formulation are sequential. thence , it is essential that highly parallel architectures can support sequential computation by emulating large memories with collections of smaller ones , thus supporting efficient execution of sequential programs or sequential algorithms included as part of parallel programs. This paper lay out a novel tiled parallel architecture which can scale to thousands of processors per-chip and can deliver this ability. Provision of an interconnect with scalable low-latency communications is essential for this and the realistic construction of such a system with a high-degree switch and a Clos-based mesh is presented. Experimental evaluation shows that sequential programs can be put to death with only a factor of 2 to 3 slowdown when compared to a conventional sequential machine and that the area is roughly only a factor of two larger. This seems an acceptable price to pay for an architecture that can switch between executing highly parallel programme and sequential programme with large memory requirements. ", "label": 1}
{"original_text": "We do a Probabilistic Analysis of the Network generated by robots involved inStochastic Boundary Coverage", "text_perturb": "We do a Probabilistic depth psychology of the Network generated by robots involved inStochastic Boundary Coverage", "label": 1}
{"original_text": "This essay argues that a new form of democracy - an \"Emergent Democracy\" - will develop as a result of the use of Internet communication tools and platforms such as blogs. The essay explores a variety of tools available and explores the history of democracy, modern experiments with democracy and how these tools might support democracy. The essay also explores concerns as these new tools emerge. These issues include concerns such as privacy and the societally negative use of these tools by corporations, totalitarian regimes and terrorists.", "text_perturb": "This essay argues that a new form of democracy - an `` Emergent Democracy '' - will develop as a result of the use of Internet communicating tools and platforms such as blogs. The essay explores a variety of tools available and explores the history of majority rule , modern experiments with majority rule and how these tools might support majority rule. The essay also explores business as these new tools emerge. These issues include concerns such as privacy and the societally damaging use of these tools by corporations , totalitarian regimes and terrorists. ", "label": 1}
{"original_text": "This paper proposes a method for utilizing thermal features of the hand for the purpose of presentation attack detection (PAD) that can be employed in a hand biometrics system's pipeline. By envisaging two different operational modes of our system, and by employing a DCNN-based classifiers fine-tuned with a dataset of real and fake hand representations captured in both visible and thermal spectrum, we were able to bring two important deliverables. First, a PAD method operating in an open-set mode, capable of correctly discerning 100 of fake thermal samples, achieving Attack Presentation Classification Error Rate (APCER) and Bona-Fide Presentation Classification Error Rate (BPCER) equal to 0, which can be easily implemented into any existing system as a separate component. Second, a hand biometrics system operating in a closed-set mode, that has PAD built right into the recognition pipeline, and operating simultaneously with the user-wise classification, achieving rank-1 recognition accuracy of up to 99.75. We also show that thermal images of the human hand, in addition to liveness features they carry, can also improve classification accuracy of a biometric system, when coupled with visible light images. To follow the reproducibility guidelines and to stimulate further research in this area, we share the trained model weights, source codes, and a newly created dataset of fake hand representations with interested researchers. footnote Paper accepted for the BTAS 2018 Special Session on Image and Video Forensics In Biometrics, 22-25 Oct, 2018, Los Angeles, USA", "text_perturb": "This paper proposes a method for utilizing thermal features of the hand for the purpose of presentation attack detection ( PAD ) that can be hire in a hand biometrics system 's pipeline. By envisaging two different operational modes of our system , and by employing a DCNN-based classifiers fine-tuned with a dataset of real and fake hand representations becharm in both visible and thermal spectrum , we were able to bring two important deliverables. First , a PAD method operating in an open-set mode , capable of correctly discerning 100 of fake caloric samples , achieving Attack Presentation Classification Error Rate ( APCER ) and Bona-Fide Presentation Classification Error Rate ( BPCER ) equal to 0 , which can be easily implemented into any existing system as a separate component. Second , a hand biometrics system operating in a closed-set mode , that induce PAD built right into the recognition pipeline , and operating simultaneously with the user-wise classification , achieving rank-1 recognition accuracy of up to 99. 75. We also show that thermal icon of the human hand , in addition to liveness features they carry , can also improve classification accuracy of a biometric system , when coupled with visible light icon. To follow the reproducibility guidelines and to stimulate further research in this area , we share the trained model weights , source computer code , and a newly created dataset of fake hand representations with interested researchers. footnote Paper accepted for the BTAS 2018 Special Session on Image and video recording Forensics In Biometrics , 22-25 Oct , 2018 , Los Angeles , USA", "label": 1}
{"original_text": "This article deals with the problem of distributed machine learning, in which agents update their models based on their local datasets, and aggregate the updated models collaboratively and in a fully decentralized manner. In this paper, we tackle the problem of information heterogeneity arising in multi-agent networks where the placement of informative agents plays a crucial role in the learning dynamics. Specifically, we propose BayGo, a novel fully decentralized joint Bayesian learning and graph optimization framework with proven fast convergence over a sparse graph. Under our framework, agents are able to learn and communicate with the most informative agent to their own learning. Unlike prior works, our framework assumes no prior knowledge of the data distribution across agents nor does it assume any knowledge of the true parameter of the system. The proposed alternating minimization based framework ensures global connectivity in a fully decentralized way while minimizing the number of communication links. We theoretically show that by optimizing the proposed objective function, the estimation error of the posterior probability distribution decreases exponentially at each iteration. Via extensive simulations, we show that our framework achieves faster convergence and higher accuracy compared to fully-connected and star topology graphs.", "text_perturb": "This clause deals with the problem of distributed machine learning , in which agents update their models based on their local datasets , and aggregate the updated models collaboratively and in a fully decentralized manner. In this paper , we tackle the problem of information heterogeneity lift in multi-agent networks where the placement of informative agents plays a crucial role in the learning dynamics. Specifically , we propose BayGo , a novel fully decentralized joint Bayesian learning and graph optimization model with proven fast convergence over a sparse graph. Under our model , agents are able to learn and communicate with the most informative agent to their own learning. Unlike prior works , our model assumes no prior knowledge of the data distribution across agents nor does it assume any knowledge of the true parameter of the system. The proposed alternating minimization based framework ensures global connectivity in a fully decentralized way while minimizing the number of communication link. We theoretically show that by optimizing the proposed objective function , the estimation error of the posterior probability distribution decreases exponentially at each looping. Via extensive simulation , we show that our framework achieves faster convergence and higher accuracy compared to fully-connected and star topology graphs. ", "label": 1}
{"original_text": "Numerical modeling of fluid flows based on kinetic equations provides an alternative approach for the description of complex flows simulations, and a number of kinetic methods have been developed from different points of view. A particular challenge for kinetic methods is whether they can capture the correct hydrodynamic behavior of the system in the continuum limit without enforcing kinetic scale resolution. Historically, the first effort to study the asymptotic behavior of kinetic schemes could be attributed to the pioneering work of Larsen (Nucl. Sci. Eng. 83, 90 (1983, where the diffusion limit of spatial differencing schemes for the linear transport equation was investigated. The approach was later employed to analyze asymptotic properties of kinetic methods for flow problems, and significant progresses have been made over the past three decades. At the current stage, a variety of asymptotic preserving (AP) kinetic methods, which keep the same algorithm in different flow regimes, have been constructed. However, the detailed asymptotic properties of these schemes are indistinguishable under the AP framework. In order to distinguish different characteristics of kinetic schemes, in this paper we will introduce the concept of unified preserving (UP) which can be used to assess the effective governing equations solved in the asymptotic process. Unlike the general analysis of AP property in the hydrodynamic scale, the current UP analysis is able to indicate asmyptotic orders of kinetic schemes by employing the modified equation approach. Generally, the UP properties of a kinetic scheme depend on the spatialtemporal accuracy and closely on the inter-connections among the three scales (kinetic scale, numerical scale, and hydrodynamic scale), and the concept of UP attempts to distinguish those scales with clear orders. Specifically, the numerical resolution and specific discretization determine the numerical flow behaviors of the scheme in different regimes, especially in the near continuum limit with a large variation of the above three scales. The UP analysis will be used in the Discrete Unified Gas-kinetic Scheme (DUGKS) to evaluate its underlying governing equations in the continuum limit in terms of the kinetic, numerical, and hydrodynamic scales.", "text_perturb": "Numerical modeling of fluid flows based on kinetic equations provides an alternative approach for the description of complex flows simulations , and a number of kinetic methods have been developed from different points of survey. A particular challenge for kinetic methods is whether they can capture the correct hydrodynamic behavior of the system in the continuum demarcation line without enforcing kinetic scale resolution. Historically , the first effort to study the asymptotic behavior of kinetic schemes could be ascribe to the pioneering work of Larsen ( Nucl. Sci. Eng. 83 , 90 ( 1983 , where the diffusion limit point of spatial differencing schemes for the linear transport equation was investigated. The access was later employed to analyze asymptotic properties of kinetic methods for flow problems , and significant progresses have been made over the past three decades. At the current stage , a variety of asymptotic preserving ( AP ) kinetic methods , which keep the like algorithm in different flow regimes , have been constructed. However , the detailed asymptotic properties of these schemes are indistinguishable under the AP model. In order to distinguish different characteristics of kinetic schemes , in this paper we will introduce the concept of incorporated preserving ( UP ) which can be used to assess the effective governing equations solved in the asymptotic process. Unlike the general analysis of AP property in the hydrodynamic scale , the current UP analysis is able to indicate asmyptotic fiat of kinetic schemes by employing the modified equation approach. Generally , the UP properties of a kinetic scheme depend on the spatialtemporal accuracy and closely on the inter-connections among the three scales ( kinetic graduated table , numerical graduated table , and hydrodynamic graduated table ) , and the concept of UP attempts to distinguish those scales with clear orders. Specifically , the numeric resolution and specific discretization determine the numeric flow behaviors of the scheme in different regimes , especially in the near continuum limit with a large variation of the above three scales. The UP analysis will be used in the Discrete Unified Gas-kinetic Scheme ( DUGKS ) to evaluate its underlying governing equations in the continuum limit in terms of the kinetic , numerical , and hydrodynamic shell. ", "label": 1}
{"original_text": "The Social Internet of Things (SIoT), integration of Internet of Things and Social networks paradigms, has been introduced to build a network of smart nodes which are capable of establishing social links. In order to deal with misbehavioral service provider nodes, service requestor nodes must evaluate their trustworthiness levels. In this paper, we propose a novel trust management mechanism in the SIoT to predict the most reliable service provider for a service requestor, that leads to reduce the risk of exposing to malicious nodes. We model an SIoT with a flexible bipartite graph (containing two sets of nodes: service providers and requestors), then build the corresponding social network among service requestor nodes, using Hellinger distance. After that, we develop a social trust model, by using nodes' centrality and similarity measures, to extract behavioral trust between the network nodes. Finally, a matrix factorization technique is designed to extract latent features of SIoT nodes to mitigate the data sparsity and cold start problems. We analyze the effect of parameters in the proposed trust prediction mechanism on prediction accuracy. The results indicate that feedbacks from the neighboring nodes of a specific service requestor with high Hellinger similarity in our mechanism outperforms the best existing methods. We also show that utilizing social trust model, which only considers the similarity measure, significantly improves the accuracy of the prediction mechanism. Furthermore, we evaluate the effectiveness of the proposed trust management system through a real-world SIoT application. Our results demonstrate that the proposed mechanism is resilient to different types of network attacks and it can accurately find the proper service provider with high trustworthiness.", "text_perturb": "The Social Internet of Things ( SIoT ) , integration of Internet of Things and Social networks paradigms , has been enclose to build a network of smart nodes which are capable of establishing social links. In order of magnitude to deal with misbehavioral service provider nodes , service requestor nodes must evaluate their trustworthiness levels. In this paper , we propose a novel reliance management mechanism in the SIoT to predict the most reliable service provider for a service requestor , that leads to reduce the risk of exposing to malicious nodes. We model an SIoT with a compromising bipartite graph ( containing two sets of nodes : service providers and requestors ) , then build the corresponding social network among service requestor nodes , using Hellinger distance. After that , we develop a social trust model , by utilise nodes ' centrality and similarity measures , to extract behavioral trust between the network nodes. Finally , a matrix factorization technique is designed to extract latent features of SIoT nodes to mitigate the data sparsity and cold start job. We analyze the effect of parameters in the proposed reliance prediction mechanism on prediction accuracy. The results point that feedbacks from the neighboring nodes of a specific service requestor with high Hellinger similarity in our mechanism outperforms the best existing methods. We also show that utilizing social trust modelling , which only considers the similarity measure , significantly improves the accuracy of the prediction mechanism. Furthermore , we evaluate the effectiveness of the proposed confidence management system through a real-world SIoT application. Our results demonstrate that the proposed mechanism represent resilient to different types of network attacks and it can accurately find the proper service provider with high trustworthiness. ", "label": 1}

{"original_text": "Smart contracts are a special type of programs running inside a blockchain. Immutable and transparent, they provide means to implement fault-tolerant and censorship-resistant services. Unfortunately, its immutability causes a serious challenge of ensuring that a business logic and implementation is correct upfront, before publishing in a blockchain. Several big accidents have indeed shown that users of this technology need special tools to verify smart contract correctness. Existing automated checkers are able to detect only well known implementation bugs, leaving the question of business logic correctness far aside. In this work, we present a symbolic model-checking technique along with a formal specification method for a subset of Solidity programming language that is able to express both state properties and trace properties; the latter constitutes a weak analogy of temporal properties. We evaluate the proposed technique on the MiniDAO smart contract, a young brother of notorious TheDAO. Our Proof-of-Concept was able to detect a non-trivial error in the business logic of this smart contract in a few seconds.", "text_perturb": "Smart contracts are a special eccentric of programs running inside a blockchain. immutable and transparent , they provide means to implement fault-tolerant and censorship-resistant services. Unfortunately , its immutability cause a serious challenge of ensuring that a business logic and implementation is correct upfront , before publishing in a blockchain. Several big accidents have so shown that users of this technology need special tools to verify smart contract correctness. Existing automated checkers are able to detect only well known carrying out bugs , leaving the question of business logic correctness far aside. In this work , we present a symbolic model-checking technique along with a formal specification method for a subset of Solidity programming language that is able to express both state properties and trace properties ; the latter form a weak analogy of temporal properties. We evaluate the proposed proficiency on the MiniDAO smart contract , a young brother of notorious TheDAO. Our Proof-of-Concept follow able to detect a non-trivial error in the business logic of this smart contract in a few seconds. ", "label": 1}
{"original_text": "Quantum memories are a fundamental of any global-scale quantum Internet, high-performance quantum networking and near-term quantum computers. A main problem of quantum memories is the low retrieval efficiency of the quantum systems from the quantum registers of the quantum memory. Here, we define a novel quantum memory called high-retrieval-efficiency (HRE) quantum memory for near-term quantum devices. An HRE quantum memory unit integrates local unitary operations on its hardware level for the optimization of the readout procedure and utilizes the advanced techniques of quantum machine learning. We define the integrated unitary operations of an HRE quantum memory, prove the learning procedure, and evaluate the achievable output signal-to-noise ratio values. We prove that the local unitaries of an HRE quantum memory achieve the optimization of the readout procedure in an unsupervised manner without the use of any labeled data or training sequences. We show that the readout procedure of an HRE quantum memory is realized in a completely blind manner without any information about the input quantum system or about the unknown quantum operation of the quantum register. We evaluate the retrieval efficiency of an HRE quantum memory and the output SNR (signal-to-noise ratio). The results are particularly convenient for gate-model quantum computers and the near-term quantum devices of the quantum Internet.", "text_perturb": "Quantum memories follow a fundamental of any global-scale quantum Internet , high-performance quantum networking and near-term quantum computers. A main job of quantum memories is the low retrieval efficiency of the quantum systems from the quantum registers of the quantum memory. Here , we fix a novel quantum memory called high-retrieval-efficiency ( HRE ) quantum memory for near-term quantum devices. An HRE quantum memory unit integrates local unitary surgical process on its hardware level for the optimization of the readout procedure and utilizes the advanced techniques of quantum machine learning. We define the integrated unitary operations of an HRE quantum memory , prove the learning procedure , and measure the achievable output signal-to-noise ratio values. We prove that the local unitaries of an HRE quantum memory achieve the optimization of the readout procedure in an unsupervised manner without the use of any tagged data or training sequences. We show that the readout procedure of an HRE quantum memory is realized in a completely blind manner without any information about the input quantum system or about the obscure quantum operation of the quantum register. We evaluate the retrieval efficiency of an HRE quantum memory and the output SNR ( signal-to-noise proportion ). The results are particularly convenient for gate-model quantum computers and the near-term quantum twist of the quantum Internet. ", "label": 1}
{"original_text": "The global health threat from COVID-19 has been controlled in a number of instances by large-scale testing and contact tracing efforts. We created this document to suggest three functionalities on how we might best harness computing technologies to supporting the goals of public health organizations in minimizing morbidity and mortality associated with the spread of COVID-19, while protecting the civil liberties of individuals. In particular, this work advocates for a third-party-free approach to assisted mobile contact tracing, because such an approach mitigates the security and privacy risks of requiring a trusted third party. We also explicitly consider the inferential risks involved in any contract tracing system, where any alert to a user could itself give rise to de-anonymizing information. More generally, we hope to participate in bringing together colleagues in industry, academia, and civil society to discuss and converge on ideas around a critical issue rising with attempts to mitigate the COVID-19 pandemic.", "text_perturb": "The global health threat from COVID-19 has been controlled in a number of instances by large scale testing and contact tracing efforts. We created this document to suggest three functionalities on how we might best harness computing technologies to supporting the goals of public health organizations in minimizing morbidity and mortality associated with the spread of COVID-19 , while protecting the polite liberties of individuals. In particular , this work advocates for a third-party-free approach to assisted peregrine contact tracing , because such an approach mitigates the security and privacy risks of requiring a trusted third party. We also explicitly consider the inferential risks involved in any contract tracing system , where any alert to a user could itself present rise to de-anonymizing information. More generally , we hope to participate in bringing together colleagues in industry , academia , and civil society to discuss and converge on ideas around a critical emergence rising with attempts to mitigate the COVID-19 pandemic. ", "label": 1}
{"original_text": "Current state-of-the-art neural dialogue models learn from human conversations following the data-driven paradigm. As such, a reliable training corpus is the crux of building a robust and well-behaved dialogue model. However, due to the open-ended nature of human conversations, the quality of user-generated training data varies greatly, and effective training samples are typically insufficient while noisy samples frequently appear. This impedes the learning of those data-driven neural dialogue models. Therefore, effective dialogue learning requires not only more reliable learning samples, but also fewer noisy samples. In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously. In particular, the data manipulation model selectively augments the training samples and assigns an importance weight to each instance to reform the training data. Note that, the proposed data manipulation framework is fully data-driven and learnable. It not only manipulates training samples to optimize the dialogue generation model, but also learns to increase its manipulation skills through gradient descent with validation samples. Extensive experiments show that our framework can improve the dialogue generation performance with respect to various automatic evaluation metrics and human judgments.", "text_perturb": "Current state-of-the-art nervous dialogue models learn from human conversations following the data-driven paradigm. As such , a reliable training corpus exist the crux of building a robust and well-behaved dialogue model. However , due to the open-ended nature of human conversations , the tone of user-generated training data varies greatly , and effective training samples are typically insufficient while noisy samples frequently appear. This impede the learning of those data-driven neural dialogue models. Therefore , effective dialogue learning requires not only to a greater extent reliable learning samples , but also fewer noisy samples. In this paper , we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and foreground effective learning samples as well as reducing the effect of inefficient samples simultaneously. In particular , the data manipulation model selectively augments the training samples and assigns an importance exercising weight to each instance to reform the training data. Note that , the proposed data manipulation theoretical account is fully data-driven and learnable. It not only manipulates training samples to optimize the dialogue propagation model , but also learns to increase its manipulation skills through gradient descent with validation samples. Extensive experiments demonstrate that our framework can improve the dialogue generation performance with respect to various automatic evaluation metrics and human judgments. ", "label": 1}
{"original_text": "This paper develops a mechanical tool as well as its manipulation policies for 2-finger parallel robotic grippers. It primarily focuses on a mechanism that converts the gripping motion of 2-finger parallel grippers into a continuous rotation to realize tasks like fastening screws. The essential structure of the tool comprises a Scissor-Like Element (SLE) mechanism and a double-ratchet mechanism. They together convert repeated linear motion into continuous rotating motion. At the joints of the SLE mechanism, elastic elements are attached to provide resisting force for holding the tool as well as for producing torque output when a gripper releases the tool. The tool is entirely mechanical, allowing robots to use the tool without any peripherals and power supply. The paper presents the details of the tool design, optimizes its dimensions and effective stroke lengths, and studies the contacts and forces to achieve stable grasping and screwing. Besides the design, the paper develops manipulation policies for the tool. The policies include visual recognition, picking-up and manipulation, and exchanging tooltips. The developed tool produces clockwise rotation at the front end and counter-clockwise rotation at the back end. Various tooltips can be installed at both two ends. Robots may employ the developed manipulation policies to exchange the tooltips and rotating directions following the needs of specific fastening or loosening tasks. Robots can also reorient the tool using pick-and-place or handover, and move the tool to work poses using the policies. The designed tool, together with the developed manipulation policies, are analyzed and verified in several real-world applications. The tool is small, cordless, convenient, and has good robustness and adaptability.", "text_perturb": "This paper develops a mechanical tool as well as its manipulation policy for 2-finger parallel robotic grippers. It primarily focuses on a mechanism that converts the gripping motility of 2-finger parallel grippers into a continuous rotation to realize tasks like fastening screws. The essential structure of the tool comprises a Scissor-Like ingredient ( SLE ) mechanism and a double-ratchet mechanism. They together convert repeated one dimensional motion into continuous rotating motion. At the joints of the SLE mechanism , elastic elements are attached to provide resisting force for holding the creature as well as for producing torque output when a gripper releases the creature. The shaft is entirely mechanical , allowing robots to use the shaft without any peripherals and power supply. The paper presents the details of the tool design , optimizes its dimensions and effective stroke lengths , and studies the inter group communication and forces to achieve stable grasping and screwing. Besides the design , the paper develops manipulation policies for the cock. The policies include visual recognition , picking-up and manipulation , and convert tooltips. The developed tool produces clockwise rotary motion at the front end and counter-clockwise rotary motion at the back end. Various tooltips can represent installed at both two ends. Robots may employ the developed use policies to exchange the tooltips and rotating directions following the needs of specific fastening or loosening tasks. Robots can also reorient the peter using pick-and-place or handover , and move the peter to work poses using the policies. The designed tool , together with the developed manipulation policies , are analyzed and verified in various real-world applications. The tool embody small , cordless , convenient , and has good robustness and adaptability. ", "label": 1}
{"original_text": "There have been major advances on the design of neural networks, but still they cannot be applied to many safety-critical systems due to the lack of efficient computational techniques to analyze and certify their robustness. Recently, various methods based on convex optimization have been proposed to address this issue. In particular, the semidefinite programming (SDP) approach has gained popularity in convexifying the robustness analysis problem. Since this approach is prone to a large relaxation gap, this paper develops a new technique to reduce the gap by adding non-convex cuts via disjunctive programming. The proposed method amounts to a sequential SDP technique. We analyze the performance of this method both theoretically and empirically, and show that it bridges the gap as the number of cuts increases.", "text_perturb": "There have been major advances on the design of neural networks , but still they can not be applied to many safety-critical systems due to the lack of efficient computational techniques to analyze and evidence their robustness. Recently , various methods based on convex optimization deliver been proposed to address this issue. In particular , the semidefinite programming ( SDP ) approach has gained popularity in convexifying the robustness psychoanalysis problem. Since this approach is prostrate to a large relaxation gap , this paper develops a new technique to reduce the gap by adding non-convex cuts via disjunctive programming. The proposed method amounts to a sequential SDP proficiency. We analyse the performance of this method both theoretically and empirically , and show that it bridges the gap as the number of cuts increases. ", "label": 1}
{"original_text": "Accurate rainfall forecasting is critical because it has a great impact on people's social and economic activities. Recent trends on various literatures shows that Deep Learning (Neural Network) is a promising methodology to tackle many challenging tasks. In this study, we introduce a brand-new data-driven precipitation prediction model called DeepRain. This model predicts the amount of rainfall from weather radar data, which is three-dimensional and four-channel data, using convolutional LSTM (ConvLSTM). ConvLSTM is a variant of LSTM (Long Short-Term Memory) containing a convolution operation inside the LSTM cell. For the experiment, we used radar reflectivity data for a two-year period whose input is in a time series format in units of 6 min divided into 15 records. The output is the predicted rainfall information for the input data. Experimental results show that two-stacked ConvLSTM reduced RMSE by 23.0 compared to linear regression.", "text_perturb": "Accurate rainfall forecasting is critical because it has a great impact on people 's social and economic bodily function. Recent trends on various literatures shows that Deep Learning ( Neural Network ) is a promising methodology to take on many challenging tasks. In this study , we introduce a brand new data-driven precipitation prediction model called DeepRain. This model predicts the amount of rainfall from weather radar data , which is three d and four-channel data , using convolutional LSTM ( ConvLSTM ). ConvLSTM is a variant of LSTM ( Long Short-Term memory board ) containing a convolution operation inside the LSTM cell. For the experiment , we used radar reflection data for a two-year period whose input is in a time series format in units of 6 min divided into 15 records. The output signal is the predicted rainfall information for the input data. Experimental results show that two-stacked ConvLSTM quash RMSE by 23. 0 compared to linear regression. ", "label": 1}
{"original_text": "In this paper, we present a novel low rank representation (LRR) algorithm for data lying on the manifold of square root densities. Unlike traditional LRR methods which rely on the assumption that the data points are vectors in the Euclidean space, our new algorithm is designed to incorporate the intrinsic geometric structure and geodesic distance of the manifold. Experiments on several computer vision datasets showcase its noise robustness and superior performance on classification and subspace clustering compared to other state-of-the-art approaches.", "text_perturb": "In this paper , we present a novel low rank representation ( LRR ) algorithm for data lying on the manifold of straightforward root densities. Unlike traditional LRR methods which rely on the presumption that the data points are vectors in the Euclidean space , our new algorithm is designed to incorporate the intrinsic geometric structure and geodesic distance of the manifold. Experiments on several computer vision datasets showcase its noise robustness and superior performance on classification and subspace clustering compared to early state-of-the-art approaches. ", "label": 1}
{"original_text": "This work proposes a novel algorithm to generate natural language adversarial input for text classification models, in order to investigate the robustness of these models. It involves applying gradient-based perturbation on the sentence embeddings that are used as the features for the classifier, and learning a decoder for generation. We employ this method to a sentiment analysis model and verify its effectiveness in inducing incorrect predictions by the model. We also conduct quantitative and qualitative analysis on these examples and demonstrate that our approach can generate more natural adversaries. In addition, it can be used to successfully perform black-box attacks, which involves attacking other existing models whose parameters are not known. On a public sentiment analysis API, the proposed method introduces a 20 relative decrease in average accuracy and 74 relative increase in absolute error.", "text_perturb": "This work proposes a novel algorithm to generate natural language adversarial input for text classification mannikin , in order to investigate the robustness of these mannikin. It involves applying gradient-based perturbation on the conviction embeddings that are used as the features for the classifier , and learning a decoder for generation. We employ this method to a sentiment analysis model and aver its effectiveness in inducing incorrect predictions by the model. We also conduct quantitative and qualitative analysis on these examples and demonstrate that our approach can generate more natural opposer. In addition , it can be used to successfully perform black-box blast , which involves attacking other existing models whose parameters are not known. On a public sentiment analysis API , the proposed method introduces a 20 relative decrease in average accuracy and 74 relative increment in absolute error. ", "label": 1}
{"original_text": "Scalability properties of deep neural networks raise key research questions, particularly as the problems considered become larger and more challenging. This paper expands on the idea of conditional computation introduced in, where the nodes of a deep network are augmented by a set of gating units that determine when a node should be calculated. By factorizing the weight matrix into a low-rank approximation, an estimation of the sign of the pre-nonlinearity activation can be efficiently obtained. For networks using rectified-linear hidden units, this implies that the computation of a hidden unit with an estimated negative pre-nonlinearity can be omitted altogether, as its value will become zero when nonlinearity is applied. For sparse neural networks, this can result in considerable speed gains. Experimental results using the MNIST and SVHN data sets with a fully-connected deep neural network demonstrate the performance robustness of the proposed scheme with respect to the error introduced by the conditional computation process.", "text_perturb": "Scalability properties of deep neural networks raise key research questions , particularly as the problems considered become gravid and more challenging. This paper expands on the idea of conditional calculation introduced in , where the nodes of a deep network are augmented by a set of gating units that determine when a node should be calculated. By factorizing the system of weights matrix into a low-rank approximation , an estimation of the sign of the pre-nonlinearity activation can be efficiently obtained. For networks utilise rectified-linear hidden units , this implies that the computation of a hidden unit with an estimated negative pre-nonlinearity can be omitted altogether , as its value will become zero when nonlinearity is applied. For sparse neural meshwork , this can result in considerable speed gains. Experimental results using the MNIST and SVHN data sets with a fully-connected deep neural network demonstrate the performance robustness of the proposed scheme with deference to the error introduced by the conditional computation process. ", "label": 1}
{"original_text": "We study the problem of learning a real-valued function that satisfies the Demographic Parity constraint. It demands the distribution of the predicted output to be independent of the sensitive attribute. We consider the case that the sensitive attribute is available for prediction. We establish a connection between fair regression and optimal transport theory, based on which we derive a close form expression for the optimal fair predictor. Specifically, we show that the distribution of this optimum is the Wasserstein barycenter of the distributions induced by the standard regression function on the sensitive groups. This result offers an intuitive interpretation of the optimal fair prediction and suggests a simple post-processing algorithm to achieve fairness. We establish risk and distribution-free fairness guarantees for this procedure. Numerical experiments indicate that our method is very effective in learning fair models, with a relative increase in error rate that is inferior to the relative gain in fairness.", "text_perturb": "We study the problem of learning a real-valued function that satisfies the Demographic Parity restraint. It demands the distribution of the predicted output to be independent of the sensitive dimension. We consider the case that the sensitive dimension is available for prediction. We establish a connection between fair regression and optimal transport possibility , based on which we derive a close form expression for the optimal fair predictor. Specifically , we show that the distribution of this optimum is the Wasserstein barycenter of the distributions induced by the standard regression procedure on the sensitive groups. This resultant role offers an intuitive interpretation of the optimal fair prediction and suggests a simple post-processing algorithm to achieve fairness. We establish risk and distribution-free fairness guaranty for this procedure. Numerical experiments indicate that our method is very effective in learning fair models , with a proportional increase in error rate that is inferior to the proportional gain in fairness. ", "label": 1}
{"original_text": "Currently in the domain of facial analysis single task approaches for face detection and landmark localization dominate. In this paper we draw attention to multi-task models solving both tasks simultaneously. We present a highly accurate model for face and landmark detection. The method, called MaskFace, extends previous face detection approaches by adding a keypoint prediction head. The new keypoint head adopts ideas of Mask R-CNN by extracting facial features with a RoIAlign layer. The keypoint head adds small computational overhead in the case of few faces in the image while improving the accuracy dramatically. We evaluate MaskFace's performance on a face detection task on the AFW, PASCAL face, FDDB, WIDER FACE datasets and a landmark localization task on the AFLW, 300W datasets. For both tasks MaskFace achieves state-of-the-art results outperforming many of single-task and multi-task models.", "text_perturb": "Currently in the domain of facial analysis single task approaches for face detection and landmark fix dominate. In this paper we draw attention to multi-task models solving both tasks at the same time. We present a highly accurate manikin for face and landmark detection. The method , shout out MaskFace , extends previous face detection approaches by adding a keypoint prediction head. The new keypoint head adopts ideas of Mask R-CNN by extracting facial feature film with a RoIAlign layer. The keypoint head adds small computational overhead in the case of few face in the image while improving the accuracy dramatically. We assess MaskFace 's performance on a face detection task on the AFW , PASCAL face , FDDB , WIDER FACE datasets and a landmark localization task on the AFLW , 300W datasets. For both tasks MaskFace achieves state-of-the-art results outperforming many of single-task and multi-task manakin. ", "label": 1}
{"original_text": "LexNLP is an open source Python package focused on natural language processing and machine learning for legal and regulatory text. The package includes functionality to (i) segment documents, (ii) identify key text such as titles and section headings, (iii) extract over eighteen types of structured information like distances and dates, (iv) extract named entities such as companies and geopolitical entities, (v) transform text into features for model training, and (vi) build unsupervised and supervised models such as word embedding or tagging models. LexNLP includes pre-trained models based on thousands of unit tests drawn from real documents available from the SEC EDGAR database as well as various judicial and regulatory proceedings. LexNLP is designed for use in both academic research and industrial applications, and is distributed at", "text_perturb": "LexNLP is an open source Python package focused on natural oral communication processing and machine learning for legal and regulatory text. The package includes functionality to ( i ) segment documents , ( ii ) identify key schoolbook such as titles and section headings , ( iii ) extract over eighteen types of structured information like distances and dates , ( iv ) extract named entities such as companies and geopolitical entities , ( v ) transform schoolbook into features for model training , and ( vi ) build unsupervised and supervised models such as word embedding or tagging models. LexNLP includes pre-trained models based on thousands of unit tests drawn from real documents available from the SEC EDGAR database as well as various judicial and regulative proceedings. LexNLP is designed for use in both pedantic research and industrial applications , and is distributed at", "label": 1}
{"original_text": "This work develops techniques for the sequential detection and location estimation of transient changes in the volatility (standard deviation) of time series data. In particular, we introduce a class of change detection algorithms based on the windowed volatility filter. The first method detects changes by employing a convex combination of two such filters with differing window sizes, such that the adaptively updated convex weight parameter is then used as an indicator for the detection of instantaneous power changes. Moreover, the proposed adaptive filtering based method is readily extended to the multivariate case by using recent advances in distributed adaptive filters, thereby using cooperation between the data channels for more effective detection of change points. Furthermore, this work also develops a novel change point location estimator based on the differenced output of the volatility filter. Finally, the performance of the proposed methods were evaluated on both synthetic and real world data. Index Terms - Volatility Change Detection, Transient Detection, Multi-SensoryMultivariate Data.", "text_perturb": "This work develops techniques for the sequential detection and location estimation of transient changes in the unpredictability ( standard deviation ) of time series data. In particular , we introduce a form of change detection algorithms based on the windowed volatility filter. The first method detects changes by employing a convex compounding of two such filters with differing window sizes , such that the adaptively updated convex weight parameter is then used as an indicator for the detection of instantaneous power changes. Moreover , the proposed adaptive filtering based method is readily extended to the multivariate case by using recent advances in distributed adaptive filters , thereby using cooperation between the data channels for to a greater extent effective detection of change points. Furthermore , this work also develops a novel change point location figurer based on the differenced output of the volatility filter. Finally , the performance of the proposed methods were evaluated on both synthetical and real world data. Index Terms - Volatility alteration Detection , Transient Detection , Multi-SensoryMultivariate Data. ", "label": 1}
{"original_text": "A wave energy converter (WEC) similar to the CETO system developed by Carnegie Clean Energy is considered for design optimisation. This WEC is able to absorb power from heave, surge and pitch motion modes, making the optimisation problem nontrivial. The WEC dynamics is simulated using the spectral-domain model taking into account hydrodynamic forces, viscous drag, and power take-off forces. The design parameters for optimisation include the buoy radius, buoy height, tether inclination angles, and control variables (damping and stiffness). The WEC design is optimised for the wave climate at Albany test site in Western Australia considering unidirectional irregular waves. Two objective functions are considered: (i) maximisation of the annual average power output, and (ii) minimisation of the levelised cost of energy (LCoE) for a given sea site. The LCoE calculation is approximated as a ratio of the produced energy to the significant mass of the system that includes the mass of the buoy and anchor system. Six different heuristic optimisation methods are applied in order to evaluate and compare the performance of the best known evolutionary algorithms, a swarm intelligence technique and a numerical optimisation approach. The results demonstrate that if we are interested in maximising energy production without taking into account the cost of manufacturing such a system, the buoy should be built as large as possible (20 m radius and 30 m height). However, if we want the system that produces cheap energy, then the radius of the buoy should be approximately 11-14 m while the height should be as low as possible. These results coincide with the overall design that Carnegie Clean Energy has selected for its CETO 6 multi-moored unit. However, it should be noted that this study is not informed by them, so this can be seen as an independent validation of the design choices.", "text_perturb": "A wave energy converter ( WEC ) similar to the CETO system developed by dale carnegie Clean Energy is considered for design optimisation. This WEC is able to take up power from heave , surge and pitch motion modes , making the optimisation problem nontrivial. The WEC dynamics is simulated using the spectral-domain model read into account hydrodynamic forces , viscous drag , and power take-off forces. The design parameters for optimisation include the buoy radius , buoy height , tether inclination angles , and control variable ( damping and stiffness ). The WEC design is optimised for the wave mood at Albany test site in Western Australia considering unidirectional irregular waves. Two objective functions are considered : ( i ) maximisation of the annual average power yield , and ( ii ) minimisation of the levelised cost of energy ( LCoE ) for a given sea site. The LCoE calculation is approximated as a ratio of the produced energy to the important mass of the system that includes the mass of the buoy and anchor system. Six different heuristic optimization methods are applied in order to evaluate and compare the performance of the best known evolutionary algorithms , a swarm intelligence technique and a numerical optimization approach. The results prove that if we are interested in maximising energy production without taking into account the cost of manufacturing such a system , the buoy should be built as large as possible ( 20 m radius and 30 m height ). However , if we require the system that produces cheap energy , then the radius of the buoy should be approximately 11-14 m while the height should be as low as possible. These results co occur with the overall design that Carnegie Clean Energy has selected for its CETO 6 multi-moored unit. However , it should comprise noted that this study is not informed by them , so this can comprise seen as an independent validation of the design choices. ", "label": 1}
{"original_text": "The Visual Dialog task requires a model to exploit both image and conversational context information to generate the next response to the dialogue. However, via manual analysis, we find that a large number of conversational questions can be answered by only looking at the image without any access to the context history, while others still need the conversation context to predict the correct answers. We demonstrate that due to this reason, previous joint-modality (history and image) models over-rely on and are more prone to memorizing the dialogue history (e.g., by extracting certain keywords or patterns in the context information), whereas image-only models are more generalizable (because they cannot memorize or extract keywords from history) and perform substantially better at the primary normalized discounted cumulative gain (NDCG) task metric which allows multiple correct answers. Hence, this observation encourages us to explicitly maintain two models, i.e., an image-only model and an image-history joint model, and combine their complementary abilities for a more balanced multimodal model. We present multiple methods for this integration of the two models, via ensemble and consensus dropout fusion with shared parameters. Empirically, our models achieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and high balance across metrics), and substantially outperform the winner of the Visual Dialog challenge 2018 on most metrics.", "text_perturb": "The Visual Dialog task requires a model to exploit both image and conversational setting information to generate the next response to the dialogue. However , via manual analysis , we find that a large number of conversational questions can be answered by only looking at the image without any access to the context history , while others nonetheless need the conversation context to predict the correct answers. We demonstrate that due to this reason , previous joint-modality ( history and image ) models over-rely on and follow more prone to memorizing the dialogue history ( e. gigabyte. , by extracting certain keywords or pattern in the context information ) , whereas image-only models are more generalizable ( because they can not memorize or extract keywords from history ) and perform substantially better at the primary normalized discounted cumulative gain ( NDCG ) task metric which allows multiple correct answers. Hence , this observation advance us to explicitly maintain two models , i. tocopherol. , an image-only model and an image-history joint model , and combine their complementary abilities for a to a greater extent balanced multimodal model. We present multiple method acting for this integration of the two models , via ensemble and consensus dropout fusion with shared parameters. Empirically , our models attain strong results on the Visual Dialog challenge 2019 ( rank 3 on NDCG and high balance across metrics ) , and substantially outperform the winner of the Visual Dialog challenge 2018 on most metrics. ", "label": 1}
{"original_text": "This paper addresses the problem of planning for a robot with a directional obstacle-detection sensor that must move through a cluttered environment. The planning objective is to remain safe by finding a path for the complete robot, including sensor, that guarantees that the robot will not move into any part of the workspace before it has been seen by the sensor. Although a great deal of work has addressed a version of this problem in which the \"field of view\" of the sensor is a sphere around the robot, there is very little work addressing robots with a narrow or occluded field of view. We give a formal definition of the problem, several solution methods with different computational trade-offs, and experimental results in illustrative domains.", "text_perturb": "This paper addresses the problem of planning for a robot with a directing obstacle-detection sensor that must move through a cluttered environment. The planning objective is to remain safe by finding a path for the complete robot , including sensor , that guarantees that the robot will not go into any part of the workspace before it has been seen by the sensor. Although a great deal of work has plow a version of this problem in which the `` field of view '' of the sensor is a sphere around the robot , there is very little work addressing robots with a narrow or occluded field of view. We give a formal definition of the problem , several solution methods with different computational trade-offs , and experimental results in illustrative sphere. ", "label": 1}
{"original_text": "Neural style transfer has drawn considerable attention from both academic and industrial field. Although visual effect and efficiency have been significantly improved, existing methods are unable to coordinate spatial distribution of visual attention between the content image and stylized image, or render diverse level of detail via different brush strokes. In this paper, we tackle these limitations by developing an attention-aware multi-stroke style transfer model. We first propose to assemble self-attention mechanism into a style-agnostic reconstruction autoencoder framework, from which the attention map of a content image can be derived. By performing multi-scale style swap on content features and style features, we produce multiple feature maps reflecting different stroke patterns. A flexible fusion strategy is further presented to incorporate the salient characteristics from the attention map, which allows integrating multiple stroke patterns into different spatial regions of the output image harmoniously. We demonstrate the effectiveness of our method, as well as generate comparable stylized images with multiple stroke patterns against the state-of-the-art methods.", "text_perturb": "Neural style transfer has drawn considerable attention from both pedantic and industrial field. Although visual effect and efficiency have been significantly improved , existing methods are unable to coordinate spatial distribution of visual attention between the content effigy and stylized effigy , or render diverse level of detail via different brush strokes. In this paper , we tackle these limitations by developing an attention-aware multi-stroke style transfer mannequin. We first propose to assemble self-attention mechanism into a style-agnostic reconstruction autoencoder theoretical account , from which the attention map of a content image can be derived. By performing multi-scale style swap on content features and style features , we produce multiple feature maps reflecting different stroke design. A conciliatory fusion strategy is further presented to incorporate the salient characteristics from the attention map , which allows integrating multiple stroke patterns into different spatial regions of the output image harmoniously. We demonstrate the effectiveness of our method , every bit well as generate comparable stylized images with multiple stroke patterns against the state-of-the-art methods. ", "label": 1}
{"original_text": "Bitcoin introduced delegation of control over a monetary system from a select few to all who participate in that system. This delegation is known as the decentralization of controlling power and is a powerful security mechanism for the ecosystem. After the introduction of Bitcoin, the field of cryptocurrency has seen widespread attention from industry and academia, so much so that the original novel contribution of Bitcoin, i.e., decentralization, may be overlooked, due to decentralizations' assumed fundamental existence for the functioning of such crypto-assets. However, recent studies have observed a trend of increased centralization in cryptocurrencies such as Bitcoin and Ethereum. As this increased centralization has an impact the security of the blockchain, it is crucial that it is measured, towards adequate control. This research derives an initial taxonomy of centralization present in decentralized blockchains through rigorous synthesis using a systematic literature review. This is followed by iterative refinement through expert interviews. We systematically analyzed 89 research papers published between 2009 and 2019. Our study contributes to the existing body of knowledge by highlighting the multiple definitions and measurements of centralization in the literature. We identify different aspects of centralization and propose an encompassing taxonomy of centralization concerns. This taxonomy is based on empirically observable and measurable characteristics. It consists of 13 aspects of centralization, classified over six architectural layers: Governance, Network, Consensus, Incentive, Operational, and Application. We also discuss how the implications of centralization can vary depending on the aspects studied. We believe that this review and taxonomy provides a comprehensive overview of centralization in decentralized blockchains involving various conceptualizations and measures.", "text_perturb": "Bitcoin introduced delegation of control over a monetary system from a select few to all who take part in that system. This delegation equal known as the decentralization of controlling power and equal a powerful security mechanism for the ecosystem. After the introduction of Bitcoin , the field of cryptocurrency has seen widespread attention from manufacture and academia , so much so that the original novel contribution of Bitcoin , i. tocopherol. , decentralization , may personify overlooked , due to decentralizations ' assumed fundamental existence for the functioning of such crypto-assets. However , recent studies make observed a trend of increased centralization in cryptocurrencies such as Bitcoin and Ethereum. As this increased centralization has an impact the security of the blockchain , it make up crucial that it make up measured , towards adequate control. This research derives an initial taxonomy of centralization present in decentralized blockchains through strict synthesis using a systematic literature review. This is followed by reiterative refinement through expert interviews. We systematically analyzed 89 research theme published between 2009 and 2019. Our study contributes to the existing body of knowledge by highlighting the multiple definitions and measurements of centralisation in the literature. We identify different view of centralization and propose an encompassing taxonomy of centralization concerns. This taxonomy is based on empirically discernible and measurable characteristics. It consists of 13 aspects of centralization , classified over six architectural layers : governance , Network , Consensus , Incentive , Operational , and Application. We also discuss how the implication of centralization can vary depending on the aspects studied. We believe that this review and taxonomy offer a comprehensive overview of centralization in decentralized blockchains involving various conceptualizations and measures. ", "label": 1}
{"original_text": "Unsupervised dependency parsing, which tries to discover linguistic dependency structures from unannotated data, is a very challenging task. Almost all previous work on this task focuses on learning generative models. In this paper, we develop an unsupervised dependency parsing model based on the CRF autoencoder. The encoder part of our model is discriminative and globally normalized which allows us to use rich features as well as universal linguistic priors. We propose an exact algorithm for parsing as well as a tractable learning algorithm. We evaluated the performance of our model on eight multilingual treebanks and found that our model achieved comparable performance with state-of-the-art approaches.", "text_perturb": "Unsupervised dependency parsing , which taste to discover linguistic dependency structures from unannotated data , is a very challenging task. Almost all previous employment on this task focuses on learning generative models. In this composition , we develop an unsupervised dependency parsing model based on the CRF autoencoder. The encoder part of our model comprise discriminative and globally normalized which allows us to use rich features as well as universal linguistic priors. We propose an exact algorithmic rule for parsing as well as a tractable learning algorithmic rule. We evaluated the performance of our model on eight multilingual treebanks and found that our model achieved comparable performance with state of the art approaches. ", "label": 1}
{"original_text": "Symmetry is present in nature and science. In image processing, kernels for spatial filtering possess some symmetry (e.g. Sobel operators, Gaussian, Laplacian). Convolutional layers in artificial feed-forward neural networks have typically considered the kernel weights without any constraint. In this paper, we propose to investigate the impact of a symmetry constraint in convolutional layers for image classification tasks, taking our inspiration from the processes involved in the primary visual cortex and common image processing techniques. The goal is to assess the extent to which it is possible to enforce symmetrical constraints on the filters throughout the training process of a convolutional neural network (CNN) by modifying the weight update preformed during the backpropagation algorithm and to evaluate the change in performance. The main hypothesis of this paper is that the symmetrical constraint reduces the number of free parameters in the network, and it is able to achieve near identical performance to the modern methodology of training. In particular, we address the following cases: xy-axis symmetry, point reflection, and anti-point reflection. The performance has been evaluated on four databases of images. The results support the conclusion that while random weights offer more freedom to the model, the symmetry constraint provides a similar level of performance while decreasing substantially the number of free parameters in the model. Such an approach can be valuable in phase-sensitive applications that require a linear phase property throughout the feature extraction process.", "text_perturb": "Symmetry cost present in nature and science. In image processing , kernels for spatial filtering posse some symmetry ( e. gibibyte. Sobel wheeler dealer , Gaussian , Laplacian ). Convolutional layers in contrived feed-forward neural networks have typically considered the kernel weights without any constraint. In this newspaper , we propose to investigate the impact of a symmetry constraint in convolutional layers for image classification tasks , taking our inspiration from the processes involved in the primary visual cortex and common image processing techniques. The goal is to assess the extent to which it is potential to enforce symmetrical constraints on the filters throughout the training process of a convolutional neural network ( CNN ) by modifying the weight update preformed during the backpropagation algorithm and to evaluate the change in performance. The main hypothesis of this paper is that the symmetrical constraint reduces the number of free parameters in the network , and it is able to achieve near monovular performance to the modern methodology of training. In particular , we speak the following cases : xy-axis symmetry , point reflection , and anti-point reflection. The performance has been evaluated on four database of images. The results support the conclusion that while random weights offer more freedom to the model , the symmetry constraint provides a similar level of performance while decreasing substantially the number of barren parameters in the model. Such an approach can be valuable in phase-sensitive applications that require a linear form property throughout the feature extraction process. ", "label": 1}
{"original_text": "We consider a wireless distributed computing system, in which multiple mobile users, connected wirelessly through an access point, collaborate to perform a computation task. In particular, users communicate with each other via the access point to exchange their locally computed intermediate computation results, which is known as data shuffling. We propose a scalable framework for this system, in which the required communication bandwidth for data shuffling does not increase with the number of users in the network. The key idea is to utilize a particular repetitive pattern of placing the dataset (thus a particular repetitive pattern of intermediate computations), in order to provide coding opportunities at both the users and the access point, which reduce the required uplink communication bandwidth from users to access point and the downlink communication bandwidth from access point to users by factors that grow linearly with the number of users. We also demonstrate that the proposed dataset placement and coded shuffling schemes are optimal (i.e., achieve the minimum required shuffling load) for both a centralized setting and a decentralized setting, by developing tight information-theoretic lower bounds.", "text_perturb": "We consider a wireless distributed computing system , in which multiple mobile users , connected wirelessly through an access point , collaborate to perform a computation project. In particular , users communicate with each other via the access point to exchange their topically computed intermediate computation results , which is known as data shuffling. We propose a scalable framework for this system , in which the required communicating bandwidth for data shuffling does not increase with the number of users in the network. The key idea is to utilize a particular insistent pattern of placing the dataset ( thus a particular insistent pattern of intermediate computations ) , in order to provide coding opportunities at both the users and the access point , which reduce the required uplink communication bandwidth from users to access point and the downlink communication bandwidth from access point to users by factors that grow linearly with the number of users. We also demonstrate that the proposed dataset placement and coded shuffling schema are optimal ( i. atomic number . , achieve the lower limit required shuffling load ) for both a centralized setting and a decentralized setting , by developing tight information-theoretic lower bounds. ", "label": 1}
{"original_text": "In this paper we present mono-stixels, a compact environment representation specially designed for dynamic street scenes. Mono-stixels are a novel approach to estimate stixels from a monocular camera sequence instead of the traditionally used stereo depth measurements. Our approach jointly infers the depth, motion and semantic information of the dynamic scene as a 1D energy minimization problem based on optical flow estimates, pixel-wise semantic segmentation and camera motion. The optical flow of a stixel is described by a homography. By applying the mono-stixel model the degrees of freedom of a stixel-homography are reduced to only up to two degrees of freedom. Furthermore, we exploit a scene model and semantic information to handle moving objects. In our experiments we use the public available DeepFlow for optical flow estimation and FCN8s for the semantic information as inputs and show on the KITTI 2015 dataset that mono-stixels provide a compact and reliable depth reconstruction of both the static and moving parts of the scene. Thereby, mono-stixels overcome the limitation to static scenes of previous structure-from-motion approaches.", "text_perturb": "In this paper we present mono-stixels , a heavyset environment representation specially designed for dynamic street scenes. Mono-stixels are a novel approach to estimate stixels from a monocular television camera sequence instead of the traditionally used stereo depth measurements. Our approach jointly infers the depth , movement and semantic information of the dynamic scene as a 1D energy minimization problem based on optical flow estimates , pixel-wise semantic segmentation and camera movement. The opthalmic flow of a stixel is described by a homography. By applying the mono-stixel model the degrees of freedom of a stixel-homography are dilute to only up to two degrees of freedom. what is more , we exploit a scene model and semantic information to handle moving objects. In our experiments we use the public available DeepFlow for optical flow estimation and FCN8s for the semantic information as inputs and show on the KITTI 2015 dataset that mono-stixels provide a compact and dependable depth reconstruction of both the static and moving parts of the scene. Thereby , mono-stixels overcome the limitation to unchanging scenes of previous structure-from-motion approaches. ", "label": 1}
{"original_text": "Architecture search is the process of automatically learning the neural model or cell structure that best suits the given task. Recently, this approach has shown promising performance improvements (on language modeling and image classification) with reasonable training speed, using a weight sharing strategy called Efficient Neural Architecture Search (ENAS). In our work, we first introduce a novel continual architecture search (CAS) approach, so as to continually evolve the model parameters during the sequential training of several tasks, without losing performance on previously learned tasks (via block-sparsity and orthogonality constraints), thus enabling life-long learning. Next, we explore a multi-task architecture search (MAS) approach over ENAS for finding a unified, single cell structure that performs well across multiple tasks (via joint controller rewards), and hence allows more generalizable transfer of the cell structure knowledge to an unseen new task. We empirically show the effectiveness of our sequential continual learning and parallel multi-task learning based architecture search approaches on diverse sentence-pair classification tasks (GLUE) and multimodal-generation based video captioning tasks. Further, we present several ablations and analyses on the learned cell structures. 1 footnote 1 1 footnote 1 All our code and models publicly available at:", "text_perturb": "Architecture search is the process of mechanically learning the neural model or cell structure that best suits the given task. Recently , this approach has shown promising performance improvements ( on language mold and image classification ) with reasonable training speed , using a weight sharing strategy called Efficient Neural Architecture Search ( ENAS ). In our work , we first introduce a novel continual architecture search ( CAS ) approach , so as to continually germinate the model parameters during the sequential training of several tasks , without losing performance on previously learned tasks ( via block-sparsity and orthogonality constraints ) , thus enabling life-long learning. Next , we explore a multi-task computer architecture search ( MAS ) approach over ENAS for finding a unified , single cell structure that performs well across multiple tasks ( via joint controller rewards ) , and hence allows more generalizable transfer of the cell structure knowledge to an unseen new task. We empirically show the effectiveness of our successive continual learning and parallel multi-task learning based architecture search approaches on diverse sentence-pair classification tasks ( GLUE ) and multimodal-generation based video captioning tasks. Further , we present various ablations and analyses on the learned cell structures. 1 footnote 1 1 footer 1 All our code and models publicly available at :", "label": 1}
{"original_text": "Deep learning models continuously break new records across different NLP tasks. At the same time, their success exposes weaknesses of model evaluation. Here, we compile several key pitfalls of evaluation of sentence embeddings, a currently very popular NLP paradigm. These pitfalls include the comparison of embeddings of different sizes, normalization of embeddings, and the low (and diverging) correlations between transfer and probing tasks. Our motivation is to challenge the current evaluation of sentence embeddings and to provide an easy-to-access reference for future research. Based on our insights, we also recommend better practices for better future evaluations of sentence embeddings.", "text_perturb": "Deep encyclopedism models continuously break new records across different NLP tasks. At the same time , their succeeder exposes weaknesses of model evaluation. Here , we amass several key pitfalls of evaluation of sentence embeddings , a currently very popular NLP paradigm. These pitfalls include the comparison of embeddings of different sizes , standardization of embeddings , and the low ( and diverging ) correlations between transfer and probing tasks. Our motivation is to dispute the current evaluation of sentence embeddings and to provide an easy-to-access reference for future research. Based on our insights , we also recommend better practices for better next evaluations of sentence embeddings. ", "label": 1}
{"original_text": "During the past two years, Flash malware has become one of the most insidious threats to detect, with almost 600 critical vulnerabilities targeting Adobe Flash Player disclosed in the wild. Research has shown that machine learning can be successfully used to tackle this increasing variability and sophistication of Flash malware, by simply leveraging static analysis to extract information from the structure of the file or from its bytecode. However, the robustness of such systems against well-crafted evasion attempts - also known as adversarial examples - has never been investigated. In this paper, we first discuss how to craft adversarial Flash malware examples, and show that it suffices to only slightly manipulate them to evade detection. We then empirically demonstrate that popular defense techniques proposed to mitigate such threat, including re-training on adversarial examples, may not always be effective. We argue that this occurs when the feature vectors extracted from adversarial examples become indistinguishable from those of benign data, meaning that the given feature representation is intrinsically vulnerable. In this respect, we are the first to formally define and quantitatively characterize this vulnerability, highlighting when an attack can be countered by solely improving the security of the learning algorithm, or when it requires also considering additional features. We conclude the paper by suggesting alternative research directions to improve the security of learning-based Flash malware detectors.", "text_perturb": "During the past two years , Flash malware has become one of the most insidious threats to detect , with almost 600 critical vulnerabilities targeting Adobe Flash Player unwrap in the wild. Research has shown that machine learning can be successfully used to tackle this increasing variability and sophistication of Flash malware , by simply leverage static analysis to extract information from the structure of the file or from its bytecode. However , the robustness of such systems against well-crafted evasion attempts - also known as adversarial examples - has never been look into. In this paper , we first hash out how to craft adversarial Flash malware examples , and show that it suffices to only slightly manipulate them to evade detection. We then empirically demonstrate that popular defense techniques proposed to mitigate such threat , including re-training on adversarial examples , may not always embody effective. We argue that this pass off when the feature vectors extracted from adversarial examples become indistinguishable from those of benign data , meaning that the given feature representation is intrinsically vulnerable. In this respect , we are the first to formally specify and quantitatively characterize this vulnerability , highlighting when an attack can be countered by solely improving the security of the learning algorithm , or when it requires also considering additional features. We conclude the paper by suggesting alternative research commission to improve the security of learning-based Flash malware detectors. ", "label": 1}
{"original_text": "Batch Normalization (BN) is capable of accelerating the training of deep models by centering and scaling activations within mini-batches. In this work, we propose Decorrelated Batch Normalization (DBN), which not just centers and scales activations but whitens them. We explore multiple whitening techniques, and find that PCA whitening causes a problem we call stochastic axis swapping, which is detrimental to learning. We show that ZCA whitening does not suffer from this problem, permitting successful learning. DBN retains the desirable qualities of BN and further improves BN's optimization efficiency and generalization ability. We design comprehensive experiments to show that DBN can improve the performance of BN on multilayer perceptrons and convolutional neural networks. Furthermore, we consistently improve the accuracy of residual networks on CIFAR-10, CIFAR-100, and ImageNet.", "text_perturb": "Batch Normalization ( BN ) is capable of accelerating the breeding of deep models by centering and scaling activations within mini-batches. In this work , we propose Decorrelated Batch Normalization ( DBN ) , which not just middle and scales activations but whitens them. We explore multiple whitening techniques , and find that PCA whitening causes a problem we promise stochastic axis swapping , which is detrimental to learning. We show that ZCA whitening does not suffer from this problem , let successful learning. DBN retains the desirable caliber of BN and further improves BN 's optimization efficiency and generalization ability. We design comprehensive experiments to show that DBN can improve the carrying out of BN on multilayer perceptrons and convolutional neural networks. Furthermore , we consistently better the accuracy of residual networks on CIFAR-10 , CIFAR-100 , and ImageNet. ", "label": 1}
{"original_text": "Accurate local fiber orientation distribution (FOD) modeling based on diffusion magnetic resonance imaging (dMRI) capable of resolving complex fiber configurations benefit from specific acquisition protocols that impose a high number of gradient directions (b-vecs), a high maximum b-value (b-vals) and multiple b-values (multi-shell). However, acquisition time is limited in a clinical setting and commercial scanners may not provide robust state-of-the-art dMRI sequences. Therefore, dMRI is often acquired as single-shell (SS) (single b-value). Here, we learn improved FODs for commercially acquired dMRI. We evaluate the use of 3D convolutional neural networks (CNNs) to regress multi-shell FOS representations from single-shell representations, using the spherical harmonics basis obtained from constrained spherical deconvolution (CSD) to model FODs. We use U-Net and HighResNet 3D CNN architectures and data from the publicly available Human Connectome Dataset and a dataset acquired at National Hospital For Neurology and Neurosurgery Queen Square. We evaluate how well the CNN models can resolve local fiber orientation 1) when training and testing on datasets with same dMRI acquisition protocol; 2) when testing on dataset with a different dMRI acquisition protocol than used training the CNN models; and 3) when testing on datasets where a fewer number dMRI gradient directions than used training the CNN models. Our approach may enable robust CSD model estimation on dMRI acquisition protocols which are single shell and with a few gradient directions, reducing acquisition times, and thus, facilitating translation to time-limited clinical environments.", "text_perturb": "Accurate local fiber orientation distribution ( FOD ) modeling based on diffusion magnetic resonance imaging ( dMRI ) capable of resolving complex fiber configurations benefit from specific acquisition protocols that impose a high number of gradient directions ( b-vecs ) , a high maximal b-value ( b-vals ) and multiple b-values ( multi-shell ). However , acquisition time is limited in a clinical setting and commercial scanners may not provide robust state-of-the-art dMRI succession. Therefore , dMRI comprise often acquired as single-shell ( SS ) ( single b-value ). Here , we learn improved FODs for commercially take dMRI. We evaluate the consumption of 3D convolutional neural networks ( CNNs ) to regress multi-shell FOS representations from single-shell representations , using the spherical harmonics basis obtained from constrained spherical deconvolution ( CSD ) to model FODs. We use U-Net and HighResNet 3D CNN architectures and data from the publicly available Human Connectome Dataset and a dataset acquired at National Hospital For clinical neurology and Neurosurgery Queen Square. We evaluate how well the CNN models can adjudicate local fiber orientation 1 ) when training and testing on datasets with same dMRI acquisition protocol ; 2 ) when testing on dataset with a different dMRI acquisition protocol than used training the CNN models ; and 3 ) when testing on datasets where a fewer number dMRI gradient directions than used training the CNN models. Our approach may enable robust CSD model estimation on dMRI acquisition protocols which are single shell and with a few gradient directions , reducing acquisition times , and thusly , facilitating translation to time-limited clinical environments. ", "label": 1}
{"original_text": "Algorithmic statistics has two different (and almost orthogonal) motivations. From the philosophical point of view, it tries to formalize how the statistics works and why some statistical models are better than others. After this notion of a \"good model\" is introduced, a natural question arises: it is possible that for some piece of data there is no good model? If yes, how often these bad (non-stochastic) data appear \"in real life\"? Another, more technical motivation comes from algorithmic information theory. In this theory a notion of complexity of a finite object (amount of information in this object) is introduced; it assigns to every object some number, called its algorithmic complexity (or Kolmogorov complexity). Algorithmic statistic provides a more fine-grained classification: for each finite object some curve is defined that characterizes its behavior. It turns out that several different definitions give (approximately) the same curve. 1 1 footnote 1 Road-map: Section considers the notion of (a, b) -stochasticity; Section considers two-part descriptions and the so-called \"minimal description length principle\"; Section gives one more approach: we consider the list of objects of bounded complexity and measure how far some object is from the end of the list, getting some natural class of \"standard descriptions\" as a by-product; finally, Section establishes a connection between these notions and resource-bounded complexity. The rest of the paper deals with an attempts to make theory close to practice by considering restricted classes of description (Section) and strong models (Section). In this survey we try to provide an exposition of the main results in the field (including full proofs for the most important ones), as well as some historical comments. We assume that the reader is familiar with the main notions of algorithmic information (Kolmogorov complexity) theory. An exposition can be found in [, chapters 1, 3, 4] or [, chapters 2, 3], see also the survey. A short survey of main results of algorithmic statistics was given in (without proofs); see also the last chapter of the book.", "text_perturb": "Algorithmic statistics make two different ( and almost orthogonal ) motivations. From the philosophical gunpoint of view , it tries to formalize how the statistics works and why some statistical models are better than others. After this notion of a `` good model '' is introduced , a natural question arises : it is possible that for some piece of data there is no good model ? If yes , how much these bad ( non-stochastic ) data appear `` in real life '' ? Another , more technical motivation comes from algorithmic information theory. In this theory a notion of complexness of a finite object ( amount of information in this object ) is introduced ; it assigns to every object some number , called its algorithmic complexness ( or Kolmogorov complexness ). Algorithmic statistic provides a more close grained classification : for each finite object some curve is defined that characterizes its behavior. It turns out that several different definitions give ( approximately ) the like curve. 1 1 footnote 1 Road-map : Section considers the notion of ( a , b ) -stochasticity ; Section considers two-part descriptions and the so-called `` minimal description length principle '' ; Section gives one more approach : we consider the list of objects of bounded complexity and measure how far some object is from the end of the list , getting some natural class of `` standard descriptions '' as a by-product ; finally , Section establishes a joining between these notions and resource-bounded complexity. The rest of the paper deals with an attempts to make theory close to practice session by considering restricted classes of description ( Section ) and strong models ( Section ). In this survey we try to provide an exposition of the main results in the field ( let in full proofs for the most important ones ) , as well as some historical comments. We assume that the lector is familiar with the main notions of algorithmic information ( Kolmogorov complexity ) theory. An exposition can be found in [ , chapters 1 , 3 , 4 ] or [ , chapters 2 , 3 ] , see as well the survey. A short sight of main results of algorithmic statistics was given in ( without proofs ) ; see also the last chapter of the book. ", "label": 1}
{"original_text": "The standard approach to providing interpretability to deep convolutional neural networks (CNNs) consists of visualizing either their feature maps, or the image regions that contribute the most to the prediction. In this paper, we introduce an alternative strategy to interpret the results of a CNN. To this end, we leverage a Bag of visual Word representation within the network and associate a visual and semantic meaning to the corresponding codebook elements via the use of a generative adversarial network. The reason behind the prediction for a new sample can then be interpreted by looking at the visual representation of the most highly activated codeword. We then propose to exploit our interpretable BoW networks for adversarial example detection. To this end, we build upon the intuition that, while adversarial samples look very similar to real images, to produce incorrect predictions, they should activate codewords with a significantly different visual representation. We therefore cast the adversarial example detection problem as that of comparing the input image with the most highly activated visual codeword. As evidenced by our experiments, this allows us to outperform the state-of-the-art adversarial example detection methods on standard benchmarks, independently of the attack strategy.", "text_perturb": "The standard approach to providing interpretability to deep convolutional neural networks ( CNNs ) consists of visualizing either their feature maps , or the image regions that kick in the most to the prediction. In this paper , we introduce an alternative scheme to interpret the results of a CNN. To this end , we leverage a Bag of visual Word internal representation within the network and associate a visual and semantic meaning to the corresponding codebook elements via the use of a generative adversarial network. The reason behind the prediction for a new sample can then be interpreted by looking at the visual representation of the most highly excited codeword. We then propose to exploit our explainable BoW networks for adversarial example detection. To this end , we build upon the intuition that , while adversarial samples look very similar to real images , to grow incorrect predictions , they should activate codewords with a significantly different visual representation. We therefore cast the adversarial example detection problem as that of comparing the input image with the most highly excited visual codeword. As evidenced by our experiments , this allows us to outperform the state-of-the-art adversarial example detection methods on stock benchmarks , independently of the attack strategy. ", "label": 1}
{"original_text": "It is a considerable task to collect digital trace data at a large scale andat the same time adhere to established academic standards. In the context ofpolitical communication, important challenges are (1) defining the social mediaaccounts and posts relevant to the campaign (content validity), (2) operationalizing the venues where relevant social media activity takes place (construct validity), (3) capturing all of the relevant social media activity (reliability), and (4) sharing as much data as possible for reuse andreplication (objectivity). This project by GESIS - Leibniz Institute for theSocial Sciences and the E-Democracy Program of the University of Koblenz-Landauconducted such an effort. We concentrated on the two social media networks ofmost political relevance, Facebook and Twitter.", "text_perturb": "It is a considerable task to collect digital trace data point at a large scale andat the same time adhere to established academic standards. In the context ofpolitical communication , important challenges are ( 1 ) defining the social mediaaccounts and posts relevant to the campaign ( content validity ) , ( 2 ) operationalizing the venues where relevant social media activity takes place ( construct validity ) , ( 3 ) seize all of the relevant social media activity ( reliability ) , and ( 4 ) sharing as much data as possible for reuse andreplication ( objectivity ). This project by GESIS - Leibniz Institute for theSocial scientific discipline and the E-Democracy Program of the University of Koblenz-Landauconducted such an effort. We digest on the two social media networks ofmost political relevance , Facebook and Twitter. ", "label": 1}
{"original_text": "Neural program embedding has shown potential in aiding the analysis of large-scale, complicated software. Newly proposed deep neural architectures pride themselves on learning program semantics rather than superficial syntactic features. However, by considering the source code only, the vast majority of neural networks do not capture a deep, precise representation of program semantics. In this paper, we present DyPro, a novel deep neural network that learns from program execution traces. Compared to the prior dynamic models, not only is DyPro capable of generalizing across multiple executions for learning a program's dynamic semantics in its entirety, but DyPro is also more efficient when dealing with programs yielding long execution traces. For evaluation, we task DyPro with semantics classification (i.e. categorizing programs based on their semantics) and compared it against two prominent static models: Gated Graph Neural Network and TreeLSTM. We find that DyPro achieves the highest prediction accuracy among all models. To further reveal the capacity of all aforementioned deep neural architectures, we examine if the models can learn to detect deeper semantic properties of a program. In particular given a task of recognizing loop invariants, we find that DyPro outperforms all static models by a wide margin.", "text_perturb": "Neural program embedding has shown potential in aiding the psychoanalysis of large-scale , complicated software. Newly proposed deep neural architectures pride themselves on learning program semantics rather than superficial syntactic lineament. However , by considering the source code only , the vast majority of neural networks do not capture a abstruse , precise representation of program semantics. In this paper , we present DyPro , a novel cryptical neural network that learns from program execution traces. Compared to the prior dynamic models , not only is DyPro capable of generalizing across multiple executions for learning a computer program 's dynamic semantics in its entirety , but DyPro is also more efficient when dealing with programs yielding long execution traces. For evaluation , we task DyPro with semantics classification ( . eastward. categorise programs based on their semantics ) and compared it against two prominent static models : Gated Graph Neural Network and TreeLSTM. We find that DyPro accomplish the highest prediction accuracy among all models. To further reveal the capacity of all aforementioned deep neural architecture , we examine if the models can learn to detect deeper semantic properties of a program. In picky given a task of recognizing loop invariants , we find that DyPro outperforms all static models by a wide margin. ", "label": 1}
{"original_text": "While significant improvements have been made in recent years in terms of end-to-end automatic speech recognition (ASR) performance, such improvements were obtained through the use of very large neural networks, unfit for embedded use on edge devices. That being said, in this paper, we work on simplifying and compressing Transformer-based encoder-decoder architectures for the end-to-end ASR task. We empirically introduce a more compact Speech-Transformer by investigating the impact of discarding particular modules on the performance of the model. Moreover, we evaluate reducing the numerical precision of our network's weights and activations while maintaining the performance of the full-precision model. Our experiments show that we can reduce the number of parameters of the full-precision model and then further compress the model 4x by fully quantizing to 8-bit fixed point precision.", "text_perturb": "While significant improvements have been made in recent years in terms of end-to-end automatic speech recognition ( ASR ) performance , such improvements were obtained through the use of very prominent neural networks , unfit for embedded use on edge devices. That being said , in this paper , we work on simplify and compressing Transformer-based encoder-decoder architectures for the end-to-end ASR task. We empirically introduce a more compact Speech-Transformer by investigating the shock of discarding particular modules on the performance of the model. Moreover , we evaluate reducing the numerical preciseness of our network 's weights and activations while maintaining the performance of the full-precision model. Our experiments show that we can reduce the number of parameters of the full-precision model and then further compress the model 4x by fully quantizing to 8-bit fixed point preciseness. ", "label": 1}
{"original_text": "We introduce submodular hypergraphs, a family of hypergraphs that have different submodular weights associated with different cuts of hyperedges. Submodular hypergraphs arise in clustering applications in which higher-order structures carry relevant information. For such hypergraphs, we define the notion of p -Laplacians and derive corresponding nodal domain theorems and k -way Cheeger inequalities. We conclude with the description of algorithms for computing the spectra of 1 - and 2 -Laplacians that constitute the basis of new spectral hypergraph clustering methods.", "text_perturb": "We introduce submodular hypergraphs , a family of hypergraphs that have dissimilar submodular weights associated with dissimilar cuts of hyperedges. Submodular hypergraphs arise in clustering applications in which higher-order construction carry relevant information. For such hypergraphs , we define the notion of p -Laplacians and derive corresponding nodal domain theorems and k -way Cheeger inequality. We close with the description of algorithms for computing the spectra of 1 - and 2 -Laplacians that constitute the basis of new spectral hypergraph clustering methods. ", "label": 1}
{"original_text": "Motivated by the problem of partisan gerrymandering, we introduce an electoral system for a representative democracy called democratic cellular voting designed to make modern packing and cracking strategies irrelevant by allowing districts to be influenced directly by voters through elections. We introduce an example of a democratic cellular voting system, called CV0, that is suitable for dynamic modelling. We develop a modification of the theory of discrete Markov chains using the algebraic structure of the semiring [ 0, ], which is used as a space of correlation coefficients. We use this to measure voter preferences and model representatives, voters, and districts in computationally feasible models with a guarantee of long-term stability. NOTE: this is a preliminary version of this paper. The results of the simulations are still pending.", "text_perturb": "Motivated by the problem of partisan gerrymandering , we introduce an electoral system for a representative democracy called democratic cellular voting designed to make modern packing and cracking strategies irrelevant by allow for districts to be influenced directly by voters through elections. We introduce an example of a democratic cellular balloting system , called CV0 , that is suitable for dynamic modelling. We develop a modification of the theory of discrete Markov chains using the algebraical structure of the semiring [ 0 , ] , which is used as a space of correlation coefficients. We use this to measure voter preferences and model representatives , voters , and districts in computationally feasible modelling with a guarantee of long-term stability. NOTE : this embody a preliminary version of this paper. The results of the simulation are still pending. ", "label": 1}
{"original_text": "We present a method for learning an embedding that places images of humans in similar poses nearby. This embedding can be used as a direct method of comparing images based on human pose, avoiding potential challenges of estimating body joint positions. Pose embedding learning is formulated under a triplet-based distance criterion. A deep architecture is used to allow learning of a representation capable of making distinctions between different poses. Experiments on human pose matching and retrieval from video data demonstrate the potential of the method.", "text_perturb": "We portray a method for learning an embedding that places images of humans in similar poses nearby. This embedding can represent used as a direct method of comparing images based on human pose , avoiding potential challenges of estimating body joint positions. Pose embedding acquisition is formulated under a triplet-based distance criterion. A deep architecture cost used to allow learning of a representation capable of making distinctions between different poses. experiment on human pose matching and retrieval from video data demonstrate the potential of the method. ", "label": 1}
{"original_text": "Kernel methods have produced state-of-the-art results for a number of NLP tasks such as relation extraction, but suffer from poor scalability due to the high cost of computing kernel similarities between natural language structures. A recently proposed technique, kernelized locality-sensitive hashing (KLSH), can significantly reduce the computational cost, but is only applicable to classifiers operating on kNN graphs. Here we propose to use random subspaces of KLSH codes for efficiently constructing an explicit representation of NLP structures suitable for general classification methods. Further, we propose an approach for optimizing the KLSH model for classification problems by maximizing an approximation of mutual information between the KLSH codes (feature vectors) and the class labels. We evaluate the proposed approach on biomedical relation extraction datasets, and observe significant and robust improvements in accuracy w.r.t. state-of-the-art classifiers, along with drastic (orders-of-magnitude) speedup compared to conventional kernel methods.", "text_perturb": "Kernel methods have produced state of the art results for a number of NLP tasks such as relation extraction , but suffer from poor scalability due to the high cost of computing kernel similarities between natural language structures. A recently proposed technique , kernelized locality-sensitive hashing ( KLSH ) , can significantly reduce the computational cost , but exist only applicable to classifiers operating on kNN graphs. Here we propose to practice random subspaces of KLSH codes for efficiently constructing an explicit representation of NLP structures suitable for general classification methods. Further , we propose an approach for optimizing the KLSH model for classification problems by maximizing an approximation of mutual information between the KLSH codes ( feature vectors ) and the class recording label. We evaluate the proposed approach on biomedical relation descent datasets , and observe significant and robust improvements in accuracy w. universal gas constant. thymine. state-of-the-art classifiers , along with drastic ( orders-of-magnitude ) speedup compared to conventional inwardness methods. ", "label": 1}
{"original_text": "In this correspondence, we introduce a minimax regret criteria to the least squares problems with bounded data uncertainties and solve it using semi-definite programming. We investigate a robust minimax least squares approach that minimizes a worst case difference regret. The regret is defined as the difference between a squared data error and the smallest attainable squared data error of a least squares estimator. We then propose a robust regularized least squares approach to the regularized least squares problem under data uncertainties by using a similar framework. We show that both unstructured and structured robust least squares problems and robust regularized least squares problem can be put in certain semi-definite programming forms. Through several simulations, we demonstrate the merits of the proposed algorithms with respect to the the well-known alternatives in the literature.", "text_perturb": "In this parallelism , we introduce a minimax regret criteria to the least squares problems with bounded data uncertainties and solve it using semi-definite programming. We investigate a robust minimax least squares approach that minimizes a worst case difference sorrow. The regret is defined as the difference between a square data error and the smallest attainable square data error of a least squares estimator. We then propose a robust regularized least squares approach to the regularized least squares problem under data uncertainties by using a standardised framework. We show that both unstructured and structured robust least squares problems and robust regularized least squares problem can embody put in certain semi-definite programming forms. Through several model , we demonstrate the merits of the proposed algorithms with respect to the the well-known alternatives in the literature. ", "label": 1}
{"original_text": "Long short-term memory (LSTM) and recurrent neural network (RNN) has achieved great successes on time-series prediction. In this paper, a methodology of using LSTM-based deep-RNN for two-phase flow regime prediction is proposed, motivated by previous research on constructing deep RNN. The method is featured with fast response and accuracy. The built RNN networks are trained and tested with time-series void fraction data collected using impedance void meter. The result shows that the prediction accuracy depends on the depth of network and the number of layer cells. However, deeper and larger network consumes more time in predicting.", "text_perturb": "Long short-term memory ( LSTM ) and recurrent neural electronic network ( RNN ) has achieved great successes on time-series prediction. In this paper , a methodology of using LSTM-based deep-RNN for two-phase flow regime forecasting is proposed , motivated by previous research on constructing deep RNN. The method is feature with fast response and accuracy. The built RNN networks equal trained and tested with time-series void fraction data collected using impedance void meter. The result shows that the prediction accuracy depends on the profundity of network and the number of layer cells. However , deeper and larger network consumes more metre in predicting. ", "label": 1}
{"original_text": "The classical constant-sum 'silent duel' game had two antagonistic marksmen walking towards each other. A more friendly formulation has two equally skilled marksmen approaching targets at which they may silently fire at distances of their own choice. The winner, who gets a unit prize, is the marksman who hits his target at the greatest distance; if both miss, they share the prize (each gets a 'consolation prize' of one half). In another formulation, if they both miss they each get zero. More generally we can consider more than two marksmen and an arbitrary consolation prize. This non-constant sum game may be interpreted as a research tournament where the entrant who successfully solves the hardest problem wins the prize. We give the first complete solution to the many-player problem with arbitrary consolation prize: moreover (by taking particular values for the consolation prize), our theorem incorporates various special results in the literature, and our proof is simpler than any of these.", "text_perturb": "The classical constant-sum 'silent duel ' game had two antagonistic marksmen walking towards each former. A to a greater extent friendly formulation has two equally skilled marksmen approaching targets at which they may silently fire at distances of their own choice. The winner , who gets a unit prize , is the marksman who tally his target at the greatest distance ; if both miss , they share the prize ( each gets a 'consolation prize ' of one half ). In another conceptualisation , if they both miss they each get zero. More generally we can consider more than two sharpshooter and an arbitrary consolation prize. This non-constant sum game may be interpreted as a research tournament where the entrant who successfully solves the hardest problem gain ground the prize. We give the world class complete solution to the many-player problem with arbitrary consolation prize : moreover ( by taking particular values for the consolation prize ) , our theorem incorporates various special results in the literature , and our proof is simpler than any of these. ", "label": 1}
{"original_text": "We propose to study equivariance in deep neural networks through parameter symmetries. In particular, given a group G that acts discretely on the input and output of a standard neural network layer: ph W - R M R N, we show that ph W is equivariant with respect to G -action iff G explains the symmetries of the network parameters W. Inspired by this observation, we then propose two parameter-sharing schemes to induce the desirable symmetry on W. Our procedure for tying the parameters achieves G -equivariance and, under some conditions on the action of G, it guarantees sensitivity to all other permutation groups outside G.", "text_perturb": "We propose to study equivariance in deep neural networks through argument symmetries. In particular , given a group G that acts discretely on the input and output of a standard neural network layer : ph W - R M R N , we record that ph W is equivariant with respect to G -action iff G explains the symmetries of the network parameters W. Inspired by this observation , we then declare oneself two parameter-sharing schemes to induce the desirable symmetry on W. Our procedure for tying the parameters achieves G -equivariance and , under some conditions on the action of G , it guarantees sensitivity to all other permutation chemical group outside G. ", "label": 1}
{"original_text": "Catastrophic forgetting can be a significant problem for institutions that must delete historic data for privacy reasons. For example, hospitals might not be able to retain patient data permanently. But neural networks trained on recent data alone will tend to forget lessons learned on old data. We present a differentially private continual learning framework based on variational inference. We estimate the likelihood of past data given the current model using differentially private generative models of old datasets.", "text_perturb": "Catastrophic forgetting can be a significant problem for institutions that must cancel historic data for privacy reasons. For example , hospitals might not cost able to retain patient data permanently. But neural networks trained on recent data alone will tend to forget lessons see on old data. We present a differentially private continual learning model based on variational inference. We estimate the likelihood of past data establish the current model using differentially private generative models of old datasets. ", "label": 1}
{"original_text": "The growth in wireless broadband users, devices, and novel applications has led to a significant increase in the demand for new radio frequency spectrum. This is expected to grow even further given the projection that the global traffic per year will reach 4.8 zettabytes by 2022. Moreover, it is projected that the number of Internet users will reach 4.8 billion and the number of connected devices will be close 28.5 billion devices. However, due to the spectrum being mostly allocated and divided, providing more spectrum to expand existing services or offer new ones has become more challenging. To address this, spectrum sharing has been proposed as a potential solution to improve spectrum utilization efficiency. Adopting effective and efficient spectrum sharing mechanisms is in itself a challenging task given the multitude of levels and techniques that can be integrated to enable it. To that end, this paper provides an overview of the different spectrum sharing levels and techniques that have been proposed in the literature. Moreover, it discusses the potential of adopting dynamic sharing mechanisms by offering Spectrum-as-a-Service architecture. Furthermore, it describes the potential role of machine learning models in facilitating the automated and efficient dynamic sharing of the spectrum and offering Spectrum-as-a-Service.", "text_perturb": "The growth in wireless broadband users , devices , and novel applications has led to a significant increase in the demand for new radiocommunication frequency spectrum. This is expected to grow even further given the projection that the global dealings per year will reach 4. 8 zb by 2022. Moreover , it is projected that the number of net users will reach 4. 8 billion and the figure of connected devices will be close 28. 5 billion gimmick. However , due to the spectrum being mostly allocated and divided , providing more spectrum to expand existing services or offer young ones has become more challenging. To address this , spectrum sharing has been proposed as a potential solution to improve spectrum employment efficiency. Adopting effective and efficient spectrum sharing mechanisms is in itself a challenging task given the multitude of levels and techniques that can be incorporate to enable it. To that end , this paper provides an overview of the different spectrum sharing levels and proficiency that have been proposed in the literature. Moreover , it discusses the potential of adopting dynamic sharing mechanisms by volunteer Spectrum-as-a-Service architecture. Furthermore , it describes the potential role of machine learning models in facilitating the automated and effective dynamic sharing of the spectrum and offering Spectrum-as-a-Service. ", "label": 1}
{"original_text": "Federated Learning (FL) is a decentralized machine learning protocol that allows a set of participating agents to collaboratively train a model without sharing their data. This makes FL particularly suitable for settings where data privacy is desired. However, it has been observed that the performance of FL is closely tied with the local data distributions of agents. Particularly, in settings where local data distributions vastly differ among agents, FL performs rather poorly with respect to the centralized training. To address this problem, we hypothesize the reasons behind the performance degradation, and develop some techniques to address these reasons accordingly. In this work, we identify four simple techniques that can improve the performance of trained models without incurring any additional communication overhead to FL, but rather, some light computation overhead either on the client, or the server-side. In our experimental analysis, a combination of our techniques improved the validation accuracy of a model trained via FL by more than 12 with respect to our baseline. This is about 5 less than the accuracy of the model trained on centralized data.", "text_perturb": "Federated Learning ( FL ) is a decentralized simple machine learning protocol that allows a set of participating agents to collaboratively train a model without sharing their data. This makes FL particularly suitable for settings where data concealment is desired. However , it has been observed that the carrying into action of FL is closely tied with the local data distributions of agents. Particularly , in settings where local data distributions vastly differ among agents , FL execute rather poorly with respect to the centralized training. To address this problem , we hypothesize the reasons behind the public presentation degradation , and develop some techniques to address these reasons accordingly. In this work , we identify four simple techniques that can improve the performance of trained models without incurring any additional communication overhead to everglade state , but rather , some light computation overhead either on the client , or the server-side. In our experimental analysis , a combination of our technique improved the validation accuracy of a model trained via FL by more than 12 with respect to our baseline. This is about 5 less than the truth of the model trained on centralized data. ", "label": 1}
{"original_text": "A network model is considered where Poisson distributed base stations transmit to N power-domain non-orthogonal multiple access (NOMA) users (UEs) each that employ successive interference cancellation (SIC) for decoding. We propose three models for the clustering of NOMA UEs and consider two different ordering techniques for the NOMA UEs: mean signal power-based and instantaneous signal-to-intercell-interference-and-noise-ratio-based. For each technique, we present a signal-to-interference-and-noise ratio analysis for the coverage of the typical UE. We plot the rate region for the two-user case and show that neither ordering technique is consistently superior to the other. We propose two efficient algorithms for finding a feasible resource allocation that maximize the cell sum rate R tot, for general N, constrained to: 1) a minimum throughput T for each UE, 2) identical throughput for all UEs. We show the existence of: 1) an optimum N that maximizes the constrained R tot given a set of network parameters, 2) a critical SIC level necessary for NOMA to outperform orthogonal multiple access. The results highlight the importance in choosing the network parameters N, the constraints, and the ordering technique to balance the R tot and fairness requirements. We also show that interference-aware UE clustering can significantly improve performance.", "text_perturb": "A network model is see where Poisson distributed base stations transmit to N power-domain non-orthogonal multiple access ( NOMA ) users ( UEs ) each that employ successive interference cancellation ( SIC ) for decoding. We propose three models for the clustering of NOMA UEs and consider two unlike ordering techniques for the NOMA UEs : mean signal power-based and instantaneous signal-to-intercell-interference-and-noise-ratio-based. For each technique , we present a signal-to-interference-and-noise ratio analytic thinking for the coverage of the typical UE. We plot the rate region for the two-user case and show that neither ordering technique exist consistently superior to the other. We propose two efficient algorithms for finding a feasible resource allocation that maximize the cell sum rate R tot , for general newton , constrained to : 1 ) a minimum throughput T for each UE , 2 ) identical throughput for all UEs. We show the existence of : 1 ) an optimum N that maximizes the constrained r tot given a set of network parameters , 2 ) a critical SIC level necessary for NOMA to outperform orthogonal multiple access. The results highlight the importance in choosing the network parameters N , the constraints , and the ordering proficiency to balance the R tot and fairness requirements. We also show that interference-aware UE clump can significantly improve performance. ", "label": 1}
{"original_text": "We show dense voxel embeddings learned via deep metric learning can be employed to produce a highly accurate segmentation of neurons from 3D electron microscopy images. A metric graph on an arbitrary set of short and long-range edges can be constructed from the dense embeddings generated by a convolutional network. Partitioning the metric graph with long-range affinities as repulsive constraints can produce an initial segmentation with high precision, with substantial improvements on very thin objects. The convolutional embedding net is reused without any modification to agglomerate the systematic splits caused by complex \"self-touching\" objects. Our proposed method achieves state-of-the-art accuracy on the challenging problem of 3D neuron reconstruction from the brain images acquired by serial section electron microscopy. Our alternative, object-centered representation could be more generally useful for other computational tasks in automated neural circuit reconstruction.", "text_perturb": "We show dense voxel embeddings learned via deep metric learning can be employed to develop a highly accurate segmentation of neurons from 3D electron microscopy images. A metric graph on an arbitrary set of short and long range edges can be constructed from the dense embeddings generated by a convolutional network. Partitioning the metric graphical record with long-range affinities as repulsive constraints can produce an initial segmentation with high precision , with substantial improvements on very thin objects. The convolutional embedding net is reused without any modification to agglomerate the taxonomic splits caused by complex `` self-touching '' objects. Our proposed method achieves state-of-the-art accuracy on the challenging problem of 3D neuron reconstruction from the brain images acquired by serial section negatron microscopy. Our substitute , object-centered representation could be more generally useful for other computational tasks in automated neural circuit reconstruction. ", "label": 1}
{"original_text": "Human activity recognition based on wearable sensor data has been an attractive research topic due to its application in areas such as healthcare and smart environments. In this context, many works have presented remarkable results using accelerometer, gyroscope and magnetometer data to represent the activities categories. However, current studies do not consider important issues that lead to skewed results, making it hard to assess the quality of sensor-based human activity recognition and preventing a direct comparison of previous works. These issues include the samples generation processes and the validation protocols used. We emphasize that in other research areas, such as image classification and object detection, these issues are already well-defined, which brings more efforts towards the application. Inspired by this, we conduct an extensive set of experiments that analyze different sample generation processes and validation protocols to indicate the vulnerable points in human activity recognition based on wearable sensor data. For this purpose, we implement and evaluate several top-performance methods, ranging from handcrafted-based approaches to convolutional neural networks. According to our study, most of the experimental evaluations that are currently employed are not adequate to perform the activity recognition in the context of wearable sensor data, in which the recognition accuracy drops considerably when compared to an appropriate evaluation approach. To the best of our knowledge, this is the first study that tackles essential issues that compromise the understanding of the performance in human activity recognition based on wearable sensor data.", "text_perturb": "Human activity recognition based on wearable sensor data has been an attractive inquiry topic due to its application in areas such as healthcare and smart environments. In this context , many workplace have presented remarkable results using accelerometer , gyroscope and magnetometer data to represent the activities categories. However , current discipline do not consider important issues that lead to skewed results , making it hard to assess the quality of sensor-based human activity recognition and preventing a direct comparison of previous works. These publication include the samples generation processes and the validation protocols used. We emphasize that in early research areas , such as image classification and object detection , these issues are already well-defined , which brings more efforts towards the application. Inspired by this , we conduct an extensive set of experiments that analyze different sample generation processes and validation protocol to indicate the vulnerable points in human activity recognition based on wearable sensor data. For this purpose , we implement and evaluate several top-performance methods , ranging from handcrafted-based approaches to convolutional neural meshwork. According to our study , most of the experimental evaluations that are currently employed are not decent to perform the activity recognition in the context of wearable sensor data , in which the recognition accuracy drops considerably when compared to an appropriate evaluation approach. To the best of our noesis , this is the first study that tackles essential issues that compromise the understanding of the performance in human activity recognition based on wearable sensor data. ", "label": 1}
{"original_text": "Characterization of the relationship between a kidney tumor's appearance on cross-sectional imaging and it's treatment outcomes is a promising direction for informing treatement decisions and improving patient outcomes. Unfortunately, the rigorous study of tumor morphology is limited by the laborious and noisy process of making manual radiographic measurements. Semantic segmentation of the tumor and surrounding organ offers a precise quantitative description of that morphology, but it too requires significant manual effort. A large publicly available dataset of high-fidelity semantic segmentations along with clinical context and treatment outcomes could accelerate not only the study of how morphology relates to outcomes, but also the development of automatic semantic segmentation systems which could enable such studies on unprecedented scales. We present the KiTS19 challenge dataset: a collection of segmented CT imaging and treatment outcomes for 300 patients treated with partial or radical nephrectomy between 2010 and 2018. 210 of these cases have been released publicly and the remaining 90 remain private for the objective evaluation of prediction systems developed using the public cases.", "text_perturb": "Characterization of the relationship between a kidney tumor 's appearance on cross-sectional imagination and it 's treatment outcomes is a promising direction for informing treatement decisions and improving patient outcomes. Unfortunately , the rigorous study of tumor syllable structure is limited by the laborious and noisy process of making manual radiographic measurements. Semantic segmentation of the tumor and surrounding organ offer a precise quantitative description of that morphology , but it too requires significant manual effort. A large publicly available dataset of high-fidelity semantic segmentations along with clinical context and treatment outcomes could accelerate non only the study of how morphology relates to outcomes , but also the development of automatic semantic segmentation systems which could enable such studies on unprecedented scales. We present the KiTS19 challenge dataset : a collection of segmented CT imaging and treatment outcomes for 300 patients treated with partial or basal nephrectomy between 2010 and 2018. 210 of these cases have been released publicly and the remaining 90 remain private for the objective evaluation of prediction scheme developed using the public cases. ", "label": 1}
{"original_text": "Literature reviews allow scientists to stand on the shoulders of giants, showing promising directions, summarizing progress, and pointing out existing challenges in research. At the same time conducting a systematic literature review is a laborious and consequently expensive process. In the last decade, there have a few studies on crowdsourcing in literature reviews. This paper explores the feasibility of crowdsourcing for facilitating the literature review process in terms of results, time and effort, as well as to identify which crowdsourcing strategies provide the best results based on the budget available. In particular we focus on the screening phase of the literature review process and we contribute and assess methods for identifying the size of tests, labels required per paper, and classification functions as well as methods to split the crowdsourcing process in phases to improve results. Finally, we present our findings based on experiments run on Crowdflower.", "text_perturb": "Literature reviews allow scientists to stand on the shoulders of giants , showing promising directions , summarise progress , and pointing out existing challenges in research. At the same time convey a systematic literature review is a laborious and consequently expensive process. In the last decade , there get a few studies on crowdsourcing in literature reviews. This paper explores the feasibility of crowdsourcing for facilitating the literature review process in terms of results , time and effort , as substantially as to identify which crowdsourcing strategies provide the best results based on the budget available. In particular we focus on the screening phase of the literature review process and we contribute and assess methods for identifying the size of tests , labels required per paper , and classification functions as well as methods to split the crowdsourcing process in phases to meliorate results. Finally , we present our finding based on experiments run on Crowdflower. ", "label": 1}
{"original_text": "We present RigNet, an end-to-end automated method for producing animation rigs from input character models. Given an input 3D model representing an articulated character, RigNet predicts a skeleton that matches the animator expectations in joint placement and topology. It also estimates surface skin weights based on the predicted skeleton. Our method is based on a deep architecture that directly operates on the mesh representation without making assumptions on shape class and structure. The architecture is trained on a large and diverse collection of rigged models, including their mesh, skeletons and corresponding skin weights. Our evaluation is three-fold: we show better results than prior art when quantitatively compared to animator rigs; qualitatively we show that our rigs can be expressively posed and animated at multiple levels of detail; and finally, we evaluate the impact of various algorithm choices on our output rigs. 1 footnote 1 1 footnote 1 Our project page with source code, datasets, and supplementary video is available at", "text_perturb": "We present RigNet , an end-to-end automated method for producing vitality rigs from input character models. Given an input 3D model representing an articulated character , RigNet predicts a skeleton that matches the animator first moment in joint placement and topology. It also estimates surface peel weights based on the predicted skeleton. Our method is based on a deep architecture that directly operates on the mesh representation without making assumptions on shape socio economic class and structure. The architecture is trained on a large and diverse appeal of rigged models , including their mesh , skeletons and corresponding skin weights. Our evaluation is three-fold : we show better results than prior art when quantitatively compared to animator rigs ; qualitatively we show that our rigs can be expressively posed and revivify at multiple levels of detail ; and finally , we evaluate the impact of various algorithm choices on our output rigs. 1 footnote 1 1 footnote 1 Our project page with source code , datasets , and subsidiary video is available at", "label": 1}
{"original_text": "As humans, our goals and our environment are persistently changing throughout our lifetime based on our experiences, actions, and internal and external drives. In contrast, typical reinforcement learning problem set-ups consider decision processes that are stationary across episodes. Can we develop reinforcement learning algorithms that can cope with the persistent change in the former, more realistic problem settings? While on-policy algorithms such as policy gradients in principle can be extended to non-stationary settings, the same cannot be said for more efficient off-policy algorithms that replay past experiences when learning. In this work, we formalize this problem setting, and draw upon ideas from the online learning and probabilistic inference literature to derive an off-policy RL algorithm that can reason about and tackle such lifelong non-stationarity. Our method leverages latent variable models to learn a representation of the environment from current and past experiences, and performs off-policy RL with this representation. We further introduce several simulation environments that exhibit lifelong non-stationarity, and empirically find that our approach substantially outperforms approaches that do not reason about environment shift. 1 footnote 1 1 footnote 1 Videos of our results are available at", "text_perturb": "As man , our goals and our environment are persistently changing throughout our lifetime based on our experiences , actions , and internal and external drives. In direct contrast , typical reinforcement learning problem set-ups consider decision processes that are stationary across episodes. Can we develop reinforcement learning algorithms that can cope with the persistent variety in the former , more realistic problem settings ? While on-policy algorithms such as policy gradients in principle can be extended to non-stationary settings , the same can not be said for more efficient off-policy algorithms that replay past experiences when learning. In this work , we formalize this problem circumstance , and draw upon ideas from the online learning and probabilistic inference literature to derive an off-policy RL algorithm that can reason about and tackle such lifelong non-stationarity. Our method leverages latent variable models to learn a representation of the environment from current and retiring experiences , and performs off-policy RL with this representation. We further introduce several simulation environments that exhibit lifelong non-stationarity , and empirically incur that our approach substantially outperforms approaches that do not reason about environment shift. 1 footnote 1 1 footnote 1 Videos of our results are usable at", "label": 1}
{"original_text": "In this work, we propose a novel crowd counting network that progressively generates crowd density maps via residual error estimation. The proposed method uses VGG16 as the backbone network and employs density map generated by the final layer as a coarse prediction to refine and generate finer density maps in a progressive fashion using residual learning. Additionally, the residual learning is guided by an uncertainty-based confidence weighting mechanism that permits the flow of only high-confidence residuals in the refinement path. The proposed Confidence Guided Deep Residual Counting Network (CG-DRCN) is evaluated on recent complex datasets, and it achieves significant improvements in errors. Furthermore, we introduce a new large scale unconstrained crowd counting dataset (JHU-CROWD) that is 2.8 x larger than the most recent crowd counting datasets in terms of the number of images. It contains 4,250 images with 1.11 million annotations. In comparison to existing datasets, the proposed dataset is collected under a variety of diverse scenarios and environmental conditions. Specifically, the dataset includes several images with weather-based degradations and illumination variations in addition to many distractor images, making it a very challenging dataset. Additionally, the dataset consists of rich annotations at both image-level and head-level. Several recent methods are evaluated and compared on this dataset.", "text_perturb": "In this work , we propose a novel crowd counting network that progressively generates crowd denseness maps via residual error estimation. The proposed method uses VGG16 as the backbone network and employs density map generated by the final layer as a coarse prediction to refine and generate finer density maps in a progressive fashion using residual scholarship. Additionally , the residual learning is guided by an uncertainty-based confidence weighting mechanism that permits the flowing of only high-confidence residuals in the refinement path. The proposed Confidence Guided Deep Residual Counting meshing ( CG-DRCN ) is evaluated on recent complex datasets , and it achieves significant improvements in errors. Furthermore , we introduce a raw large scale unconstrained crowd counting dataset ( JHU-CROWD ) that is 2. 8 x larger than the virtually recent crowd counting datasets in terms of the number of images. It contain 4,250 images with 1. 11 million note. In comparison to existing datasets , the proposed dataset is hoard under a variety of diverse scenarios and environmental conditions. Specifically , the dataset includes several images with weather-based degradations and illumination variations in addition to many distractor images , making it a very thought provoking dataset. Additionally , the dataset lie in of rich annotations at both image-level and head-level. Several recent methods are value and compared on this dataset. ", "label": 1}
{"original_text": "Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.", "text_perturb": "Experience replay lets on line reinforcement learning agents remember and reuse experiences from the past. In anterior work , experience transitions were uniformly sampled from a replay memory. However , this approach simply replays passage at the same frequency that they were originally experienced , regardless of their significance. In this paper we develop a framework for prioritizing experience , so as to play back important transitions more frequently , and therefore learn more efficiently. We use prioritized experience rematch in Deep Q-Networks ( DQN ) , a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art , outperforming DQN with unvarying replay on 41 out of 49 games. ", "label": 1}
{"original_text": "Many transformations in deep learning architectures are sparsely connected. When such transformations cannot be designed by hand, they can be learned, even through plain backpropagation, for instance in attention mechanisms. However, during learning, such sparse structures are often represented in a dense form, as we do not know beforehand which elements will eventually become non-zero. We introduce the adaptive, sparse hyperlayer, a method for learning a sparse transformation, paramatrized sparsely: as index-tuples with associated values. To overcome the lack of gradients from such a discrete structure, we introduce a method of randomly sampling connections, and backpropagating over the randomly wired computation graph. To show that this approach allows us to train a model to competitive performance on real data, we use it to build two architectures. First, an attention mechanism for visual classification. Second, we implement a method for differentiable sorting: specifically, learning to sort unlabeled MNIST digits, given only the correct order.", "text_perturb": "Many transformations in rich learning architectures are sparsely connected. When such transformations put up not be designed by hand , they put up be learned , even through plain backpropagation , for instance in attention mechanisms. However , during learning , such sparse structures exist often represented in a dense form , as we do not know beforehand which elements will eventually become non-zero. We introduce the adaptive , thin hyperlayer , a method for learning a thin transformation , paramatrized sparsely : as index-tuples with associated values. To sweep over the lack of gradients from such a discrete structure , we introduce a method of randomly sampling connections , and backpropagating over the randomly wired computation graph. To show that this approach allows us to train a fashion model to competitive performance on real data , we use it to build two architectures. First , an attention mechanism for visual categorization. Second , we implement a method for differentiable sorting : specifically , learning to sort unlabeled MNIST digits , generate only the correct order. ", "label": 1}
{"original_text": "Uses of underwater videos to assess diversity and abundance of fish are being rapidly adopted by marine biologists. Manual processing of videos for quantification by human analysts is time and labour intensive. Automatic processing of videos can be employed to achieve the objectives in a cost and time-efficient way. The aim is to build an accurate and reliable fish detection and recognition system, which is important for an autonomous robotic platform. However, there are many challenges involved in this task (e.g. complex background, deformation, low resolution and light propagation). Recent advancement in the deep neural network has led to the development of object detection and recognition in real time scenarios. An end-to-end deep learning-based architecture is introduced which outperformed the state of the art methods and first of its kind on fish assessment task. A Region Proposal Network (RPN) introduced by an object detector termed as Faster R-CNN was combined with three classification networks for detection and recognition of fish species obtained from Remote Underwater Video Stations (RUVS). An accuracy of 82.4 (mAP) obtained from the experiments are much higher than previously proposed methods.", "text_perturb": "Uses of underwater videos to assess diversity and abundance of fish are being apace adopted by marine biologists. Manual processing of video for quantification by human analysts is time and labour intensive. Automatic processing of videos can be employed to achieve the target in a cost and time-efficient way. The aim is to construct an accurate and reliable fish detection and recognition system , which is important for an autonomous robotic platform. However , there are many challenge involved in this task ( e. gm. complex background , deformation , humble resolution and light propagation ). Recent advancement in the deep neural network has led to the developing of object detection and recognition in real time scenarios. An end-to-end deep learning-based architecture is introduced which outperformed the state of the art method acting and first of its kind on fish assessment task. A Region Proposal Network ( RPN ) introduced by an object detector termed as Faster R-CNN was combined with three sorting networks for detection and recognition of fish species obtained from Remote Underwater Video Stations ( RUVS ). An truth of 82. 4 ( mAP ) obtained from the experiments embody much higher than previously proposed methods. ", "label": 1}
{"original_text": "Communication services with heterogeneous performance requirements are emerging as key use cases for 5G and beyond. This paper deals with the coexistence of two service classes, i.e., critical service (CS) and non-critical service (NCS) on a grant-free channel consisting of the radio access and backhaul segments. On the radio access segment, Internet-of-Things (IoT) devices send packets to a set of non-cooperative access points (APs) using slotted ALOHA (SA). The APs then forward correctly received messages to a base station over a shared wireless backhaul segment adopting SA. The APs hence play the role of low-complexity relays that improve space diversity and reduce performance losses caused by interference on the access segment. We study first a simplified erasure channel model, which is well suited for non-terrestrial applications. Then, in order to account for terrestrial scenarios, the impact of fading is considered. Throughput and packet success rate metrics are derived, and numerical results are provided to assess the performance trade-offs between CS and NCS. Among the main conclusions, we show that orthogonal inter-service resource allocation is generally preferred for NCS devices, while non-orthogonal protocols can improve the throughput and packet success rate of CS devices for both terrestrial and non-terrestrial scenarios.", "text_perturb": "Communication services with heterogenous performance requirements are emerging as key use cases for 5G and beyond. This paper deals with the coexistence of two military service classes , i. east. , critical service ( CS ) and non-critical service ( NCS ) on a grant-free channel consisting of the wireless access and backhaul segments. On the radio access segment , Internet-of-Things ( IoT ) gimmick send packets to a set of non-cooperative access points ( APs ) using slotted ALOHA ( SA ). The APs then forward correctly received messages to a base station over a shared wireless backhaul segment adopting sturmabteilung. The APs hence play the role of low-complexity relays that improve space diversity and decoct performance losses caused by interference on the access segment. We study first a simplified erasure communication channel model , which is well suited for non-terrestrial applications. Then , in order to answer for for terrestrial scenarios , the impact of fading is considered. Throughput and packet success rate metrics are derived , and numerical upshot are provided to assess the performance trade-offs between CS and NCS. Among the main conclusions , we show that orthogonal inter-service resource allocation is generally preferred for NCS devices , while non-orthogonal protocols can improve the throughput and mail boat success rate of CS devices for both terrestrial and non-terrestrial scenarios. ", "label": 1}
{"original_text": "In this paper, joint transceiver design for dual-hop amplify-and-forward (AF) MIMO relay systems with Gaussian distributed channel estimation errors in both two hops is investigated. Due to the fact that various linear transceiver designs can be transformed to a weighted linear minimum mean-square-error (LMMSE) transceiver design with specific weighting matrices, weighted mean square error (MSE) is chosen as the performance metric. Precoder matrix at source, forwarding matrix at relay and equalizer matrix at destination are jointly designed with channel estimation errors taken care of by Bayesian philosophy. Several existing algorithms are found to be special cases of the proposed solution. The performance advantage of the proposed robust design is demonstrated by the simulation results.", "text_perturb": "In this paper , joint transceiver pattern for dual-hop amplify-and-forward ( AF ) MIMO relay systems with Gaussian distributed channel estimation errors in both two hops is investigated. Due to the fact that various additive transceiver designs can be transformed to a weighted additive minimum mean-square-error ( LMMSE ) transceiver design with specific weighting matrices , weighted mean square error ( MSE ) is chosen as the performance metric. Precoder matrix at source , forwarding matrix at relay and equalizer matrix at destination are jointly designed with channel estimation errors claim care of by Bayesian philosophy. Several existing algorithms are found to be special cases of the declare oneself solution. The execution advantage of the proposed robust design is demonstrated by the simulation results. ", "label": 1}
{"original_text": "Broad application of answer set programming (ASP) for declarative problem solving requires the development of tools supporting the coding process. Program debugging is one of the crucial activities within this process. Modern ASP debugging approaches allow efficient computation of possible explanations of a fault. However, even for a small program a debugger might return a large number of possible explanations and selection of the correct one must be done manually. In this paper we present an interactive query-based ASP debugging method which extends previous approaches and finds a preferred explanation by means of observations. The system automatically generates a sequence of queries to a programmer asking whether a set of ground atoms must be true in all (cautiously) or some (bravely) answer sets of the program. Since some queries can be more informative than the others, we discuss query selection strategies which, given user's preferences for an explanation, can find the best query. That is, the query an answer of which reduces the overall number of queries required for the identification of a preferred explanation.", "text_perturb": "Broad application of answer set programming ( ASP ) for declarative problem solving requires the development of tools supporting the steganography process. Program debugging is one of the crucial activities within this mental process. Modern ASP debugging approaches allow efficient computing of possible explanations of a fault. However , even for a small program a debugger might return a enceinte number of possible explanations and selection of the correct one must be done manually. In this paper we present an interactive query-based ASP debugging method which extends premature approaches and finds a preferred explanation by means of observations. The system automatically generates a episode of queries to a programmer asking whether a set of ground atoms must be true in all ( cautiously ) or some ( bravely ) answer sets of the program. Since some queries give the sack be more informative than the others , we discuss query selection strategies which , given user 's preferences for an explanation , give the sack find the best query. That is , the query an answer of which reduces the overall bit of queries required for the identification of a preferred explanation. ", "label": 1}
{"original_text": "Many sciences have made significant breakthroughs by adopting online tools that help organize, structure and mine information that is too detailed to be printed in journals. In this paper, we introduce OpenML, a place for machine learning researchers to share and organize data in fine detail, so that they can work more effectively, be more visible, and collaborate with others to tackle harder problems. We discuss how OpenML relates to other examples of networked science and what benefits it brings for machine learning research, individual scientists, as well as students and practitioners.", "text_perturb": "Many sciences have made significant breakthroughs by adopting online tools that help organize , structure and mine information that is too detailed to be printed in diary. In this paper , we introduce OpenML , a place for machine learning researchers to share and organize data in fine detail , so that they can work more efficaciously , be more visible , and collaborate with others to tackle harder problems. We discuss how OpenML relates to other examples of networked science and what benefits it brings for auto learning research , individual scientists , as well as students and practitioners. ", "label": 1}
{"original_text": "The logic FO (ID) uses ideas from the field of logic programming to extend first order logic with non-monotone inductive definitions. Such logic formally extends logic programming, abductive logic programming and datalog, and thus formalizes the view on these formalisms as logics of (generalized) inductive definitions. The goal of this paper is to study a deductive inference method for PC (ID), which is the propositional fragment of FO (ID). We introduce a formal proof system based on the sequent calculus (Gentzen-style deductive system) for this logic. As PC (ID) is an integration of classical propositional logic and propositional inductive definitions, our sequent calculus proof system integrates inference rules for propositional calculus and definitions. We present the soundness and completeness of this proof system with respect to a slightly restricted fragment of PC (ID). We also provide some complexity results for PC (ID). By developing the proof system for PC (ID), it helps us to enhance the understanding of proof-theoretic foundations of FO (ID), and therefore to investigate useful proof systems for FO (ID).", "text_perturb": "The logic FO ( ID ) uses ideas from the field of logic programming to extend first club logic with non-monotone inductive definitions. Such logic formally unfold logic programming , abductive logic programming and datalog , and thus formalizes the view on these formalisms as logics of ( generalized ) inductive definitions. The goal of this paper is to canvas a deductive inference method for PC ( ID ) , which is the propositional fragment of FO ( ID ). We introduce a formal proof system based on the sequent concretion ( Gentzen-style deductive system ) for this logic. As PC ( ID ) follow an integration of classical propositional logic and propositional inductive definitions , our sequent calculus proof system integrates inference rules for propositional calculus and definitions. We present the soundness and completeness of this proof system with respect to a slightly restricted shard of PC ( ID ). We too provide some complexity results for PC ( ID ). By developing the proof system for PC ( ID ) , it helps us to enhance the understanding of proof-theoretic foundations of fo ( ID ) , and therefore to investigate useful proof systems for fo ( ID ). ", "label": 1}
{"original_text": "Benchmarking the performance of community detection methods on empirical social network data has been identified as critical for improving these methods. In particular, while most current research focuses on detecting communities in data that has been digitally extracted from large social media and telecommunications services, most evaluation of this research is based on small, hand-curated datasets. We argue that these two types of networks differ so significantly that by evaluating algorithms solely on the former, we know little about how well they perform on the latter. To address this problem, we consider the difficulties that arise in constructing benchmarks based on digitally extracted network data, and propose a task-based strategy which we feel addresses these difficulties. To demonstrate that our scheme is effective, we use it to carry out a substantial benchmark based on Facebook data. The benchmark reveals that some of the most popular algorithms fail to detect fine-grained community structure. community detection, benchmarking, evaluation, social networks, datamining, social media data", "text_perturb": "Benchmarking the performance of community detection methods on empirical social network data has be identified as critical for improving these methods. In particular , while most current research focuses on detecting community of interests in data that has been digitally extracted from large social media and telecommunications services , most evaluation of this research is based on small , hand-curated datasets. We argue that these two types of networks differ so significantly that by evaluating algorithms solely on the late , we know little about how well they perform on the latter. To address this problem , we consider the difficulties that arise in constructing benchmarks based on digitally extracted network data , and propose a task-based strategy which we feel savoir faire these difficulties. To demonstrate that our scheme is effective , we use it to carry out a substantial bench mark based on Facebook data. The benchmark unveil that some of the most popular algorithms fail to detect fine-grained community structure. community detection , benchmarking , evaluation , societal networks , datamining , societal media data", "label": 1}
{"original_text": "Automated design of neural network architectures tailored for a specific task is an extremely promising, albeit inherently difficult, avenue to explore. While most results in this domain have been achieved on image classification and language modelling problems, here we concentrate on dense per-pixel tasks, in particular, semantic image segmentation using fully convolutional networks. In contrast to the aforementioned areas, the design choices of a fully convolutional network require several changes, ranging from the sort of operations that need to be used - e.g., dilated convolutions - to a solving of a more difficult optimisation problem. In this work, we are particularly interested in searching for high-performance compact segmentation architectures, able to run in real-time using limited resources. To achieve that, we intentionally over-parameterise the architecture during the training time via a set of auxiliary cells that provide an intermediate supervisory signal and can be omitted during the evaluation phase. The design of the auxiliary cell is emitted by a controller, a neural network with the fixed structure trained using reinforcement learning. More crucially, we demonstrate how to efficiently search for these architectures within limited time and computational budgets. In particular, we rely on a progressive strategy that terminates non-promising architectures from being further trained, and on Polyak averaging coupled with knowledge distillation to speed-up the convergence. Quantitatively, in 8 GPU-days our approach discovers a set of architectures performing on-par with state-of-the-art among compact models on the semantic segmentation, pose estimation and depth prediction tasks. Code will be made available here:", "text_perturb": "Automated design of neural network architectures tailored for a specific task is an extremely promising , albeit inherently hard , avenue to explore. While most results in this domain have been achieved on image classification and linguistic communication modelling problems , here we concentrate on dense per-pixel tasks , in particular , semantic image segmentation using fully convolutional networks. In contrast to the aforementioned areas , the design choices of a fully convolutional network require several changes , ranging from the sort of operations that need to constitute used - e. gigabyte. , dilated convolutions - to a resolution of a more difficult optimisation problem. In this work , we are particularly interested in searching for high-performance compact segmentation architectures , able to run in real time using limited resources. To achieve that , we intentionally over-parameterise the architecture during the training time via a lot of auxiliary cells that provide an intermediate supervisory signal and can be omitted during the evaluation phase. The design of the auxiliary cell is emitted by a controller , a neural network with the fixed structure trained employ reinforcement learning. More crucially , we demonstrate how to expeditiously search for these architectures within limited time and computational budgets. In particular , we rely on a progressive strategy that terminates non-promising architectures from being further trained , and on Polyak average coupled with knowledge distillation to speed-up the convergence. Quantitatively , in 8 GPU-days our approach discovers a set of architectures performing on-par with state-of-the-art among compact models on the semantic segmentation , pose estimation and depth foretelling tasks. Code will be made usable here :", "label": 1}
{"original_text": "We present a channel spectral estimator for OFDM signals containing pilot carriers, assuming a known delay spread or a bound on this parameter. The estimator is based on modeling the channel's spectrum as a band-limited function, instead of as the discrete Fourier transform of a tapped delay line (TDL). Its main advantage is its immunity to the truncation mismatch in usual TDL models (Gibbs phenomenon). In order to assess the estimator, we compare it with the well-known TDL maximum likelihood (ML) estimator in terms of root-mean-square (RMS) error. The main result is that the proposed estimator improves on the ML estimator significantly, whenever the average spectral sampling rate is above the channel's delay spread. The improvement increases with the spectral oversampling ratio.", "text_perturb": "We portray a channel spectral estimator for OFDM signals containing pilot carriers , assuming a known delay spread or a bound on this parameter. The estimator is based on model the channel 's spectrum as a band-limited function , instead of as the discrete Fourier transform of a tapped delay line ( TDL ). Its principal advantage is its immunity to the truncation mismatch in usual TDL models ( Gibbs phenomenon ). In order to assess the estimator , we compare it with the well-known TDL maximum likelihood ( ML ) estimator in terms of root-mean-square ( RMS ) mistake. The main result is that the proposed estimator improves on the ML estimator significantly , whenever the average spectral sampling rate is above the transmission channel 's delay spread. The improvement increases with the spectral oversampling proportion. ", "label": 1}
{"original_text": "Some research institutions demand researchers to distribute the incomes they earn from publishing papers to their researchers andor co-authors. In this study, we deal with the Impact Factor-based ranking journal as a criteria for the correct distribution of these incomes. We also include the Authorship Credit factor for distribution of the incomes among authors, using the geometric progression of Cantor's theory and the Harmonic Credit Index. Depending on the ranking of the journal, the proposed model develops a proper publication credit allocation among all authors. Moreover, our tool can be deployed in the evaluation of an institution for a funding program, as well as calculating the amounts necessary to incentivize research among personnel.", "text_perturb": "Some research institutions demand researchers to distribute the income they earn from publishing papers to their researchers andor co-authors. In this study , we deal with the Impact Factor-based ranking journal as a touchstone for the correct distribution of these incomes. We also include the Authorship Credit factor for dispersion of the incomes among authors , using the geometric progression of Cantor 's theory and the Harmonic Credit Index. Depending on the ranking of the journal , the proposed model develops a proper publication credit apportioning among all authors. Moreover , our cock can be deployed in the evaluation of an institution for a funding program , as well as calculating the amounts necessary to incentivize research among personnel. ", "label": 1}
{"original_text": "A separator for two languages is a third language containing the first one and disjoint from the second one. We investigate the following decision problem: given two regular input languages, decide whether there exists a locally testable (resp. a locally threshold testable) separator. In both cases, we design a decision procedure based on the occurrence of special patterns in automata accepting the input languages. We prove that the problem is computationally harder than deciding membership. The correctness proof of the algorithm yields a stronger result, namely a description of a possible separator. Finally, we discuss the same problem for context-free input languages.", "text_perturb": "A separator for two languages is a third terminology containing the first one and disjoint from the second one. We investigate the following determination problem : given two regular input languages , decide whether there exists a locally testable ( resp. a locally threshold testable ) separator. In both cases , we design a decision procedure based on the occurrence of special blueprint in automata accepting the input languages. We prove that the problem is computationally harder than deciding rank. The correctness proof of the algorithm yields a stronger result , namely a description of a possible centrifuge. Finally , we discuss the same job for context-free input languages. ", "label": 1}
{"original_text": "Transient execution attacks, also called speculative execution attacks, have drawn much interest as they exploit the transient execution of instructions, e.g., during branch prediction, to leak data. Transient execution is fundamental to modern computer architectures, yet poses a security risk as has been demonstrated. Since the first disclosure of Spectre and Meltdown attacks in January 2018, a number of new attack types or variants of the attacks have been presented. These attacks have motivated computer architects to rethink the design of processors and propose hardware defenses. This paper summarizes the components and the phases of the transient execution attacks. Each of the components is further discussed and categorized. A set of metrics is proposed for each component to evaluate the feasibility of an attack. Moreover, the data that can be leaked in the attacks are summarized. Further, the existing attacks are compared, and the limitations of these attacks are discussed based on the proposed metrics. In the end, existing mitigations at the micro-architecture level from literature are discussed.", "text_perturb": "Transient execution attacks , also called speculative execution attacks , take drawn much interest as they exploit the transient execution of instructions , e. gram. , during branch prediction , to leak datum. transitory execution is fundamental to modern computer architectures , yet poses a security risk as has been demonstrated. Since the first disclosure of Spectre and Meltdown attacks in January 2018 , a number of new attack types or variant of the attacks have been presented. These attacks have motivated computer architects to rethink the design of processors and propose computer hardware defenses. This paper summarizes the components and the phases of the transient execution attack. Each of the ingredient is further discussed and categorized. A set of metrics is proposed for each component to appraise the feasibility of an attack. Moreover , the data that can be leaked in the attacks are summarize. Further , the existing attacks represent compared , and the limitations of these attacks represent discussed based on the proposed metrics. In the end , existing palliation at the micro-architecture level from literature are discussed. ", "label": 1}
{"original_text": "Artificial life originated and has long studied the topic of open-ended evolution, which seeks the principles underlying artificial systems that innovate continually, inspired by biological evolution. Recently, interest has grown within the broader field of AI in a generalization of open-ended evolution, here called open-ended search, wherein such questions of open-endedness are explored for advancing AI, whatever the nature of the underlying search algorithm (e.g. evolutionary or gradient-based). For example, open-ended search might design new architectures for neural networks, new reinforcement learning algorithms, or most ambitiously, aim at designing artificial general intelligence. This paper proposes that open-ended evolution and artificial life have much to contribute towards the understanding of open-ended AI, focusing here in particular on the safety of open-ended search. The idea is that AI systems are increasingly applied in the real world, often producing unintended harms in the process, which motivates the growing field of AI safety. This paper argues that open-ended AI has its own safety challenges, in particular, whether the creativity of open-ended systems can be productively and predictably controlled. This paper explains how unique safety problems manifest in open-ended search, and suggests concrete contributions and research questions to explore them. The hope is to inspire progress towards creative, useful, and safe open-ended search algorithms.", "text_perturb": "Artificial life originated and has long studied the topic of open ended evolution , which seeks the principles underlying artificial systems that innovate continually , inspired by biological evolution. Recently , interest has grown within the broader field of AI in a generalization of open-ended evolution , here called open-ended search , wherein such questions of open-endedness are explore for advancing AI , whatever the nature of the underlying search algorithm ( e. thousand. evolutionary or gradient-based ). For example , open-ended search might design new architectures for neural networks , new reinforcement learning algorithms , or most ambitiously , aim at design artificial general intelligence. This paper proposes that open ended evolution and artificial life have much to contribute towards the understanding of open ended AI , focusing here in particular on the safety of open ended search. The idea is that AI systems are progressively applied in the real world , often producing unintended harms in the process , which motivates the growing field of AI safety. This paper argues that open-ended AI has its own safety challenges , in particular , whether the creativity of open-ended systems can constitute productively and predictably controlled. This paper explains how unequaled safety problems manifest in open-ended search , and suggests concrete contributions and research questions to explore them. The hope is to inspire progress towards creative , useful , and safe open ended search algorithms. ", "label": 1}
{"original_text": "A Full Duplex Base Station (FD-BS) can be used to serve simultaneously two Half-Duplex (HD) Mobile Stations (MSs), one working in the uplink and one in the downlink, respectively. The same functionality can be realized by having two interconnected and spatially separated Half Duplex Base Stations (HD-BSs), which is a scheme termed CoMPflex (CoMP for In-Band Wireless Full Duplex). A FD-BS can be seen as a special case of CoMPflex with separation distance zero. In this paper we study the performance of CoMPflex in a two-dimensional cellular scenario using stochastic geometry and compare it to the one achieved by FD-BSs. By deriving the Cumulative Distribution Functions, we show that CoMPflex brings BSs closer to the MSs they are serving, while increasing the distance between a MS and interfering MSs. Furthermore, the results show that CoMPflex brings benefits over FD-BS in terms of communication reliability. Following the trend of wireless network densification, CoMPflex can be regarded as a method with a great potential to effectively use the dense HD deployments.", "text_perturb": "A Full Duplex Base Station ( FD-BS ) can be used to serve simultaneously two Half-Duplex ( HD ) Mobile Stations ( disseminated sclerosis ) , one working in the uplink and one in the downlink , respectively. The same functionality can be realized by having two interconnected and spatially separated one half Duplex Base Stations ( HD-BSs ) , which is a scheme termed CoMPflex ( CoMP for In-Band Wireless Full Duplex ). A FD-BS can be seen as a special case of CoMPflex with breakup distance zero. In this paper we study the performance of CoMPflex in a two-dimensional cellular scenario using stochastic geometry and liken it to the one achieved by FD-BSs. By deriving the Cumulative Distribution mathematical function , we show that CoMPflex brings BSs closer to the MSs they are serving , while increasing the distance between a MS and interfering MSs. Furthermore , the results show that CoMPflex brings welfare over FD-BS in terms of communication reliability. Following the drift of wireless network densification , CoMPflex can be regarded as a method with a great potential to effectively use the dense HD deployments. ", "label": 1}
{"original_text": "We study three orientation-based shape descriptors on a set of continuously moving points: the first principal component, the smallest oriented bounding box and the thinnest strip. Each of these shape descriptors essentially defines a cost capturing the quality of the descriptor and uses the orientation that minimizes the cost. This optimal orientation may be very unstable as the points are moving, which is undesirable in many practical scenarios. If we bound the speed with which the orientation of the descriptor may change, this may lower the quality of the resulting shape descriptor. In this paper we study the trade-off between stability and quality of these shape descriptors. We first show that there is no stateless algorithm, an algorithm that keeps no state over time, that both approximates the minimum cost of a shape descriptor and achieves continuous motion for the shape descriptor. On the other hand, if we can use the previous state of the shape descriptor to compute the new state, we can define \"chasing\" algorithms that attempt to follow the optimal orientation with bounded speed. We show that, under mild conditions, chasing algorithms with sufficient bounded speed approximate the optimal cost at all times for oriented bounding boxes and strips. The analysis of such chasing algorithms is challenging and has received little attention in literature, hence we believe that our methods used in this analysis are of independent interest.", "text_perturb": "We study three orientation-based pattern descriptors on a set of continuously moving points : the first principal component , the smallest oriented bounding box and the thinnest strip. Each of these shape descriptors essentially defines a cost seize the quality of the descriptor and uses the orientation that minimizes the cost. This optimal orientation course may be very unstable as the points are moving , which is undesirable in many practical scenarios. If we bound the speed with which the orientation of the descriptor may change , this may let down the quality of the resulting shape descriptor. In this paper we study the trade-off between stableness and quality of these shape descriptors. We first show that there is no stateless algorithm , an algorithm that keeps no state over time , that both approximates the minimum cost of a shape descriptor and achieves continuous apparent movement for the shape descriptor. On the other paw , if we can use the previous state of the shape descriptor to compute the new state , we can define `` chasing '' algorithms that attempt to follow the optimal orientation with bounded speed. We show that , under mild conditions , give chase algorithms with sufficient bounded speed approximate the optimal cost at all times for oriented bounding boxes and strips. The analysis of such chasing algorithms is challenging and own received little attention in literature , hence we believe that our methods used in this analysis are of independent interest. ", "label": 1}
{"original_text": "Graphlets are induced subgraph patterns and have been frequently applied to characterize the local topology structures of graphs across various domains, e.g., online social networks (OSNs) and biological networks. Discovering and computing graphlet statistics are highly challenging. First, the massive size of real-world graphs makes the exact computation of graphlets extremely expensive. Secondly, the graph topology may not be readily available so one has to resort to web crawling using the available application programming interfaces (APIs). In this work, we propose a general and novel framework to estimate graphlet statistics of \" any size .\" Our framework is based on collecting samples through consecutive steps of random walks. We derive an analytical bound on the sample size (via the Chernoff-Hoeffding technique) to guarantee the convergence of our unbiased estimator. To further improve the accuracy, we introduce two novel optimization techniques to reduce the lower bound on the sample size. Experimental evaluations demonstrate that our methods outperform the state-of-the-art method up to an order of magnitude both in terms of accuracy and time cost.", "text_perturb": "Graphlets are induced subgraph patterns and have be frequently applied to characterize the local topology structures of graphs across various domains , e. constant of gravitation. , online societal networks ( OSNs ) and biological networks. distinguish and computing graphlet statistics are highly challenging. First , the monolithic size of real-world graphs makes the exact computation of graphlets extremely expensive. Secondly , the graph topology may non be readily available so one has to resort to web crawling using the available application programming interfaces ( APIs ). In this work , we propose a general and new framework to estimate graphlet statistics of `` any size. `` Our fabric is based on collecting samples through consecutive steps of random walks. We derive an analytical bound on the sample size ( via the Chernoff-Hoeffding technique ) to guarantee the convergence of our indifferent estimator. To further improve the accuracy , we introduce two novel optimization techniques to reduce the lower leap on the sample size. Experimental evaluations demonstrate that our methods outperform the state-of-the-art method up to an order of magnitude both in terms of accuracy and fourth dimension cost. ", "label": 1}
{"original_text": "Recent research provides evidence that effective communication in collaborative software development has significant impact on the software development lifecycle. Although related qualitative and quantitative studies point out textual characteristics of well-formed messages, the underlying semantics of the intertwined linguistic structures still remain largely misinterpreted or ignored. Especially, regarding quality of code reviews the importance of thorough feedback, and explicit rationale is often mentioned but rarely linked with related linguistic features. As a first step towards addressing this shortcoming, we propose grounding these studies on theories of linguistics. We particularly focus on linguistic structures of coherent speech and explain how they can be exploited in practice. We reflect on related approaches and examine through a preliminary study on four open source projects, possible links between existing findings and the directions we suggest for detecting textual features of useful code reviews.", "text_perturb": "Recent research provides evidence that effective communication in collaborative software development has significant shock on the software development lifecycle. Although related qualitative and quantitative studies point out textual characteristics of well-formed messages , the underlying semantics of the intertwined linguistic structure still remain largely misinterpreted or ignored. Especially , regarding timbre of code reviews the importance of thorough feedback , and explicit rationale is often mentioned but rarely linked with related linguistic features. As a initiatory step towards addressing this shortcoming , we propose grounding these studies on theories of linguistics. We particularly focus on linguistic structures of coherent address and explain how they can be exploited in practice. We reflect on related approaches and canvass through a preliminary study on four open source projects , possible links between existing findings and the directions we suggest for detecting textual features of useful code reviews. ", "label": 1}
{"original_text": "We present Nopol an approach for automatically repairing buggy if conditions and missing preconditions. As input, it takes a program and a test suite which contains passing test cases modeling the expected behavior of the program and at least one failing test case embodying the bug to be repaired. It consists of collecting data from multiple instrumented test suite executions, transforming this data into a Satisfiability Modulo Theory (SMT) problem, and translating the SMT result - if there exists one - into a source code patch. Nopol repairs object oriented code and allows the patches to contain nullness checks as well as specific method calls.", "text_perturb": "We present Nopol an approach for automatically repairing buggy if conditions and overlook preconditions. As input , it takes a political program and a test suite which contains passing test cases modeling the expected behavior of the political program and at least one failing test case embodying the bug to be repaired. It consists of collecting data from multiple instrumented test suite executions , transforming this data into a Satisfiability Modulo Theory ( SMT ) problem , and translating the SMT result - if there exist one - into a source code patch. Nopol repairs object oriented code and allows the patches to comprise nullness checks as well as specific method calls. ", "label": 1}
{"original_text": "Move blocking (MB) is a widely used strategy to reduce the degrees of freedom of the Optimal Control Problem (OCP) arising in receding horizon control. The size of the OCP is reduced by forcing the input variables to be constant over multiple discretization steps. In this paper, we focus on developing computationally efficient MB schemes for multiple shooting based nonlinear model predictive control (NMPC). The degrees of freedom of the OCP is reduced by introducing MB in the shooting step, resulting in a smaller but sparse OCP. Therefore, the discretization accuracy and level of sparsity is maintained. A condensing algorithm that exploits the sparsity structure of the OCP is proposed, that allows to reduce the computation complexity of condensing from quadratic to linear in the number of discretization nodes. As a result, active-set methods with warm-start strategy can be efficiently employed, thus allowing the use of a longer prediction horizon. A detailed comparison between the proposed scheme and the nonuniform grid NMPC is given. Effectiveness of the algorithm in reducing computational burden while maintaining optimization accuracy and constraints fulfillment is shown by means of simulations with two different problems.", "text_perturb": "Move blocking ( MB ) is a widely used strategy to reduce the degrees of freedom of the Optimal Control Problem ( OCP ) arising in receding horizon controller. The size of the OCP is reduced by forcing the input variable to be constant over multiple discretization steps. In this paper , we focus on developing computationally efficient MB schemes for multiple shot based nonlinear model predictive control ( NMPC ). The degrees of exemption of the OCP is reduced by introducing MB in the shooting step , resulting in a smaller but sparse OCP. Therefore , the discretization accuracy and tier of sparsity is maintained. A condensing algorithm that exploits the sparsity structure of the OCP is proposed , that allows to reduce the computation complexity of concentrate from quadratic to linear in the number of discretization nodes. As a result , active-set methods with warm-start strategy can be efficiently employ , thus allowing the use of a longer prediction horizon. A detailed comparison between the proposed scheme and the nonuniform power grid NMPC is given. Effectiveness of the algorithmic program in reducing computational burden while maintaining optimization accuracy and constraints fulfillment is shown by means of simulations with two different problems. ", "label": 1}
{"original_text": "One of the primary goals of the mathematical analysis of algorithms is to provide guidance about which algorithm is the \"best\" for solving a given computational problem. Worst-case analysis summarizes the performance profile of an algorithm by its worst performance on any input of a given size, implicitly advocating for the algorithm with the best-possible worst-case performance. Strong worst-case guarantees are the holy grail of algorithm design, providing an application-agnostic certification of an algorithm's robustly good performance. However, for many fundamental problems and performance measures, such guarantees are impossible and a more nuanced analysis approach is called for. This chapter surveys several alternatives to worst-case analysis that are discussed in detail later in the book.", "text_perturb": "One of the primary goals of the mathematical analysis of algorithmic rule is to provide guidance about which algorithm is the `` best '' for solving a given computational problem. Worst-case analysis summarizes the performance profile of an algorithmic program by its worst performance on any input of a given size , implicitly advocating for the algorithmic program with the best-possible worst-case performance. Strong worst-case guarantees are the holy grail of algorithm design , providing an application-agnostic certification of an algorithm 's robustly serious performance. However , for many fundamental problems and performance measures , such warrant are impossible and a more nuanced analysis approach is called for. This chapter surveys several option to worst-case analysis that are discussed in detail later in the book. ", "label": 1}
{"original_text": "Zero-shot learning (ZSL) aims to discriminate images from unseen classes by exploiting relations to seen classes via their semantic descriptions. Some recent papers have shown the importance of localized features together with fine-tuning the feature extractor to obtain discriminative and transferable features. However, these methods require complex attention or part detection modules to perform explicit localization in the visual space. In contrast, in this paper we propose localizing representations in the semanticattribute space, with a simple but effective pipeline where localization is implicit. Focusing on attribute representations, we show that our method obtains state-of-the-art performance on CUB and SUN datasets, and also achieves competitive results on AWA2 dataset, outperforming generally more complex methods with explicit localization in the visual space. Our method can be implemented easily, which can be used as a new baseline for zero shot-learning. In addition, our localized representations are highly interpretable as attribute-specific heatmaps.", "text_perturb": "Zero-shot learning ( ZSL ) aims to discriminate images from unseen division by exploiting relations to seen division via their semantic descriptions. Some recent papers make shown the importance of localized features together with fine-tuning the feature extractor to obtain discriminative and transferable features. however , these methods require complex attention or part detection modules to perform explicit localization in the visual space. In contrast , in this paper we suggest localizing representations in the semanticattribute space , with a simple but effective pipeline where localization is implicit. Focusing on attribute representations , we show that our method obtains state of the art performance on CUB and SUN datasets , and also achieves competitive results on AWA2 dataset , outperforming generally more complex methods with explicit localization in the visual space. Our method can be implemented easily , which can be used as a newfangled baseline for zero shot-learning. In addition , our localized representations are extremely interpretable as attribute-specific heatmaps. ", "label": 1}
{"original_text": "This application paper presents a novel framework based on topological data analysis for the automatic evaluation and ranking of viscous finger simulation runs in an ensemble with respect to a reference acquisition. Individual fingers in a given time-step are associated with critical point pairs in the distance field to the injection point, forming persistence diagrams. Different metrics, based on optimal transport, for comparing time-varying persistence diagrams in this specific applicative case are introduced. We evaluate the relevance of the rankings obtained with these metrics, both qualitatively thanks to a lightweight web visual interface, and quantitatively by studying the deviation from a reference ranking suggested by experts. Extensive experiments show the quantitative superiority of our approach compared to traditional alternatives. Our web interface allows experts to conveniently explore the produced rankings. We show a complete viscous fingering case study demonstrating the utility of our approach in the context of porous media fluid flow, where our framework can be used to automatically discard physically-irrelevant simulation runs from the ensemble and rank the most plausible ones. We document an in-situ implementation to lighten IO and performance constraints arising in the context of parametric studies.", "text_perturb": "This application paper presents a fresh framework based on topological data analysis for the automatic evaluation and ranking of viscous finger simulation runs in an ensemble with respect to a reference acquisition. Individual fingers in a given time-step are associated with critical point pairs in the distance field to the injection point , form persistence diagrams. Different system of measurement , based on optimal transport , for comparing time-varying persistence diagrams in this specific applicative case are introduced. We evaluate the relevance of the rankings obtained with these metrics , both qualitatively thanks to a lightweight web visual interface , and quantitatively by studying the deviation from a quotation ranking suggested by experts. Extensive experiments show the quantitative superiority of our plan of attack compared to traditional alternatives. Our web user interface allows experts to conveniently explore the produced rankings. We show a complete viscous fingering case study demonstrating the utility of our approach in the context of poriferous media fluid flow , where our framework can be used to automatically discard physically-irrelevant simulation runs from the ensemble and rank the most plausible ones. We document an in-situ implementation to lighten IO and performance restraint arising in the context of parametric studies. ", "label": 1}
{"original_text": "Cyber-physical systems (CPS), which integrate algorithmic control with physical processes, often consist of physically distributed components communicating over a network. A malfunctioning or compromised component in such a CPS can lead to costly consequences, especially in the context of public infrastructure. In this short paper, we argue for the importance of constructing invariants (or models) of the physical behaviour exhibited by CPS, motivated by their applications to the control, monitoring, and attestation of components. To achieve this despite the inherent complexity of CPS, we propose a new technique for learning invariants that combines machine learning with ideas from mutation testing. We present a preliminary study on a water treatment system that suggests the efficacy of this approach, propose strategies for establishing confidence in the correctness of invariants, then summarise some research questions and the steps we are taking to investigate them.", "text_perturb": "Cyber-physical systems ( CPS ) , which integrate algorithmic control with physical processes , often consist of physically distributed components communicating over a electronic network. A malfunctioning or compromised component in such a CPS can lead to costly consequences , especially in the context of public base. In this short paper , we argue for the importance of constructing invariants ( or models ) of the physical behaviour exhibited by CPS , motivated by their applications to the control , monitoring , and attestation of constituent. To achieve this despite the inherent complexity of CPS , we propose a new technique for learn invariants that combines machine learn with ideas from mutation testing. We present a preliminary study on a urine treatment system that suggests the efficacy of this approach , propose strategies for establishing confidence in the correctness of invariants , then summarise some research questions and the steps we are taking to investigate them. ", "label": 1}
{"original_text": "We consider vector space interference alignment strategies over the K -user interference channel and derive an upper bound on the achievable degrees of freedom as a function of the channel diversity L, where the channel diversity is modeled by L real-valued parallel channels with coefficients drawn from a non-degenerate joint distribution. The seminal work of Cadambe and Jafar shows that when L is unbounded, vector space interference alignment can achieve 1 2 degrees of freedom per user independent of the number of users K. However wireless channels have limited diversity in practice, dictated by their coherence time and bandwidth, and an important question is the number of degrees of freedom achievable at finite L. When K 3 and if L is finite, Bresler et al show that the number of degrees of freedom achievable with vector space interference alignment is bounded away from 1 2, and the gap decreases inversely proportional to L. In this paper, we show that when K 4, the gap is significantly larger. In particular, the gap to the optimal 1 2 degrees of freedom per user can decrease at most like 1 L, and when L is smaller than the order of 2 K 2) K 3), it decays at most like 1 4 L.", "text_perturb": "We consider vector space interference alignment strategies over the K -user interference channel and derive an upper bound on the achievable degrees of freedom as a subroutine of the channel diversity L , where the channel diversity is modeled by L real-valued parallel channels with coefficients drawn from a non-degenerate joint distribution. The seminal work of Cadambe and Jafar shows that when L is unbounded , vector space interference alignment can attain 1 2 degrees of freedom per user independent of the number of users K. However wireless channels have limited diversity in practice , dictated by their coherence time and bandwidth , and an important question is the number of degrees of freedom achievable at finite cubic decimeter. When K 3 and if L is finite , Bresler et al show that the number of degrees of freedom achievable with vector space interference alignment is bounded away from 1 2 , and the gap decrease inversely proportional to L. In this paper , we show that when K 4 , the gap is significantly great. In particular , the gap to the optimal 1 2 degrees of freedom per user can decrease at most like 1 L , and when L is small scale than the order of 2 K 2 ) K 3 ) , it decays at most like 1 4 L. ", "label": 1}
{"original_text": "In this paper, we consider a novel cache-enabled heterogeneous network (HetNet), where macro base stations (BSs) with traditional sub-6 GHz are overlaid by dense millimeter wave (mmWave) pico BSs. These two-tier BSs, which are modeled as two independent homogeneous Poisson Point Processes, cache multimedia contents following the popularity rank. High-capacity backhauls are utilized between macro BSs and the core server. A maximum received power strategy is introduced for deducing novel algorithms of the success probability and area spectral efficiency (ASE). Moreover, Monte Carlo simulations are presented to verify the analytical conclusions and numerical results demonstrate that: 1) the proposed HetNet is an interference-limited system and it outperforms the traditional HetNets; 2) there exists an optimal pre-decided rate threshold that contributes to the maximum ASE; and 3) 73 GHz is the best mmWave carrier frequency regarding ASE due to the large antenna scale.", "text_perturb": "In this paper , we consider a novel cache-enabled heterogeneous network ( HetNet ) , where macro base stations ( BSs ) with traditional sub-6 GHz are overlaid by dense millimetre wave ( mmWave ) pico BSs. These two-tier BSs , which are modeled as two independent homogenous Poisson Point Processes , cache multimedia contents following the popularity rank. High-capacity backhauls are utilized between macro instruction BSs and the core server. A maximum standard power strategy is introduced for deducing novel algorithms of the success probability and area spectral efficiency ( ASE ). Moreover , Monte Carlo simulations are presented to verify the analytical conclusions and numerical results demonstrate that : 1 ) the proposed HetNet is an interference-limited system and it outperforms the traditional HetNets ; 2 ) there exists an optimal pre-decided pace threshold that contributes to the maximum ASE ; and 3 ) 73 GHz is the best mmWave carrier frequency regarding ASE due to the large antenna scale. ", "label": 1}
{"original_text": "Image forgery localization is a very active and open research field for the difficulty to handle the large variety of manipulations a malicious user can perform by means of more and more sophisticated image editing tools. Here, we propose a localization framework based on the fusion of three very different tools, based, respectively, on sensor noise, patch-matching, and machine learning. The binary masks provided by these tools are finally fused based on some suitable reliability indexes. According to preliminary experiments on the training set, the proposed framework provides often a very good localization accuracy and sometimes valuable clues for visual scrutiny.", "text_perturb": "Image forgery localization is a very active and open research field for the difficulty to handle the large variety of manipulations a malicious user can perform by means of more and more sophisticated image editing shaft. here , we propose a localization framework based on the fusion of three very different tools , based , respectively , on sensor noise , patch-matching , and machine learning. The binary masks provided by these tools are last fused based on some suitable reliability indexes. According to preliminary experiments on the training set , the proposed framework provides often a very good localization accuracy and sometimes valuable clues for visual examination. ", "label": 1}
{"original_text": "Access to parallel and distributed computation has enabled researchers and developers to improve algorithms and performance in many applications. Recent research has focused on next generation special purpose systems with multiple kinds of coprocessors, known as heterogeneous system-on-chips (SoC) (,). In this paper, we introduce a method to intelligently schedule-and learn to schedule-a stream of tasks to available processing elements in such a system. We use deep reinforcement learning enabling complex sequential decision making and empirically show that our reinforcement learning system provides for a viable, better alternative to conventional scheduling heuristics with respect to minimizing execution time.", "text_perturb": "Access to parallel and give out computation has enabled researchers and developers to improve algorithms and performance in many applications. Recent enquiry has focused on next generation special purpose systems with multiple kinds of coprocessors , known as heterogeneous system-on-chips ( SoC ) ( , ). In this paper , we introduce a method to intelligently schedule-and learn to schedule-a stream of tasks to available processing elements in such a scheme. We use deep reinforcement learning enabling complex sequential decision making and through empirical observation show that our reinforcement learning system provides for a viable , better alternative to conventional scheduling heuristics with respect to minimizing execution time. ", "label": 1}
{"original_text": "In this paper, we propose a novel image calibration algorithm for a twofold c TIDAC. The algorithm is based on simulated annealing, which is often used in the field of machine learning to solve c DFO problems. The c DAC under consideration is part of a digital transceiver core that contains a high speed c ADC, microcontroller, and digital control via a c SPI. These are used as tools for designing an algorithm which suppresses the interleave image to the noise floor. The algorithm is supported with experimental results in silicon on a 10-bit twofold c TIDAC operating at a sample rate of 50 GSs in 14nm CMOS technology.", "text_perturb": "In this composition , we propose a novel image calibration algorithm for a twofold c TIDAC. The algorithm is based on faux annealing , which is often used in the field of machine learning to solve c DFO problems. The degree celsius DAC under consideration is part of a digital transceiver core that contains a high speed degree celsius ADC , microcontroller , and digital control via a degree celsius SPI. These exist used as tools for designing an algorithm which suppresses the interleave image to the noise floor. The algorithm is supported with experimental results in silicon on a 10-bit twofold c TIDAC operating at a sample charge per unit of 50 GSs in 14nm CMOS technology. ", "label": 1}
{"original_text": "We show that the sensor self-localization problem can be cast as a static parameter estimation problem for Hidden Markov Models and we implement fully decentralized versions of the Recursive Maximum Likelihood and on-line Expectation-Maximization algorithms to localize the sensor network simultaneously with target tracking. For linear Gaussian models, our algorithms can be implemented exactly using a distributed version of the Kalman filter and a novel message passing algorithm. The latter allows each node to compute the local derivatives of the likelihood or the sufficient statistics needed for Expectation-Maximization. In the non-linear case, a solution based on local linearization in the spirit of the Extended Kalman Filter is proposed. In numerical examples we demonstrate that the developed algorithms are able to learn the localization parameters.", "text_perturb": "We show that the sensor self-localization problem can be cast as a static parameter estimation problem for Hidden Markov Models and we implement fully decentralized adaptation of the Recursive Maximum Likelihood and on-line Expectation-Maximization algorithms to localize the sensor network simultaneously with target tracking. For linear Gaussian models , our algorithmic rule can be implemented exactly using a distributed version of the Kalman filter and a novel message passing algorithm. The latter allows each node to compute the local derivatives of the likelihood or the sufficient statistic needed for Expectation-Maximization. In the non-linear case , a solution found on local linearization in the spirit of the Extended Kalman Filter is proposed. In numerical examples we demonstrate that the developed algorithm are able to learn the localization parameters. ", "label": 1}
{"original_text": "Sequence set is a widely-used type of data source in a large variety of fields. A typical example is protein structure prediction, which takes an multiple sequence alignment (MSA) as input and aims to infer structural information from it. Almost all of the existing approaches exploit MSAs in an indirect fashion, i.e., they transform MSAs into position-specific scoring matrices (PSSM) that represent the distribution of amino acid types at each column. PSSM could capture column-wise characteristics of MSA, however, the column-wise characteristics embedded in each individual component sequence were nearly totally neglected. The drawback of PSSM is rooted in the fact that an MSA is essentially an unordered sequence set rather than a matrix. Specifically, the interchange of any two sequences will not affect the whole MSA. In contrast, the pixels in an image essentially form a matrix since any two rows of pixels cannot be interchanged. Therefore, the traditional deep neural networks designed for image processing cannot be directly applied on sequence sets. Here, we proposed a novel deep neural network framework (called Seq-SetNet) for sequence set processing. By employing a symmetric function module to integrate features calculated from preceding layers, Seq-SetNet are immune to the order of sequences in the input MSA. This advantage enables us to directly and fully exploit MSAs by considering each component protein individually. We evaluated Seq-SetNet by using it to extract structural information from MSA for protein secondary structure prediction. Experimental results on popular benchmark sets suggests that Seq-SetNet outperforms the state-of-the-art approaches by 3.6 in precision. These results clearly suggest the advantages of Seq-SetNet in sequence set processing and it can be readily used in a wide range of fields, say natural language processing.", "text_perturb": "Sequence set is a widely-used character of data source in a large variety of fields. A typical example is protein structure prediction , which train an multiple sequence alignment ( MSA ) as input and aims to infer structural information from it. Almost all of the survive approaches exploit MSAs in an indirect fashion , i. atomic number . , they transform MSAs into position-specific marking matrices ( PSSM ) that represent the distribution of amino acid types at each column. PSSM could capture column-wise device characteristic of MSA , however , the column-wise device characteristic embedded in each individual component sequence were nearly totally neglected. The drawback of PSSM is rooted in the fact that an MSA is essentially an unordered sequence set quite than a matrix. Specifically , the interchange of any two sequences will not affect the hale MSA. In contrast , the pixels in an image essentially form a matrix since any two rows of pixels can not personify interchanged. Therefore , the traditional bass neural networks designed for image processing can not be directly applied on sequence sets. Here , we proposed a novel cryptical neural network framework ( called Seq-SetNet ) for sequence set processing. By employing a symmetric function faculty to integrate features calculated from preceding layers , Seq-SetNet are immune to the order of sequences in the input MSA. This advantage enables us to straight off and fully exploit MSAs by considering each component protein individually. We appraise Seq-SetNet by using it to extract structural information from MSA for protein secondary structure prediction. Experimental results on popular bench mark sets suggests that Seq-SetNet outperforms the state-of-the-art approaches by 3. 6 in preciseness. These results clearly suggest the advantages of Seq-SetNet in sequence set processing and it can exist readily used in a wide range of fields , say natural language processing. ", "label": 1}
{"original_text": "This paper examines the problem of rate allocation for multicasting over slow Rayleigh fading channels using network coding. In the proposed model, the network is treated as a collection of Rayleigh fading multiple access channels. In this model, rate allocation scheme that is based solely on the statistics of the channels is presented. The rate allocation scheme is aimed at minimizing the outage probability. An upper bound is presented for the probability of outage in the fading multiple access channel. A suboptimal solution based on this bound is given. A distributed primal-dual gradient algorithm is derived to solve the rate allocation problem.", "text_perturb": "This paper examines the problem of rate allocation for multicasting over dull Rayleigh fading channels using network coding. In the proposed model , the network is treated as a appeal of Rayleigh fading multiple access channels. In this model , rate allocation scheme that is based solely on the statistics of the channels is lay out. The rate parceling scheme is aimed at minimizing the outage probability. An upper leap is presented for the probability of outage in the fading multiple access channel. A suboptimal solution based on this bound is given. A distributed primal-dual gradient algorithm is infer to solve the rate allocation problem. ", "label": 1}
{"original_text": "We prove a quantum information-theoretic conjecture due to Ji, Liu and Song (CRYPTO 2018) which suggested that a uniform superposition with random binary phase is statistically indistinguishable from a Haar random state. That is, any polynomial number of copies of the aforementioned state is within exponentially small trace distance from the same number of copies of a Haar random state. As a consequence, we get a provable elementary construction of pseudorandom quantum states from post-quantum pseudorandom functions. Generating pseduorandom quantum states is desirable for physical applications as well as for computational tasks such as quantum money. We observe that replacing the pseudorandom function with a (2 t) -wise independent function (either in our construction or in previous work), results in an explicit construction for quantum state t -designs for all t. In fact, we show that the circuit complexity (in terms of both circuit size and depth) of constructing t -designs is bounded by that of (2 t) -wise independent functions. Explicitly, while in prior literature t -designs required linear depth (for t 2), this observation shows that polylogarithmic depth suffices for all t. We note that our constructions yield pseudorandom states and state designs with only real-valued amplitudes, which was not previously known. Furthermore, generating these states require quantum circuit of restricted form: applying one layer of Hadamard gates, followed by a sequence of Toffoli gates. This structure may be useful for efficiency and simplicity of implementation.", "text_perturb": "We prove a quantum information-theoretic conjecture due to Ji , Liu and Song ( CRYPTO 2018 ) which suggested that a uniform superposition principle with random binary phase is statistically indistinguishable from a Haar random state. That is , any polynomial number of transcript of the aforementioned state is within exponentially small trace distance from the same number of transcript of a Haar random state. As a consequence , we get a provable elemental construction of pseudorandom quantum states from post-quantum pseudorandom functions. Generating pseduorandom quantum dos is desirable for physical applications as well as for computational tasks such as quantum money. We observe that replacing the pseudorandom function with a ( 2 t ) -wise independent function ( either in our construction or in previous oeuvre ) , results in an explicit construction for quantum state t -designs for all t. In fact , we show that the circuit complexity ( in terms of both circuit sizing and depth ) of constructing t -designs is bounded by that of ( 2 t ) -wise independent functions. Explicitly , while in prior literature thyroxin -designs required linear depth ( for t 2 ) , this observation shows that polylogarithmic depth suffices for all thyroxin. We note that our constructions yield pseudorandom states and state designs with only real-valued amplitudes , which was not antecedently known. Furthermore , generating these states require quantum circuit of restricted form : applying one layer of Hadamard logic gate , followed by a sequence of Toffoli logic gate. This structure may be useful for efficiency and easiness of implementation. ", "label": 1}
{"original_text": "Anomalies in time-series data give essential and often actionable information in many applications. In this paper we consider a model-free anomaly detection method for univariate time-series which adapts to non-stationarity in the data stream and provides probabilistic abnormality scores based on the conformal prediction paradigm. Despite its simplicity the method performs on par with complex prediction-based models on the Numenta Anomaly Detection benchmark and the Yahoo! S5 dataset.", "text_perturb": "Anomalies in time-series data give essential and often actionable data in many applications. In this paper we consider a model-free anomaly detection method for univariate time-series which adapts to non-stationarity in the data stream and provides probabilistic abnormality scores base on the conformal prediction paradigm. Despite its simplicity the method performs on equivalence with complex prediction-based models on the Numenta Anomaly Detection benchmark and the Yahoo ! S5 dataset. ", "label": 1}
{"original_text": "The main research involving globalization nowadays is to describe the impact of globalization in their respective fields. However, globalization is a complex phenomenon across multiple sections. But as a concept in the social science, it barely has the rigid mathematical foundation. Because of this lack, this article made a simple attempt to express and prove the trend of globalization with mathematical features. By abstracting an sub-area that is widely influenced by globalization, the article are trying to test whether this area can be used as an indicator of globalization.", "text_perturb": "The main research involving globalization nowadays is to draw the impact of globalization in their respective fields. However , globalisation is a complex phenomenon across multiple sections. But as a concept in the social skill , it barely has the rigid mathematical foundation. Because of this lack , this article made a simple attempt to extract and prove the trend of globalization with mathematical features. By filch an sub-area that is widely influenced by globalization , the article are trying to test whether this area can be used as an indicator of globalization. ", "label": 1}
{"original_text": "Building good 3D maps is a challenging and expensive task, which requires high-quality sensors and careful, time-consuming scanning. We seek to reduce the cost of building good reconstructions by correcting views of existing low-quality ones in a post-hoc fashion using learnt priors over surfaces and appearance. We train a model to predict the difference in inverse-depth from varying viewpoints of two meshes - one of low quality that we wish to correct, and one of high-quality that we use as a reference. In contrast to previous work, we pay attention to the problem of excessive smoothing in corrected meshes. We address this with a suitable network architecture, and introduce a loss-weighting mechanism that emphasises edges in the prediction. Furthermore, smooth predictions result in geometrical inconsistencies. To deal with this issue, we present a loss function which penalises re-projection differences that are not due to occlusions. Our model reduces gross errors by 45.3-77.5, up to five times more than previous work.", "text_perturb": "construct good 3D maps is a challenging and expensive task , which requires high-quality sensors and careful , time-consuming scanning. We seek to reduce the cost of building effective reconstructions by correcting views of existing low-quality ones in a post-hoc fashion using learnt priors over surfaces and appearance. We train a model to predict the difference in inverse-depth from varying viewpoints of two meshes - one of low timber that we wish to correct , and one of high-quality that we use as a reference. In contrast to previous work , we pay attention to the problem of inordinate smoothing in corrected meshes. We address this with a suitable network computer architecture , and introduce a loss-weighting mechanism that emphasises edges in the prediction. Furthermore , placid predictions result in geometrical inconsistencies. To deal with this issue , we present a loss function which penalises re-projection divergence that are not due to occlusions. Our mannikin reduces gross errors by 45. 3-77. 5 , upward to five times more than previous work. ", "label": 1}
{"original_text": "In this work we introduce Deforming Autoencoders, a generative model for images that disentangles shape from appearance in an unsupervised manner. As in the deformable template paradigm, shape is represented as a deformation between a canonical coordinate system template and an observed image, while appearance is modeled in 'canonical', template, coordinates, thus discarding variability due to deformations. We introduce novel techniques that allow this approach to be deployed in the setting of autoencoders and show that this method can be used for unsupervised group-wise image alignment. We show experiments with expression morphing in humans, hands, and digits, face manipulation, such as shape and appearance interpolation, as well as unsupervised landmark localization. A more powerful form of unsupervised disentangling becomes possible in template coordinates, allowing us to successfully decompose face images into shading and albedo, and further manipulate face images.", "text_perturb": "In this work we introduce Deforming Autoencoders , a generative model for prototype that disentangles shape from appearance in an unsupervised manner. As in the deformable template paradigm , shape is represented as a deformation between a canonical coordinate system template and an ascertained image , while appearance is modeled in 'canonical ' , template , coordinates , thus discarding variability due to deformations. We introduce fresh techniques that allow this approach to be deployed in the setting of autoencoders and show that this method can be used for unsupervised group-wise image alignment. We show experiments with expression morphing in mankind , hands , and digits , face manipulation , such as shape and appearance interpolation , as well as unsupervised landmark localization. A more powerful form of unsupervised disentangling becomes possible in template coordinates , provide us to successfully decompose face images into shading and albedo , and further manipulate face images. ", "label": 1}
{"original_text": "In this article, we propose a model-driven deep learning (DL) approach that combines DL with the expert knowledge to replace the existing orthogonal frequency-division multiplexing (OFDM) receiver in wireless communications. Different from the data-driven fully connected deep neural network (FC-DNN) method, we adopt the block-by-block signal processing method that divides the receiver into channel estimation subnet and signal detection subnet. Each subnet is constructed by a DNN and uses the existing simple and traditional solution as initialization. The proposed model-driven DL receiver offers more accurate channel estimation comparing with the linear minimum mean-squared error (LMMSE) method and exhibits higher data recovery accuracy comparing with the existing methods and FC-DNN. Simulation results further demonstrate the robustness of the proposed approach in terms of signal-to-noise ratio and its superiority to the FC-DNN approach in the computational complexities or the memory usage.", "text_perturb": "In this article , we propose a model-driven deep learning ( deciliter ) approach that combines deciliter with the expert knowledge to replace the existing orthogonal frequency-division multiplexing ( OFDM ) receiver in wireless communications. Different from the data-driven fully connected deep neural mesh ( FC-DNN ) method , we adopt the block-by-block signal processing method that divides the receiver into channel estimation subnet and signal detection subnet. Each subnet is constructed by a DNN and uses the existing simpleton and traditional solution as initialization. The proposed model-driven DL receiver offers more accurate channel estimation comparing with the additive minimum mean-squared error ( LMMSE ) method and exhibits higher data recovery accuracy comparing with the existing methods and FC-DNN. Simulation results further demonstrate the robustness of the proposed approach in terms of signal-to-noise ratio and its favorable position to the FC-DNN approach in the computational complexities or the memory usage. ", "label": 1}
{"original_text": "We propose a comprehensive nonlinear ODE-based thermo-hydraulic model of a district heating system featuring several heat producers, consumers and storage devices which are interconnected through a distribution network of meshed topology whose temperature dynamics are explicitly considered. Moreover, we present conditions under which the hydraulic and thermal subsystems of the model exhibit shifted passivity properties and discuss some of the beneficial implications for decentralized control design and stability analysis. For the former subsystem, our results draw on the monotonicity attributes manifested by the mappings involved. For the latter, we propose a storage function based on the ectropy function of a thermodynamic system, recently used in the passivity analysis of heat exchanger networks. Our formal analysis is supported with numerical simulations on a case study using realistic system parameters.", "text_perturb": "We pop the question a comprehensive nonlinear ODE-based thermo-hydraulic model of a district heating system featuring several heat producers , consumers and storage devices which are interconnected through a distribution network of meshed topology whose temperature dynamics are explicitly considered. Moreover , we present conditions under which the hydraulic and thermal subsystems of the model exhibit shifted passivity properties and talk over some of the beneficial implications for decentralized control design and stability analysis. For the erstwhile subsystem , our results draw on the monotonicity attributes manifested by the mappings involved. For the latter , we propose a computer memory function based on the ectropy function of a thermodynamic system , recently used in the passivity analysis of heat exchanger networks. Our formal analysis is supported with numerical simulations on a case study habituate realistic system parameters. ", "label": 1}
{"original_text": "In this paper, we study the parallel and the space complexity of the graph isomorphism problem (GI) for several parameterizations. Let H {H 1, H 2, , H l } be a finite set of graphs where V (H i) d for all I and for some constant d. Let G be an H -free graph class i.e., none of the graphs G G contain any H H as an induced subgraph. We show that GI parameterized by vertex deletion distance to G is in a parameterized version of AC 1, denoted Para - AC 1, provided the colored graph isomorphism problem for graphs in G is in AC 1. From this, we deduce that GI parameterized by the vertex deletion distance to cographs is in Para - AC 1. The parallel parameterized complexity of GI parameterized by the size of a feedback vertex set remains an open problem. Towards this direction we show that the graph isomorphism problem is in Para - TC 0 when parameterized by vertex cover or by twin-cover. Let G ' be a graph class such that recognizing graphs from G ' and the colored version of GI for G ' is in logspace (L). We show that GI for bounded vertex deletion distance to G ' is in L. From this, we obtain logspace algorithms for GI for graphs with bounded vertex deletion distance to interval graphs and graphs with bounded vertex deletion distance to cographs.", "text_perturb": "In this paper , we study the parallel and the place complexity of the graph isomorphism problem ( GI ) for several parameterizations. Let H { H 1 , H 2 , , H l } be a finite set of graphs where V ( H unity ) d for all I and for some constant d. Let G exist an H -free graph class i. vitamin e. , none of the graphs grand grand contain any H H as an induced subgraph. We show that GI parameterized by vertex deletion distance to G is in a parameterized version of AC 1 , denoted Para - AC 1 , render the colored graph isomorphism problem for graphs in G is in AC 1. From this , we deduce that GI parameterized by the vertex deletion distance to cographs represent in Para - AC 1. The parallel parameterized complexity of GI parameterized by the sizing of a feedback vertex set remains an open problem. Towards this direction we show that the graph isomorphism problem is in Para - TC 0 when parameterized by vertex natural covering or by twin-cover. allow G ' be a graph class such that recognizing graphs from G ' and the colored version of GI for G ' is in logspace ( L ). We show that GI for bounded vertex deletion space to G ' is in L. From this , we obtain logspace algorithmic program for GI for graphs with bounded vertex deletion distance to interval graphs and graphs with bounded vertex deletion distance to cographs. ", "label": 1}
{"original_text": "We consider the age-old problem of allocating items among different agents in a way that is efficient and fair. Two papers, by Dolev et al. and Ghodsi et al., have recently studied this problem in the context of computer systems. Both papers had similar models for agent preferences, but advocated different notions of fairness. We formalize both fairness notions in economic terms, extending them to apply to a larger family of utilities. Noting that in settings with such utilities efficiency is easily achieved in multiple ways, we study notions of fairness as criteria for choosing between different efficient allocations. Our technical results are algorithms for finding fair allocations corresponding to two fairness notions: Regarding the notion suggested by Ghodsi et al., we present a polynomial-time algorithm that computes an allocation for a general class of fairness notions, in which their notion is included. For the other, suggested by Dolev et al., we show that a competitive market equilibrium achieves the desired notion of fairness, thereby obtaining a polynomial-time algorithm that computes such a fair allocation and solving the main open problem raised by Dolev et al.", "text_perturb": "We consider the age-old problem of allocating items among different agents in a way that equal efficient and fair. Two papers , by Dolev et aluminium. and Ghodsi et camellia state. , have recently studied this problem in the context of data processor systems. Both papers had similar models for agent penchant , but advocated different notions of fairness. We formalize both fairness notions in economical terms , extending them to apply to a larger family of utilities. Noting that in settings with such public utility company efficiency is easily achieved in multiple ways , we study notions of fairness as criteria for choosing between different efficient allocations. Our technical results are algorithms for finding fair allocations corresponding to two fairness notions : view the notion suggested by Ghodsi et al. , we present a polynomial-time algorithm that computes an allocation for a general category of fairness notions , in which their notion is included. For the other , suggested by Dolev et al. , we show that a competitive market equilibrium achieves the desired notion of fairness , thereby obtaining a polynomial-time algorithmic rule that computes such a fair allocation and solving the main open problem raised by Dolev et al. ", "label": 1}
{"original_text": "We present a novel unsupervised deep learning framework for anomalous event detection in complex video scenes. While most existing works merely use hand-crafted appearance and motion features, we propose Appearance and Motion DeepNet (AMDN) which utilizes deep neural networks to automatically learn feature representations. To exploit the complementary information of both appearance and motion patterns, we introduce a novel double fusion framework, combining both the benefits of traditional early fusion and late fusion strategies. Specifically, stacked denoising autoencoders are proposed to separately learn both appearance and motion features as well as a joint representation (early fusion). Based on the learned representations, multiple one-class SVM models are used to predict the anomaly scores of each input, which are then integrated with a late fusion strategy for final anomaly detection. We evaluate the proposed method on two publicly available video surveillance datasets, showing competitive performance with respect to state of the art approaches.", "text_perturb": "We represent a novel unsupervised deep learning framework for anomalous event detection in complex video scenes. While most existing works merely use hand-crafted appearance and motion feature article , we propose Appearance and Motion DeepNet ( AMDN ) which utilizes deep neural networks to automatically learn feature representations. To exploit the complementary information of both appearance and motion patterns , we introduce a novel double fusion framework , combining both the benefits of traditional early fusion and later fusion strategies. Specifically , stacked denoising autoencoders are aim to separately learn both appearance and motion features as well as a joint representation ( early fusion ). Based on the learned representations , multiple one-class SVM models are used to predict the anomaly scores of each input , which are then integrate with a late fusion strategy for final anomaly detection. We pass judgment the proposed method on two publicly available video surveillance datasets , showing competitive performance with respect to state of the art approaches. ", "label": 1}
{"original_text": "We prove the completeness of an axiomatization for differential equation invariants. First, we show that the differential equation axioms in differential dynamic logic are complete for all algebraic invariants. Our proof exploits differential ghosts, which introduce additional variables that can be chosen to evolve freely along new differential equations. Cleverly chosen differential ghosts are the proof-theoretical counterpart of dark matter. They create new hypothetical state, whose relationship to the original state variables satisfies invariants that did not exist before. The reflection of these new invariants in the original system then enables its analysis. We then show that extending the axiomatization with existence and uniqueness axioms makes it complete for all local progress properties, and further extension with a real induction axiom makes it complete for all real arithmetic invariants. This yields a parsimonious axiomatization, which serves as the logical foundation for reasoning about invariants of differential equations. Moreover, our results are purely axiomatic, and so the axiomatization is suitable for sound implementation in foundational theorem provers. Keywords: differential equation axiomatization, differential dynamic logic, differential ghosts", "text_perturb": "We testify the completeness of an axiomatization for differential equation invariants. First , we show that the differential equation axioms in differential dynamic logic are unadulterated for all algebraic invariants. Our proof exploits differential ghosts , which introduce additional variables that can be chosen to develop freely along new differential equations. Cleverly chosen differential ghosts are the proof-theoretical counterpart of sinister matter. They create new hypothetical state , whose relationship to the original state variables satisfies invariants that cause not exist before. The reflection of these new invariants in the original system then enables its psychoanalysis. We then show that extending the axiomatization with existence and uniqueness axioms makes it complete for all local progress properties , and further extension with a real generalization axiom makes it complete for all real arithmetic invariants. This yields a parsimonious axiomatization , which serves as the logical foundation for reasoning about invariant of differential equations. moreover , our results are purely axiomatic , and so the axiomatization is suitable for sound implementation in foundational theorem provers. Keywords : differential equation axiomatization , differential dynamical logic , differential ghosts", "label": 1}
{"original_text": "Consensus protocols are crucial for reliable distributed systems as they let them cope with network and server failures. For decades, most consensus protocols have been designed as variations of the seminal Paxos, yet in 2014 Raft was presented as a new, \"understandable\" protocol, meant to be easier to implement than the notoriously subtle Paxos family. Raft has since been used in various industrial projects, e.g. Hashicorp's Consul or etcd (used by Google's Kubernetes). The correctness of Raft is established via a manual proof, based on a TLA specification of the protocol. This paper reports our experience in modeling Raft in the LNT process algebra. We found a couple of issues with the original TLA specification of Raft, which has been corrected since. More generally, this exercise offers a great opportunity to discuss how to best use the features of the LNT formal language and the associated CADP verification toolbox to model distributed protocols, including network and server failures.", "text_perturb": "consensus protocols are crucial for reliable distributed systems as they let them cope with network and server failures. For decades , most consensus protocols have been designed as sport of the seminal Paxos , yet in 2014 Raft was presented as a new , `` understandable '' protocol , meant to be easier to implement than the notoriously subtle Paxos family. Raft has since been used in versatile industrial projects , e. grand. Hashicorp 's Consul or etcd ( utilize by Google 's Kubernetes ). The correctness of Raft is established via a manual proof , establish on a TLA specification of the protocol. This paper reports our experience in modeling great deal in the LNT process algebra. We found a couple of payoff with the original TLA specification of Raft , which has been corrected since. More generally , this exercise offers a great opportunity to discuss how to outflank use the features of the LNT formal language and the associated CADP verification toolbox to model distributed protocols , including network and server failures. ", "label": 1}
{"original_text": "In this work we introduce a differential rendering module which allows neural networks to efficiently process cluttered data. The module is composed of continuous piecewise differentiable functions defined as a sensor array of cells embedded in 3D space. Our module is learnable and can be easily integrated into neural networks allowing to optimize data rendering towards specific learning tasks using gradient based methods in an end-to-end fashion. Essentially, the module's sensor cells are allowed to transform independently and locally focus and sense different parts of the 3D data. Thus, through their optimization process, cells learn to focus on important parts of the data, bypassing occlusions, clutter and noise. Since sensor cells originally lie on a grid, this equals to a highly non-linear rendering of the scene into a 2D image. Our module performs especially well in presence of clutter and occlusions. Similarly, it deals well with non-linear deformations and improves classification accuracy through proper rendering of the data. In our experiments, we apply our module to demonstrate efficient localization and classification tasks in cluttered data both 2D and 3D.", "text_perturb": "In this work we introduce a differential rendering module which allows neural networks to efficiently process clutter up data. The module is composed of continuous piecewise differentiable procedure defined as a sensor array of cells embedded in 3D space. Our module is learnable and can be easily integrated into neural mesh allowing to optimize data rendering towards specific learning tasks using gradient based methods in an end-to-end fashion. Essentially , the module 's sensor cells are allowed to transform independently and locally focus and sense different constituent of the 3D data. Thus , through their optimization process , cells pick up to focus on important parts of the data , bypassing occlusions , clutter and noise. Since sensing element cells originally lie on a grid , this equals to a highly non-linear rendering of the scene into a 2D image. Our faculty performs especially well in presence of clutter and occlusions. Similarly , it allot well with non-linear deformations and improves classification accuracy through proper rendering of the data. In our experiment , we apply our module to demonstrate efficient localization and classification tasks in cluttered data both 2D and 3D. ", "label": 1}
{"original_text": "We propose a validity preserving translation from a subset of epistemic Alternating-time Temporal Logic (ATL) to epistemic Computation Tree Logic (CTL). The considered subset of epistemic ATL is known to have the finite model property and decidable model-checking. This entails the decidability of validity but the implied algorithm is unfeasible. Reducing the validity problem to that in a corresponding system of CTL makes the techniques for automated deduction for that logic available for the handling of the apparently more complex system of ATL.", "text_perturb": "We propose a validity preserving transformation from a subset of epistemic Alternating-time Temporal Logic ( ATL ) to epistemic Computation Tree Logic ( CTL ). The take subset of epistemic ATL is known to have the finite model property and decidable model-checking. This entails the decidability of robustness but the implied algorithm is unfeasible. Reducing the validity problem to that in a like system of CTL makes the techniques for automated deduction for that logic available for the handling of the apparently more complex system of ATL. ", "label": 1}
{"original_text": "We introduce the first known mechanism providing realtime server location verification. Its uses include enhancing server authentication (e.g., augmenting TLS) by enabling browsers to automatically interpret server location information. We describe the design of this new measurement-based technique, Server Location Verification (SLV), and evaluate it using PlanetLab. We explain how SLV is compatible with the increasing trends of geographically distributed content dissemination over the Internet, without causing any new interoperability conflicts. Additionally, we introduce the notion of (verifiable) server location pinning within TLS (conceptually similar to certificate pinning) to support SLV, and evaluate their combined impact using a server-authentication evaluation framework. The results affirm the addition of new security benefits to the existing SSLTLS-based authentication mechanisms. We implement SLV through a location verification service, the simplest version of which requires no server-side changes. We also implement a simple browser extension that interacts seamlessly with the verification infrastructure to obtain realtime server location-verification results.", "text_perturb": "We introduce the first known mechanism providing realtime server emplacement verification. Its uses admit enhancing server authentication ( e. thou. , augmenting TLS ) by enabling browsers to automatically interpret server location data. We describe the design of this new measurement-based technique , Server Location check ( SLV ) , and evaluate it using PlanetLab. We explain how SLV is compatible with the increasing trends of geographically distributed content dissemination over the Internet , without causing any novel interoperability conflicts. Additionally , we bring out the notion of ( verifiable ) server location pinning within TLS ( conceptually similar to certificate pinning ) to support SLV , and evaluate their combined impact using a server-authentication evaluation framework. The results affirm the addition of new security benefit to the existing SSLTLS-based authentication mechanisms. We implement SLV through a placement verification service , the simplest version of which requires no server-side changes. We also implement a simple browser extension that interacts seamlessly with the confirmation infrastructure to obtain realtime server location-verification results. ", "label": 1}
{"original_text": "This paper investigates a general framework to discover categories of unlabeled scene images according to their appearances (i.e., textures and structures). We jointly solve the two coupled tasks in an unsupervised manner: (i) classifying images without pre-determining the number of categories, and (ii) pursuing generative model for each category. In our method, each image is represented by two types of image descriptors that are effective to capture image appearances from different aspects. By treating each image as a graph vertex, we build up an graph, and pose the image categorization as a graph partition process. Specifically, a partitioned sub-graph can be regarded as a category of scenes, and we define the probabilistic model of graph partition by accumulating the generative models of all separated categories. For efficient inference with the graph, we employ a stochastic cluster sampling algorithm, which is designed based on the Metropolis-Hasting mechanism. During the iterations of inference, the model of each category is analytically updated by a generative learning algorithm. In the experiments, our approach is validated on several challenging databases, and it outperforms other popular state-of-the-art methods. The implementation details and empirical analysis are presented as well.", "text_perturb": "This paper investigates a general framework to discover categories of unlabeled tantrum images according to their appearances ( i. tocopherol. , textures and social organisation ). We jointly solve the two coupled tasks in an unsupervised manner : ( ace ) classifying images without pre-determining the number of categories , and ( ii ) pursuing generative model for each category. In our method , each persona is represented by two types of persona descriptors that are effective to capture persona appearances from different aspects. By treating each image as a graphical record vertex , we build up an graphical record , and pose the image categorization as a graph partition process. Specifically , a partitioned sub-graph can be regarded as a category of scenes , and we define the probabilistic model of graph partition by accumulating the generative models of all separated class. For efficient inference with the graphical record , we employ a stochastic cluster sampling algorithm , which is designed based on the Metropolis-Hasting mechanism. During the iterations of inference , the model of each family is analytically updated by a generative learning algorithm. In the experiments , our approach is corroborate on several challenging databases , and it outperforms other popular state-of-the-art methods. The implementation details and empirical analysis are presented as comfortably. ", "label": 1}
{"original_text": "It is rigorously proved that ideal memcapacitors and meminductors are not passive or lossless devices, nor are they satisfying the weaker notion of cyclo-passivity, which arises when dropping the requirement of non-negativity of the storage function. Equivalently, this implies that there exist excitation profiles that allow to extract more energy from the device than it is supplied with; so that their energy conversion efficiency exceeds 100. This means that ideal memcapacitors and meminductors constitute so-called overunity systems. An illustrative mechanical analogue is provided that explicitly confirms this property. Hence, the question arises if ideal memcapacitors and meminductors will just remain some mathematical toys or artefacts.", "text_perturb": "It is rigorously proved that ideal memcapacitors and meminductors are not passive or lossless devices , nor are they satisfying the weaker opinion of cyclo-passivity , which arises when dropping the requirement of non-negativity of the storage function. Equivalently , this implies that there exist excitation profiles that allow to extract more energy from the device than it is add with ; so that their energy conversion efficiency exceeds 100. This imply that ideal memcapacitors and meminductors constitute so-called overunity systems. An illustrative mechanical analogue is put up that explicitly confirms this property. Hence , the question arises if ideal memcapacitors and meminductors will hardly remain some mathematical toys or artefacts. ", "label": 1}
{"original_text": "Complex networks provide a means to describe cities through their street mesh, expressing characteristics that refer to the structure and organization of an urban zone. Although other studies have used complex networks to model street meshes, we observed a lack of methods to characterize the relationship between cities by using their topological features. Accordingly, this paper aims to describe interactions between cities by using vectors of topological features extracted from their street meshes represented as complex networks. The methodology of this study is based on the use of digital maps. Over the computational representation of such maps, we extract global complex-network features that embody the characteristics of the cities. These vectors allow for the use of multidimensional projection and clustering techniques, enabling a similarity-based comparison of the street meshes. We experiment with 645 cities from the Brazilian state of Sao Paulo. Our results show how the joint of global features describes urban indicators that are deep-rooted in the network's topology and how they reveal characteristics and similarities among sets of cities that are separated from each other.", "text_perturb": "Complex networks provide a means to describe cities through their street mesh , state characteristics that refer to the structure and organization of an urban zone. Although other studies have used complex networks to model street mesh , we observed a lack of methods to characterize the relationship between cities by using their topological features. Accordingly , this paper aims to describe interactions between cities by using vectors of topological features take out from their street meshes represented as complex networks. The methodology of this study exist based on the use of digital maps. Over the computational representation of such maps , we extract global complex-network features that embody the characteristic of the cities. These vectors allow for the use of multidimensional projection and clustering techniques , enabling a similarity-based comparison of the street net. We experiment with 645 cities from the brazilian state of Sao Paulo. Our answer show how the joint of global features describes urban indicators that are deep-rooted in the network 's topology and how they reveal characteristics and similarities among sets of cities that are separated from each other. ", "label": 1}
{"original_text": "We study black-box reductions from mechanism design to algorithm design for welfare maximization in settings of incomplete information. Given oracle access to an algorithm for an underlying optimization problem, the goal is to simulate an incentive compatible mechanism. The mechanism will be evaluated on its expected welfare, relative to the algorithm provided, and its complexity is measured by the time (and queries) needed to simulate the mechanism on any input. While it is known that black-box reductions are not possible in many prior-free settings, settings with priors appear more promising: there are known reductions for Bayesian incentive compatible (BIC) mechanism design for general classes of welfare maximization problems. This dichotomy begs the question: which mechanism design problems admit black-box reductions, and which do not? Our main result is that black-box mechanism design is impossible under two of the simplest settings not captured by known positive results. First, for the problem of allocating n goods to a single buyer whose valuation is additive and independent across the goods, subject to a downward-closed constraint on feasible allocations, we show that there is no polytime (in n) BIC black-box reduction for expected welfare maximization. Second, for the setting of multiple single-parameter agents - where polytime BIC reductions are known - we show that no polytime reductions exist when the incentive requirement is tightened to Max-In-Distributional-Range. In each case, we show that achieving a sub-polynomial approximation to the expected welfare requires exponentially many queries, even when the set of feasible allocations is known to be downward-closed.", "text_perturb": "We study black-box reductions from mechanism design to algorithm design for welfare maximization in setting of incomplete information. return oracle access to an algorithm for an underlying optimization problem , the goal is to simulate an incentive compatible mechanism. The mechanism will equal evaluated on its expected welfare , relative to the algorithm provided , and its complexity is measured by the time ( and queries ) needed to simulate the mechanism on any input. While it is known that black-box reductions are not possible in many prior-free settings , settings with priors appear more promising : there are known reductions for Bayesian incentive compatible ( BIC ) mechanism design for general classes of welfare maximization job. This dichotomy begs the question : which mechanism design trouble admit black-box reductions , and which do not ? Our main result is that black-box mechanism design is impossible under two of the simplest settings not captured by known positive results. First , for the problem of allocating n goods to a single buyer whose valuation is additive and independent across the goods , subject to a downward-closed restraint on feasible allocations , we show that there is no polytime ( in n ) BIC black-box reduction for expected welfare maximization. Second , for the setting of multiple single-parameter agents - where polytime BIC reductions are known - we show that no polytime reductions exist when the incentive requirement is fasten to Max-In-Distributional-Range. In each case , we show that achieving a sub-polynomial approximation to the expected welfare requires exponentially many queries , even when the set of feasible allocations is lie with to be downward-closed. ", "label": 1}
{"original_text": "To mitigate the detection performance drop caused by domain shift, we aim to develop a novel few-shot adaptation approach that requires only a few target domain images with limited bounding box annotations. To this end, we first observe several significant challenges. First, the target domain data is highly insufficient, making most existing domain adaptation methods ineffective. Second, object detection involves simultaneous localization and classification, further complicating the model adaptation process. Third, the model suffers from over-adaptation (similar to overfitting when training with a few data example) and instability risk that may lead to degraded detection performance in the target domain. To address these challenges, we first introduce a pairing mechanism over source and target features to alleviate the issue of insufficient target domain samples. We then propose a bi-level module to adapt the source trained detector to the target domain: 1) the split pooling based image level adaptation module uniformly extracts and aligns paired local patch features over locations, with different scale and aspect ratio; 2) the instance level adaptation module semantically aligns paired object features while avoids inter-class confusion. Meanwhile, a source model feature regularization (SMFR) is applied to stabilize the adaptation process of the two modules. Combining these contributions gives a novel few-shot adaptive Faster-RCNN framework, termed FAFRCNN, which effectively adapts to target domain with a few labeled samples. Experiments with multiple datasets show that our model achieves new state-of-the-art performance under both the interested few-shot domain adaptation (FDA) and unsupervised domain adaptation (UDA) setting.", "text_perturb": "To mitigate the detection performance drop get by domain shift , we aim to develop a novel few-shot adaptation approach that requires only a few target domain images with limited bounding box annotations. To this last , we first observe several significant challenges. First , the target domain data is highly insufficient , making most existing domain adaptation method acting ineffective. Second , object detection involves simultaneous localization and classification , farther complicating the model adaptation process. Third , the model suffers from over-adaptation ( similar to overfitting when training with a few data example ) and instability risk that may lead to degraded sleuthing performance in the target domain. To address these challenges , we first introduce a pairing mechanism over source and objective features to alleviate the issue of insufficient objective domain samples. We then propose a bi-level module to adapt the beginning trained detector to the target domain : 1 ) the split pooling based image level adaptation module uniformly extracts and aligns paired local patch features over locations , with different scale and aspect ratio ; 2 ) the instance level adaptation module semantically aligns paired object features while avoids inter-class confusion. Meanwhile , a source poser feature regularization ( SMFR ) is applied to stabilize the adaptation process of the two modules. Combining these contributions gives a novel few-shot adaptive Faster-RCNN framework , termed FAFRCNN , which effectively adapts to target knowledge base with a few labeled samples. Experiments with multiple datasets show that our model achieves new state-of-the-art performance under both the interested few-shot domain adaptation ( FDA ) and unsupervised domain adaptation ( UDA ) ready. ", "label": 1}
{"original_text": "Distributed machine learning is becoming a popular model-training method due to privacy, computational scalability, and bandwidth capacities. In this work, we explore scalable distributed-training versions of two algorithms commonly used in object detection. A novel distributed training algorithm using Mean Weight Matrix Aggregation (MWMA) is proposed for Linear Support Vector Machine (L-SVM) object detection based in Histogram of Orientated Gradients (HOG). In addition, a novel Weighted Bin Aggregation (WBA) algorithm is proposed for distributed training of Ensemble of Regression Trees (ERT) landmark localization. Both algorithms do not restrict the location of model aggregation and allow custom architectures for model distribution. For this work, a Pool-Based Local Training and Aggregation (PBLTA) architecture for both algorithms is explored. The application of both algorithms in the medical field is examined using a paradigm from the fields of psychology and neuroscience - eyeblink conditioning with infants - where models need to be trained on facial images while protecting participant privacy. Using distributed learning, models can be trained without sending image data to other nodes. The custom software has been made available for public use on GitHub: Results show that the aggregation of models for the HOG algorithm using MWMA not only preserves the accuracy of the model but also allows for distributed learning with an accuracy increase of 0.9 compared with traditional learning. Furthermore, WBA allows for ERT model aggregation with an accuracy increase of 8 when compared to single-node models.", "text_perturb": "lot machine learning is becoming a popular model-training method due to privacy , computational scalability , and bandwidth capacities. In this work , we explore scalable distributed-training versions of two algorithms commonly utilise in object detection. A novel distributed breeding algorithm using Mean Weight Matrix Aggregation ( MWMA ) is proposed for Linear Support Vector Machine ( L-SVM ) object detection based in Histogram of Orientated Gradients ( HOG ). In addition , a novel Weighted Bin Aggregation ( WBA ) algorithmic rule is proposed for distributed training of Ensemble of Regression Trees ( ERT ) landmark localization. Both algorithms do not restrict the location of exemplar aggregation and allow custom architectures for exemplar distribution. For this work , a Pool-Based Local Training and Aggregation ( PBLTA ) architecture for both algorithms equal explored. The application of both algorithms in the medical field is examined using a paradigm from the fields of psychology and neuroscience - eyeblink conditioning with infants - where models need to be trained on facial images while protecting participant secrecy. employ distributed learning , models can be trained without sending image data to other nodes. The custom software has been made available for public use on GitHub : Results show that the aggregation of models for the HOG algorithm using MWMA non only preserves the accuracy of the model but also allows for distributed learning with an accuracy increase of 0. 9 compared with traditional learnedness. Furthermore , WBA allows for ert model aggregation with an accuracy increase of 8 when compared to single-node models. ", "label": 1}
{"original_text": "Mutant selection refers to the problem of choosing, among a large number of mutants, the (few) ones that should be used by the testers. In view of this, we investigate the problem of selecting the fault revealing mutants, i.e., the mutants that are most likely to be killable and lead to test cases that uncover unknown program faults. We formulate two variants of this problem: the fault revealing mutant selection and the fault revealing mutant prioritization. We argue and show that these problems can be tackled through a set of 'static' program features and propose a machine learning approach, named FaRM, that learns to select and rank killable and fault revealing mutants. Experimental results involving 1,692 real faults show the practical benefits of our approach in both examined problems. Our results show that FaRM achieves a good trade-off between application cost and effectiveness (measured in terms of faults revealed). We also show that FaRM outperforms all the existing mutant selection methods, i.e., the random mutant sampling, the selective mutation and defect prediction (mutating the code areas pointed by defect prediction). In particular, our results show that with respect to mutant selection, our approach reveals 23 to 34 more faults than any of the baseline methods, while, with respect to mutant prioritization, it achieves higher average percentage of revealed faults with a median difference between 4 and 9 (from the random mutant orderings).", "text_perturb": "Mutant selection refers to the problem of choosing , among a large number of variation , the ( few ) ones that should be used by the testers. In view of this , we investigate the problem of selecting the fault unwrap mutants , i. einsteinium. , the mutants that are most potential to be killable and lead to test cases that uncover unknown program faults. We contrive two variants of this problem : the fault revealing mutant selection and the fault revealing mutant prioritization. We argue and show that these problems can be tackled through a set of 'static ' program features and propose a machine learning approach , named FaRM , that ascertain to select and rank killable and fault revealing mutants. data based results involving 1,692 real faults show the practical benefits of our approach in both examined problems. Our results show that FaRM achieves a good trade-off between application cost and effectiveness ( measured in term of faults revealed ). We also show that FaRM outperforms all the survive mutant selection methods , i. eastward. , the random mutant sampling , the selective mutation and defect prediction ( mutating the codification areas pointed by defect prediction ). In particular , our results show that with respect to mutant selection , our approach reveals 23 to 34 more error than any of the baseline methods , while , with respect to mutant prioritization , it achieves higher average percentage of revealed error with a median difference between 4 and 9 ( from the random mutant orderings ). ", "label": 1}
{"original_text": "This study focuses on the mobile video delivery from a video server to a multi-homed client with a network of heterogeneous wireless. Joint Source-Channel Coding is effectively used to transmit video over bandwidth-limited, noisy wireless networks. But most existing JSCC methods only consider single path video transmission of the server and the client network. The problem will become more complicated when consider multi-path video transmission, because involving low-bandwidth, high-drop-rate or high-latency wireless network will only reduce the video quality. To solve this critical problem, we propose a novel Path Adaption JSCC (PA-JSCC) method that contain below characters: (1) path adaption, and (2) dynamic rate allocation. We use Exata to evaluate the performance of PA-JSCC and Experiment show that PA-JSCC has a good results in terms of PSNR (Peak Signal-to-Noise Ratio).", "text_perturb": "This study focuses on the mobile video bringing from a video server to a multi-homed client with a network of heterogeneous wireless. Joint Source-Channel Coding is effectively used to beam video over bandwidth-limited , noisy wireless networks. But most existing JSCC methods only consider single path tv transmission of the server and the client network. The problem will become more complicated when consider multi-path video transmission , because involving low-bandwidth , high-drop-rate or high-latency wireless network will only scale down the video quality. To solve this critical job , we propose a novel Path Adaption JSCC ( PA-JSCC ) method that contain below characters : ( 1 ) path adaption , and ( 2 ) dynamic rate allocation. We use Exata to evaluate the performance of PA-JSCC and Experiment show that PA-JSCC own a good results in terms of PSNR ( Peak Signal-to-Noise Ratio ). ", "label": 1}
{"original_text": "This article provides the first procedure for computing a fully data-dependent interval that traps the mixing time t mix of a finite reversible ergodic Markov chain at a prescribed confidence level. The interval is computed from a single finite-length sample path from the Markov chain, and does not require the knowledge of any parameters of the chain. This stands in contrast to previous approaches, which either only provide point estimates, or require a reset mechanism, or additional prior knowledge. The interval is constructed around the relaxation time t relax, which is strongly related to the mixing time, and the width of the interval converges to zero roughly at a n rate, where n is the length of the sample path. Upper and lower bounds are given on the number of samples required to achieve constant-factor multiplicative accuracy. The lower bounds indicate that, unless further restrictions are placed on the chain, no procedure can achieve this accuracy level before seeing each state at least O (t relax) times on the average. Finally, future directions of research are identified.", "text_perturb": "This article provides the first procedure for computing a to the full data-dependent interval that traps the mixing time t mix of a finite reversible ergodic Markov chain at a prescribed confidence level. The interval is reckon from a single finite-length sample path from the Markov chain , and does not require the knowledge of any parameters of the chain. This stands in contrast to previous approaches , which either only provide point estimates , or want a reset mechanism , or additional prior knowledge. The interval be constructed around the relaxation time t relax , which be strongly related to the mixing time , and the width of the interval converges to zero roughly at a n rate , where n be the length of the sample path. Upper and lower saltation are given on the number of samples required to achieve constant-factor multiplicative accuracy. The lower bounds indicate that , unless further restrictions are placed on the chain , no procedure can achieve this accuracy level before see to it each state at least O ( t relax ) times on the average. at long last , future directions of research are identified. ", "label": 1}
{"original_text": "We design polar codes for empirical coordination and strong coordination in two-node networks. extcolor black Our constructions hinge on the fact that polar codes enable explicit low-complexity schemes for soft covering. We leverage this property to propose explicit and low-complexity coding schemes that achieve the capacity regions of both empirical coordination and strong coordination for sequences of actions taking value in an alphabet of prime cardinality. Our results improve previously known polar coding schemes, which (i) were restricted to uniform distributions and to actions obtained via binary symmetric channels for strong coordination, (ii) required a non-negligible amount of common randomness for empirical coordination, and (iii) assumed that the simulation of discrete memoryless channels could be perfectly implemented. As a by-product of our results, we obtain a polar coding scheme that achieves channel resolvability for an arbitrary discrete memoryless channel whose input alphabet has prime cardinality.", "text_perturb": "We design opposite codes for empirical coordination and strong coordination in two-node networks. extcolor black Our constructions hinge on the fact that polar codes enable explicit low-complexity schemes for delicate covering. We leverage this property to propose explicit and low-complexity coding schemes that achieve the electrical capacity regions of both empirical coordination and strong coordination for sequences of actions taking value in an alphabet of prime cardinality. Our answer improve previously known polar coding schemes , which ( i ) were restricted to uniform distributions and to actions obtained via binary symmetric channels for strong coordination , ( ii ) required a non-negligible amount of common randomness for empirical coordination , and ( iii ) assumed that the simulation of discrete memoryless channels could be perfectly implemented. As a by-product of our results , we obtain a polar coding scheme that reach channel resolvability for an arbitrary discrete memoryless channel whose input alphabet has prime cardinality. ", "label": 1}
{"original_text": "One issue limiting the adaption of large-scale multi-region segmentation is the sometimes prohibitive memory requirements. This is especially troubling considering advances in massively parallel computing and commercial graphics processing units because of their already limited memory compared to the current random access memory used in more traditional computation. To address this issue in the field of continuous max-flow segmentation, we have developed a pseudo-flow framework using the theory of Bregman proximal projections and entropic distances which implicitly represents flow variables between labels and designated source and sink nodes. This reduces the memory requirements for max-flow segmentation by approximately 20 for Potts models and approximately 30 for hierarchical max-flow (HMF) and directed acyclic graph max-flow (DAGMF) models. This represents a great improvement in the state-of-the-art in max-flow segmentation, allowing for much larger problems to be addressed and accelerated using commercially available graphics processing hardware.", "text_perturb": "One issue limiting the adaption of large scale multi-region segmentation is the sometimes prohibitive memory requirements. This is especially troubling considering advances in massively parallel computing and commercial graphic processing units because of their already limited memory compared to the current random access memory used in more traditional computation. To address this issue in the field of continuous max-flow segmentation , we have developed a pseudo-flow framework using the theory of Bregman proximal projections and entropic distances which implicitly represents flow variables between labels and designated reservoir and sink nodes. This reduces the memory requirements for max-flow segmentation by approximately 20 for Potts models and approximately 30 for hierarchical max-flow ( HMF ) and directed open chain graph max-flow ( DAGMF ) models. This represents a great improvement in the state-of-the-art in max-flow segmentation , allowing for much larger problems to be turn to and accelerated using commercially available graphics processing hardware. ", "label": 1}
{"original_text": "Sparse and irregularly sampled multivariate time series are common in clinical, climate, financial and many other domains. Most recent approaches focus on classification, regression or forecasting tasks on such data. In forecasting, it is necessary to not only forecast the right value but also to forecast when that value will occur in the irregular time series. In this work, we present an approach to forecast not only the values but also the time at which they are expected to occur.", "text_perturb": "Sparse and irregularly sampled multivariate time series are common in clinical , clime , financial and many other domains. most recent approaches focus on classification , regression or forecasting tasks on such data. In forecasting , it is necessary to not only forecast the ripe value but also to forecast when that value will occur in the irregular time series. In this work , we present an feeler to forecast not only the values but also the time at which they are expected to occur. ", "label": 1}
{"original_text": "Many large datasets exhibit power-law statistics: The web graph, social networks, text data, clickthrough data etc. Their adjacency graphs are termed natural graphs, and are known to be difficult to partition. As a consequence most distributed algorithms on these graphs are communication-intensive. Many algorithms on natural graphs involve an Allreduce: a sum or average of partitioned data which is then shared back to the cluster nodes. Examples include PageRank, spectral partitioning, and many machine learning algorithms including regression, factor (topic) models, and clustering. In this paper we describe an efficient and scalable Allreduce primitive for power-law data. We point out scaling problems with existing butterfly and round-robin networks for Sparse Allreduce, and show that a hybrid approach improves on both. Furthermore, we show that Sparse Allreduce stages should be nested instead of cascaded (as in the dense case). And that the optimum throughput Allreduce network should be a butterfly of heterogeneous degree where degree decreases with depth into the network. Finally, a simple replication scheme is introduced to deal with node failures. We present experiments showing significant improvements over existing systems such as PowerGraph and Hadoop.", "text_perturb": "Many large datasets exhibit power-law statistics : The www graph , social networks , text data , clickthrough data etc. Their adjacency graphs are termed natural graphs , and are known to be unmanageable to partition. As a issue most distributed algorithms on these graphs are communication-intensive. Many algorithms on innate graphs involve an Allreduce : a sum or average of partitioned data which is then shared back to the cluster nodes. Examples include PageRank , phantasmal partitioning , and many machine learning algorithms including regression , factor ( topic ) models , and clustering. In this paper we describe an efficient and scalable Allreduce primitive person for power-law data. We point out scaling problem with existing butterfly and round-robin networks for Sparse Allreduce , and show that a hybrid approach improves on both. Furthermore , we show that Sparse Allreduce stages should be nested instead of cascade down ( as in the dense case ). And that the optimum throughput Allreduce web should be a butterfly of heterogeneous degree where degree decreases with depth into the web. Finally , a simple replication scheme embody introduced to deal with node failures. We present experiments showing significant improvements over existing organization such as PowerGraph and Hadoop. ", "label": 1}
{"original_text": "Architectural description languages are a useful tool for modeling complex software systems at a high level of abstraction. If based on formal methods, they can also serve for enabling the early verification of various properties such as component coordination and for guiding the synthesis of code correct by construction. This is the case with process algebraic architectural description languages, which are process calculi enhanced with the main architectural concepts. However, the techniques with which those languages have been equipped are mainly conceived to work with synchronous communications only. The objective of this paper is threefold. On the modeling side, we show how to enhance the expressiveness of a typical process algebraic architectural description language by including the capability of representing nonsynchronous communications in such a way that the usability of the original language is preserved. On the verification side, we show how to modify techniques for analyzing the absence of coordination mismatches like the compatibility check for acyclic topologies and the interoperability check for cyclic topologies in such a way that those checks are valid also for nonsynchronous communications. On the implementation side, we show how to generate multithreaded object-oriented software in the presence of synchronous and nonsynchronous communications in such a way that the properties proved at the architectural level are preserved at the code level.", "text_perturb": "Architectural description languages are a useful tool for modeling complex package systems at a high level of abstraction. If based on formal methods , they can also serve for enabling the early verification of various properties such as component coordination and for channelize the synthesis of code correct by construction. This is the case with process algebraic architectural description languages , which comprise process calculi enhanced with the main architectural concepts. However , the techniques with which those languages have been equipped are mainly conceived to work with synchronous communication theory only. The aim of this paper is threefold. On the modeling side , we show how to enhance the expressiveness of a distinctive process algebraic architectural description language by including the capability of representing nonsynchronous communications in such a way that the usability of the original language is preserved. On the verification side of meat , we show how to modify techniques for analyzing the absence of coordination mismatches like the compatibility check for acyclic topologies and the interoperability check for cyclic topologies in such a way that those checks are valid also for nonsynchronous communications. On the implementation side , we show how to generate multithreaded object-oriented software in the presence of synchronal and nonsynchronous communications in such a way that the properties proved at the architectural level are preserved at the code level. ", "label": 1}
{"original_text": "In this paper, we study the consensus problem of multiple agents on a kind of famous graph, Peterson graph. It is an undirected graph with 10 vertices and 15 edges. Each agent randomly walks on this graph and communicates with each other if and only if they coincide on a node at the same time. We conduct numerical study on the consensus problem in this framework and show that global consensus can be achieved. Keywords: consensus problem; discrete-time protocol; Peterson graph.", "text_perturb": "In this paper , we study the consensus job of multiple agents on a kind of famous graph , Peterson graph. It is an undirected graph with 10 vertices and 15 sharpness. Each broker randomly walks on this graph and communicates with each other if and only if they coincide on a node at the same time. We conduct numerical study on the consensus problem in this framework and display that global consensus can be achieved. Keywords : consensus problem ; discrete-time protocol ; Peterson graphical record. ", "label": 1}
{"original_text": "In this paper we present a framework for secure identification using deep neural networks, and apply it to the task of template protection for face authentication. We use deep convolutional neural networks (CNNs) to learn a mapping from face images to maximum entropy binary (MEB) codes. The mapping is robust enough to tackle the problem of exact matching, yielding the same code for new samples of a user as the code assigned during training. These codes are then hashed using any hash function that follows the random oracle model (like SHA-512) to generate protected face templates (similar to text based password protection). The algorithm makes no unrealistic assumptions and offers high template security, cancelability, and state-of-the-art matching performance. The efficacy of the approach is shown on CMU-PIE, Extended Yale B, and Multi-PIE face databases. We achieve high (95) genuine accept rates (GAR) at zero false accept rate (FAR) with up to 1024 bits of template security.", "text_perturb": "In this paper we present a framework for secure identification using deep neural networks , and use it to the task of template protection for face authentication. We use deep convolutional neural networks ( CNNs ) to learn a mapping from face persona to maximum entropy binary ( MEB ) codes. The mapping is robust enough to tackle the problem of exact matching , yielding the like code for new samples of a user as the code assigned during training. These codes are then hashed apply any hash function that follows the random oracle model ( like SHA-512 ) to generate protected face templates ( similar to text based password protection ). The algorithm makes no unrealistic assumptions and offers gamy template security , cancelability , and state-of-the-art matching performance. The efficacy of the approach is shown on CMU-PIE , Extended Yale B , and Multi-PIE aspect databases. We achieve high ( 95 ) genuine accept rates ( GAR ) at zero false accept charge per unit ( FAR ) with up to 1024 bits of template security. ", "label": 1}
{"original_text": "Latent feature models are canonical tools for exploratory analysis in classical and modern multivariate statistics. Many high-dimensional data can be approximated using a union of low-dimensional subspaces or factors. The allocation of data points to these latent factors itself typically uncovers key relationships in the input and helps us represent hidden causes explaining the data. A widely adopted view is to model feature allocation with discrete latent variables, where each data point is associated with a binary vector indicating latent features possessed by this data point. In this work we revise some of the issues with existing parametric and Bayesian nonparametric processes for feature allocation modelling and propose a novel framework that can capture wider set of feature allocation distributions. This new framework allows for explicit control over the number of features used to express each point and enables a more flexible set of allocation distributions including feature allocations with different sparsity levels. We use this approach to derive a novel adaptive Factor analysis (aFA), as well as, an adaptive probabilistic principle component analysis (aPPCA) capable of flexible structure discovery and dimensionality reduction in a wide case of scenarios. Motivated by the often prohibitive slowness of feature allocation models, we derive both standard a Gibbs sampler, as well as, an expectation-maximization inference algorithms for aPPCA and aFA that converge orders of magnitude faster to a reasonable point estimate solution. We demonstrate that aFA can handle richer feature distributions, when compared to widely used sparse FA models and Bayesian nonparametric FA models. The utility of the proposed aPPCA model is demonstrated for standard PCA tasks such as feature learning, data visualization and data whitening. We show that aPPCA and aFA can infer interpretable high level features both when applied on raw MNIST and when applied for interpreting autoencoder features. We also demonstrate an application of the aPPCA to more robust blind source separation for functional magnetic resonance imaging (fMRI).", "text_perturb": "Latent feature theoretical account are canonical tools for exploratory analysis in classical and modern multivariate statistics. Many high-dimensional data can be approximated using a union of low-dimensional subspaces or agent. The allocation of data points to these latent factors itself typically uncovers key relationships in the input and helps us represent hidden causes explicate the data. A widely adopted view is to model feature allocation with discrete latent variables , where each data point is associated with a binary vector indicating latent features have by this data point. In this work we retool some of the issues with existing parametric and Bayesian nonparametric processes for feature allocation modelling and propose a novel framework that can capture wider set of feature allocation distributions. This new framework allows for explicit control over the number of features used to express each point and enables a more flexible set of allocation distributions including feature assignation with different sparsity levels. We use this approach to derive a novel adaptive Factor analysis ( aFA ) , as well as , an adaptive probabilistic principle component analysis ( aPPCA ) capable of flexible structure find and dimensionality reduction in a wide case of scenarios. Motivated by the often prohibitive slowness of feature parceling models , we derive both standard a Gibbs sampler , as well as , an expectation-maximization inference algorithms for aPPCA and aFA that converge orders of magnitude faster to a reasonable point estimate solution. We demonstrate that aFA can handle copious feature distributions , when compared to widely used sparse FA models and Bayesian nonparametric FA models. The public utility of the proposed aPPCA model is demonstrated for standard PCA tasks such as feature learning , data visualization and data whitening. We show that aPPCA and aFA can infer interpretable high level features both when use on raw MNIST and when use for interpreting autoencoder features. We also demonstrate an application of the aPPCA to more robust blind source separation for operable magnetic resonance imaging ( fMRI ). ", "label": 1}
{"original_text": "Nowadays, offensive content in social media has become a serious problem, and automatically detecting offensive language is an essential task. In this paper, we build an offensive language detection system, which combines multi-task learning with BERT-based models. Using a pre-trained language model such as BERT, we can effectively learn the representations for noisy text in social media. Besides, to boost the performance of offensive language detection, we leverage the supervision signals from other related tasks. In the OffensEval-2020 competition, our model achieves 91.51 F1 score in English Sub-task A, which is comparable to the first place (92.23 F1). An empirical analysis is provided to explain the effectiveness of our approaches.", "text_perturb": "Nowadays , offensive content in social mass medium has become a serious problem , and automatically detecting offensive language is an essential task. In this paper , we build an nauseating language detection system , which combines multi-task learning with BERT-based models. Using a pre-trained language model such as BERT , we can effectively learn the representations for noisy text edition in social media. Besides , to boost the performance of nauseating language detection , we leverage the supervision signals from other related tasks. In the OffensEval-2020 competition , our model achieves 91. 51 F1 score in English Sub-task deoxyadenosine monophosphate , which is comparable to the first place ( 92. 23 F1 ). An empirical analysis represent provided to explain the effectiveness of our approaches. ", "label": 1}
{"original_text": "Random Constraint Satisfaction Problems exhibit several phase transitionswhen their density of constraints is varied. One of these threshold phenomena,known as the clustering or dynamic transition, corresponds to a transition foran information theoretic problem called tree reconstruction. In this article westudy this threshold for two CSPs, namely the bicoloring of k-uniformhypergraphs with a density lpha of constraints, and the q-coloring ofrandom graphs with average degree c. We show that in the large k,q limitthe clustering transition occurs for lpha rac{2{k-1k} (ln k lnln k gamma{ m d} o (1 , c q (ln q ln ln q gamma{ m d}o (1 , where gamma{ m d} is the same constant for both models. Wecharacterize gamma{ m d} via a functional equation, solve the latternumerically to estimate gamma{ m d} pprox 0.871, and obtain an analyticlowerbound gamma{ m d} ge 1 ln (2 (sqrt{21 pprox 0.812. Ouranalysis unveils a subtle interplay of the clustering transition with therigidity (naive reconstruction) threshold that occurs on the same asymptoticscale at gamma{ m r}1.", "text_perturb": "Random Constraint Satisfaction Problems exhibit respective phase transitionswhen their density of constraints is varied. One of these threshold phenomenon , known as the clustering or dynamic transition , corresponds to a transition foran information theoretic problem called tree reconstruction. In this article westudy this threshold for two CSPs , namely the bicoloring of k-uniformhypergraphs with a compactness lpha of constraints , and the q-coloring ofrandom graphs with average degree c. We show that in the large k , q limitthe clustering transition occurs for lpha rac { 2 { k-1k } ( ln k lnln k gamma { one thousand d } o ( 1 , c q ( ln q ln ln q gamma { one thousand d } o ( 1 , where gamma { one thousand d } is the same constant for both models. Wecharacterize gamma { m five hundred } via a functional equation , solve the latternumerically to estimate gamma { m five hundred } pprox 0. 871 , and obtain an analyticlowerbound gamma { m viosterol } ge 1 ln ( 2 ( sqrt { 21 pprox 0. 812. Ouranalysis unveils a subtle interplay of the clustering transition with therigidity ( naive reconstructive memory ) threshold that occurs on the same asymptoticscale at gamma { m r } 1. ", "label": 1}
{"original_text": "Face recognition techniques have been developed significantly in recent years. However, recognizing faces with partial occlusion is still challenging for existing face recognizers which is heavily desired in real-world applications concerning surveillance and security. Although much research effort has been devoted to developing face de-occlusion methods, most of them can only work well under constrained conditions, such as all the faces are from a pre-defined closed set. In this paper, we propose a robust LSTM-Autoencoders (RLA) model to effectively restore partially occluded faces even in the wild. The RLA model consists of two LSTM components, which aims at occlusion-robust face encoding and recurrent occlusion removal respectively. The first one, named multi-scale spatial LSTM encoder, reads facial patches of various scales sequentially to output a latent representation, and occlusion-robustness is achieved owing to the fact that the influence of occlusion is only upon some of the patches. Receiving the representation learned by the encoder, the LSTM decoder with a dual channel architecture reconstructs the overall face and detects occlusion simultaneously, and by feat of LSTM, the decoder breaks down the task of face de-occlusion into restoring the occluded part step by step. Moreover, to minimize identify information loss and guarantee face recognition accuracy over recovered faces, we introduce an identity-preserving adversarial training scheme to further improve RLA. Extensive experiments on both synthetic and real datasets of faces with occlusion clearly demonstrate the effectiveness of our proposed RLA in removing different types of facial occlusion at various locations. The proposed method also provides significantly larger performance gain than other de-occlusion methods in promoting recognition performance over partially-occluded faces.", "text_perturb": "Face recognition techniques have cost developed significantly in recent years. However , recognizing faces with partial occlusion embody still challenging for existing face recognizers which embody heavily desired in real-world applications concerning surveillance and security. Although much research effort has been devoted to developing face de-occlusion methods , most of them can only work well under constrained conditions , such as all the faces personify from a pre-defined closed set. In this paper , we propose a robust LSTM-Autoencoders ( RLA ) model to effectively restore partially block faces even in the wild. The RLA model consists of two LSTM components , which aims at occlusion-robust face encryption and recurrent occlusion removal respectively. The first one , named multi-scale spatial LSTM encoder , reads facial darn of various scales sequentially to output a latent representation , and occlusion-robustness is achieved owing to the fact that the influence of occlusion is only upon some of the darn. Receiving the representation learned by the encoder , the LSTM decoder with a dual channel architecture reconstructs the overall face and detects occlusion simultaneously , and by feat of LSTM , the decoder breaks down the task of face de-occlusion into restoring the occluded piece step by step. Moreover , to minimize identify information loss and guarantee face recognition accuracy over healed faces , we introduce an identity-preserving adversarial training scheme to further improve RLA. Extensive experiments on both synthetic and real datasets of faces with occlusion clearly manifest the effectiveness of our proposed RLA in removing different types of facial occlusion at various locations. The proposed method also provides significantly larger performance gain than other de-occlusion methods in encourage recognition performance over partially-occluded faces. ", "label": 1}
{"original_text": "Background: Understanding the distinction between function and role is vexing and difficult. While it appears to be useful, in practice this distinction is hard to apply, particularly within biology. Results: I take an evolutionary approach, considering a series of examples, to develop and generate definitions for these concepts. I test them in practice against the Ontology for Biomedical Investigations (OBI). Finally, I give an axiomatisation and discuss methods for applying these definitions in practice. Conclusions: The definitions in this paper are applicable, formalizing current practice. As such, they make a significant contribution to the use of these concepts within biomedical ontologies.", "text_perturb": "Background : Understanding the distinction between function and purpose is vexing and difficult. While it appears to be useful , in practice this distinction is hard to apply , especially within biology. Results : I take an evolutionary approach , considering a series of examples , to develop and generate definitions for these concept. I test them in practice against the Ontology for Biomedical Investigations ( obi ). Finally , I give an axiomatisation and discuss methods for applying these definition in practice. Conclusions : The definition in this paper are applicable , formalizing current practice. As such , they make a significant contribution to the usance of these concepts within biomedical ontologies. ", "label": 1}
{"original_text": "In this paper we present various distributed algorithms for LP-type problems in the well-known gossip model. LP-type problems include many important classes of problems such as (integer) linear programming, geometric problems like smallest enclosing ball and polytope distance, and set problems like hitting set and set cover. In the gossip model, a node can only push information to or pull information from nodes chosen uniformly at random. Protocols for the gossip model are usually very practical due to their fast convergence, their simplicity, and their stability under stress and disruptions. Our algorithms are very efficient (logarithmic rounds or better with just polylogarithmic communication work per node per round) whenever the combinatorial dimension of the given LP-type problem is constant, even if the size of the given LP-type problem is polynomially large in the number of nodes.", "text_perturb": "In this paper we present various distributed algorithms for LP-type problems in the well-known gossip modeling. LP-type problems include many important classes of problems such as ( integer ) linear programming , geometric problems like small enclosing ball and polytope distance , and set problems like hitting set and set cover. In the scuttlebutt model , a node can only push information to or pull information from nodes chosen uniformly at random. Protocols for the gab model are usually very practical due to their fast convergence , their simplicity , and their stability under stress and disruptions. Our algorithms are very efficient ( logarithmic rounds or better with just polylogarithmic communication work per node per round ) whenever the combinatorial dimension of the given LP-type problem live constant , even if the size of the given LP-type problem live polynomially large in the number of nodes. ", "label": 1}
{"original_text": "Automatic software plagiarism detection tools are widely used in educational settings to ensure that submitted work was not copied. These tools have grown in use together with the rise in enrollments in computer science programs and the widespread availability of code on-line. Educators rely on the robustness of plagiarism detection tools; the working assumption is that the effort required to evade detection is as high as that required to actually do the assigned work. This paper shows this is not the case. It presents an entirely automatic program transformation approach, Mossad, that defeats popular software plagiarism detection tools. Mossad comprises a framework that couples techniques inspired by genetic programming with domain-specific knowledge to effectively undermine plagiarism detectors. Mossad is effective at defeating four plagiarism detectors, including Moss (,) and JPlag (,). Mossad is both fast and effective: it can, in minutes, generate modified versions of programs that are likely to escape detection. More insidiously, because of its non-deterministic approach, Mossad can, from a single program, generate dozens of variants, which are classified as no more suspicious than legitimate assignments. A detailed study of Mossad across a corpus of real student assignments demonstrates its efficacy at evading detection. A user study shows that graduate student assistants consistently rate Mossad -generated code as just as readable as authentic student code. This work motivates the need for both research on more robust plagiarism detection tools and greater integration of naturally plagiarism-resistant methodologies like code review into computer science education.", "text_perturb": "Automatic software plagiarism detection tools are widely used in educational settings to ensure that submitted work was non copied. These tools have grown in use unitedly with the rise in enrollments in computer science programs and the widespread availability of code on-line. Educators rely on the robustness of plagiarism spotting tools ; the working assumption is that the effort required to evade spotting is as high as that required to actually do the assigned work. This paper shows this personify not the case. It presents an entirely automatic program transformation coming , Mossad , that defeats popular software plagiarism detection tools. Mossad comprises a framework that couples techniques barrack by genetic programming with domain-specific knowledge to effectively undermine plagiarism detectors. mossad is effective at defeating four plagiarism detectors , including Moss ( , ) and JPlag ( , ). Mossad be both fast and effective : it can , in minutes , generate modified versions of programs that are likely to escape detection. More insidiously , because of its non-deterministic approach , Mossad can , from a single program , father dozens of variants , which are classified as no more suspicious than legitimate assignments. A detailed study of Mossad across a corpus of real student assignments demonstrate its efficacy at evading detection. A user study shows that graduate student assistants consistently rate Mossad -generated code as just as clear as authentic student code. This work motivates the need for both research on more robust plagiarism detection tools and greater integration of naturally plagiarism-resistant methodologies like code review into computer science instruction. ", "label": 1}
{"original_text": "At the 2017 Artificial and Computational Intelligence in Games meeting at Dagstuhl, Julian Togelius asked how to make spaces where every way of filling in the details yielded a good game. This study examines the possibility of enriching search spaces so that they contain very high rates of interesting objects, specifically game elements. While we do not answer the full challenge of finding good games throughout the space, this study highlights a number of potential avenues. These include naturally rich spaces, a simple technique for modifying a representation to search only rich parts of a larger search space, and representations that are highly expressive and so exhibit highly restricted and consequently enriched search spaces.", "text_perturb": "At the 2017 Artificial and Computational Intelligence in Games meeting at Dagstuhl , Julian Togelius asked how to make spaces where every way of filling in the details concede a good game. This study examines the possibility of enrich search spaces so that they contain very high rates of interesting objects , specifically game elements. While we do non answer the full challenge of finding good games throughout the space , this study highlights a number of potential avenues. These include naturally rich spaces , a simple technique for modifying a representation to search only rich parts of a larger search space , and representations that are highly expressive and then exhibit highly restricted and consequently enriched search spaces. ", "label": 1}
{"original_text": "Regular decompositions are necessary for most superpixel-based object recognition or tracking applications. So far in the literature, the regularity or compactness of a superpixel shape is mainly measured by its circularity. In this work, we first demonstrate that such measure is not adapted for superpixel evaluation, since it does not directly express regularity but circular appearance. Then, we propose a new metric that considers several shape regularity aspects: convexity, balanced repartition, and contour smoothness. Finally, we demonstrate that our measure is robust to scale and noise and enables to more relevantly compare superpixel methods.", "text_perturb": "Regular decompositions are necessary for most superpixel-based object acknowledgement or tracking applications. So far in the lit , the regularity or compactness of a superpixel shape is mainly measured by its circularity. In this work , we first demonstrate that such measure cost not adapted for superpixel evaluation , since it does not directly express regularity but circular appearance. Then , we propose a new metric that considers several conformation regularity aspects : convexity , balanced repartition , and contour smoothness. Finally , we demonstrate that our measure is robust to surmount and noise and enables to more relevantly compare superpixel methods. ", "label": 1}
{"original_text": "A multiple-antenna amplify-and-forward two-hop interference network with multiple links and multiple relays is considered. We optimize transmit precoders, receive decoders and relay AF matrices to maximize the achievable sum rate. Under per user and total relay sum power constraints, we propose an efficient algorithm to maximize the total signal to total interference plus noise ratio (TSTINR). Computational complexity analysis shows that our proposed algorithm for TSTINR has lower complexity than the existing weighted minimum mean square error (WMMSE) algorithm. We analyze and confirm by simulations that the TSTINR, WMMSE and the total leakage interference plus noise (TLIN) minimization models with per user and total relay sum power constraints can only transmit a single data stream for each user. Thus we propose a novel multiple stream TSTINR model with requirement of orthogonal columns for precoders, in order to support multiple data streams and thus utilize higher Degrees of Freedom. Multiple data streams and larger multiplexing gains are guaranteed. Simulation results show that for single stream models, our TSTINR algorithm outperforms the TLIN algorithm generally and outperforms WMMSE in medium to high Signal-to-Noise-Ratio scenarios; the system sum rate significantly benefits from multiple data streams in medium to high SNR scenarios.", "text_perturb": "A multiple-antenna amplify-and-forward two-hop interference network with multiple nexus and multiple relays is considered. We optimize transmit precoders , receive decoders and relay AF matrices to maximize the achievable heart and soul rate. Under per user and total relay sum power constraints , we propose an effective algorithm to maximize the total signal to total interference plus noise ratio ( TSTINR ). Computational complexity analysis shows that our proposed algorithm for TSTINR has downhearted complexity than the existing weighted minimum mean square error ( WMMSE ) algorithm. We analyze and confirm by simulations that the TSTINR , WMMSE and the total leakage interference plus noise ( TLIN ) minimization models with per user and total relay sum power restraint can only transmit a single data stream for each user. Thus we propose a novel multiple stream TSTINR model with prerequisite of orthogonal columns for precoders , in order to support multiple data streams and thus utilize higher Degrees of Freedom. Multiple data watercourse and larger multiplexing gains are guaranteed. Simulation results show that for single stream models , our TSTINR algorithm outperforms the TLIN algorithm generally and outperforms WMMSE in medium to high Signal-to-Noise-Ratio scenarios ; the system sum rate importantly benefits from multiple data streams in medium to high SNR scenarios. ", "label": 1}
{"original_text": "A suitable state representation is a fundamental part of the learning process in Reinforcement Learning. In various tasks, the state can either be described by natural language or be natural language itself. This survey outlines the strategies used in the literature to build natural language state representations. We appeal for more linguistically interpretable and grounded representations, careful justification of design decisions and evaluation of the effectiveness of different approaches.", "text_perturb": "A suitable state representation equal a fundamental part of the learning process in Reinforcement Learning. In various tasks , the country can either be described by natural language or be natural language itself. This survey outlines the strategies used in the literature to build natural linguistic communication state representations. We appeal for more linguistically interpretable and grounded representations , careful justification of purpose decisions and evaluation of the effectiveness of different approaches. ", "label": 1}
{"original_text": "HDBSCAN, a state-of-the-art density-based hierarchical clustering method, produces a hierarchical organization of clusters in a dataset w.r.t. a parameter m p t s. While the performance of HDBSCAN is robust w.r.t. m p t s in the sense that a small change in m p t s typically leads to only a small or no change in the clustering structure, choosing a \"good\" m p t s value can be challenging: depending on the data distribution, a high or low value for m p t s may be more appropriate, and certain data clusters may reveal themselves at different values of m p t s. To explore results for a range of m p t s values, however, one has to run HDBSCAN for each value in the range independently, which is computationally inefficient. In this paper, we propose an efficient approach to compute all HDBSCAN hierarchies for a range of m p t s values by replacing the graph used by HDBSCAN with a much smaller graph that is guaranteed to contain the required information. An extensive experimental evaluation shows that with our approach one can obtain over one hundred hierarchies for the computational cost equivalent to running HDBSCAN about 2 times.", "text_perturb": "HDBSCAN , a state-of-the-art density-based hierarchical clustering method , produces a hierarchical establishment of clusters in a dataset w. radius. liothyronine. a argument m p t s. While the functioning of HDBSCAN is robust w. universal gas constant. thyroxin. m atomic number  t s in the sense that a small change in m atomic number  t s typically leads to only a small or no change in the clustering structure , choosing a `` good '' m atomic number  t s value can be challenging : depending on the data distribution , a high or low value for m atomic number  t s may be more appropriate , and certain data clusters may reveal themselves at different values of m atomic number  t s. To explore results for a image of m p t s values , however , one has to run HDBSCAN for each value in the image independently , which is computationally inefficient. In this paper , we propose an efficient approach to compute all HDBSCAN hierarchies for a range of m p t s values by replace the graph used by HDBSCAN with a much smaller graph that is guaranteed to contain the required information. An extensive experimental evaluation shows that with our glide slope one can obtain over one hundred hierarchies for the computational cost equivalent to running HDBSCAN about 2 times. ", "label": 1}
{"original_text": "In this paper, we consider the joint task of simultaneously optimizing (i) the weights of a deep neural network, (ii) the number of neurons for each hidden layer, and (iii) the subset of active input features (i.e., feature selection). While these problems are generally dealt with separately, we present a simple regularized formulation allowing to solve all three of them in parallel, using standard optimization routines. Specifically, we extend the group Lasso penalty (originated in the linear regression literature) in order to impose group-level sparsity on the network's connections, where each group is defined as the set of outgoing weights from a unit. Depending on the specific case, the weights can be related to an input variable, to a hidden neuron, or to a bias unit, thus performing simultaneously all the aforementioned tasks in order to obtain a compact network. We perform an extensive experimental evaluation, by comparing with classical weight decay and Lasso penalties. We show that a sparse version of the group Lasso penalty is able to achieve competitive performances, while at the same time resulting in extremely compact networks with a smaller number of input features. We evaluate both on a toy dataset for handwritten digit recognition, and on multiple realistic large-scale classification problems.", "text_perturb": "In this paper , we consider the joint task of at the same time optimizing ( i ) the weights of a deep neural network , ( ii ) the number of neurons for each hidden layer , and ( iii ) the subset of active input features ( i. vitamin e. , feature option ). While these problems are generally dealt with separately , we present a simple regularized preparation allowing to solve all three of them in parallel , using standard optimization routines. Specifically , we extend the group Lasso penalty ( originated in the linear regression literature ) in order to impose group-level sparsity on the network 's connections , where each group is defined as the set of outgoing weight unit from a unit. Depending on the specific subject , the weights can be related to an input variable , to a hidden neuron , or to a bias unit , thus performing simultaneously all the aforementioned tasks in order to obtain a compact network. We perform an extensive experimental evaluation , by comparing with greco roman weight decay and Lasso penalties. We show that a sparse version of the group Lasso penalty is able to accomplish competitive performances , while at the same time resulting in extremely compact networks with a smaller number of input features. We evaluate both on a toy dataset for handwritten digit recognition , and on multiple naturalistic large-scale classification problems. ", "label": 1}
{"original_text": "Information propagation is a hard task where the goal is to predict users behavior. We introduce an extension of a model which make use of a kernel to modelize diffusion in a latent space. This extension introduce a threhsold to differentiate if users are contaminated or not.", "text_perturb": "Information propagation constitute a hard task where the goal constitute to predict users behavior. We introduce an extension of a model which make use of a kernel to modelize diffusion in a latent distance. This extension introduce a threhsold to differentiate if users are pollute or not. ", "label": 1}
{"original_text": "Cooperators that refuse to participate in sanctioning defectors create the second-order free-rider problem. Such cooperators will not be punished because they contribute to the public good, but they also eschew the costs associated with punishing defectors. Altruistic punishers - those that cooperate and punish - are at a disadvantage, and it is puzzling how such behaviour has evolved. We show that sharing the responsibility to sanction defectors rather than relying on certain individuals to do so permanently can solve the problem of costly punishment. Inspired by the fact that humans have strong but also emotional tendencies for fair play, we consider probabilistic sanctioning as the simplest way of distributing the duty. In well-mixed populations the public goods game is transformed into a coordination game with full cooperation and defection as the two stable equilibria, while in structured populations pattern formation supports additional counterintuitive solutions that are reminiscent of Parrondo's paradox.", "text_perturb": "Cooperators that refuse to participate in sanctioning defectors create the second-order free-rider job. Such cooperators will not be punished because they kick in to the public good , but they also eschew the costs associated with punishing defectors. Altruistic punishers - those that cooperate and punish - are at a disadvantage , and it is puzzling how such behaviour experience evolved. We show that sharing the responsibility to sanction defector rather than relying on certain individuals to do so permanently can solve the problem of costly punishment. Inspired by the fact that humans have strong but also emotional tendencies for just play , we consider probabilistic sanctioning as the simplest way of distributing the duty. In well-mixed populations the public goods biz is transformed into a coordination biz with full cooperation and defection as the two stable equilibria , while in structured populations pattern formation supports additional counterintuitive solutions that are reminiscent of Parrondo 's paradox. ", "label": 1}
{"original_text": "All the content consumed by mobile users, be it a web page or a live stream, undergoes some processing along the way; as an example, web pages and videos are transcoded to fit each device's screen. The recent multi-access edge computing (MEC) paradigm envisions performing such processing within the cellular network, as opposed to resorting to a cloud server on the Internet. Designing a MEC network, i.e., placing and dimensioning the computational facilities therein, requires information on how much computational power is required to produce the contents needed by the users. However, real-world demand traces only contain information on how much data is downloaded. In this paper, we demonstrate how to enrich demand traces with information about the computational power needed to process the different types of content, and we show the substantial benefit that can be obtained from using such enriched traces for the design of MEC-based networks.", "text_perturb": "All the content consumed by mobile users , be it a web page or a live stream , undergoes some processing along the path ; as an example , web pages and videos are transcoded to fit each device 's screen. The late multi-access edge computing ( MEC ) paradigm envisions performing such processing within the cellular network , as opposed to resorting to a cloud server on the Internet. design a MEC network , i. due east. , placing and dimensioning the computational facilities therein , necessitate information on how much computational power is required to produce the contents needed by the users. However , real-world demand traces only contain information on how much data is download. In this paper , we demonstrate how to enrich demand traces with information about the computational power needed to process the dissimilar types of content , and we show the substantial benefit that can be obtained from using such enriched traces for the design of MEC-based networks. ", "label": 1}
{"original_text": "Consider the estimation of a signal x R N from noisy observations r x z, where the input x is generated by an independent and identically distributed (i.i.d.) Gaussian mixture source, and z is additive white Gaussian noise (AWGN) in parallel Gaussian channels. Typically, the l 2 -norm error (squared error) is used to quantify the performance of the estimation process. In contrast, we consider the l -norm error (worst case error). For this error metric, we prove that, in an asymptotic setting where the signal dimension - N , the l -norm error always comes from the Gaussian component that has the largest variance, and the Wiener filter asymptotically achieves the optimal expected l -norm error. The i.i.d. Gaussian mixture case is easily applicable to i.i.d. Bernoulli-Gaussian distributions, which are often used to model sparse signals. Finally, our results can be extended to linear mixing systems with i.i.d. Gaussian mixture inputs, in settings where a linear mixing system can be decoupled to parallel Gaussian channels.", "text_perturb": "Consider the estimation of a signal ex R N from noisy observations r ex z , where the input ex is generated by an independent and identically distributed ( i. single. viosterol. ) gaussian mixture source , and z is additive white gaussian noise ( AWGN ) in parallel gaussian channels. Typically , the l 2 -norm error ( squared error ) is used to measure the performance of the estimation process. In contrast , we consider the cubic decimetre -norm error ( worst case error ). For this error metric , we prove that , in an asymptotic setting where the signal dimension - N , the litre -norm error always comes from the Gaussian component that has the largest variance , and the Wiener filter asymptotically achieves the optimal expected litre -norm error. The unity. iodine. viosterol. Gaussian mixture case is easily applicable to i. iodin. ergocalciferol. Bernoulli-Gaussian distributions , which are often used to model thin signals. Finally , our results can be extended to linear fuse systems with i. ace. five hundred. Gaussian mixture inputs , in settings where a linear mixing system can be uncouple to parallel Gaussian channels. ", "label": 1}
{"original_text": "Recurrent Neural Networks (RNNs) are powerful tools for solving sequence-based problems, but their efficacy and execution time are dependent on the size of the network. Following recent work in simplifying these networks with model pruning and a novel mapping of work onto GPUs, we design an efficient implementation for sparse RNNs. We investigate several optimizations and tradeoffs: Lamport timestamps, wide memory loads, and a bank-aware weight layout. With these optimizations, we achieve speedups of over 6 x over the next best algorithm for a hidden layer of size 2304, batch size of 4, and a density of 30. Further, our technique allows for models of over 5 x the size to fit on a GPU for a speedup of 2 x, enabling larger networks to help advance the state-of-the-art. We perform case studies on NMT and speech recognition tasks in the appendix, accelerating their recurrent layers by up to 3 x.", "text_perturb": "Recurrent Neural Networks ( RNNs ) are powerful tools for lick sequence-based problems , but their efficacy and execution time are dependent on the size of the network. Following recent work in simplifying these networks with model pruning and a new mapping of work onto GPUs , we design an efficient implementation for sparse RNNs. We investigate respective optimizations and tradeoffs : Lamport timestamps , wide memory loads , and a bank-aware weight layout. With these optimizations , we achieve speedups of over 6 x over the next best algorithm for a secret layer of size 2304 , batch size of 4 , and a density of 30. Further , our technique let for models of over 5 x the size to fit on a GPU for a speedup of 2 x , enabling larger networks to help advance the state-of-the-art. We perform case studies on NMT and speech recognition tasks in the appendix , accelerating their recurrent layer by up to 3 x. ", "label": 1}
{"original_text": "In this note we revisit a \"ring of graphs\" Q in which the set of finite simple graphs N extend the role of the natural numbers N and the signed graphs Z extend the role of the integers Z. We point out the existence of a norm which allows to complete Q to a real or complex Banach algebra R or C.", "text_perturb": "In this note we revisit a `` ring of graphs '' Q in which the set of finite simple graphs N extend the role of the natural numbers N and the signed graphs Z extend the role of the whole number Z. We point out the existence of a average which allows to complete Q to a real or complex Banach algebra R or C. ", "label": 1}
{"original_text": "Many computer vision applications involve modeling complex spatio-temporal patterns in high-dimensional motion data. Recently, restricted Boltzmann machines (RBMs) have been widely used to capture and represent spatial patterns in a single image or temporal patterns in several time slices. To model global dynamics and local spatial interactions, we propose to theoretically extend the conventional RBMs by introducing another term in the energy function to explicitly model the local spatial interactions in the input data. A learning method is then proposed to perform efficient learning for the proposed model. We further introduce a new method for multi-class classification that can effectively estimate the infeasible partition functions of different RBMs such that RBM is treated as a generative model for classification purpose. The improved RBM model is evaluated on two computer vision applications: facial expression recognition and human action recognition. Experimental results on benchmark databases demonstrate the effectiveness of the proposed algorithm.", "text_perturb": "Many computer visual modality applications involve modeling complex spatio-temporal patterns in high-dimensional motion data. Recently , restricted Boltzmann motorcar ( RBMs ) have been widely used to capture and represent spatial patterns in a single image or temporal patterns in several time slices. To model global dynamics and local spacial interactions , we propose to theoretically extend the conventional RBMs by introducing another term in the energy function to explicitly model the local spacial interactions in the input data. A learning method is then proposed to perform efficient learning for the proposed poser. We further introduce a new method for multi-class classification that can effectively estimate the infeasible partition functions of different RBMs such that RBM is treated as a reproductive model for classification purpose. The improved RBM model is evaluated on two computer vision applications : facial manifestation recognition and human action recognition. data based results on benchmark databases demonstrate the effectiveness of the proposed algorithm. ", "label": 1}
{"original_text": "Co-occurrence Data is a common and important information source in many areas, such as the word co-occurrence in the sentences, friends co-occurrence in social networks and products co-occurrence in commercial transaction data, etc, which contains rich correlation and clustering information about the items. In this paper, we study co-occurrence data using a general energy-based probabilistic model, and we analyze three different categories of energy-based model, namely, the L 1, L 2 and L k models, which are able to capture different levels of dependency in the co-occurrence data. We also discuss how several typical existing models are related to these three types of energy models, including the Fully Visible Boltzmann Machine (FVBM) (L 2), Matrix Factorization (L 2), Log-BiLinear (LBL) models (L 2), and the Restricted Boltzmann Machine (RBM) model (L k). Then, we propose a Deep Embedding Model (DEM) (an L k model) from the energy model in a principled manner. Furthermore, motivated by the observation that the partition function in the energy model is intractable and the fact that the major objective of modeling the co-occurrence data is to predict using the conditional probability, we apply the maximum pseudo-likelihood method to learn DEM. In consequence, the developed model and its learning method naturally avoid the above difficulties and can be easily used to compute the conditional probability in prediction. Interestingly, our method is equivalent to learning a special structured deep neural network using back-propagation and a special sampling strategy, which makes it scalable on large-scale datasets. Finally, in the experiments, we show that the DEM can achieve comparable or better results than state-of-the-art methods on datasets across several application domains.", "text_perturb": "Co-occurrence Data is a common and important information source in many areas , such as the word co-occurrence in the sentences , friends co-occurrence in social networks and cartesian product co-occurrence in commercial transaction data , etc , which contains rich correlation and clustering information about the items. In this paper , we study co-occurrence data using a general energy-based probabilistic model , and we analyze three different categories of energy-based model , namely , the L 1 , L 2 and L k models , which are able to capture different storey of dependency in the co-occurrence data. We also discuss how several typical existing models are related to these three types of energy models , including the Fully Visible Boltzmann automobile ( FVBM ) ( L 2 ) , Matrix Factorization ( L 2 ) , Log-BiLinear ( LBL ) models ( L 2 ) , and the Restricted Boltzmann automobile ( RBM ) model ( L k ). Then , we propose a Deep Embedding Model ( DEM ) ( an L k model ) from the energy model in a principled fashion. Furthermore , motivated by the observation that the partition function in the energy framework is intractable and the fact that the major objective of modeling the co-occurrence data is to predict using the conditional probability , we apply the maximum pseudo-likelihood method to learn DEM. In consequence , the developed model and its learning method naturally avoid the above difficulties and can be easily used to compute the conditional chance in prediction. Interestingly , our method is equivalent to learning a special structured deep neural network using back-propagation and a special sampling strategy , which induce it scalable on large-scale datasets. Finally , in the experiments , we show that the DEM can achieve comparable or better results than state of the art methods on datasets across several application domains. ", "label": 1}
{"original_text": "We report the 'Recurrent Deterioration' (RD) phenomenon observed in online recommender systems. The RD phenomenon is reflected by the trend of performance degradation when the recommendation model is always trained based on users' feedbacks of the previous recommendations. There are several reasons for the recommender systems to encounter the RD phenomenon, including the lack of negative training data and the evolution of users' interests, etc. Motivated to tackle the problems causing the RD phenomenon, we propose the POMDP-Rec framework, which is a neural-optimized Partially Observable Markov Decision Process algorithm for recommender systems. We show that the POMDP-Rec framework effectively uses the accumulated historical data from real-world recommender systems and automatically achieves comparable results with those models fine-tuned exhaustively by domain exports on public datasets.", "text_perturb": "We describe the 'Recurrent Deterioration ' ( RD ) phenomenon observed in online recommender systems. The RD phenomenon is reflected by the trend of performance degradation when the recommendation mannequin is always trained based on users ' feedbacks of the previous recommendations. There are several reasons for the recommender systems to encounter the RD phenomenon , including the lack of negative training data and the evolution of exploiter ' interests , etc. Motivated to tackle the trouble causing the RD phenomenon , we propose the POMDP-Rec framework , which is a neural-optimized Partially Observable Markov Decision Process algorithm for recommender systems. We show that the POMDP-Rec framework effectively uses the accumulated historical data from real-world recommender systems and automatically achieves comparable results with those mannequin fine-tuned exhaustively by domain exports on public datasets. ", "label": 1}
{"original_text": "We consider an extension of the massive unsourced random access originally proposed in to the case where the receiver has a very large number of antennas (a massive MIMO base station) and no channel state information is given to the receiver (fully non-coherent detection). Our coding approach borrows the concatenated coding idea from, combined with a novel non-Bayesian \"activity detection\" algorithm for massive MIMO random access channels, that outperforms currently proposed Bayesian vector AMP (VAMP) schemes currently proposed for activity detection, and does not suffer from the numerical instabilities and requirement for accurate a priori statistics as VAMP. We show that the required transmit E b N 0 for reliable communication can be made arbitrarily small as the number of receiver antennas M grows sufficiently large.", "text_perturb": "We consider an extension of the massive unsourced random access originally proposed in to the cause where the receiver has a very large number of antennas ( a massive MIMO base station ) and no channel state information is given to the receiver ( fully non-coherent detection ). Our coding approach borrows the concatenated coding idea from , combined with a novel non-Bayesian `` activity spying '' algorithm for massive MIMO random access channels , that outperforms currently proposed Bayesian vector AMP ( VAMP ) schemes currently proposed for activity spying , and does not suffer from the numerical instabilities and requirement for accurate a priori statistics as VAMP. We show that the required transmit E b N 0 for reliable communication can embody made arbitrarily small as the number of receiver antennas M grows sufficiently large. ", "label": 1}
{"original_text": "The primary obstacle to developing technologies for low-resource languages is the lack of usable data. In this paper, we report the adoption and deployment of 4 technology-driven methods of data collection for Gondi, a low-resource vulnerable language spoken by around 2.3 million tribal people in south and central India. In the process of data collection, we also help in its revival by expanding access to information in Gondi through the creation of linguistic resources that can be used by the community, such as a dictionary, children's stories, an app with Gondi content from multiple sources and an Interactive Voice Response (IVR) based mass awareness platform. At the end of these interventions, we collected a little less than 12,000 translated words andor sentences and identified more than 650 community members whose help can be solicited for future translation efforts. The larger goal of the project is collecting enough data in Gondi to build and deploy viable language technologies like machine translation and speech to text systems that can help take the language onto the internet. Keywords Low-Resource Languages, Deployment, Applications", "text_perturb": "The primary obstacle to developing technologies for low-resource languages constitute the lack of usable data. In this paper , we report the adoption and deployment of 4 technology-driven methods of data ingathering for Gondi , a low-resource vulnerable language spoken by around 2. 3 million tribal people in south and cardinal India. In the process of data assemblage , we also help in its revival by expanding access to information in Gondi through the creation of linguistic resources that can be used by the community , such as a dictionary , children 's stories , an app with Gondi content from multiple sources and an Interactive Voice Response ( IVR ) based mass awareness platform. At the end of these interventions , we collected a little less than 12,000 translated words andor sentences and identify more than 650 community members whose help can be solicited for future translation efforts. The larger goal of the project is collecting decent data in Gondi to build and deploy viable language technologies like machine translation and speech to text systems that can help take the language onto the internet. Keywords Low-Resource Languages , deployment , Applications", "label": 1}
{"original_text": "Nonzero-sum stochastic differential games with impulse controls offer a realistic and far-reaching modelling framework for applications within finance, energy markets, and other areas, but the difficulty in solving such problems has hindered their proliferation. Semi-analytical approaches make strong assumptions pertaining to very particular cases. To the author's best knowledge, the only numerical method in the literature is the heuristic one we put forward in to solve an underlying system of quasi-variational inequalities. Focusing on symmetric games, this paper presents a simpler, more precise and efficient fixed-point policy-iteration-type algorithm which removes the strong dependence on the initial guess and the relaxation scheme of the previous method. A rigorous convergence analysis is undertaken with natural assumptions on the players strategies, which admit graph-theoretic interpretations in the context of weakly chained diagonally dominant matrices. A novel provably convergent single-player impulse control solver is also provided. The main algorithm is used to compute with high precision equilibrium payoffs and Nash equilibria of otherwise very challenging problems, and even some which go beyond the scope of the currently available theory.", "text_perturb": "Nonzero-sum stochastic differential games with impulse controls offer a realistic and far-reaching modelling model for applications within finance , energy markets , and other areas , but the difficulty in solving such problems has hindered their proliferation. Semi-analytical approaches make strong presumption pertaining to very particular cases. To the author 's best knowledge , the only numerical method in the literature is the heuristic one we position forward in to solve an underlying system of quasi-variational inequalities. Focusing on symmetric games , this paper presents a simpler , more precise and efficient fixed-point policy-iteration-type algorithmic rule which removes the strong dependence on the initial guess and the relaxation scheme of the previous method. A rigorous convergence analysis is undertaken with natural assumptions on the players strategies , which admit graph-theoretic interpretations in the context of weakly chain diagonally dominant matrices. A novel provably convergent single-player impulse control convergent thinker is also provided. The main algorithm is used to compute with high precision equilibrium payoffs and Nash equilibria of otherwise rattling challenging problems , and even some which go beyond the scope of the currently available theory. ", "label": 1}
{"original_text": "Automatic charge prediction aims to predict appropriate final charges according to the fact descriptions for a given criminal case. Automatic charge prediction plays a critical role in assisting judges and lawyers to improve the efficiency of legal decisions, and thus has received much attention. Nevertheless, most existing works on automatic charge prediction perform adequately on high-frequency charges but are not yet capable of predicting few-shot charges with limited cases. In this paper, we propose a S equence E nhanced Caps ule model, dubbed as SECaps model, to relieve this problem. Specifically, following the work of capsule networks, we propose the seq-caps layer, which considers sequence information and spatial information of legal texts simultaneously. Then we design a attention residual unit, which provides auxiliary information for charge prediction. In addition, our SECaps model introduces focal loss, which relieves the problem of imbalanced charges. Comparing the state-of-the-art methods, our SECaps model obtains 4.5 and 6.4 absolutely considerable improvements under Macro F1 in Criminal-S and Criminal-L respectively. The experimental results consistently demonstrate the superiorities and competitiveness of our proposed model.", "text_perturb": "robotlike charge prediction aims to predict appropriate final charges according to the fact descriptions for a given criminal case. Automatic charge prediction plays a critical purpose in assisting judges and lawyers to improve the efficiency of legal decisions , and thus has received much attention. Nevertheless , most existing works on automatic charge prediction perform adequately on high-frequency charges but are not yet capable of predict few-shot charges with limited cases. In this paper , we propose a S equence E nhanced Caps ule good example , dubbed as SECaps good example , to relieve this problem. Specifically , play along the work of capsule networks , we propose the seq-caps layer , which considers sequence information and spatial information of legal texts simultaneously. Then we design a attention residual unit , which provides subsidiary information for charge prediction. In addition , our SECaps model introduces focal personnel casualty , which relieves the problem of imbalanced charges. Comparing the state-of-the-art methods , our SECaps modeling obtains 4. 5 and 6. 4 absolutely considerable improvements under Macro F1 in Criminal-S and Criminal-L severally. The experimental results systematically demonstrate the superiorities and competitiveness of our proposed model. ", "label": 1}
{"original_text": "Co-simulation consists of the theory and techniques to enable globalsimulation of a coupled system via the composition of simulators. Despite thelarge number of applications and growing interest in the challenges, the fieldremains fragmented into multiple application domains, with limited sharing ofknowledge. This tutorial aims at introducing co-simulation of continuous systems,targeted at researchers new to the field.", "text_perturb": "Co-simulation consists of the theory and proficiency to enable globalsimulation of a coupled system via the composition of simulators. Despite thelarge number of applications and growing interest in the challenges , the fieldremains fragmentize into multiple application domains , with limited sharing ofknowledge. This tutorial aims at introducing co-simulation of continuous systems , targeted at researchers fresh to the field. ", "label": 1}
{"original_text": "Overlapped community detection in social networks has become an important research area with the increasing popularity and complexity of the networks. Most of the existing solutions are either centralized or parallel algorithms, which are computationally intensive - require complete knowledge of the entire networks. But it isn't easy to collect entire network data because the size of the actual networks may be prohibitively large. This may be a result of either privacy concerns (users of a social network may be unwilling to reveal their social links) or technological impediments (implementation of an efficient web crawler). Performing in-network computation solves both problems utilizing the computational capability of the individual nodes of the network. Simultaneously, nodes communicate and share data with their neighbours via message passing, which may go a long way toward mitigating individual nodes' privacy concerns in the network. All the aforementioned concerns motivated us to design a decentralized or distributed technique to detect overlapped communities in a large-scale network. It is desirable because this technique does not offer a single point of failure, and the system as a whole can continue to function even when many of the nodes fail. To overcome the disadvantages of the existing solutions, in this paper, we address the overlapped community detection problem for large-scale networks. We present an efficient distributed algorithm, named DOCD, to identify the overlapped communities in the network. The efficiency of DOCD algorithm is verified with extensive simulation study on both synthetic and real networks data such as, Dolphin, Zachary karate club, Football club, and Facebook ego networks. We show that DOCD algorithm is capable of keeping the asymptotically same results with the existing classical centralized algorithms in terms of community modularity and the number of identified communities. The DOCD algorithm can also efficiently identify the overlapped nodes and overlapped communities with a small number of rounds of communication and computation.", "text_perturb": "Overlapped biotic community detection in social networks has become an important research area with the increasing popularity and complexity of the networks. Most of the existing solutions are either centralized or parallel algorithms , which are computationally intensive - require complete cognition of the entire networks. But it is n't easy to collect entire mesh data because the size of the actual networks may be prohibitively large. This may be a result of either privacy concerns ( users of a social network may be unwilling to reveal their social links ) or technological hindrance ( implementation of an efficient web crawler ). Performing in-network computation solves both problems utilizing the computational capability of the individual guest of the network. Simultaneously , nodes communicate and share data with their neighbours via message passing , which may go a long way toward mitigating case by case nodes ' privacy concerns in the network. All the aforementioned concerns motivated us to design a decentralized or distributed technique to notice overlapped communities in a large-scale network. It is desirable because this technique does not offer a unmarried point of failure , and the system as a whole can continue to function even when many of the nodes fail. To overcome the disadvantages of the existing solutions , in this paper , we address the overlapped community detection problem for large-scale mesh. We salute an efficient distributed algorithm , named DOCD , to identify the overlapped communities in the network. The efficiency of DOCD algorithm is verified with extensive simulation study on both synthetic and real network data such as , Dolphin , Zachary karate club , Football club , and Facebook ego network. We show that DOCD algorithmic program is capable of keeping the asymptotically same results with the existing classical centralized algorithms in terms of community modularity and the number of identified communities. The DOCD algorithmic program can also efficiently identify the overlapped nodes and overlapped communities with a small number of rounds of communication and computation. ", "label": 1}
{"original_text": "The aim of this paper is to facilitate nuanced discussion around research norms and practices to mitigate the harmful impacts of advances in machine learning (ML). We focus particularly on the use of ML to create \"synthetic media\" (e.g. to generate or manipulate audio, video, images, and text), and the question of what publication and release processes around such research might look like, though many of the considerations discussed will apply to ML research more broadly. We are not arguing for any specific approach on when or how research should be distributed, but instead try to lay out some useful tools, analogies, and options for thinking about these issues. We begin with some background on the idea that ML research might be misused in harmful ways, and why advances in synthetic media, in particular, are raising concerns. We then outline in more detail some of the different paths to harm from ML research, before reviewing research risk mitigation strategies in other fields and identifying components that seem most worth emulating in the ML and synthetic media research communities. Next, we outline some important dimensions of disagreement on these issues which risk polarizing conversations. Finally, we conclude with recommendations, suggesting that the machine learning community might benefit from: working with subject matter experts to increase understanding of the risk landscape and possible mitigation strategies; building a community and norms around understanding the impacts of ML research, e.g. through regular workshops at major conferences; and establishing institutions and systems to support release practices that would otherwise be onerous and error-prone.", "text_perturb": "The aim of this paper is to facilitate nuanced give and take around research norms and practices to mitigate the harmful impacts of advances in machine learning ( ML ). We concentre particularly on the use of ML to create `` synthetic media '' ( e. m. to generate or manipulate audio , video , images , and text ) , and the question of what publication and release processes around such inquiry might look like , though many of the considerations discussed will apply to ML inquiry more broadly. We are not arguing for any specific approach on when or how research should be stagger , but instead try to lay out some useful tools , analogies , and options for thinking about these issues. We begin with some background on the idea that ML research might be misused in harmful ways , and why advances in synthetic media , in particular , are evoke concerns. We then outline in more detail some of the different paths to harm from milliliter research , before reviewing research risk mitigation strategies in other fields and identifying components that seem most worth emulating in the milliliter and synthetic media research communities. Next , we outline some important dimensions of dissension on these issues which risk polarizing conversations. Finally , we conclude with recommendations , suggesting that the machine learning community might benefit from : working with subject issue experts to increase understanding of the risk landscape and possible mitigation strategies ; building a community and norms around understanding the impacts of ML research , e. k. through regular workshops at major conferences ; and establishing institutions and systems to support release practices that would otherwise be burdensome and error-prone. ", "label": 1}
{"original_text": "The Dubins Traveling Salesman Problem (DTSP) has generated significant interest over the last decade due to its occurrence in several civil and military surveillance applications. Currently, there is no algorithm that can find an optimal solution to the problem. In addition, relaxing the motion constraints and solving the resulting Euclidean TSP (ETSP) provides the only lower bound available for the problem. However, in many problem instances, the lower bound computed by solving the ETSP is far below the cost of the feasible solutions obtained by some well-known algorithms for the DTSP. This article addresses this fundamental issue and presents the first systematic procedure for developing tight lower bounds for the DTSP.", "text_perturb": "The Dubins Traveling Salesman trouble ( DTSP ) has generated significant interest over the last decade due to its occurrence in several civil and military surveillance applications. Currently , there is no algorithm that give notice find an optimal solution to the problem. In addition , relaxing the motion constraints and solving the result Euclidean TSP ( ETSP ) provides the only lower bound available for the problem. However , in many problem instances , the lower bound computed by solving the ETSP is far below the cost of the feasible solutions obtained by some well-known algorithmic rule for the DTSP. This clause addresses this fundamental issue and presents the first systematic procedure for developing tight lower bounds for the DTSP. ", "label": 1}
{"original_text": "Music recommender systems (MRS) have experienced a boom in recent years, thanks to the emergence and success of online streaming services, which nowadays make available almost all music in the world at the user's fingertip. While today's MRS considerably help users to find interesting music in these huge catalogs, MRS research is still facing substantial challenges. In particular when it comes to build, incorporate, and evaluate recommendation strategies that integrate information beyond simple user-item interactions or content-based descriptors, but dig deep into the very essence of listener needs, preferences, and intentions, MRS research becomes a big endeavor and related publications quite sparse. The purpose of this trends and survey article is twofold. We first identify and shed light on what we believe are the most pressing challenges MRS research is facing, from both academic and industry perspectives. We review the state of the art towards solving these challenges and discuss its limitations. Second, we detail possible future directions and visions we contemplate for the further evolution of the field. The article should therefore serve two purposes: giving the interested reader an overview of current challenges in MRS research and providing guidance for young researchers by identifying interesting, yet under-researched, directions in the field.", "text_perturb": "Music recommender systems ( MRS ) have experienced a boom in recent years , thanks to the emergence and success of online streaming services , which nowadays make available almost all music in the world at the exploiter 's fingertip. While today 's MRS considerably help users to find interesting euphony in these huge catalogs , MRS research is still facing substantial challenges. In particular when it comes to build , incorporate , and evaluate recommendation strategies that integrate information beyond elementary user-item interactions or content-based descriptors , but dig deep into the very essence of listener needs , preferences , and intentions , MRS research becomes a big endeavor and related publications quite sparse. The purpose of this trends and sight article is twofold. We first identify and shed light on what we believe are the most pressing challenges mrs research is facing , from both academic and industry perspectives. We review the state of the art towards solving these challenge and discuss its limitations. Second , we detail possible future directions and visions we excogitate for the further evolution of the field. The article should therefore serve two purposes : giving the interested reader an overview of current challenges in MRS research and providing guidance for young researchers by identifying interesting , yet under-researched , directions in the champaign. ", "label": 1}
{"original_text": "There are many scenarios in which inferring the type of a client browser is desirable, for instance to fight against session stealing. This is known as browser fingerprinting. This paper presents and evaluates a novel fingerprinting technique to determine the exact nature (browser type and version, eg Firefox 15) of a web-browser, exploiting HTML parser quirks exercised through XSS. Our experiments show that the exact version of a web browser can be determined with 71 of accuracy, and that only 6 tests are sufficient to quickly determine the exact family a web browser belongs to.", "text_perturb": "There are many scenarios in which inferring the type of a client browser follow desirable , for instance to fight against session stealing. This cost known as browser fingerprinting. This paper present and evaluates a novel fingerprinting technique to determine the exact nature ( browser type and version , eg Firefox 15 ) of a web-browser , exploiting HTML parser quirks exercised through XSS. Our experiments show that the exact version of a web browser can be fix with 71 of accuracy , and that only 6 tests are sufficient to quickly determine the exact family a web browser belongs to. ", "label": 1}
{"original_text": "We introduce a new category of higher-dimensional automata in which the morphisms are functional homotopy simulations, i.e. functional simulations up to concurrency of independent events. For this, we use unfoldings of higher-dimensional automata into higher-dimensional trees. Using a notion of open maps in this category, we define homotopy bisimilarity. We show that homotopy bisimilarity is equivalent to a straight-forward generalization of standard bisimilarity to higher dimensions, and that it is finer than split bisimilarity and incomparable with history-preserving bisimilarity.", "text_perturb": "We introduce a new category of higher-dimensional automata in which the morphisms embody functional homotopy simulations , i. es. functional simulations up to concurrency of sovereign events. For this , we use unfolding of higher-dimensional automata into higher-dimensional trees. Using a notion of open maps in this class , we define homotopy bisimilarity. We show that homotopy bisimilarity embody equivalent to a straight-forward generalization of standard bisimilarity to higher dimensions , and that it embody finer than split bisimilarity and incomparable with history-preserving bisimilarity. ", "label": 1}
{"original_text": "Modern pattern recognition methods are based on convolutional networks since they are able to learn complex patterns that benefit the classification. However, convolutional networks are computationally expensive and require a considerable amount of memory, which limits their deployment on low-power and resource-constrained systems. To handle these problems, recent approaches have proposed pruning strategies that find and remove unimportant neurons (i.e., filters) in these networks. Despite achieving remarkable results, existing pruning approaches are ineffective since the accuracy of the original network is degraded. In this work, we propose a novel approach to efficiently remove filters from convolutional networks. Our approach estimates the filter importance based on its relationship with the class label on a low-dimensional space. This relationship is computed using Partial Least Squares (PLS) and Variable Importance in Projection (VIP). Our method is able to reduce up to 67 of the floating point operations (FLOPs) without penalizing the network accuracy. With a negligible drop in accuracy, we can reduce up to 90 of FLOPs. Additionally, sometimes the method is even able to improve the accuracy compared to original, unpruned, network. We show that employing PLSVIP as the criterion for detecting the filters to be removed is better than recent feature selection techniques, which have been employed by state-of-the-art pruning methods. Finally, we show that the proposed method achieves the highest FLOPs reduction and the smallest drop in accuracy when compared to state-of-the-art pruning approaches. Codes are available at:", "text_perturb": "Modern pattern recognition methods personify based on convolutional networks since they personify able to learn complex patterns that benefit the classification. However , convolutional networks embody computationally expensive and require a considerable amount of memory , which limits their deployment on low-power and resource-constrained systems. To cover these problems , recent approaches have proposed pruning strategies that find and remove unimportant neurons ( i. east. , filter ) in these networks. Despite attain remarkable results , existing pruning approaches are ineffective since the accuracy of the original network is degraded. In this work , we aim a novel approach to efficiently remove filters from convolutional networks. Our approach calculate the filter importance based on its relationship with the class label on a low-dimensional space. This relationship is computed using Partial least Squares ( PLS ) and Variable Importance in Projection ( VIP ). Our method is able to reduce up to 67 of the floating point surgical operation ( FLOPs ) without penalizing the network accuracy. With a negligible drop in truth , we can reduce up to 90 of FLOPs. Additionally , sometimes the method is even able to improve the truth compared to original , unpruned , network. We show that employing PLSVIP as the criterion for detecting the filters to be removed is intimately than recent feature selection techniques , which have been employed by state-of-the-art pruning methods. Finally , we show that the nominate method achieves the highest FLOPs reduction and the smallest drop in accuracy when compared to state-of-the-art pruning approaches. Codes are usable at :", "label": 1}
{"original_text": "We present a novel deep learning based algorithm for video inpainting. Video inpainting is a process of completing corrupted or missing regions in videos. Video inpainting has additional challenges compared to image inpainting due to the extra temporal information as well as the need for maintaining the temporal coherency. We propose a novel DNN-based framework called the Copy-and-Paste Networks for video inpainting that takes advantage of additional information in other frames of the video. The network is trained to copy corresponding contents in reference frames and paste them to fill the holes in the target frame. Our network also includes an alignment network that computes affine matrices between frames for the alignment, enabling the network to take information from more distant frames for robustness. Our method produces visually pleasing and temporally coherent results while running faster than the state-of-the-art optimization-based method. In addition, we extend our framework for enhancing overunder exposed frames in videos. Using this enhancement technique, we were able to significantly improve the lane detection accuracy on road videos.", "text_perturb": "We present a novel deep encyclopedism based algorithm for video inpainting. Video inpainting is a process of completing sully or missing regions in videos. Video inpainting has additional challenges compared to image inpainting due to the extra temporal information as well as the motive for maintaining the temporal coherency. We propose a fresh DNN-based framework called the Copy-and-Paste Networks for video inpainting that takes advantage of additional information in other frames of the video. The network is trained to copy corresponding contents in reference frames and paste them to fill the muddle in the target frame. Our network also includes an alignment network that figure affine matrices between frames for the alignment , enabling the network to take information from more distant frames for robustness. Our method produces visually pleasing and temporally consistent results while running faster than the state-of-the-art optimization-based method. In accession , we extend our framework for enhancing overunder exposed frames in videos. use this enhancement technique , we were able to significantly improve the lane detection accuracy on road videos. ", "label": 1}
{"original_text": "Device-to-device (D2D) communication underlaying cellular networks allows mobile devices such as smartphones and tablets to use the licensed spectrum allocated to cellular services for direct peer-to-peer transmission. D2D communication can use either one-hop transmission (i.e., D2D direct communication) or multi-hop cluster-based transmission (i.e., in D2D local area networks). The D2D devices can compete or cooperate with each other to reuse the radio resources in D2D networks. Therefore, resource allocation and access for D2D communication can be treated as games. The theories behind these games provide a variety of mathematical tools to effectively model and analyze the individual or group behaviors of D2D users. In addition, game models can provide distributed solutions to the resource allocation problems for D2D communication. The aim of this article is to demonstrate the applications of game-theoretic models to study the radio resource allocation issues in D2D communication. The article also outlines several key open research directions.", "text_perturb": "Device-to-device ( D2D ) communication underlaying cellular networks allows mobile gimmick such as smartphones and tablets to use the licensed spectrum allocated to cellular services for direct peer-to-peer transmission. D2D communicating can use either one-hop transmission ( i. east. , D2D direct communication ) or multi-hop cluster-based transmission ( i. tocopherol. , in D2D local area networks ). The D2D devices can compete or cooperate with each other to reuse the radio imagination in D2D networks. Therefore , resource allocation and access for D2D communication can be regale as games. The theories behind these games provide a variety of mathematical tools to effectively sit and analyze the individual or group behaviors of D2D users. In summation , game models can provide distributed solutions to the resource allocation problems for D2D communication. The aim of this article is to demonstrate the applications of game-theoretic models to study the radio resource allocation takings in D2D communication. The article too outlines several key open research directions. ", "label": 1}
{"original_text": "In this paper we address the problem of unsupervised gaze correction in the wild, presenting a solution that works without the need for precise annotations of the gaze angle and the head pose. We have created a new dataset called CelebAGaze, which consists of two domains X, Y, where the eyes are either staring at the camera or somewhere else. Our method consists of three novel modules: the Gaze Correction module (GCM), the Gaze Animation module (GAM), and the Pretrained Autoencoder module (PAM). Specifically, GCM and GAM separately train a dual in-painting network using data from the domain X for gaze correction and data from the domain Y for gaze animation. Additionally, a Synthesis-As-Training method is proposed when training GAM to encourage the features encoded from the eye region to be correlated with the angle information, resulting in a gaze animation which can be achieved by interpolation in the latent space. To further preserve the identity information (e.g., eye shape, iris color), we propose the PAM with an Autoencoder, which is based on Self-Supervised mirror learning where the bottleneck features are angle-invariant and which works as an extra input to the dual in-painting models. Extensive experiments validate the effectiveness of the proposed method for gaze correction and gaze animation in the wild and demonstrate the superiority of our approach in producing more compelling results than state-of-the-art baselines. Our code, the pretrained models and the supplementary material are available at:", "text_perturb": "In this paper we address the problem of unsupervised gaze correction in the wild , presenting a solution that works without the need for precise annotations of the gaze angle and the head mannerism. We have create a new dataset called CelebAGaze , which consists of two domains X , Y , where the eyes are either staring at the camera or somewhere else. Our method acting consists of three novel modules : the Gaze Correction module ( GCM ) , the Gaze Animation module ( GAM ) , and the Pretrained Autoencoder module ( PAM ). Specifically , GCM and GAM separately train a dual in-painting network using information from the domain X for gaze correction and information from the domain Y for gaze animation. Additionally , a Synthesis-As-Training method is advise when training GAM to encourage the features encoded from the eye region to be correlated with the angle information , resulting in a gaze animation which can be achieved by interpolation in the latent space. To further continue the identity information ( e. thou. , eye shape , iris color ) , we propose the PAM with an Autoencoder , which is based on Self-Supervised mirror learning where the bottleneck features are angle-invariant and which lick as an extra input to the dual in-painting models. Extensive experiments validate the effectiveness of the proposed method for gaze correction and gaze brio in the wild and demonstrate the superiority of our approach in producing more compelling results than state-of-the-art baselines. Our code , the pretrained models and the supplementary stuff are available at :", "label": 1}
{"original_text": "Margin enlargement over training data has been an important strategy since perceptrons in machine learning for the purpose of boosting the robustness of classifiers toward a good generalization ability. Yet Breiman shows a dilemma (,) that a uniform improvement on margin distribution does not necessarily reduces generalization errors. In this paper, we revisit Breiman's dilemma in deep neural networks with recently proposed spectrally normalized margins. A novel perspective is provided to explain Breiman's dilemma based on phase transitions in dynamics of normalized margin distributions, that reflects the trade-off between expressive power of models and complexity of data. When data complexity is comparable to the model expressiveness in the sense that both training and test data share similar phase transitions in normalized margin dynamics, two efficient ways are derived to predict the trend of generalization or test error via classic margin-based generalization bounds with restricted Rademacher complexities. On the other hand, over-expressive models that exhibit uniform improvements on training margins, as a distinct phase transition to test margin dynamics, may lose such a prediction power and fail to prevent the overfitting. Experiments are conducted to show the validity of the proposed method with some basic convolutional networks, AlexNet, VGG-16, and ResNet-18, on several datasets including Cifar10100 and mini-ImageNet.", "text_perturb": "Margin enlargement over training data has been an important strategy since perceptrons in machine learning for the purpose of boosting the robustness of classifier toward a good generalization ability. Yet Breiman shows a dilemma ( , ) that a uniform improvement on margin distribution does not inevitably reduces generalization errors. In this paper , we revisit Breiman 's dilemma in deep neural networks with latterly proposed spectrally normalized margins. A novel perspective is provided to explain Breiman 's dilemma based on phase angle transitions in dynamics of normalized margin distributions , that reflects the trade-off between expressive power of models and complexity of data. When data complexity is comparable to the model expressiveness in the sense that both training and test data share similar phase transitions in normalized margin dynamics , two efficient ways are derived to predict the trend of generalization or test error via classic margin-based generalization bound with restricted Rademacher complexities. On the other hand , over-expressive models that exhibit uniform improvements on training margins , as a distinct phase passage to test margin dynamics , may lose such a prediction power and fail to prevent the overfitting. Experiments are conducted to show the validity of the proposed method with some basic convolutional networks , AlexNet , VGG-16 , and ResNet-18 , on various datasets including Cifar10100 and mini-ImageNet. ", "label": 1}
{"original_text": "The computation of the order of Frobenius action on the l -torsion is a part of Schoof-Elkies-Atkin algorithm for point counting on an elliptic curve E over a finite field F q. The idea of Schoof's algorithm is to compute the trace of Frobenius t modulo primes l and restore it by the Chinese remainder theorem. Atkin's improvement consists of computing the order r of the Frobenius action on E [ l ] and of restricting the number t (mod l) to enumerate by using the formula t 2 q (z z - 1) 2 (mod l). Here z is a primitive r -th root of unity. In this paper, we generalize Atkin's formula to the general case of abelian variety of dimension g. Classically, finding of the order r involves expensive computation of modular polynomials. We study the distribution of the Frobenius orders in case of abelian surfaces and q 1 (mod l) in order to replace these expensive computations by probabilistic algorithms.", "text_perturb": "The computation of the order of Frobenius action on the l -torsion is a component of Schoof-Elkies-Atkin algorithm for point counting on an elliptic curve E over a finite field F q. The estimate of Schoof 's algorithm is to compute the trace of Frobenius t modulo primes l and restore it by the Chinese remainder theorem. Atkin 's improvement consists of computing the order r of the Frobenius action on E [ l ] and of restricting the number t ( mod l ) to enumerate by using the normal t 2 q ( z z - 1 ) 2 ( mod l ). Here zee is a primitive r -th root of unity. In this paper , we generalize Atkin 's formula to the general case of abelian variety of proportion g. Classically , finding of the order universal gas constant involves expensive computation of modular polynomials. We study the dispersion of the Frobenius orders in case of abelian surfaces and q 1 ( mod l ) in order to replace these expensive computations by probabilistic algorithms. ", "label": 1}
{"original_text": "A superconducting optoelectronic neuron will produce a small current pulse upon reaching threshold. We present an amplifier chain that converts this small current pulse to a voltage pulse sufficient to produce light from a semiconductor diode. This light is the signal used to communicate between neurons in the network. The amplifier chain comprises a thresholding Josephson junction, a relaxation oscillator Josephson junction, a superconducting thin-film current-gated current amplifier, and a superconducting thin-film current-gated voltage amplifier. We analyze the performance of the elements in the amplifier chain in the time domain to calculate the energy consumption per photon created for several values of light-emitting diode capacitance and efficiency. The speed of the amplification sequence allows neuronal firing up to at least 20 MHz with power density low enough to be cooled easily with standard 4 He cryogenic systems operating at 4.2 K.", "text_perturb": "A superconducting optoelectronic nerve cell will produce a small current pulse upon reaching threshold. We present an amplifier chain that converts this small current pulse to a voltage pulse sufficient to produce light from a semiconductor junction rectifier. This light is the signal use to communicate between neurons in the network. The amplifier chain make up a thresholding Josephson junction , a relaxation oscillator Josephson junction , a superconducting thin-film current-gated current amplifier , and a superconducting thin-film current-gated voltage amplifier. We analyze the performance of the component in the amplifier chain in the time domain to calculate the energy consumption per photon created for several values of light-emitting diode capacitance and efficiency. The speed of the amplification sequence allows neuronal firing up to at least 20 MHz with power density low enough to be cooled well with standard 4 He cryogenic systems operating at 4. 2 grand. ", "label": 1}
{"original_text": "One of the challenges in large-scale information retrieval (IR) is to develop fine-grained and domain-specific methods to answer natural language questions. Despite the availability of numerous sources and datasets for answer retrieval, Question Answering (QA) remains a challenging problem due to the difficulty of the question understanding and answer extraction tasks. One of the promising tracks investigated in QA is to map new questions to formerly answered questions that are \"similar.\" In this paper, we propose a novel QA approach based on Recognizing Question Entailment (RQE) and we describe the QA system and resources that we built and evaluated on real medical questions. First, we compare machine learning and deep learning methods for RQE using different kinds of datasets, including textual inference, question similarity and entailment in both the open and clinical domains. Second, we combine IR models with the best RQE method to select entailed questions and rank the retrieved answers. To study the end-to-end QA approach, we built the MedQuAD collection of 47,457 question-answer pairs from trusted medical sources, that we introduce and share in the scope of this paper. Following the evaluation process used in TREC 2017 LiveQA, we find that our approach exceeds the best results of the medical task with a 29.8 increase over the best official score. The evaluation results also support the relevance of question entailment for QA and highlight the effectiveness of combining IR and RQE for future QA efforts. Our findings also show that relying on a restricted set of reliable answer sources can bring a substantial improvement in medical QA.", "text_perturb": "One of the challenges in large-scale information retrieval ( IR ) is to develop fine-grained and domain-specific method acting to answer natural language questions. Despite the availability of numerous sources and datasets for answer retrieval , Question Answering ( QA ) remains a challenging trouble due to the difficulty of the question understanding and answer extraction tasks. One of the promising tracks investigated in QA is to map new questions to erst answered questions that are `` similar. `` In this paper , we propose a novel QA approach based on Recognizing Question Entailment ( RQE ) and we describe the QA system and imagination that we built and evaluated on real medical questions. First , we compare machine learnedness and deep learnedness methods for RQE using different kinds of datasets , including textual inference , question similarity and entailment in both the open and clinical domains. Second , we combine IR models with the effective RQE method to select entailed questions and rank the retrieved answers. To read the end-to-end QA approach , we built the MedQuAD collection of 47,457 question-answer pairs from trusted medical sources , that we introduce and share in the scope of this paper. Following the evaluation operation used in TREC 2017 LiveQA , we find that our approach exceeds the best results of the medical task with a 29. 8 increase over the best functionary score. The evaluation results also indorse the relevance of question entailment for QA and highlight the effectiveness of combining IR and RQE for future QA efforts. Our findings also show that relying on a restricted set of reliable answer sources can bring a hearty improvement in medical QA. ", "label": 1}
{"original_text": "The COVID-19 pandemic has affected almost all countries in the world in the first half of 2020. During this time, a massive number of attempts on the predictions of the number of cases and the other future trends of this pandemic have been made. However, they fail to predict, in a reliable way, the medium and long term evolution of fundamental features of COVID-19 outbreak within acceptable accuracy. This paper gives an explanation for the failure of machine learning models in this particular forecasting problem. The paper shows that simple linear regression models provide high prediction accuracy values reliably but only for a 2-weeks period and that relatively complex machine learning models, which have the potential of learning long term predictions with low errors, cannot achieve to obtain good predictions with possessing a high generalization ability. It is suggested in the paper that the lack of a sufficient number of samples is the source of low prediction performance of the forecasting models. The reliability of the forecasting results about the active cases is measured in terms of the cross-validation prediction errors, which are used as expectations for the generalization errors of the forecasters. To exploit the information, which is of most relevant with the active cases, we perform feature selection over a variety of variables such as the numbers of active cases, deaths, recoveries, and people per kilometer square. We apply different feature selection methods, namely the Pairwise Correlation, Recursive Feature Selection, and feature selection by using the Lasso regression and compare them to each other and also with the models not employing any feature selection. Furthermore, we compare Linear Regression, Multi-Layer Perceptron, and Long-Short Term Memory models each of which is used for prediction active cases together with the mentioned feature selection methods. Our results show that the accurate forecasting of the active cases with high generalization ability is possible up to 3 days only because of the small sample size of COVID-19 data. We observe that the linear regression model has much better prediction performance with high generalization ability as compared to the complex models but, as expected, its performance decays sharply for more than 14-days prediction horizons.", "text_perturb": "The COVID-19 pandemic has affected almost all countries in the humankind in the first half of 2020. During this time , a massive number of attempts on the predictions of the number of cases and the other future trends of this pandemic have live made. However , they fail to predict , in a reliable way , the medium and long term evolution of fundamental features of COVID-19 outbreak within acceptable truth. This paper gives an account for the failure of machine learning models in this particular forecasting problem. The paper shows that simple linear regression models provide high prediction accuracy values reliably but merely for a 2-weeks period and that relatively complex machine learning models , which have the potential of learning long term predictions with low errors , can not achieve to obtain good predictions with possessing a high generalization ability. It is suggested in the paper that the lack of a sufficient number of samples is the source of low prediction performance of the prognostication models. The reliability of the forecasting results about the alive cases is measured in terms of the cross-validation prediction errors , which are used as expectations for the generalization errors of the forecasters. To exploit the information , which is of most relevant with the alive cases , we perform feature selection over a variety of variables such as the numbers of alive cases , deaths , recoveries , and people per kilometer square. We apply different feature selection methods , namely the Pairwise Correlation , Recursive Feature Selection , and feature selection by using the Lasso regression and compare them to each former and also with the models not employing any feature selection. Furthermore , we compare Linear Regression , Multi-Layer Perceptron , and Long-Short Term Memory models each of which is used for prediction active cases together with the mentioned feature selection method. Our results show that the accurate forecasting of the active cases with high generalization ability is possible up to 3 days only because of the small sampling size of COVID-19 data. We maintain that the linear regression model has much better prediction performance with high generalization ability as compared to the complex models but , as expected , its performance decays sharply for more than 14-days prediction horizons. ", "label": 1}
{"original_text": "Recent GAN-based architectures have been able to deliver impressive performance on the general task of image-to-image translation. In particular, it was shown that a wide variety of image translation operators may be learned from two image sets, containing images from two different domains, without establishing an explicit pairing between the images. This was made possible by introducing clever regularizers to overcome the under-constrained nature of the unpaired translation problem. In this work, we introduce a novel architecture for unpaired image translation, and explore several new regularizers enabled by it. Specifically, our architecture comprises a pair of GANs, as well as a pair of translators between their respective latent spaces. These cross-translators enable us to impose several regularizing constraints on the learnt image translation operator, collectively referred to as latent cross-consistency. Our results show that our proposed architecture and latent cross-consistency constraints are able to outperform the existing state-of-the-art on a variety of image translation tasks.", "text_perturb": "Recent GAN-based architectures own been able to deliver impressive performance on the general task of image-to-image translation. In particular , it was shown that a wide variety of image translation wheeler dealer may be learned from two image sets , containing images from two different domains , without establishing an explicit pairing between the images. This was made possible by precede clever regularizers to overcome the under-constrained nature of the unpaired translation problem. In this work , we introduce a refreshing architecture for unpaired image translation , and explore several new regularizers enabled by it. Specifically , our architecture comprises a pair of GANs , as well as a pair of translators between their various latent spaces. These cross-translators enable us to impose several regularizing constraints on the learnt image interlingual rendition operator , collectively referred to as latent cross-consistency. Our results show that our proposed architecture and latent cross-consistency restraint are able to outperform the existing state-of-the-art on a variety of image translation tasks. ", "label": 1}
{"original_text": "Disclosure of data analytics has important scientific and commercial justifications. However, disclosure should not be allowed without due diligence investigation of the risks that it poses for information privacy of data subjects. Does the data analytics community have the right tools at their disposal to perform such due diligence? We present Privug, a way to explore leakage properties, or information privacy risks, involved with disclosing results of an analytics program. The method uses classical off-the-shelf tools for Bayesian probabilistic programming, exploiting the fact that they can reinterpret a regular program probabilistically. This in turn allows information-theoretic analysis of program behavior. These tools and skills are often available for a data scientist pondering disclosure questions. For privacy researchers, the method provides a fast and lightweight way to experiment with privacy protection measures and mechanisms. We demonstrate that Privug is accurate, scalable, and applicable, and use it to explore parameters of a differential privacy mechanism.", "text_perturb": "revealing of data analytics has important scientific and commercial justifications. However , disclosure should not be allowed without due diligence investigation of the risks that it poses for information privacy of datum subjects. coiffure the data analytics community have the right tools at their disposal to perform such due diligence ? We present Privug , a way to explore leakage properties , or information privacy risks , involved with disclosing results of an analytics program. The method uses classical off-the-shelf tools for Bayesian probabilistic programming , exploiting the fact that they can reinterpret a regular broadcast probabilistically. This in turn allows information-theoretic analysis of program behavior. These tools and accomplishment are often available for a data scientist pondering disclosure questions. For seclusion researchers , the method provides a fast and lightweight way to experiment with seclusion protection measures and mechanisms. We demonstrate that Privug is accurate , scalable , and applicable , and use it to research parameters of a differential privacy mechanism. ", "label": 1}
{"original_text": "Robot manipulation and grasping mechanisms have received considerable attention in the recent past, leading to development of wide-range of industrial applications. This paper proposes the development of an autonomous robotic grasping system for object sorting application. RGB-D data is used by the robot for performing object detection, pose estimation, trajectory generation and object sorting tasks. The proposed approach can also handle grasping on certain objects chosen by users. Trained convolutional neural networks are used to perform object detection and determine the corresponding point cloud cluster of the object to be grasped. From the selected point cloud data, a grasp generator algorithm outputs potential grasps. A grasp filter then scores these potential grasps, and the highest-scored grasp will be chosen to execute on a real robot. A motion planner will generate collision-free trajectories to execute the chosen grasp. The experiments on AUBO robotic manipulator show the potentials of the proposed approach in the context of autonomous object sorting with robust and fast sorting performance.", "text_perturb": "Robot manipulation and dig mechanisms have received considerable attention in the recent past , leading to development of wide-range of industrial applications. This paper advise the development of an autonomous robotic grasping system for object sorting application. RGB-D data is used by the robot for do object detection , pose estimation , trajectory generation and object sorting tasks. The proposed approach can also handle compass on certain objects chosen by users. Trained convolutional neuronic networks are used to perform object detection and determine the corresponding point cloud cluster of the object to be grasped. From the selected point cloud data , a grasp generator algorithmic rule outputs potential grasps. A grasp filter then scores these potential grasps , and the highest-scored grasp will be opt to execute on a real robot. A motion planner will return collision-free trajectories to execute the chosen grasp. The experiments on AUBO robotic manipulator show the potentials of the advise approach in the context of autonomous object sorting with robust and fast sorting performance. ", "label": 1}
{"original_text": "We seek to learn a representation on a large annotated data source that generalizes to a target domain using limited new supervision. Many prior approaches to this problem have focused on learning \"disentangled\" representations so that as individual factors vary in a new domain, only a portion of the representation need be updated. In this work, we seek the generalization power of disentangled representations, but relax the requirement of explicit latent disentanglement and instead encourage linearity of individual factors of variation by requiring them to be manipulable by learned linear transformations. We dub these transformations latent canonicalizers, as they aim to modify the value of a factor to a pre-determined (but arbitrary) canonical value (e.g., recoloring the image foreground to black). Assuming a source domain with access to meta-labels specifying the factors of variation within an image, we demonstrate experimentally that our method helps reduce the number of observations needed to generalize to a similar target domain when compared to a number of supervised baselines.", "text_perturb": "We seek to learn a representation on a large annotated data source that vulgarise to a target domain using limited new supervision. Many prior approaches to this trouble have focused on learning `` disentangled '' representations so that as individual factors vary in a new domain , only a portion of the representation need be updated. In this work , we seek the generalization power of disentangled representations , but relax the requirement of explicit latent disentanglement and instead encourage linearity of individual factors of variation by requiring them to be manipulable by learned linear transmutation. We dub these transformations latent canonicalizers , as they aim to modify the value of a constituent to a pre-determined ( but arbitrary ) canonical value ( e. thousand. , recoloring the double foreground to black ). Assuming a source domain with access to meta-labels specifying the factors of variation within an image , we demonstrate experimentally that our method helps reduce the identification number of observations needed to generalize to a similar target domain when compared to a identification number of supervised baselines. ", "label": 1}
{"original_text": "Feature extraction from financial data is one of the most important problems in market prediction domain for which many approaches have been suggested. Among other modern tools, convolutional neural networks (CNN) have recently been applied for automatic feature selection and market prediction. However, in experiments reported so far, less attention has been paid to the correlation among different markets as a possible source of information for extracting features. In this paper, we suggest a CNN-based framework with specially designed CNNs, that can be applied on a collection of data from a variety of sources, including different markets, in order to extract features for predicting the future of those markets. The suggested framework has been applied for predicting the next day's direction of movement for the indices of SP 500, NASDAQ, DJI, NYSE, and RUSSELL markets based on various sets of initial features. The evaluations show a significant improvement in prediction's performance compared to the state of the art baseline algorithms.", "text_perturb": "feature extraction from financial data is one of the most important problems in market prediction domain for which many approaches have been suggested. Among other modern tools , convolutional neural networks ( CNN ) deliver recently been applied for automatic feature selection and market prediction. However , in experiments reported so far , less attention has been paid to the correlation among different markets as a possible source of info for extracting features. In this paper , we suggest a CNN-based framework with specially designed CNNs , that can be applied on a collection of data from a variety of sources , including different markets , in order to extract features for prefigure the future of those markets. The suggested framework has been give for predicting the next day 's direction of movement for the indices of SP 500 , NASDAQ , DJI , NYSE , and RUSSELL markets based on various sets of initial features. The evaluations show a significant improvement in prediction 's performance compared to the state of the artistic production baseline algorithms. ", "label": 1}
{"original_text": "We consider channels affected by intersymbol interference with reduced-complexity, mutual information optimized, channel-shortening detection. For such settings, we optimize the transmit filter, taking into consideration the reduced receiver complexity constraint. As figure of merit, we consider the achievable information rate of the entire system and with functional analysis, we establish a general form of the optimal transmit filter, which can then be optimized by standard numerical methods. As a corollary to our main result, we obtain some insight of the behavior of the standard waterfilling algorithm for intersymbol interference channels. With only some minor changes, the general form we derive can be applied to multiple-input multiple-output channels with intersymbol interference. To illuminate the practical use of our results, we provide applications of our theoretical results by deriving the optimal shaping pulse of a linear modulation transmitted over a bandlimited additive white Gaussian noise channel which has possible applications in the faster-than-Nyquisttime packing technique.", "text_perturb": "We consider channels affected by intersymbol interference with reduced-complexity , mutual information optimized , channel-shortening sensing. For such settings , we optimize the transmit filter , taking into consideration the cut down receiver complexity constraint. As figure of merit , we consider the achievable information rate of the entire system and with functional analysis , we establish a general form of the optimal transmit filter , which can then be optimized by standard numerical method acting. As a corollary to our main result , we receive some insight of the behavior of the standard waterfilling algorithm for intersymbol interference channels. With only some small scale changes , the general form we derive can be applied to multiple-input multiple-output channels with intersymbol interference. To illuminate the practical use of our results , we provide applications of our theoretical results by infer the optimal shaping pulse of a linear modulation transmitted over a bandlimited additive white Gaussian noise channel which has possible applications in the faster-than-Nyquisttime packing technique. ", "label": 1}
{"original_text": "We propose a flat nonlinear placement algorithm FFTPL using fast Fourier transform for density equalization. The placement instance is modeled as an electrostatic system with the analogy of density cost to the potential energy. A well-defined Poisson's equation is proposed for gradient and cost computation. Our placer outperforms state-of-the-art placers with better solution quality and efficiency.", "text_perturb": "We propose a flat nonlinear placement algorithm FFTPL utilise fast Fourier transform for density equalization. The placement instance is modeled as an static system with the analogy of density cost to the potential energy. A well-defined Poisson 's equating is proposed for gradient and cost computation. Our placer exceed state-of-the-art placers with better solution quality and efficiency. ", "label": 1}
{"original_text": "In this article, we investigate the transient behavior of a sequence of packetsbits traversing a multi-hop wireless network. Our work is motivated by novel applications from the domain of process automation, Machine-Type Communication (MTC) and cyber-physical systems, where short messages are communicated and statistical guarantees need to be provided on a per-message level. In order to optimize such a network, apart from understanding the stationary system dynamics, an understanding of the short-term dynamics (i.e., transient behavior) is also required. To this end, we derive novel Wireless Transient Bounds (WTB) for end-to-end delay and backlog in a multi-hop wireless network using stochastic network calculus approach. WTB depends on the initial backlog at each node as well as the instantaneous channel states. We numerically compare WTB with State-Of-The-Art Transient bounds (SOTAT), that can be obtained by adapting existing stationary bounds, as well as simulation of the network. While SOTAT and stationary bounds are not able to capture the short-term system dynamics well, WTB provides relatively tight upper bound and has a decay rate that closely matches the simulation. This is achieved by WTB only with a slight increase in the computational complexity, by a factor of O (T N), where T is the duration of the arriving sequence and N is the number of hops in the network. We believe that the presented analysis and the bounds can be used as base for future work on transient network optimization, e.g., in massive MTC, critical MTC, edge computing and autonomous vehicle.", "text_perturb": "In this article , we investigate the transient behavior of a chronological sequence of packetsbits traversing a multi-hop wireless network. Our work is motivated by novel practical application from the domain of process automation , Machine-Type Communication ( MTC ) and cyber-physical systems , where short messages are communicated and statistical guarantees need to be provided on a per-message level. In order to optimize such a network , apart from sympathize the stationary system dynamics , an understanding of the short-term dynamics ( i. vitamin e. , transient doings ) is also required. To this end , we derive novel Wireless Transient Bounds ( WTB ) for end to end delay and backlog in a multi-hop wireless network using stochastic network calculus approach. WTB look on the initial backlog at each node as well as the instantaneous channel states. We numerically compare WTB with State-Of-The-Art Transient limit ( SOTAT ) , that can be obtained by adapting existing stationary limit , as well as simulation of the network. While SOTAT and stationary bounds are not able to capture the short-term system dynamics advantageously , WTB provides relatively tight upper bound and has a decay rate that closely matches the simulation. This is achieved by WTB only with a slight increase in the computational complexity , by a factor of O ( T N ) , where T is the length of the arriving sequence and N is the number of hops in the network. We believe that the presented analysis and the leap can be used as base for future work on transient network optimization , e. thousand. , in massive MTC , critical MTC , edge computing and autonomous fomite. ", "label": 1}
{"original_text": "A common sparse linear regression formulation is the l 1 regularized least squares, which is also known as least absolute shrinkage and selection operator (LASSO). Approximate message passing (AMP) has been proved to asymptotically achieve the LASSO solution when the regression matrix has independent and identically distributed (i.i.d.) Gaussian entries in the sense that the averaged per-coordinate l 2 distance between the AMP iterates and the LASSO solution vanishes as the signal dimension goes to infinity before the iteration number. However, in finite dimensional settings, characterization of AMP iterates in the limit of large iteration number has not been established. In this work, we propose an AMP variant by including a parameter that depends on the largest singular value of the regression matrix. The proposed algorithm can also be considered as a primal dual hybrid gradient algorithm with adaptive stepsizes. We show that whenever the AMP variant converges, it converges to the LASSO solution for arbitrary finite dimensional regression matrices. Moreover, we show that the AMP variant is locally stable around the LASSO solution under the condition that the LASSO solution is unique and that the regression matrix is drawn from a continuous distribution. Our local stability result implies that in the special case where the regression matrix is large and has i.i.d. random entries, the original AMP, which is a special case of the proposed AMP variant, is locally stable around the LASSO solution.", "text_perturb": "A common sparse linear regression formulation is the l 1 regularized least squares , which is also known as least absolute shrinkage and selection operator ( lasso ). Approximate message passing ( AMP ) has been test to asymptotically achieve the LASSO solution when the regression matrix has independent and identically distributed ( i. single. ergocalciferol. ) Gaussian entries in the sense that the averaged per-coordinate l 2 distance between the AMP iterates and the LASSO solution vanishes as the signal dimension lead to infinity before the iteration number. However , in finite dimensional settings , characterization of a iterates in the limit of large iteration number has not been established. In this work , we offer an AMP variant by including a parameter that depends on the largest singular value of the regression matrix. The proposed algorithm can also be considered as a cardinal dual hybrid gradient algorithm with adaptive stepsizes. We indicate that whenever the AMP variant converges , it converges to the LASSO solution for arbitrary finite dimensional regression matrices. Moreover , we show that the AMP variant is locally stable around the LASSO result under the condition that the LASSO result is unique and that the regression matrix is drawn from a continuous distribution. Our local stability result implies that in the special case where the regression matrix is expectant and has i. single. cholecalciferol. random entries , the original AMP , which comprise a special case of the proposed AMP variant , comprise locally stable around the LASSO solution. ", "label": 1}
{"original_text": "This report documents the program and the outcomes of Dagstuhl Seminar 13082 \"Communication Complexity, Linear Optimization, and lower bounds for the nonnegative rank of matrices,\" held in February 2013 at Dagstuhl Castle.", "text_perturb": "This report documents the program and the outcomes of Dagstuhl seminar 13082 `` Communication Complexity , Linear Optimization , and lower bounds for the nonnegative rank of matrices , '' held in February 2013 at Dagstuhl Castle. ", "label": 1}
{"original_text": "Multi-object tracking has recently become an important area of computer vision, especially for Advanced Driver Assistance Systems (ADAS). Despite growing attention, achieving high performance tracking is still challenging, with state-of-the-art systems resulting in high complexity with a large number of hyper parameters. In this paper, we focus on reducing overall system complexity and the number hyper parameters that need to be tuned to a specific environment. We introduce a novel tracking system based on similarity mapping by Enhanced Siamese Neural Network (ESNN), which accounts for both appearance and geometric information, and is trainable end-to-end. Our system achieves competitive performance in both speed and accuracy on MOT16 challenge and KITTI benchmarks, compared to known state-of-the-art methods.", "text_perturb": "Multi-object tracking has recently become an important area of computer visual modality , especially for Advanced Driver Assistance Systems ( ADAS ). Despite growing attention , achieving high performance trailing is still challenging , with state-of-the-art systems resulting in high complexity with a large number of hyper parameters. In this paper , we focus on shorten overall system complexity and the number hyper parameters that need to be tuned to a specific environment. We introduce a novel tracking system based on similarity mapping by Enhanced Siamese Neural Network ( ESNN ) , which accounts for both appearance and geometrical information , and is trainable end-to-end. Our system achieves competitive performance in both speed and accuracy on MOT16 challenge and KITTI benchmarks , compared to known state of the art methods. ", "label": 1}
{"original_text": "Among the available solutions for drone swarm simulations, we identified a gap in simulation frameworks that allow easy algorithms prototyping, tuning, debugging and performance analysis, and do not require the user to interface with multiple programming languages. We present SwarmLab, a software entirely written in Matlab, that aims at the creation of standardized processes and metrics to quantify the performance and robustness of swarm algorithms, and in particular, it focuses on drones. We showcase the functionalities of SwarmLab by comparing two state-of-the-art algorithms for the navigation of aerial swarms in cluttered environments, Olfati-Saber's and Vasarhelyi's. We analyze the variability of the inter-agent distances and agents' speeds during flight. We also study some of the performance metrics presented, i.e. order, inter and extra-agent safety, union, and connectivity. While Olfati-Saber's approach results in a faster crossing of the obstacle field, Vasarhelyi's approach allows the agents to fly smoother trajectories, without oscillations. We believe that SwarmLab is relevant for both the biological and robotics research communities, and for education, since it allows fast algorithm development, the automatic collection of simulated data, the systematic analysis of swarming behaviors with performance metrics inherited from the state of the art. Index Terms: Swarms, Agent-Based Systems, Simulation and Animation, Aerial Systems: Applications", "text_perturb": "Among the available solutions for drone swarm simulations , we identified a gap in simulation frameworks that allow easy algorithms prototyping , tuning , debugging and public presentation analysis , and do not require the user to interface with multiple programming languages. We present SwarmLab , a software program entirely written in Matlab , that aims at the creation of standardized processes and metrics to quantify the performance and robustness of swarm algorithms , and in particular , it focuses on drones. We showcase the functionalities of SwarmLab by comparing two state-of-the-art algorithms for the navigation of aerial drove in cluttered environments , Olfati-Saber 's and Vasarhelyi 's. We analyze the variability of the inter-agent aloofness and agents ' speeds during flight. We also study some of the performance metrics submit , i. due east. order , inter and extra-agent rubber , union , and connectivity. While Olfati-Saber 's approach results in a faster hybridization of the obstacle field , Vasarhelyi 's approach allows the agents to fly smoother trajectories , without oscillations. We believe that SwarmLab is relevant for both the biological and robotics research communities , and for education , since it allows fast algorithm growing , the automatic collection of simulated data , the systematic analysis of swarming behaviors with performance metrics inherited from the state of the art. Index Terms : Swarms , Agent-Based Systems , Simulation and Animation , aerial Systems : Applications", "label": 1}
{"original_text": "3D photography is a new medium that allows viewers to more fully experience a captured moment. In this work, we refer to a 3D photo as one that displays parallax induced by moving the viewpoint (as opposed to a stereo pair with a fixed viewpoint). 3D photos are static in time, like traditional photos, but are displayed with interactive parallax on mobile or desktop screens, as well as on Virtual Reality devices, where viewing it also includes stereo. We present an end-to-end system for creating and viewing 3D photos, and the algorithmic and design choices therein. Our 3D photos are captured in a single shot and processed directly on a mobile device. The method starts by estimating depth from the 2D input image using a new monocular depth estimation network that is optimized for mobile devices. It performs competitively to the state-of-the-art, but has lower latency and peak memory consumption and uses an order of magnitude fewer parameters. The resulting depth is lifted to a layered depth image, and new geometry is synthesized in parallax regions. We synthesize color texture and structures in the parallax regions as well, using an inpainting network, also optimized for mobile devices, on the LDI directly. Finally, we convert the result into a mesh-based representation that can be efficiently transmitted and rendered even on low-end devices and over poor network connections. Altogether, the processing takes just a few seconds on a mobile device, and the result can be instantly viewed and shared. We perform extensive quantitative evaluation to validate our system and compare its new components against the current state-of-the-art.", "text_perturb": "3D photography is a new medium that allows viewers to more in full experience a captured moment. In this oeuvre , we refer to a 3D photo as one that displays parallax induced by moving the viewpoint ( as opposed to a stereo pair with a fixed viewpoint ). 3D photo are static in time , like traditional photo , but are displayed with interactive parallax on mobile or desktop screens , as well as on Virtual Reality devices , where viewing it also includes stereo. We present an end-to-end system for creating and regard 3D photos , and the algorithmic and design choices therein. Our 3D photos are captured in a single shot and processed directly on a mobile gimmick. The method starts by estimating profundity from the 2D input image using a new monocular profundity estimation network that is optimized for mobile devices. It performs competitively to the state-of-the-art , but has lower latency and peak remembering consumption and uses an order of magnitude fewer parameters. The resulting depth is lifted to a superimposed depth image , and new geometry is synthesized in parallax regions. We synthesize color texture and social system in the parallax regions as well , using an inpainting network , also optimized for mobile devices , on the LDI directly. Finally , we convert the result into a mesh-based representation that displace be efficiently transmitted and rendered even on low-end devices and over poor network connections. Altogether , the processing takes just a few seconds on a mobile device , and the result can embody instantly viewed and shared. We perform extensive quantitative evaluation to validate our system and equate its new components against the current state-of-the-art. ", "label": 1}
{"original_text": "Recent advances in Fourier analysis have brought new tools to efficiently represent and learn set functions. In this paper, we bring the power of Fourier analysis to the design of iterative combinatorial auctions. The key idea is to approximate the bidders' value functions using Fourier-sparse set functions, which can be computed using a relatively small number of queries. Since this number is still too large for real-world auctions, we propose a novel hybrid auction design: we first use neural networks to learn bidders' values and then apply Fourier analysis to those learned representations. On a technical level, we formulate a Fourier transform-based winner determination problem and derive its mixed integer program formulation. Based on this, we devise an iterative mechanism that asks Fourier-based queries. Our experimental evaluation shows that our hybrid auction leads to a fairer distribution of social welfare among bidders and significantly reduces runtime, while matching the economic efficiency of state-of-the-art auction designs. With this paper, we are the first to leverage Fourier analysis in combinatorial auction design and lay the foundation for future work in this area.", "text_perturb": "Recent advances in Fourier analysis have fetch new tools to efficiently represent and learn set functions. In this paper , we bring the powerfulness of Fourier analysis to the design of iterative combinatorial auctions. The key idea is to approximate the bidders ' value social function using Fourier-sparse set social function , which can be computed using a relatively small number of queries. Since this number is still too large for real-world auctions , we propose a novel hybrid auction design : we first use neural networks to learn bidders ' economic value and then apply Fourier analysis to those learned representations. On a technical level , we formulate a Fourier transform-based winner determination job and derive its mixed integer program formulation. Based on this , we excogitate an iterative mechanism that asks Fourier-based queries. Our experimental evaluation shows that our hybrid auction leads to a fairer distribution of social upbeat among bidders and significantly reduces runtime , while matching the economic efficiency of state-of-the-art auction designs. With this paper , we are the first to leverage Fourier analysis in combinatorial auction design and rest the foundation for future work in this area. ", "label": 1}
{"original_text": "Most deraining works focus on rain streaks removal but they cannot deal adequately with heavy rain images. In heavy rain, streaks are strongly visible, dense rain accumulation or rain veiling effect significantly washes out the image, further scenes are relatively more blurry, etc. In this paper, we propose a novel method to address these problems. We put forth a 2-stage network: a physics-based backbone followed by a depth-guided GAN refinement. The first stage estimates the rain streaks, the transmission, and the atmospheric light governed by the underlying physics. To tease out these components more reliably, a guided filtering framework is used to decompose the image into its low- and high-frequency components. This filtering is guided by a rain-free residue image - its content is used to set the passbands for the two channels in a spatially-variant manner so that the background details do not get mixed up with the rain-streaks. For the second stage, the refinement stage, we put forth a depth-guided GAN to recover the background details failed to be retrieved by the first stage, as well as correcting artefacts introduced by that stage. We have evaluated our method against the state of the art methods. Extensive experiments show that our method outperforms them on real rain image data, recovering visually clean images with good details.", "text_perturb": "Most deraining deeds focus on rain streaks removal but they can not deal adequately with heavy rain images. In heavy rain , streaks are strongly visible , obtuse rain accumulation or rain veiling effect significantly washes out the image , further scenes are relatively more blurry , etc. In this paper , we propose a fresh method to address these problems. We put forth a 2-stage network : a physics-based backbone follow by a depth-guided GAN refinement. The first stage estimates the rain streaks , the transmission , and the atmospheric light governed by the rudimentary physics. To tease out these portion more reliably , a guided filtering framework is used to decompose the image into its low- and high-frequency portion. This filtering is guided by a rain-free residue image - its content is used to set the passbands for the two channels in a spatially-variant manner so that the desktop details do not get mixed up with the rain-streaks. For the second stage , the refinement stage , we put forth a depth-guided GAN to recover the background details failed to be retrieved by the first stage , as well as sort out artefacts introduced by that stage. We have valuate our method against the state of the art methods. Extensive experiments show that our method outperforms them on real rain image data , recovering visually clean images with good detail. ", "label": 1}
{"original_text": "To achieve a dexterous robotic manipulation, we need to endow our robot with tactile feedback capability, i.e. the ability to drive action based on tactile sensing. In this paper, we specifically address the challenge of tactile servoing, i.e. given the current tactile sensing and a targetgoal tactile sensing - memorized from a successful task execution in the past - what is the action that will bring the current tactile sensing to move closer towards the target tactile sensing at the next time step. We develop a data-driven approach to acquire a dynamics model for tactile servoing by learning from demonstration. Moreover, our method represents the tactile sensing information as to lie on a surface - or a 2D manifold - and perform a manifold learning, making it applicable to any tactile skin geometry. We evaluate our method on a contact point tracking task using a robot equipped with a tactile finger.", "text_perturb": "To achieve a dextrous robotic manipulation , we need to endow our robot with tactile feedback capability , i. due east. the power to drive action based on tactile sensing. In this paper , we specifically cover the challenge of tactile servoing , i. atomic number . given the current tactile sensing and a targetgoal tactile sensing - memorized from a successful task execution in the past - what is the action that bequeath bring the current tactile sensing to move closer towards the target tactile sensing at the next time step. We develop a data-driven attack to acquire a dynamics model for tactile servoing by learning from demonstration. moreover , our method represents the tactile sensing information as to lie on a surface - or a 2D manifold - and perform a manifold learning , making it applicable to any tactile skin geometry. We evaluate our method on a contact point tracking project using a robot equipped with a tactile finger. ", "label": 1}
{"original_text": "Online communities have gained considerable importance in recent years due to the increasing number of people connected to the Internet. Moderating user content in online communities is mainly performed manually, and reducing the workload through automatic methods is of great financial interest for community maintainers. Often, the industry uses basic approaches such as bad words filtering and regular expression matching to assist the moderators. In this article, we consider the task of automatically determining if a message is abusive. This task is complex since messages are written in a non-standardized way, including spelling errors, abbreviations, community-specific codes... First, we evaluate the system that we propose using standard features of online messages. Then, we evaluate the impact of the addition of pre-processing strategies, as well as original specific features developed for the community of an online in-browser strategy game. We finally propose to analyze the usefulness of this wide range of features using feature selection. This work can lead to two possible applications: 1) automatically flag potentially abusive messages to draw the moderator's attention on a narrow subset of messages; and 2) fully automate the moderation process by deciding whether a message is abusive without any human intervention.", "text_perturb": "Online communities have profit considerable importance in recent years due to the increasing number of people connected to the Internet. Moderating user content in online communities is mainly performed manually , and reducing the workload through automatic methods is of bang up financial interest for community maintainers. Often , the industry uses basic approaches such as bad speech filtering and regular expression matching to assist the moderators. In this article , we consider the project of automatically determining if a message is abusive. This task is complex since messages are written in a non-standardized way , including import errors , abbreviations , community-specific codes. . . First , we evaluate the system that we propose using standard lineament of online messages. Then , we evaluate the impact of the addition of pre-processing strategies , as well as original specific features modernize for the community of an online in-browser strategy game. We finally propose to take apart the usefulness of this wide range of features using feature selection. This work can lead to two possible applications : 1 ) automatically flag potentially abusive messages to get out the moderator 's attention on a narrow subset of messages ; and 2 ) fully automate the moderation process by deciding whether a message is abusive without any human intervention. ", "label": 1}
{"original_text": "Nonlocal operators of fractional type are a popular modeling choice for applications that do not adhere to classical diffusive behavior; however, one major challenge in nonlocal simulations is the selection of model parameters. In this work we propose an optimization-based approach to parameter identification for fractional models with an optional truncation radius. We formulate the inference problem as an optimal control problem where the objective is to minimize the discrepancy between observed data and an approximate solution of the model, and the control variables are the fractional order and the truncation length. For the numerical solution of the minimization problem we propose a gradient-based approach, where we enhance the numerical performance by an approximation of the bilinear form of the state equation and its derivative with respect to the fractional order. Several numerical tests in one and two dimensions illustrate the theoretical results and show the robustness and applicability of our method.", "text_perturb": "Nonlocal manipulator of fractional type are a popular modeling choice for applications that do not adhere to classical diffusive behavior ; however , one major challenge in nonlocal simulations is the selection of model parameters. In this work we propose an optimization-based approach to parameter identification for fractional models with an optional truncation r. We formulate the inference problem as an optimal ascendency problem where the objective is to minimize the discrepancy between observed data and an approximate solution of the model , and the ascendency variables are the fractional order and the truncation length. For the numerical solution of the minimization problem we propose a gradient-based approach , where we enhance the numerical performance by an approximation of the bilinear form of the state par and its derivative with respect to the fractional order. Several numerical tests in one and two dimensions exemplify the theoretical results and show the robustness and applicability of our method. ", "label": 1}
{"original_text": "Heterogeneous many-cores are now an integral part of modern computing systems ranging from embedding systems to supercomputers. While heterogeneous many-core design offers the potential for energy-efficient high-performance, such potential can only be unlocked if the application programs are suitably parallel and can be made to match the underlying heterogeneous platform. In this article, we provide a comprehensive survey for parallel programming models for heterogeneous many-core architectures and review the compiling techniques of improving programmability and portability. We examine various software optimization techniques for minimizing the communicating overhead between heterogeneous computing devices. We provide a road map for a wide variety of different research areas. We conclude with a discussion on open issues in the area and potential research directions. This article provides both an accessible introduction to the fast-moving area of heterogeneous programming and a detailed bibliography of its main achievements.", "text_perturb": "Heterogeneous many-cores are now an integral part of modern computing system ranging from embedding system to supercomputers. While heterogeneous many-core design offers the potential for energy-efficient high-performance , such potential can only be unlocked if the application programs are fitly parallel and can be made to match the underlying heterogeneous platform. In this article , we put up a comprehensive survey for parallel programming models for heterogeneous many-core architectures and review the compiling techniques of improving programmability and portability. We examine various software optimisation techniques for minimizing the communicating overhead between heterogeneous computing devices. We provide a road map for a wide variety of dissimilar research areas. We conclude with a discussion on open issues in the country and potential research directions. This article provides both an accessible innovation to the fast-moving area of heterogeneous programming and a detailed bibliography of its main achievements. ", "label": 1}
{"original_text": "Traditionally, we have two possibilities to design tools for program comprehension and analysis. The first option is to create a standalone program, independent of any source code editor. This way, the act of source code editing is separated from the act of viewing the code analysis results. The second option is to create a plugin for a specific IDE (integrated development environment) - in this case, a separate version must be created for each IDE. We propose an approach where information about source code elements is written directly into source files as annotations or special comments. Before committing to a version control system, the annotations are removed from the source code to avoid code pollution. We briefly evaluate the approach and delineate its limitations.", "text_perturb": "traditionally , we have two possibilities to design tools for program comprehension and analysis. The first option comprise to create a standalone program , independent of any source code editor. This way , the act of source code editing is separated from the act of catch the code analysis results. The second option is to create a plugin for a specific IDE ( integrated ontogeny environment ) - in this case , a separate version must be created for each IDE. We propose an approach where information about source codification elements is written directly into source files as annotations or special comments. Before committing to a version control system , the annotations are removed from the source codification to avoid codification pollution. We briefly assess the approach and delineate its limitations. ", "label": 1}
{"original_text": "We consider a point-to-point communication scenario where the receiver intends to maintain a specific linear function of a message vector over a finite field. When the value of the message vector changes, which is modelled as a sparse update, the transmitter broadcasts a coded version of the modified message while the receiver uses this codeword and the current value of the linear function to update its contents. It is assumed that the transmitter has access to only the modified message and is unaware of the exact difference vector between the original and modified messages. Under the assumption that the difference vector is sparse and that its Hamming weight is at the most a known constant, the objective is to design a linear code with as small a codelength as possible that allows successful update of the linear function at the receiver. This problem is motivated by applications to distributed data storage systems. Recently, Prakash and Medard derived a lower bound on the codelength, which is independent of the size of the underlying finite field, and provided constructions that achieve this bound if the size of the finite field is sufficiently large. However, this requirement on the field size can be prohibitive for even moderate values of the system parameters. In this paper, we provide a field-size aware analysis of the function update problem, including a tighter lower bound on the codelength, and design codes that trade-off the codelength for a smaller field size requirement. We also show that the problem of designing codes for updating linear functions is related to functional index coding or generalized index coding. We first characterize the family of function update problems where linear coding can provide reduction in codelength compared to a naive transmission scheme. We then provide field-size dependent bounds on the optimal codelength, and construct coding schemes based on error correcting codes and subspace codes when the receiver maintains linear functions of striped message vector. These codes provide a trade-off between the codelength and the size of the operating finite field, and whenever the achieved codelengths equal those reported by Prakash and Medard the requirements on the size of the finite field are matched as well. Finally, for any given function update problem, we construct an equivalent functional index coding or generalized index coding problem such that any linear coding scheme is valid for the function update problem if and only if it is valid for the constructed functional index coding problem.", "text_perturb": "We consider a point-to-point communication scenario where the receiver intends to maintain a specific linear function of a message vector over a finite battleground. When the value of the message vector changes , which is modelled as a sparse update , the transmitter broadcasts a coded version of the modified message while the receiving system uses this codeword and the current value of the linear function to update its contents. It make up assumed that the transmitter has access to only the modified message and make up unaware of the exact difference vector between the original and modified messages. Under the assumption that the difference vector is sparse and that its Hamming weight is at the nearly a known constant , the objective is to design a linear code with as small a codelength as possible that allows successful update of the linear function at the receiver. This problem is move by applications to distributed data storage systems. Recently , Prakash and Medard come a lower bound on the codelength , which is independent of the size of the underlying finite field , and provided constructions that achieve this bound if the size of the finite field is sufficiently large. However , this requirement on the field of battle size can be prohibitive for even moderate values of the system parameters. In this paper , we provide a field-size aware analysis of the function update problem , including a tighter lower bound on the codelength , and design codes that trade-off the codelength for a smaller field size of it requirement. We also show that the trouble of designing codes for updating linear functions is related to functional index coding or generalized index coding. We first characterize the family of function update problems where linear coding can provide reduction in codelength compared to a primitive transmission scheme. We then provide field-size dependent bounds on the optimal codelength , and construct twit schemes based on error correcting codes and subspace codes when the receiver maintains linear functions of striped message vector. These codes allow for a trade-off between the codelength and the size of the operating finite field , and whenever the achieved codelengths equal those reported by Prakash and Medard the requirements on the size of the finite field are matched as well. Finally , for any given function update problem , we construct an equivalent functional index coding or generalized index ride problem such that any linear coding scheme is valid for the function update problem if and only if it is valid for the constructed functional index coding problem. ", "label": 1}
{"original_text": "Skills like computational thinking, problem solving, handling complexity, team-work and project management are essential for future careers and needs to be taught to students at the elementary level itself. Computer programming knowledge and skills, experiencing technology and conducting science and engineering experiments are also important for students at elementary level. However, teaching such skills effectively through active learning can be challenging for educators. In this paper, we present our approach and experiences in teaching such skills to several elementary level children using Lego Mindstorms EV3 robotics education kit. We describe our learning environment consisting of lessons, worksheets, hands-on activities and assessment. We taught students how to design, construct and program robots using components such as motors, sensors, wheels, axles, beams, connectors and gears. Students also gained knowledge on basic programming constructs such as control flow, loops, branches and conditions using a visual programming environment. We carefully observed how students performed various tasks and solved problems. We present experimental results which demonstrates that our teaching methodology consisting of both the course content and pedagogy was effective in imparting the desired skills and knowledge to elementary level children. The students also participated in a competitive World Robot Olympiad India event and qualified during the regional round which is an evidence of the effectiveness of the approach.", "text_perturb": "Skills like computational thinking , problem solving , handling complexity , team-work and project management are essential for future careers and needs to be teach to students at the elementary level itself. Computer programming knowledge and skills , experiencing technology and conducting scientific discipline and engineering experiments are also important for students at elementary level. However , teaching such skills in effect through active learning can be challenging for educators. In this paper , we present our approach and experiences in teaching such skills to respective elementary level children using Lego Mindstorms EV3 robotics education kit. We describe our learning environment consisting of lessons , worksheet , hands-on activities and assessment. We taught students how to design , construct and program robots using components such as motors , sensors , roulette wheel , axles , beams , connectors and gears. Students likewise gained knowledge on basic programming constructs such as control flow , loops , branches and conditions using a visual programming environment. We carefully observed how students performed various chore and solved problems. We present experimental results which demonstrates that our teaching methodology consisting of both the course content and pedagogy was effective in imparting the craved skills and knowledge to elementary level children. The students also participated in a competitive World Robot olympic games India event and qualified during the regional round which is an evidence of the effectiveness of the approach. ", "label": 1}
{"original_text": "Real data are often with multiple modalities or from multiple heterogeneous sources, thus forming so-called multi-view data, which receives more and more attentions in machine learning. Multi-view clustering (MVC) becomes its important paradigm. In real-world applications, some views often suffer from instances missing. Clustering on such multi-view datasets is called incomplete multi-view clustering (IMC) and quite challenging. To date, though many approaches have been developed, most of them are offline and have high computational and memory costs especially for large scale datasets. To address this problem, in this paper, we propose an One-Pass Incomplete Multi-view Clustering framework (OPIMC). With the help of regularized matrix factorization and weighted matrix factorization, OPIMC can relatively easily deal with such problem. Different from the existing and sole online IMC method, OPIMC can directly get clustering results and effectively determine the termination of iteration process by introducing two global statistics. Finally, extensive experiments conducted on four real datasets demonstrate the efficiency and effectiveness of the proposed OPIMC method.", "text_perturb": "Real data are often with multiple modalities or from multiple heterogeneous sources , thus forming alleged multi-view data , which receives more and more attentions in machine learning. Multi-view clustering ( MVC ) becomes its important paradigm. In real-world application , some views often suffer from instances missing. Clustering on such multi-view datasets is called uncomplete multi-view clustering ( IMC ) and quite challenging. To date , though many approaches bear been developed , most of them are offline and bear high computational and memory costs especially for large scale datasets. To address this problem , in this paper , we nominate an One-Pass Incomplete Multi-view Clustering framework ( OPIMC ). With the help of regularized matrix factorization and weighted matrix factorization , OPIMC can relatively easily manage with such problem. Different from the existing and sole online IMC method , OPIMC can directly get bunch results and effectively determine the termination of iteration process by introducing two global statistics. Finally , extensive experiments conducted on four real datasets attest the efficiency and effectiveness of the proposed OPIMC method. ", "label": 1}
{"original_text": "We prove that octants are cover-decomposable into multiple coverings, i.e., for any k there is an m (k) such that any m (k) -fold covering of any subset of the space with a finite number of translates of a given octant can be decomposed into k coverings. As a corollary, we obtain that any m (k) -fold covering of any subset of the plane with a finite number of homothetic copies of a given triangle can be decomposed into k coverings. Previously only some weaker bounds were known for related problems.", "text_perturb": "We prove that octants are cover-decomposable into multiple application , i. einsteinium. , for any kilobyte there is an m ( kilobyte ) such that any m ( kilobyte ) -fold covering of any subset of the space with a finite number of translates of a given octant can be decomposed into kilobyte coverings. As a corollary , we obtain that any m ( k ) -fold covering of any subset of the aeroplane with a finite number of homothetic copies of a given triangle can be decomposed into k coverings. Previously only some weaker saltation were known for related problems. ", "label": 1}
{"original_text": "We consider the learning of algorithmic tasks by mere observation of input-output pairs. Rather than studying this as a black-box discrete regression problem with no assumption whatsoever on the input-output mapping, we concentrate on tasks that are amenable to the principle of divide and conquer, and study what are its implications in terms of learning. This principle creates a powerful inductive bias that we leverage with neural architectures that are defined recursively and dynamically, by learning two scale-invariant atomic operations: how to split a given input into smaller sets, and how to merge two partially solved tasks into a larger partial solution. Our model can be trained in weakly supervised environments, namely by just observing input-output pairs, and in even weaker environments, using a non-differentiable reward signal. Moreover, thanks to the dynamic aspect of our architecture, we can incorporate the computational complexity as a regularization term that can be optimized by backpropagation. We demonstrate the flexibility and efficiency of the Divide-and-Conquer Network on several combinatorial and geometric tasks: convex hull, clustering, knapsack and euclidean TSP. Thanks to the dynamic programming nature of our model, we show significant improvements in terms of generalization error and computational complexity.", "text_perturb": "We consider the learning of algorithmic tasks by mere observation of input-output couple. Rather than studying this as a black-box discrete regression problem with no august  whatsoever on the input-output mapping , we concentrate on tasks that are amenable to the principle of divide and conquer , and study what are its implications in terms of learning. This principle creates a powerful inductive preconception that we leverage with neural architectures that are defined recursively and dynamically , by learning two scale-invariant atomic operations : how to split a given input into smaller sets , and how to merge two partially solved tasks into a larger partial solution. Our model can be trained in weakly supervised environments , namely by only observing input-output pairs , and in even weaker environments , using a non-differentiable reward signal. Moreover , thanks to the dynamic aspect of our architecture , we can incorporate the computational complexity as a regulation term that can be optimized by backpropagation. We demonstrate the flexibility and efficiency of the Divide-and-Conquer Network on various combinatorial and geometric tasks : convex hull , clustering , knapsack and euclidean TSP. Thanks to the dynamic programming nature of our model , we point significant improvements in terms of generalization error and computational complexity. ", "label": 1}
{"original_text": "In unsupervised classification, Hidden Markov Models (HMM) are used to account for a neighborhood structure between observations. The emission distributions are often supposed to belong to some parametric family. In this paper, a semiparametric modeling where the emission distributions are a mixture of parametric distributions is proposed to get a higher flexibility. We show that the classical EM algorithm can be adapted to infer the model parameters. For the initialisation step, starting from a large number of components, a hierarchical method to combine them into the hidden states is proposed. Three likelihood-based criteria to select the components to be combined are discussed. To estimate the number of hidden states, BIC-like criteria are derived. A simulation study is carried out both to determine the best combination between the merging criteria and the model selection criteria and to evaluate the accuracy of classification. The proposed method is also illustrated using a biological dataset from the model plant Arabidopsis thaliana. A R package HMMmix is freely available on the CRAN.", "text_perturb": "In unsupervised classification , Hidden Markov Models ( HMM ) are use to account for a neighborhood structure between observations. The expelling distributions are often supposed to belong to some parametric family. In this paper , a semiparametric modeling where the emission distributions are a mixture of parametric distributions is proposed to start a higher flexibility. We show that the classical EM algorithmic rule can be adapted to infer the model parameters. For the initialisation step , starting from a large number of components , a hierarchical method acting to combine them into the hidden states is proposed. Three likelihood-based measure to select the components to be combined are discussed. To estimate the numeral of hidden states , BIC-like criteria are derived. A feigning study is carried out both to determine the best combination between the merging criteria and the model selection criteria and to evaluate the accuracy of classification. The proposed method is also illustrated using a biological dataset from the model plant life Arabidopsis thaliana. A R package HMMmix is freely available on the cran. ", "label": 1}
{"original_text": "Neural Architecture Search (NAS) has shown great potentials in finding a better neural network design than human design. Sample-based NAS is the most fundamental method aiming at exploring the search space and evaluating the most promising architecture. However, few works have focused on improving the sampling efficiency for a multi-objective NAS. Inspired by the nature of the graph structure of a neural network, we propose BOGCN-NAS, a NAS algorithm using Bayesian Optimization with Graph Convolutional Network (GCN) predictor. Specifically, we apply GCN as a surrogate model to adaptively discover and incorporate nodes structure to approximate the performance of the architecture. For NAS-oriented tasks, we also design a weighted loss focusing on architectures with high performance. Our method further considers an efficient multi-objective search which can be flexibly injected into any sample-based NAS pipelines to efficiently find the best speedaccuracy trade-off. Extensive experiments are conducted to verify the effectiveness of our method over many competing methods, e.g. 128.4 x more efficient than Random Search and 7.8 x more efficient than previous SOTA LaNAS for finding the best architecture on the largest NAS dataset NASBench-101.", "text_perturb": "Neural architecture Search ( NAS ) has shown great potentials in finding a better neural network design than human design. Sample-based NAS is the virtually fundamental method aiming at exploring the search space and evaluating the virtually promising architecture. However , few works have concenter on improving the sampling efficiency for a multi-objective NAS. Inspired by the nature of the graph structure of a neural network , we propose BOGCN-NAS , a NAS algorithm using Bayesian Optimization with Graph Convolutional mesh ( GCN ) predictor. Specifically , we enforce GCN as a surrogate model to adaptively discover and incorporate nodes structure to approximate the performance of the architecture. For NAS-oriented tasks , we also project a weighted loss focusing on architectures with high performance. Our method further considers an efficient multi-objective search which can be flexibly injected into any sample-based NAS line to efficiently find the best speedaccuracy trade-off. Extensive experiments are conducted to verify the effectiveness of our method over many competing methods , atomic number . gib. 128. 4 x to a greater extent efficient than Random Search and 7. 8 x more efficient than previous SOTA LaNAS for determine the best architecture on the largest NAS dataset NASBench-101. ", "label": 1}
{"original_text": "In this paper, we develop a Bayesian evidence maximization framework to solve the sparse non-negative least squares problem (S-NNLS). We introduce a family of scale mixtures referred as to Rectified Gaussian Scale Mixture (R-GSM) to model the sparsity enforcing prior distribution for the signal of interest. Through proper choice of the mixing density, the R-GSM prior encompasses a wide variety of heavy-tailed distributions such as the rectified Laplacian and rectified Student-t distributions. Utilizing the hierarchical representation induced by the scale mixture prior, an evidence maximization or Type II estimation method based on the expectation-maximization (EM) framework is developed to estimate the hyper-parameters and to obtain a point estimate of the parameter of interest. In the proposed method, called rectified Sparse Bayesian Learning (R-SBL), we provide four alternative approaches that offer a range of options to trade-off computational complexity to quality of the E-step computation. The methods include the Markov Chain Monte Carlo EM, linear minimum mean square estimation, approximate message passing and a diagonal approximation. Through numerical experiments, we show that the proposed R-SBL method outperforms existing S-NNLS solvers in terms of both signal and support recovery.", "text_perturb": "In this paper , we develop a Bayesian evidence maximization framework to solve the sparse non-negative least square toes problem ( S-NNLS ). We introduce a fellowship of scale mixtures referred as to Rectified Gaussian Scale Mixture ( R-GSM ) to model the sparsity enforcing prior distribution for the signal of interest. Through proper choice of the mixing density , the R-GSM prior encompasses a wide variety of heavy-tailed statistical distribution such as the rectified Laplacian and rectified Student-t statistical distribution. Utilizing the hierarchical representation induced by the scale mixture prior , an evidence maximization or Type II estimation method based on the expectation-maximization ( EM ) framework follow developed to estimate the hyper-parameters and to obtain a point estimate of the parameter of interest. In the proposed method , called rectified Sparse Bayesian Learning ( R-SBL ) , we provide four alternative approaches that offer a range of options to trade-off computational complexity to quality of the E-step calculation. The methods include the Markov Chain Monte Carlo EM , linear minimum mean square estimation , approximate message loss and a diagonal approximation. Through numerical experiments , we show that the proposed R-SBL method acting outperforms existing S-NNLS solvers in terms of both signal and support recovery. ", "label": 1}
{"original_text": "To reduce the training time of large-scale Deep Neural Networks (DNNs), scientists have started to explore parallelization strategies like data-parallelism, model-parallelism, and hybrid-parallelism. While data-parallelism has been extensively studied and developed, several problems exist in realizing model-parallelism and hybrid-parallelism efficiently. Four major problems we focus on are: 1) defining a notion of a distributed model across processes, 2) implementing forwardback-propagation across process boundaries that requires explicit communication, 3) obtaining parallel speedup on an inherently sequential task, and 4) achieving scalability without losing out on a model's accuracy. To address these problems, we create HyPar-Flow - a model-size-type agnostic, scalable, practical, and user-transparent system for hybrid-parallel training by exploiting MPI, Keras, and TensorFlow. HyPar-Flow provides a single API that can be used to perform data, model, and hybrid parallel training of any Keras model at scale. We create an internal distributed representation of the user-provided Keras model, utilize TF's Eager execution features for distributed forwardback-propagation across processes, exploit pipelining to improve performance and leverage efficient MPI primitives for scalable communication. Between model partitions, we use send and recv to exchange layer-datapartial-errors while allreduce is used to accumulateaverage gradients across model replicas. Beyond the design and implementation of HyPar-Flow, we also provide comprehensive correctness and performance results on three state-of-the-art HPC systems including TACC Frontera (5 on Top500.org). For ResNet-1001, an ultra-deep model, HyPar-Flow provides: 1) Up to 1.6 x speedup over Horovod-based data-parallel training, 2) 110 x speedup over single-node on 128 Stampede2 nodes, and 3) 481 x speedup over single-node on 512 Frontera nodes.", "text_perturb": "To subjugate the training time of large-scale Deep Neural Networks ( DNNs ) , scientists have started to explore parallelization strategies like data-parallelism , model-parallelism , and hybrid-parallelism. While data-parallelism sustain been extensively studied and developed , several problems exist in realizing model-parallelism and hybrid-parallelism efficiently. Four major problems we focus on are : 1 ) defining a notion of a distributed model across processes , 2 ) go through forwardback-propagation across process boundaries that requires explicit communication , 3 ) obtaining parallel speedup on an inherently sequential task , and 4 ) achieving scalability without losing out on a model 's accuracy. To address these problems , we make HyPar-Flow - a model-size-type agnostic , scalable , practical , and user-transparent system for hybrid-parallel training by exploiting MPI , Keras , and TensorFlow. HyPar-Flow provides a single API that can be used to do data , model , and hybrid parallel training of any Keras model at scale. We create an internal distributed representation of the user-provided Keras model , utilize TF 's eagre execution features for distributed forwardback-propagation across processes , exploit pipelining to improve performance and leverage efficient MPI primitives for scalable communication. Between exemplar partitions , we use send and recv to exchange layer-datapartial-errors while allreduce is used to accumulateaverage gradients across exemplar replicas. Beyond the blueprint and implementation of HyPar-Flow , we also provide comprehensive correctness and performance results on three state-of-the-art HPC systems including TACC Frontera ( 5 on Top500. org ). For ResNet-1001 , an ultra-deep simulation , HyPar-Flow provides : 1 ) Up to 1. 6 x quickening over Horovod-based data-parallel training , 2 ) 110 x quickening over single-node on 128 Stampede2 nodes , and 3 ) 481 x quickening over single-node on 512 Frontera nodes. ", "label": 1}
{"original_text": "This paper analyzes the effects of approximate multiplication when performing inferences on deep convolutional neural networks (CNNs). The approximate multiplication can reduce the cost of underlying circuits so that CNN inferences can be performed more efficiently in hardware accelerators. The study identifies the critical factors in the convolution, fully-connected, and batch normalization layers that allow more accurate CNN predictions despite the errors from approximate multiplication. The same factors also provide an arithmetic explanation of why bfloat16 multiplication performs well on CNNs. The experiments are performed with recognized network architectures to show that the approximate multipliers can produce predictions that are nearly as accurate as the FP32 references, without additional training. For example, the ResNet and Inception-v4 models with Mitch- w 6 multiplication produces Top-5 errors that are within 0.2 compared to the FP32 references. A brief cost comparison of Mitch- w 6 against bfloat16 is presented, where a MAC operation saves up to 80 of energy compared to the bfloat16 arithmetic. The most far-reaching contribution of this paper is the analytical justification that multiplications can be approximated while additions need to be exact in CNN MAC operations.", "text_perturb": "This report analyzes the effects of approximate multiplication when performing inferences on deep convolutional neural networks ( CNNs ). The approximate multiplication can reduce the cost of underlying circuits so that CNN inferences can be performed more expeditiously in hardware accelerators. The study identifies the critical factors in the convolution , fully-connected , and batch normalization stratum that allow more accurate CNN predictions despite the errors from approximate multiplication. The same factors as well provide an arithmetic explanation of why bfloat16 multiplication performs well on CNNs. The experiments are performed with recognized network architectures to show that the approximate multipliers can produce predictions that are nearly as accurate as the FP32 cite , without additional training. For example , the ResNet and Inception-v4 models with Mitch- atomic number  6 multiplication produces Top-5 errors that are within 0. 2 compared to the FP32 references. A brief cost comparison of Mitch- w 6 against bfloat16 is presented , where a MAC operation salve up to 80 of energy compared to the bfloat16 arithmetic. The most far-reaching contribution of this paper is the analytical justification that multiplications can be approximated while additions postulate to be exact in CNN MAC operations. ", "label": 1}
{"original_text": "In this paper, we develop a new accelerated stochastic gradient method for efficiently solving the convex regularized empirical risk minimization problem in mini-batch settings. The use of mini-batches is becoming a golden standard in the machine learning community, because mini-batch settings stabilize the gradient estimate and can easily make good use of parallel computing. The core of our proposed method is the incorporation of our new \"double acceleration\" technique and variance reduction technique. We theoretically analyze our proposed method and show that our method much improves the mini-batch efficiencies of previous accelerated stochastic methods, and essentially only needs size n mini-batches for achieving the optimal iteration complexities for both non-strongly and strongly convex objectives, where n is the training set size. Further, we show that even in non-mini-batch settings, our method achieves the best known convergence rate for both non-strongly and strongly convex objectives.", "text_perturb": "In this paper , we develop a new speed up stochastic gradient method for efficiently solving the convex regularized empirical risk minimization problem in mini-batch settings. The use of mini-batches make up becoming a golden standard in the machine learning community , because mini-batch settings stabilize the gradient estimate and can easily make good use of parallel computing. The core of our declare oneself method is the incorporation of our new `` double acceleration '' technique and variance reduction technique. We theoretically analyze our proposed method and show that our method much improves the mini-batch efficiencies of previous accelerated stochastic methods , and essentially only needs size n mini-batches for achieving the optimal iteration complexities for both non-strongly and strongly bulging objectives , where n is the training set size. further , we show that even in non-mini-batch settings , our method achieves the best known convergence rate for both non-strongly and strongly convex objectives. ", "label": 1}
{"original_text": "In service computing, the same target functions can be achieved by multiple Web services from different providers. Due to the functional similarities, the client needs to consider the non-functional criteria. However, Quality of Service provided by the developers suffers scarcity and lack of reliability. In addition, the reputation of the service providers is an important factor, especially those with little experience, to select a service. Most of the previous studies were focused on the user's feedbacks for justifying the selection. Unfortunately, not all the users provide the feedback unless they had extremely good or bad experience with the service. In this vision paper, we propose a novel architecture for the web service discovery and selection. The core component is a machine learning based methodology to predict the QoS properties using source code metrics. The credibility value and previous usage count are used to determine the reputation of the service.", "text_perturb": "In service computing , the like target functions can be achieved by multiple Web services from different providers. due to the functional similarities , the client needs to consider the non-functional criteria. However , Quality of Service supply by the developers suffers scarcity and lack of reliability. In summation , the reputation of the service providers is an important factor , especially those with little experience , to select a service. Most of the previous studies constitute focused on the user 's feedbacks for justifying the selection. Unfortunately , not all the users provide the feedback unless they had extremely good or bad experience with the robert william service. In this vision paper , we purpose a novel architecture for the web service discovery and selection. The core component is a machine learning based methodology to predict the QoS properties using source codification metrics. The credibility economic value and previous usage count are used to determine the reputation of the service. ", "label": 1}
{"original_text": "We study the problem of alleviating the instability issue in the GAN training procedure via new architecture design. The discrepancy between the minimax and maximin objective values could serve as a proxy for the difficulties that the alternating gradient descent encounters in the optimization of GANs. In this work, we give new results on the benefits of multi-generator architecture of GANs. We show that the minimax gap shrinks to as the number of generators increases with rate O (1). This improves over the best-known result of O (1 2). At the core of our techniques is a novel application of Shapley-Folkman lemma to the generic minimax problem, where in the literature the technique was only known to work when the objective function is restricted to the Lagrangian function of a constraint optimization problem. Our proposed Stackelberg GAN performs well experimentally in both synthetic and real-world datasets, improving Frechet Inception Distance by 14.61 over the previous multi-generator GANs on the benchmark datasets.", "text_perturb": "We study the problem of alleviating the instability issue in the GAN training procedure via new architecture figure. The discrepancy between the minimax and maximin objective values could serve as a proxy for the difficulties that the take turns gradient descent encounters in the optimization of GANs. In this work , we give modern results on the benefits of multi-generator architecture of GANs. We show that the minimax gap head shrinker to as the number of generators increases with rate O ( 1 ). This amend over the best-known result of O ( 1 2 ). At the core of our techniques is a novel application of Shapley-Folkman lemma to the generic minimax problem , where in the literature the proficiency was only known to work when the objective function is restricted to the Lagrangian function of a constraint optimization problem. Our proposed Stackelberg GAN performs easily experimentally in both synthetic and real-world datasets , improving Frechet Inception Distance by 14. 61 over the former multi-generator GANs on the benchmark datasets. ", "label": 1}
{"original_text": "Real-world scenarios demand reasoning about process, more than final outcome prediction, to discover latent causal chains and better understand complex systems. It requires the learning algorithms to offer both accurate predictions and clear interpretations. We design a set of trajectory reasoning tasks on graphs with only the source and the destination observed. We present the attention flow mechanism to explicitly model the reasoning process, leveraging the relational inductive biases by basing our models on graph networks. We study the way attention flow can effectively act on the underlying information flow implemented by message passing. Experiments demonstrate that the attention flow driven by and interacting with graph networks can provide higher accuracy in prediction and better interpretation for trajectory reasoning.", "text_perturb": "Real-world scenarios requirement reasoning about process , more than final outcome prediction , to discover latent causal chains and better understand complex systems. It requires the learning algorithms to offer both accurate anticipation and clear interpretations. We design a set of trajectory reasoning tasks on graphs with only the source and the destination celebrate. We present the attention flow mechanism to explicitly model the logical thinking process , leveraging the relational inductive biases by basing our models on graph networks. We study the way attention flow dismiss effectively act on the underlying information flow implemented by message passing. Experiments demonstrate that the attention flow driven by and interacting with graph meshing can provide higher accuracy in prediction and better interpretation for trajectory reasoning. ", "label": 1}
{"original_text": "Process mining techniques such as process discovery and conformance checking provide insights into actual processes by analyzing event data that are widely available in information systems. These data are very valuable, but often contain sensitive information, and process analysts need to balance confidentiality and utility. Privacy issues in process mining are recently receiving more attention from researchers which should be complemented by a tool to integrate the solutions and make them available in the real world. In this paper, we introduce a Python-based infrastructure implementing state-of-the-art privacy preservation techniques in process mining. The infrastructure provides a hierarchy of usages from single techniques to the collection of techniques, integrated as web-based tools. Our infrastructure manages both standard and non-standard event data resulting from privacy preservation techniques. It also stores explicit privacy metadata to track the modifications applied to protect sensitive data.", "text_perturb": "Process mining techniques such as process discovery and conformance checking allow for insights into actual processes by analyzing event data that are widely available in information systems. These data are real valuable , but often contain sensitive information , and process analysts need to balance confidentiality and utility. Privacy issues in process mining embody recently receiving more attention from researchers which should be complemented by a tool to integrate the solutions and make them available in the real world. In this paper , we put in a Python-based infrastructure implementing state-of-the-art privacy preservation techniques in process mining. The infrastructure provides a hierarchy of custom from single techniques to the collection of techniques , integrated as web-based tools. Our infrastructure manages both standard and non-standard event datum resulting from privacy preservation techniques. It also stores explicit privacy metadata to pass over the modifications applied to protect sensitive data. ", "label": 1}
{"original_text": "Segregating an audio mixture containing multiple simultaneous bird sounds is a challenging task. However, birdsong often contains rapid pitch modulations, and these modulations carry information which may be of use in automatic recognition. In this paper we demonstrate that an improved spectrogram representation, based on the distribution derivative method, leads to improved performance of a segregation algorithm which uses a Markov renewal process model to track vocalisation patterns consisting of singing and silences.", "text_perturb": "Segregating an audio mixture containing multiple simultaneous shuttle sounds is a challenging task. However , birdsong often contains rapid pitch modulations , and these modulations carry information which may be of exercise in automatic recognition. In this paper we demonstrate that an improved spectrogram representation , based on the distribution derivative method , leads to improved performance of a segregation algorithm which uses a Markov renewal process model to track vocalisation patterns consisting of telling and silences. ", "label": 1}
{"original_text": "We address the question of whether a point inside a domain bounded by a simple closed arc spline is circularly visible from a specified arc from the boundary. We provide a simple and numerically stable linear time algorithm that solves this problem. In particular, we present an easy-to-check criterion that implies that a point is not visible from a specified boundary arc.", "text_perturb": "We address the question of whether a point inside a domain bounded by a simple closed arc spline is circularly visible from a condition arc from the boundary. We supply a simple and numerically stable linear time algorithm that solves this problem. In particular , we present an easy-to-check measure that implies that a point is not visible from a specified boundary arc. ", "label": 1}
{"original_text": "In markets for online advertising, some advertisers pay only when users respond to ads. So publishers estimate ad response rates and multiply by advertiser bids to estimate expected revenue for showing ads. Since these estimates may be inaccurate, the publisher risks not selecting the ad for each ad call that would maximize revenue. The variance of revenue can be decomposed into two components - variance due to 'uncertainty' because the true response rate is unknown, and variance due to 'randomness' because realized response statistics fluctuate around the true response rate. Over a sequence of many ad calls, the variance due to randomness nearly vanishes due to the law of large numbers. However, the variance due to uncertainty doesn't diminish. We introduce a technique for ad selection that augments existing estimation and explore-exploit methods. The technique uses methods from portfolio optimization to produce a distribution over ads rather than selecting the single ad that maximizes estimated expected revenue. Over a sequence of similar ad calls, ads are selected according to the distribution. This approach decreases the effects of uncertainty and increases revenue.", "text_perturb": "In markets for online advertising , some advertisers pay only when users respond to advertisement. So publishers estimate ad response rates and multiply by advertiser play to estimate expected revenue for showing ads. Since these estimates may be inaccurate , the publisher take chances not selecting the ad for each ad call that would maximize revenue. The variance of revenue can be decomposed into two components - variance due to 'uncertainty ' because the true response rate is unknown , and variance due to 'randomness ' because realized response statistic fluctuate around the true response rate. Over a sequence of many ad calls , the divergence due to randomness nearly vanishes due to the law of large numbers. However , the variant due to uncertainty does n't diminish. We introduce a technique for ad selection that augments existing estimation and explore-exploit method acting. The technique uses methods from portfolio optimization to produce a distribution over ads rather than selecting the single ad that maximizes calculate expected revenue. Over a sequence of similar ad calls , ads are selected according to the dispersion. This approaching decreases the effects of uncertainty and increases revenue. ", "label": 1}
{"original_text": "Development of additive manufacturing in last decade greatly improves tissue engineering. During the manufacturing of porous scaffold, simplified but functionally equivalent models are getting focused for practically reasons. Scaffolds can be classified into regular porous scaffolds and irregular porous scaffolds. Several methodologies are developed to design these scaffolds. A novel method is proposed in this paper using anisotropic radial basis function (ARBF) interpolation. This is method uses geometric models such as volumetric meshes as input and proves to be flexible because geometric models are able to capture the characteristics of complex tissues easily. Moreover, this method is straightforward and easy to implement. Keywords: additive manufacturing, tissue engineering, anisotropic radial basis function, geometric models", "text_perturb": "Development of additive manufacturing in last decade greatly amend tissue engineering. During the fabrication of porous scaffold , simplified but functionally equivalent models are getting focused for practically reasons. Scaffolds can be classified into regular holey scaffolds and irregular holey scaffolds. several methodologies are developed to design these scaffolds. A novel method is proposed in this paper using anisotropic radial basis function ( ARBF ) interposition. This is method uses geometric models such as volumetric meshes as input and proves to be flexible because geometric models are able to enamour the characteristics of complex tissues easily. Moreover , this method is straightforward and leisurely to implement. Keywords : additive manufacturing , tissue engineering , anisotropic radial basis function , geometric role model", "label": 1}
{"original_text": "This paper provides a new way to improve the efficiency of the REINFORCE training process. We apply it to the task of instance selection in distant supervision. Modeling the instance selection in one bag as a sequential decision process, a reinforcement learning agent is trained to determine whether an instance is valuable or not and construct a new bag with less noisy instances. However unbiased methods, such as REINFORCE, could usually take much time to train. This paper adopts posterior regularization (PR) to integrate some domain-specific rules in instance selection using REINFORCE. As the experiment results show, this method remarkably improves the performance of the relation classifier trained on cleaned distant supervision dataset as well as the efficiency of the REINFORCE training.", "text_perturb": "This paper provides a new way to improve the efficiency of the REINFORCE breeding process. We apply it to the task of example selection in distant supervision. Modeling the instance selection in one bag as a sequential decision process , a reinforcement learning agentive role is trained to determine whether an instance is valuable or not and construct a new bag with less noisy instances. However unbiased methods , such as REINFORCE , could usually take much sentence to train. This paper adopts posterior regularization ( PR ) to incorporate some domain-specific rules in instance selection using REINFORCE. As the experiment results show , this method remarkably amend the performance of the relation classifier trained on cleaned distant supervision dataset as well as the efficiency of the REINFORCE training. ", "label": 1}
{"original_text": "In this paper, new results on convolution of spectral components in binary fields have been presented for combiatorial sequences. A novel method of convolution of DFT points through Chinese Remainder Theorem (CRT) is presented which has lower complexity as compared to known methods of spectral point computations. Exploring the inherent structures in cyclic nature of finite fields, certain fixed mappings between the spectral components from composite fields to their decomposed subfield components has been illustrated which are significant for analysis of combiner generators. Complexity estimations of our CRT based methodology of convolutions in binary fields proves that our proposed method is far efficient as comparised to to existing methods of DFT computations for convolving sequences in frequency domain.", "text_perturb": "In this report , new results on convolution of spectral components in binary fields have been presented for combiatorial sequences. A novel method acting of convolution of DFT points through Chinese Remainder Theorem ( CRT ) is presented which has lower complexity as compared to known methods of spectral point computations. Exploring the inherent structures in cyclic nature of finite fields , certain fixed mappings between the spectral components from composite fields to their decomposed subfield components take in been illustrated which are significant for analysis of combiner generators. Complexity estimations of our CRT based methodology of convolutions in binary fields proves that our proposed method is far efficient as comparised to to existing methods of DFT computations for convolving sequences in oftenness domain. ", "label": 1}
{"original_text": "The residual network is now one of the most effective structures in deep learning, which utilizes the skip connections to \"guarantee\" the performance will not get worse. However, the non-convexity of the neural network makes it unclear whether the skip connections do provably improve the learning ability since the nonlinearity may create many local minima. In some previous works, it is shown that despite the non-convexity, the loss landscape of the two-layer ReLU network has good properties when the number m of hidden nodes is very large. In this paper, we follow this line to study the topology (sub-level sets) of the loss landscape of deep ReLU neural networks with a skip connection and theoretically prove that the skip connection network inherits the good properties of the two-layer network and skip connections can help to control the connectedness of the sub-level sets, such that any local minima worse than the global minima of some two-layer ReLU network will be very \"shallow.\" The \"depth\" of these local minima are at most O (m e 1) n), where n is the input dimension, e 1. This provides a theoretical explanation for the effectiveness of the skip connection in deep learning.", "text_perturb": "The residual network is now one of the most effective structures in deep learning , which utilizes the skip connections to `` guarantee '' the performance will not get speculative. However , the non-convexity of the neural network makes it unclear whether the skip connectedness do provably improve the learning ability since the nonlinearity may create many local minima. In some previous works , it is shown that despite the non-convexity , the loss landscape of the two-layer ReLU network has good properties when the numeral m of hidden nodes is very large. In this paper , we follow this line to study the topology ( sub-level sets ) of the loss landscape of deep ReLU neural networks with a skip connection and theoretically prove that the skip connection network inherits the good properties of the two-layer network and skip connections can help to master the connectedness of the sub-level sets , such that any local minima worse than the global minima of some two-layer ReLU network will be very `` shallow. `` The `` deepness '' of these local minima are at most O ( m e 1 ) n ) , where n is the input dimension , e 1. This provides a theoretical account for the effectiveness of the skip connection in deep learning. ", "label": 1}
{"original_text": "Neural networks trained with backpropagation often struggle to identify classes that have been observed a small number of times. In applications where most class labels are rare, such as language modelling, this can become a performance bottleneck. One potential remedy is to augment the network with a fast-learning non-parametric model which stores recent activations and class labels into an external memory. We explore a simplified architecture where we treat a subset of the model parameters as fast memory stores. This can help retain information over longer time intervals than a traditional memory, and does not require additional space or compute. In the case of image classification, we display faster binding of novel classes on an Omniglot image curriculum task. We also show improved performance for word-based language models on news reports (GigaWord), books (Project Gutenberg) and Wikipedia articles (WikiText-103) - the latter achieving a state-of-the-art perplexity of 29.2.", "text_perturb": "neuronal networks trained with backpropagation often struggle to identify classes that have been observed a small number of times. In applications where most class labels are rarefied , such as language modelling , this can become a performance bottleneck. One potential remedy is to augment the network with a fast-learning non-parametric model which stores late activations and class labels into an external memory. We search a simplified architecture where we treat a subset of the model parameters as fast memory stores. This can help hold back information over longer time intervals than a traditional memory , and does not require additional space or compute. In the case of image classification , we display faster binding of novel classes on an Omniglot image course of study task. We also show improved performance for word-based language models on news reports ( GigaWord ) , books ( Project Gutenberg ) and Wikipedia clause ( WikiText-103 ) - the latter achieving a state-of-the-art perplexity of 29. 2. ", "label": 1}
{"original_text": "Recognizing multiple labels of images is a fundamental but challenging task in computer vision, and remarkable progress has been attained by localizing semantic-aware image regions and predicting their labels with deep convolutional neural networks. The step of hypothesis regions (region proposals) localization in these existing multi-label image recognition pipelines, however, usually takes redundant computation cost, e.g., generating hundreds of meaningless proposals with non-discriminative information and extracting their features, and the spatial contextual dependency modeling among the localized regions are often ignored or over-simplified. To resolve these issues, this paper proposes a recurrent attention reinforcement learning framework to iteratively discover a sequence of attentional and informative regions that are related to different semantic objects and further predict label scores conditioned on these regions. Besides, our method explicitly models long-term dependencies among these attentional regions that help to capture semantic label co-occurrence and thus facilitate multi-label recognition. Extensive experiments and comparisons on two large-scale benchmarks (i.e., PASCAL VOC and MS-COCO) show that our model achieves superior performance over existing state-of-the-art methods in both performance and efficiency as well as explicitly identifying image-level semantic labels to specific object regions.", "text_perturb": "Recognizing multiple labels of images is a fundamental but challenging task in computer vision , and remarkable progress has been attained by localizing semantic-aware image regions and predicting their labels with abstruse convolutional neural networks. The step of hypothesis regions ( realm proposals ) localization in these existing multi-label image recognition pipelines , however , usually takes redundant computation cost , e. g force. , generating hundreds of meaningless proposals with non-discriminative information and extracting their features , and the spacial contextual dependency modeling among the localized regions are often ignored or over-simplified. To resolve these issues , this paper proposes a recurrent attention reinforcement learning framework to iteratively discover a chronological succession of attentional and informative regions that are related to different semantic objects and further predict label scores conditioned on these regions. Besides , our method explicitly models long-term dependencies among these attentional regions that help to capture semantic label co-occurrence and thus help multi-label recognition. Extensive experiments and comparisons on two large-scale benchmarks ( atomic number . vitamin e. , PASCAL VOC and MS-COCO ) show that our example achieves superior performance over existing state-of-the-art methods in both performance and efficiency as well as explicitly identifying image-level semantic labels to specific object regions. ", "label": 1}
{"original_text": "Fisheye cameras are commonly used in applications like autonomous driving and surveillance to provide a large field of view (180). However, they come at the cost of strong non-linear distortion which require more complex algorithms. In this paper, we explore Euclidean distance estimation on fisheye cameras for automotive scenes. Obtaining accurate and dense depth supervision is difficult in practice, but self-supervised learning approaches show promising results and could potentially overcome the problem. We present a novel self-supervised scale-aware framework for learning Euclidean distance and ego-motion from raw monocular fisheye videos without applying rectification. While it is possible to perform piece-wise linear approximation of fisheye projection surface and apply standard rectilinear models, it has its own set of issues like re-sampling distortion and discontinuities in transition regions. To encourage further research in this area, we will release this dataset as part of our WoodScape project. We further evaluated the proposed algorithm on the KITTI dataset and obtained state-of-the-art results comparable to other self-supervised monocular methods. Qualitative results on an unseen fisheye video demonstrate impressive performance 1 1 footnote 1", "text_perturb": "Fisheye cameras are commonly used in applications like autonomous driving and surveillance to provide a with child field of view ( 180 ). However , they come at the toll of strong non-linear distortion which require more complex algorithms. In this paper , we explore Euclidean distance estimation on fisheye photographic camera for automotive scenes. Obtaining accurate and dense depth supervision is difficult in practice , but self-supervised learning approaches show promising results and could potentially overcome the job. We present a novel self-supervised scale-aware framework for learning Euclidean distance and ego-motion from unsanded monocular fisheye videos without applying rectification. While it is possible to perform piece-wise linear approximation of fisheye projection surface and apply standard rectilinear models , it has its own set of issues like re-sampling distortion and discontinuity in transition regions. To encourage further research in this area , we will release this dataset as part of our WoodScape undertaking. We further evaluated the proposed algorithm on the KITTI dataset and obtained state-of-the-art results comparable to former self-supervised monocular methods. Qualitative results on an unseen fisheye tv demonstrate impressive performance 1 1 footnote 1", "label": 1}
{"original_text": "Neural machine translation (NMT) approaches have improved the state of the art in many machine translation settings over the last couple of years, but they require large amounts of training data to produce sensible output. We demonstrate that NMT can be used for low-resource languages as well, by introducing more local dependencies and using word alignments to learn sentence reordering during translation. In addition to our novel model, we also present an empirical evaluation of low-resource phrase-based statistical machine translation (SMT) and NMT to investigate the lower limits of the respective technologies. We find that while SMT remains the best option for low-resource settings, our method can produce acceptable translations with only 70 000 tokens of training data, a level where the baseline NMT system fails completely.", "text_perturb": "Neural machine translation ( NMT ) approaches have improved the state of the art in many machine translation settings over the last couple of years , but they require large amounts of education data to produce sensible output. We demonstrate that NMT can be used for low-resource languages as well , by introducing more local dependencies and using word alignments to learn sentence reordering during rendering. In addition to our novel model , we also lay out an empirical evaluation of low-resource phrase-based statistical machine translation ( SMT ) and NMT to investigate the lower limits of the respective technologies. We find that while SMT remains the best option for low-resource mount , our method can produce acceptable translations with only 70 000 tokens of training data , a level where the baseline NMT system fails completely. ", "label": 1}
{"original_text": "Knowledge graphs capture entities and relations from long documents and can facilitate reasoning in many downstream applications. Extracting compact knowledge graphs containing only salient entities and relations is important but challenging for understanding and summarizing long documents. We introduce a new text-to-graph task of predicting summarized knowledge graphs from long documents. We develop a dataset of 200k documentgraph pairs using automatic and human annotations. We also develop strong baselines for this task based on graph learning and text summarization, and provide quantitative and qualitative studies of their effect.", "text_perturb": "Knowledge graphs capture entities and relations from longsighted documents and can facilitate reasoning in many downstream applications. Extracting compact knowledge graphs containing only salient entity and relations is important but challenging for understanding and summarizing long documents. We introduce a new text-to-graph chore of predicting summarized knowledge graphs from long documents. We develop a dataset of 200k documentgraph pairs habituate automatic and human annotations. We also develop strong baseline for this task based on graph learning and text summarization , and provide quantitative and qualitative studies of their effect. ", "label": 1}
{"original_text": "With the richness of present-day hardware architectures, tightening the synergy between hardware and software has attracted a great attention. The interest in unified approaches paved the way for newborn frameworks that target hardware and software co-design. This paper confirms that a unified statistical framework can successfully classify algorithms based on a combination of the heterogeneous characteristics of their hardware and software implementations. The proposed framework produces customizable indicators for any hybridization of processing systems and can be contextualized for any area of application. The framework is used to develop the Lightness Indicator System (LIS) as a case-study that targets a set of cryptographic algorithms that are known in the literature to be tiny and light. The LIS targets state-of-the-art multi-core processors and high-end Field Programmable Gate Arrays (FPGAs). The presented work includes a generic benchmark model that aids the clear presentation of the framework and extensive performance analysis and evaluation.", "text_perturb": "With the richness of present-day hardware architectures , tightening the synergy between hardware and software has attracted a great care. The interest in unified approaches paved the fashion for newborn frameworks that target hardware and software co-design. This paper confirms that a unified statistical framework can successfully classify algorithms free base on a combination of the heterogeneous characteristics of their hardware and software implementations. The proposed framework produces customizable index number for any hybridization of processing systems and can be contextualized for any area of application. The framework is used to develop the Lightness indicant System ( LIS ) as a case-study that targets a set of cryptographic algorithms that are known in the literature to be tiny and light. The LIS targets state-of-the-art multi-core processors and high-end Field Programmable Gate regalia ( FPGAs ). The presented work includes a generic benchmark model that aids the clear presentation of the framework and extended performance analysis and evaluation. ", "label": 1}
{"original_text": "We study the problem of leader selection in leader-follower multi-agent systems that are subject to stochastic disturbances. This problem arises in applications such as vehicle formation control, distributed clock synchronization, and distributed localization in sensor networks. We pose a new leader selection problem called the in-network leader selection problem. Initially, an arbitrary node is selected to be a leader, and in all consequent steps the network must have exactly one leader. The agents must collaborate to find the leader that minimizes the variance of the deviation from the desired trajectory, and they must do so within the network using only communication between neighbors. To develop a solution for this problem, we first show a connection between the leader selection problem and a class of discrete facility location problems. We then leverage a previously proposed self-stabilizing facility location algorithm to develop a self-stabilizing in-network leader selection algorithm for acyclic graphs.", "text_perturb": "We study the problem of leader selection in leader-follower multi-agent systems that are open to stochastic disturbances. This problem arises in applications such as vehicle formation control , dispense clock synchronization , and distributed localization in sensor networks. We pose a young leader selection problem called the in-network leader selection problem. Initially , an arbitrary lymph gland is selected to be a leader , and in all consequent steps the network must have exactly one leader. The agents must collaborate to find the leader that minimizes the variance of the deviation from the desired trajectory , and they must suffice so within the network using only communication between neighbors. To develop a solution for this job , we first show a connection between the leader selection job and a class of discrete facility location problems. We then leverage a antecedently proposed self-stabilizing facility location algorithm to develop a self-stabilizing in-network leader selection algorithm for acyclic graphs. ", "label": 1}
{"original_text": "In this paper, we investigate dynamic resource allocation (DRA) problems for Internet of Things (IoT) in real-time cloud radio access networks (C-RANs), by combining gradient boosting approximation and deep reinforcement learning to solve the following two major problems. Firstly, in C-RANs, the decision making process of resource allocation is time-consuming and computational-expensive, motivating us to use an approximation method, i.e. the gradient boosting decision tree (GBDT) to approximate the solutions of second order cone programming (SOCP) problem. Moreover, considering the innumerable states in real-time C-RAN systems, we employ a deep reinforcement learning framework, i.e., deep Q-network (DQN) to generate a robust policy that controls the status of remote radio heads (RRHs). We propose a GBDT-based DQN framework for the DRA problem, where the heavy computation to solve SOCP problems is cut down and great power consumption is saved in the whole C-RAN system. We demonstrate that the generated policy is error-tolerant even the gradient boosting regression may not be strictly subject to the constraints of the original problem. Comparisons between the proposed method and existing baseline methods confirm the advantages of our method.", "text_perturb": "In this paper , we investigate dynamic resource allocation ( DRA ) problems for Internet of Things ( IoT ) in real-time cloud radio access networks ( C-RANs ) , by combining gradient boosting approximation and cryptical reinforcement learning to solve the following two major problems. Firstly , in C-RANs , the decision making process of resource allocation is time-consuming and computational-expensive , motivating us to use an approximation method , unity. east. the gradient boosting decision tree ( GBDT ) to approximate the solutions of second fiat cone programming ( SOCP ) problem. Moreover , deal the innumerable states in real-time C-RAN systems , we employ a deep reinforcement learning framework , i. eastward. , deep Q-network ( DQN ) to generate a robust policy that controls the status of remote radio brain ( RRHs ). We propose a GBDT-based DQN framework for the DRA problem , where the heavy computation to solve SOCP problems represent cut down and great power consumption represent saved in the whole C-RAN system. We demonstrate that the generated policy is error-tolerant even the gradient boosting regression may not be strictly subject to the constraints of the original job. Comparisons between the proposed method and existing baseline method acting confirm the advantages of our method. ", "label": 1}
{"original_text": "Given a positive integer k, a k -dominating set in a graph G is a set of vertices such that every vertex not in the set has at least k neighbors in the set. A total k -dominating set, also known as a k -tuple total dominating set, is a set of vertices such that every vertex of the graph has at least k neighbors in the set. The problems of finding the minimum size of a k -dominating, respectively total k -dominating set, in a given graph, are referred to as k -domination, respectively total k -domination. These generalizations of the classical domination and total domination problems are known to be NP-hard in the class of chordal graphs, and, more specifically, even in the classes of split graphs (both problems) and undirected path graphs (in the case of total k -domination). On the other hand, it follows from recent work of Kang et al. (2017) that these two families of problems are solvable in time O (V (G) 6 k 4) in the class of interval graphs. We develop faster algorithms for k -domination and total k -domination in the class of proper interval graphs, by means of reduction to a single shortest path computation in a derived directed acyclic graph with O (V (G) 2 k) nodes and O (V (G) 4 k) arcs. We show that a suitable implementation, which avoids constructing all arcs of the digraph, leads to a running time of O (V (G) 3 k). The algorithms are also applicable to the weighted case.", "text_perturb": "Given a positive integer k , a k -dominating set in a graph G is a set of vertices such that every vertex not in the set has at least k neighbour in the set. A total k -dominating set , also known as a k -tuple total dominating set , comprise a set of vertices such that every vertex of the graph has at least k neighbors in the set. The problems of finding the minimum size of a k -dominating , severally total k -dominating set , in a given graph , are referred to as k -domination , severally total k -domination. These abstraction of the classical domination and total domination problems are known to be NP-hard in the class of chordal graphs , and , more specifically , even in the classes of split graphs ( both problems ) and undirected path graphs ( in the case of total k -domination ). On the other hand , it follows from recent study of Kang et al. ( 2017 ) that these two phratry of problems are solvable in time O ( V ( G ) 6 k 4 ) in the class of interval graphs. We develop faster algorithms for thousand -domination and total thousand -domination in the class of proper interval graphs , by means of reduction to a single shortest path computation in a derived directed acyclic graph with O ( V ( G ) 2 thousand ) nodes and O ( V ( G ) 4 thousand ) arcs. We show that a suitable implementation , which avoids constructing all spark of the digraph , leads to a running time of O ( V ( G ) 3 k ). The algorithms are also applicable to the weighted case. ", "label": 1}
{"original_text": "Many computer vision and medical imaging problems are faced with learning from large-scale datasets, with millions of observations and features. In this paper we propose a novel efficient learning scheme which tightens a sparsity constraint by gradually removing variables based on a criterion and a schedule. The attractive fact that the problem size keeps dropping throughout the iterations makes it particularly suitable for big data learning. Our approach applies generically to the optimization of any differentiable loss function, and finds applications in regression, classification and ranking. The resultant algorithms build variable screening into estimation and are extremely simple to implement. We provide theoretical guarantees of convergence and selection consistency. In addition, one dimensional piecewise linear response functions are used to account for nonlinearity and a second order prior is imposed on these functions to avoid overfitting. Experiments on real and synthetic data show that the proposed method compares very well with other state of the art methods in regression, classification and ranking while being computationally very efficient and scalable.", "text_perturb": "many computer vision and medical imaging problems are faced with learning from large-scale datasets , with millions of observations and features. In this paper we propose a novel efficient ascertain scheme which tightens a sparsity constraint by gradually removing variables based on a criterion and a schedule. The attractive fact that the problem size keep dropping throughout the iterations makes it particularly suitable for big data learning. Our approach applies generically to the optimization of any differentiable loss function , and finds diligence in regression , classification and ranking. The result algorithms build variable screening into estimation and are extremely simple to implement. We provide theoretical guarantees of overlap and selection consistency. In addition , one dimensional piecewise linear reaction functions are used to account for nonlinearity and a second order prior is imposed on these functions to avoid overfitting. Experiments on real and synthetic data read that the proposed method compares very well with other state of the art methods in regression , classification and ranking while being computationally very efficient and scalable. ", "label": 1}
{"original_text": "The similarity of the mathematical description of random-field spin systems to orthogonal frequency-division multiplexing (OFDM) scheme for wireless communication is exploited in an intercarrier-interference (ICI) canceller used in the demodulation of OFDM. The translational symmetry in the Fourier domain generically concentrates the major contribution of ICI from each subcarrier in the subcarrier's neighborhood. This observation in conjunction with mean field approach leads to a development of an ICI canceller whose necessary cost of computation scales linearly with respect to the number of subcarriers. It is also shown that the dynamics of the mean-field canceller are well captured by a discrete map of a single macroscopic variable, without taking the spatial and time correlations of estimated variables into account.", "text_perturb": "The similarity of the mathematical description of random-field spin systems to orthogonal frequency-division multiplexing ( OFDM ) scheme for wireless communicating is exploited in an intercarrier-interference ( ICI ) canceller used in the demodulation of OFDM. The translational symmetry in the Fourier domain generically concentrates the major donation of ICI from each subcarrier in the subcarrier 's neighborhood. This observation in conjunction with mean field approach leads to a development of an ICI canceller whose necessary price of computation scales linearly with respect to the number of subcarriers. It is also shown that the dynamics of the mean-field canceller are well captured by a discrete map of a single macroscopic variable , without taking the spacial and time correlations of estimated variables into account. ", "label": 1}
{"original_text": "The recently proposed multi-layer sparse model has raised insightful connections between sparse representations and convolutional neural networks (CNN). In its original conception, this model was restricted to a cascade of convolutional synthesis representations. In this paper, we start by addressing a more general model, revealing interesting ties to fully connected networks. We then show that this multi-layer construction admits a brand new interpretation in a unique symbiosis between synthesis and analysis models: while the deepest layer indeed provides a synthesis representation, the mid-layers decompositions provide an analysis counterpart. This new perspective exposes the suboptimality of previously proposed pursuit approaches, as they do not fully leverage all the information comprised in the model constraints. Armed with this understanding, we address fundamental theoretical issues, revisiting previous analysis and expanding it. Motivated by the limitations of previous algorithms, we then propose an integrated - holistic - alternative that estimates all representations in the model simultaneously, and analyze all these different schemes under stochastic noise assumptions. Inspired by the synthesis-analysis duality, we further present a Holistic Pursuit algorithm, which alternates between synthesis and analysis sparse coding steps, eventually solving for the entire model as a whole, with provable improved performance. Finally, we present numerical results that demonstrate the practical advantages of our approach.", "text_perturb": "The recently proposed multi-layer sparse model has raised insightful connections between sparse representations and convolutional neural network ( CNN ). In its original conception , this model was restricted to a cascade of convolutional synthesis histrionics. In this paper , we start by addressing a more worldwide model , revealing interesting ties to fully connected networks. We then show that this multi-layer construction admits a brand new interpretation in a unique symbiosis between synthesis and analysis models : while the deepest layer indeed provides a synthesis theatrical , the mid-layers decompositions provide an analysis counterpart. This new perspective exposes the suboptimality of previously proposed pursuit approaches , as they do not fully leverage all the information comprised in the manikin constraints. Armed with this understanding , we address profound theoretical issues , revisiting previous analysis and expanding it. Motivated by the limitations of previous algorithms , we and then propose an integrated - holistic - alternative that estimates all representations in the model simultaneously , and analyze all these different schemes under stochastic noise assumptions. Inspired by the synthesis-analysis duality , we further present a Holistic Pursuit algorithm , which alternates between synthesis and analysis sparse coding steps , finally solving for the entire model as a whole , with provable improved performance. Finally , we demo numerical results that demonstrate the practical advantages of our approach. ", "label": 1}
{"original_text": "In this paper a class of discrete optimization problems with uncertain costs is discussed. The uncertainty is modeled by introducing a scenario set containing a finite number of cost scenarios. A probability distribution over the set of scenarios is available. In order to choose a solution the weighted OWA criterion (WOWA) is applied. This criterion allows decision makers to take into account both probabilities for scenarios and the degree of pessimism optimism. In this paper the complexity of the considered class of discrete optimization problems is described and some exact and approximation algorithms for solving it are proposed. Applications to a selection and the assignment problems, together with results of computational tests are shown.", "text_perturb": "In this newspaper a class of discrete optimization problems with uncertain costs is discussed. The uncertainty is modeled by introducing a scenario set hold in a finite number of cost scenarios. A probability distribution over the circle of scenarios is available. In lodge to choose a solution the weighted OWA criterion ( WOWA ) is applied. This criterion allows decision makers to take into account both probability for scenarios and the degree of pessimism optimism. In this report the complexity of the considered class of discrete optimization problems is described and some exact and approximation algorithms for solving it are proposed. Applications to a excerpt and the assignment problems , together with results of computational tests are shown. ", "label": 1}
{"original_text": "Many algorithms for congestion control, scheduling, network measurement, active queue management, security, and load balancing require custom processing of packets as they traverse the data plane of a network switch. To run at line rate, these data-plane algorithms must be in hardware. With today's switch hardware, algorithms cannot be changed, nor new algorithms installed, after a switch has been built. This paper shows how to program data-plane algorithms in a high-level language and compile those programs into low-level microcode that can run on emerging programmable line-rate switching chipsets. The key challenge is that these algorithms create and modify algorithmic state. The key idea to achieve line-rate programmability for stateful algorithms is the notion of a packet transaction: a sequential code block that is atomic and isolated from other such code blocks. We have developed this idea in Domino, a C-like imperative language to express data-plane algorithms. We show with many examples that Domino provides a convenient and natural way to express sophisticated data-plane algorithms, and show that these algorithms can be run at line rate with modest estimated die-area overhead.", "text_perturb": "Many algorithms for over crowding control , scheduling , network measurement , active queue management , security , and load balancing require custom processing of packets as they traverse the data plane of a network switch. To run at line rate , these data-plane algorithmic rule must be in hardware. With today 's switch hardware , algorithmic rule can not be changed , nor new algorithmic rule installed , after a switch has been built. This paper shows how to program data-plane algorithms in a high altitude language and compile those programs into low-level microcode that can run on emerging programmable line-rate switching chipsets. The fundamental challenge is that these algorithms create and modify algorithmic state. The key idea to achieve line-rate programmability for stateful algorithms exist the notion of a packet transaction : a sequential code block that exist atomic and isolated from other such code blocks. We have developed this idea in antoine domino , a C-like imperative language to express data-plane algorithms. We show with many examples that Domino offer a convenient and natural way to express sophisticated data-plane algorithms , and show that these algorithms can be run at line rate with modest estimated die-area overhead. ", "label": 1}
{"original_text": "With this paper, we contribute to the growing research area of feature-based analysis of bio-inspired computing. In this research area, problem instances are classified according to different features of the underlying problem in terms of their difficulty of being solved by a particular algorithm. We investigate the impact of different sets of evolved instances for building prediction models in the area of algorithm selection. Building on the work of Poursoltan and Neumann, we consider how evolved instances can be used to predict the best performing algorithm for constrained continuous optimisation from a set of bio-inspired computing methods, namely high performing variants of differential evolution, particle swarm optimization, and evolution strategies. Our experimental results show that instances evolved with a multi-objective approach in combination with random instances of the underlying problem allow to build a model that accurately predicts the best performing algorithm for a wide range of problem instances.", "text_perturb": "With this paper , we contribute to the growing research area of feature-based analysis of bio-inspired calculation. In this research area , problem instances are classified according to different lineament of the underlying problem in terms of their difficulty of being solved by a particular algorithm. We investigate the impact of unlike sets of evolved instances for building prediction models in the area of algorithm selection. Building on the work of Poursoltan and von neumann , we consider how evolved instances can be used to predict the best performing algorithm for constrained continuous optimisation from a set of bio-inspired computing methods , namely high performing variants of differential evolution , particle swarm optimization , and evolution strategies. Our experimental results show that example evolved with a multi-objective approach in combination with random example of the underlying problem allow to build a model that accurately predicts the best performing algorithm for a wide range of problem example. ", "label": 1}
{"original_text": "Many industrial machine learning (ML) systems require frequent retraining to keep up-to-date with constantly changing data. This retraining exacerbates a large challenge facing ML systems today: model training is unstable, i.e., small changes in training data can cause significant changes in the model's predictions. In this paper, we work on developing a deeper understanding of this instability, with a focus on how a core building block of modern natural language processing (NLP) pipelines - pre-trained word embeddings - affects the instability of downstream NLP models. We first empirically reveal a tradeoff between stability and memory: increasing the embedding memory 2 x can reduce the disagreement in predictions due to small changes in training data by 5 to 37 (relative). To theoretically explain this tradeoff, we introduce a new measure of embedding instability - the eigenspace instability measure - which we prove bounds the disagreement in downstream predictions introduced by the change in word embeddings. Practically, we show that the eigenspace instability measure can be a cost-effective way to choose embedding parameters to minimize instability without training downstream models, outperforming other embedding distance measures and performing competitively with a nearest neighbor-based measure. Finally, we demonstrate that the observed stability-memory tradeoffs extend to other types of embeddings as well, including knowledge graph and contextual word embeddings.", "text_perturb": "many industrial machine learning ( ML ) systems require frequent retraining to keep up-to-date with constantly changing data. This retraining aggravate a large challenge facing ML systems today : model training is unstable , i. einsteinium. , small changes in training data can cause significant changes in the fashion model 's predictions. In this paper , we work on developing a deeper understanding of this instability , with a focus on how a core building block of modern natural language processing ( natural language processing ) pipelines - pre-trained word embeddings - affects the instability of downstream natural language processing models. We first empirically reveal a tradeoff between stability and memory : increasing the embedding memory 2 x can reduce the dissonance in predictions due to small changes in training data by 5 to 37 ( relative ). To theoretically explain this tradeoff , we introduce a new measure of embedding instability - the eigenspace instability measure - which we prove restrain the disagreement in downstream predictions introduced by the change in word embeddings. Practically , we show that the eigenspace instability measure can be a cost-effective way to choose embedding parameters to minimize instability without training downstream models , outperforming former embedding distance measures and performing competitively with a nearest neighbor-based measure. Finally , we demonstrate that the observed stability-memory tradeoffs extend to other character of embeddings as well , including knowledge graph and contextual word embeddings. ", "label": 1}
{"original_text": "Conditional Simple Temporal Network (CSTN) is a constraint-based graph-formalism for conditional temporal planning. It offers a more flexible formalism than the equivalent CSTP model of, from which it was derived mainly as a sound formalization. Three notions of consistency arise for CSTNs: weak, strong, and dynamic. Dynamic consistency is the most interesting notion, but it is also the most challenging and it was conjectured to be hard to assess. gave a doubly-exponential time algorithm for checking dynamic consistency in CSTNs and to produce an exponentially sized dynamic execution strategy whenever the input CSTN is dynamically-consistent. CSTNs may be viewed as an extension of Simple Temporal Networks (STNs), directed weighted graphs where nodes represent events to be scheduled in time and arcs represent temporal distance constraints between pairs of events. Recently, STNs have been generalized into Hyper Temporal Networks (HyTNs), by considering weighted directed hypergraphs where each hyperarc models a disjunctive temporal constraint named hyperconstraint; being directed, the hyperarcs can be either multi-head or multi-tail. The computational equivalence between checking consistency in HyTNs and determining winning regions in Mean Payoff Games (MPGs) was also pointed out; MPGs are a family of 2-player infinite pebble games played on finite graphs, which is well known for having applications in model-checking and formal verification. In this work we introduce the Conditional Hyper Temporal Network (CHyTN) model, a natural extension and generalization of both the CSTN and the HyTN model which is obtained by blending them together. We show that deciding whether a given CSTN or CHyTN is dynamically-consistent is coNP -hard; and that deciding whether a given CHyTN is dynamically-consistent is PSPACE -hard, provided that the input instances are allowed to include both multi-head and multi-tail hyperarcs. In light of this, we continue our study by focusing on CHyTNs that allow only multi-head hyperarcs, and we offer the first deterministic (pseudo) singly-exponential time algorithm for the problem of checking the dynamic consistency of such CHyTNs, also producing a dynamic execution strategy whenever the input CHyTN is dynamically-consistent. Since CSTNs are a special case of CHyTNs, as a byproduct this provides the first sound-and-complete (pseudo) singly-exponential time algorithm for checking dynamic consistency in CSTNs. The proposed algorithm is based on a novel connection between CHyTNs and MPGs; due to the existence of efficient pseudo-polynomial time algorithms for MPGs, it is quite promising to be competitive in practice. The presentation of such connection is mediated by the HyTN model. In order to analyze the time complexity of the algorithm, we introduce a refined notion of dynamic consistency, named -dynamic consistency, and present a sharp lower bounding analysis on the critical value of the reaction time e where a CHyTN transits from being, to not being, dynamically-consistent. The proof technique introduced in this analysis of e is applicable more generally when dealing with linear difference constraints which include strict inequalities.", "text_perturb": "conditional Simple Temporal Network ( CSTN ) is a constraint-based graph-formalism for conditional temporal planning. It offers a more flexible formalism than the equivalent CSTP model of , from which it was derived chiefly as a sound formalization. Three notions of consistency arise for CSTNs : weak , stiff , and dynamic. Dynamic consistency is the almost interesting notion , but it is also the almost challenging and it was conjectured to be hard to assess. gave a doubly-exponential time algorithmic rule for checking dynamic consistency in CSTNs and to produce an exponentially sized dynamic execution strategy whenever the input CSTN is dynamically-consistent. CSTNs may represent viewed as an extension of Simple Temporal Networks ( STNs ) , directed weighted graphs where nodes represent events to represent scheduled in time and arcs represent temporal distance constraints between pairs of events. Recently , STNs have been generalized into Hyper Temporal Networks ( HyTNs ) , by considering weighted directed hypergraphs where each hyperarc mannikin a disjunctive temporal constraint named hyperconstraint ; being directed , the hyperarcs can be either multi-head or multi-tail. The computational par between checking consistency in HyTNs and determining winning regions in Mean Payoff Games ( MPGs ) was also pointed out ; MPGs are a family of 2-player infinite pebble games played on finite graphs , which is well known for having applications in model-checking and formal verification. In this work we introduce the Conditional Hyper Temporal Network ( CHyTN ) model , a natural reference and generalization of both the CSTN and the HyTN model which is obtained by blending them together. We show that decide whether a given CSTN or CHyTN is dynamically-consistent is coNP -hard ; and that decide whether a given CHyTN is dynamically-consistent is PSPACE -hard , provided that the input instances are allowed to include both multi-head and multi-tail hyperarcs. In light of this , we continue our study by focusing on CHyTNs that allow only multi-head hyperarcs , and we offer the first deterministic ( pseudo ) singly-exponential time algorithm for the problem of assure the dynamic consistency of such CHyTNs , also producing a dynamic execution strategy whenever the input CHyTN is dynamically-consistent. Since CSTNs are a special case of CHyTNs , as a byproduct this provides the first sound-and-complete ( pseudo ) singly-exponential time algorithmic rule for checking dynamic consistency in CSTNs. The proposed algorithm is base on a novel connection between CHyTNs and MPGs ; due to the existence of efficient pseudo-polynomial time algorithms for MPGs , it is quite promising to be competitive in practice. The introduction of such connection is mediated by the HyTN model. In order to analyze the time complexness of the algorithm , we introduce a refined notion of dynamic consistency , named -dynamic consistency , and present a sharp lower bounding analysis on the critical value of the reaction time e where a CHyTN transits from being , to not being , dynamically-consistent. The proof technique introduced in this analysis of e is applicable more generally when dealing with linear difference constraints which include nonindulgent inequalities. ", "label": 1}
{"original_text": "Recently, Image-to-Image Translation (IIT) has achieved great progress in image style transfer and semantic context manipulation for images. However, existing approaches require exhaustively labelling training data, which is labor demanding, difficult to scale up, and hard to adapt to a new domain. To overcome such a key limitation, we propose Sparsely Grouped Generative Adversarial Networks (SG-GAN) as a novel approach that can translate images in sparsely grouped datasets where only a few train samples are labelled. Using a one-input multi-output architecture, SG-GAN is well-suited for tackling multi-task learning and sparsely grouped learning tasks. The new model is able to translate images among multiple groups using only a single trained model. To experimentally validate the advantages of the new model, we apply the proposed method to tackle a series of attribute manipulation tasks for facial images as a case study. Experimental results show that SG-GAN can achieve comparable results with state-of-the-art methods on adequately labelled datasets while attaining a superior image translation quality on sparsely grouped datasets 1 1 footnote 1 Code:", "text_perturb": "Recently , Image-to-Image Translation ( IIT ) has achieved great progress in image style transfer and semantic context manipulation for mental image. However , existing approaches require exhaustively labelling prepare data , which is labor demanding , difficult to scale up , and hard to adapt to a new domain. To overcome such a key limitation , we propose Sparsely Grouped Generative Adversarial Networks ( SG-GAN ) as a novel approach that can translate prototype in sparsely grouped datasets where only a few train samples are labelled. Using a one-input multi-output architecture , SG-GAN is well-suited for tackling multi-task learning and sparsely grouped memorise tasks. The new model is able to translate images among multiple groups using only a undivided trained model. To experimentally validate the advantages of the new model , we apply the proposed method to tackle a series of attribute manipulation tasks for facial prototype as a case study. Experimental results show that SG-GAN can achieve comparable results with state-of-the-art methods on adequately labelled datasets while attaining a superior image translation quality on sparsely group datasets 1 1 footnote 1 Code :", "label": 1}
{"original_text": "In this paper, we study the problem of 3D object detection from stereo images, in which the key challenge is how to effectively utilize stereo information. Different from previous methods using pixel-level depth maps, we propose employing 3D anchors to explicitly construct object-level correspondences between the regions of interest in stereo images, from which the deep neural network learns to detect and triangulate the targeted object in 3D space. We also introduce a cost-efficient channel reweighting strategy that enhances representational features and weakens noisy signals to facilitate the learning process. All of these are flexibly integrated into a solid baseline detector that uses monocular images. We demonstrate that both the monocular baseline and the stereo triangulation learning network outperform the prior state-of-the-arts in 3D object detection and localization on the challenging KITTI dataset.", "text_perturb": "In this paper , we study the problem of 3D object detection from stereo images , in which the key challenge is how to in effect utilize stereo information. Different from previous method using pixel-level depth maps , we propose employing 3D anchors to explicitly construct object-level correspondences between the regions of interest in stereo images , from which the deep neural network learns to detect and triangulate the targeted object in 3D space. We also introduce a cost-efficient channel reweighting strategy that enhances representational features and weakens noisy signaling to facilitate the learning process. All of these are flexibly incorporate into a solid baseline detector that uses monocular images. We demonstrate that both the monocular service line and the stereo triangulation learning network outperform the prior state-of-the-arts in 3D object detection and localization on the challenging KITTI dataset. ", "label": 1}
{"original_text": "A discrete-time Quantum Walk (QW) is essentially an operator driving the evolution of a single particle on the lattice, through local unitaries. Some QWs admit a continuum limit, leading to well-known physics partial differential equations, such as the Dirac equation. We show that these simulation results need not rely on the grid: the Dirac equation in (2 1) -dimensions can also be simulated, through local unitaries, on the honeycomb or the triangular lattice, both of interest in the study of quantum propagation on the non-rectangular grids, as in graphene-like materials. The latter, in particular, we argue, opens the door for a generalization of the Dirac equation to arbitrary discrete surfaces.", "text_perturb": "A discrete-time Quantum Walk ( QW ) is essentially an operator driving the development of a single particle on the lattice , through local unitaries. Some QWs admit a continuum limit , head to well-known physics partial differential equations , such as the Dirac equation. We show that these simulation results need not bank on the grid : the Dirac equation in ( 2 1 ) -dimensions can also be simulated , through local unitaries , on the honeycomb or the triangular lattice , both of interest in the study of quantum propagation on the non-rectangular grids , as in graphene-like materials. The latter , in particular , we argue , spread the door for a generalization of the Dirac equation to arbitrary discrete surfaces. ", "label": 1}
{"original_text": "Forecasting stock market direction is always an amazing but challenging problem in finance. Although many popular shallow computational methods (such as Backpropagation Network and Support Vector Machine) have extensively been proposed, most algorithms have not yet attained a desirable level of applicability. In this paper, we present a deep learning model with strong ability to generate high level feature representations for accurate financial prediction. Precisely, a stacked denoising autoencoder (SDAE) from deep learning is applied to predict the daily CSI 300 index, from Shanghai and Shenzhen Stock Exchanges in China. We use six evaluation criteria to evaluate its performance compared with the back propagation network, support vector machine. The experiment shows that the underlying financial model with deep machine technology has a significant advantage for the prediction of the CSI 300 index.", "text_perturb": "Forecasting stock market direction is constantly an amazing but challenging problem in finance. Although many popular shallow computational methods ( such as Backpropagation Network and Support Vector machine ) have extensively been proposed , most algorithms have not yet attained a desirable level of applicability. In this paper , we present a deep learning model with strong ability to generate high level feature histrionics for accurate financial prediction. Precisely , a stacked denoising autoencoder ( SDAE ) from deep learning is implement to predict the daily CSI 300 index , from Shanghai and Shenzhen Stock Exchanges in China. We use six evaluation criteria to evaluate its performance compared with the back propagation network , support vector car. The experiment shows that the underlying financial model with deep political machine technology has a significant advantage for the prediction of the CSI 300 index. ", "label": 1}
{"original_text": "This paper introduces a reinforcement-learning based resource allocation framework for dynamic placement of threads of parallel applications to Non-Uniform Memory Access (NUMA) many-core systems. We propose a two-level learning-based decision making process, where at the first level each thread independently decides on which group of cores (NUMA node) it will execute, and on the second level it decides to which particular core from the group it will be pinned. Additionally, a novel performance-based learning dynamics is introduced to handle measurement noise and rapid variations in the performance of the threads. Experiments on a 24-core system show the improvement of up to 16 in the execution time of parallel applications under our framework, compared to the Linux operating system scheduler.", "text_perturb": "This paper introduces a reinforcement-learning based resource assignation framework for dynamic placement of threads of parallel applications to Non-Uniform Memory Access ( NUMA ) many-core systems. We propose a two-level learning-based decision fashioning process , where at the first level each thread independently decides on which group of cores ( NUMA node ) it will execute , and on the second level it decides to which particular core from the group it will be pinned. Additionally , a novel performance-based learning dynamics is introduced to handle measurement noise and speedy variations in the performance of the threads. Experiments on a 24-core system show the improvement of up to 16 in the execution time of parallel applications under our framework , compared to the linux operating system scheduler. ", "label": 1}
{"original_text": "This note further studies the previously proposed consensus protocol for linear multi-agent systems with communication noises in. Each agent is allowed to have its own time-varying gain to attenuate the effect of communication noises. Therefore, the common assumption in most references that all agents have the same noise-attenuation gain is not necessary. It has been proved that if all noise-attenuation gains are infinitesimal of the same order, then the mean square leader-following consensus can be reached. Furthermore, the convergence rate of the multi-agent system has been investigated. If the noise-attenuation gains belong to a class of functions which are bounded above and below by t - b (b (0, 1 asymptotically, then the states of all follower agents are convergent in mean square to the leader's state with the rate characterized by a function bounded above by t - b asymptotically.", "text_perturb": "This note further studies the previously proposed consensus protocol for linear multi-agent arrangement with communication noises in. Each factor is allowed to have its own time-varying gain to attenuate the effect of communication noises. Therefore , the unwashed assumption in most references that all agents have the same noise-attenuation gain is not necessary. It has been proved that if all noise-attenuation gains are infinitesimal of the same order , then the mean square leader-following consensus can be get to. Furthermore , the convergence rate of the multi-agent system has been enquire. If the noise-attenuation gains belong to a class of functions which are bounded above and below by t - atomic number  ( atomic number  ( 0 , 1 asymptotically , then the states of all follower agents are convergent in mean square to the leader 's state with the rate characterized by a function bounded above by t - atomic number  asymptotically. ", "label": 1}
{"original_text": "Reinforcement learning with function approximation can be unstable and even divergent, especially when combined with off-policy learning and Bellman updates. In deep reinforcement learning, these issues have been dealt with empirically by adapting and regularizing the representation, in particular with auxiliary tasks. This suggests that representation learning may provide a means to guarantee stability. In this paper, we formally show that there are indeed nontrivial state representations under which the canonical TD algorithm is stable, even when learning off-policy. We analyze representation learning schemes that are based on the transition matrix of a policy, such as proto-value functions, along three axes: approximation error, stability, and ease of estimation. In the most general case, we show that a Schur basis provides convergence guarantees, but is difficult to estimate from samples. For a fixed reward function, we find that an orthogonal basis of the corresponding Krylov subspace is an even better choice. We conclude by empirically demonstrating that these stable representations can be learned using stochastic gradient descent, opening the door to improved techniques for representation learning with deep networks.", "text_perturb": "reinforcing stimulus learning with function approximation can be unstable and even divergent , especially when combined with off-policy learning and Bellman updates. In deep reinforcement learning , these issues have been dealt with empirically by adapting and regularizing the delegacy , in particular with auxiliary tasks. This suggests that representation learning may allow a means to guarantee stability. In this paper , we officially show that there are indeed nontrivial state representations under which the canonical TD algorithm is stable , even when learning off-policy. We canvas representation learning schemes that are based on the transition matrix of a policy , such as proto-value functions , along three axes : approximation error , stability , and ease of estimation. In the most general case , we show that a Schur basis allow convergence guarantees , but is difficult to estimate from samples. For a fixed reward function , we find that an orthogonal basis of the like Krylov subspace is an even better choice. We conclude by empirically demonstrating that these stable representations can be learned using stochastic gradient descent , opening the door to improve techniques for representation learning with deep networks. ", "label": 1}
{"original_text": "that capture users' dynamic intents by modeling user sequential behaviors can recommend closely accurate products to users. Previous work on is mostly focused on optimizing the recommendation accuracy, often ignoring the recommendation diversity, even though it is an important criterion for evaluating the recommendation performance. Most existing methods for improving the diversity of recommendations are not ideally applicable for because they assume that user intents are static and rely on post-processing the list of recommendations to promote diversity. We consider both recommendation accuracy and diversity for by proposing an end-to-end neural model, called. Specifically, we introduce an module into to capture different user intents reflected in user behavior sequences. Then, we design an loss to supervise the learning of the module and force the model to take recommendation diversity into consideration during training. Extensive experiments on two benchmark datasets show that significantly outperforms state-of-the-art methods in terms of recommendation diversity while yielding comparable or superior recommendation accuracy.", "text_perturb": "that capture exploiter ' dynamic intents by modeling user sequential behaviors can recommend closely accurate products to exploiter. Previous work on is mostly focused on optimizing the recommendation accuracy , often ignoring the recommendation diversity , even though it is an crucial criterion for evaluating the recommendation performance. Most existing method for improving the diversity of recommendations are not ideally applicable for because they assume that user intents are static and rely on post-processing the list of recommendations to promote diversity. We consider both recommendation accuracy and diversity for by proposing an end-to-end neural modelling , called. Specifically , we introduce an module into to captivate different user intents reflected in user behavior sequences. so , we design an loss to supervise the learning of the module and force the model to take recommendation diversity into consideration during training. Extensive experiments on two benchmark datasets show that significantly outperforms state-of-the-art methods in terms of good word diversity while yielding comparable or superior good word accuracy. ", "label": 1}
{"original_text": "This paper provides the extension of the observability rank condition and the extension of the controllability rank condition to time-varying nonlinear systems. Previous conditions to check the state observability and controllability, only account for nonlinear systems that do not explicitly depend on time, or, for time-varying systems, they only account for the linear case. In this paper, the general analytic conditions are provided. The paper shows that both these two new conditions (the extended observability rank condition and the extended controllability rank condition) reduce to the well known rank conditions for observability and controllability in the two simpler cases of time-varying linear systems and time-invariant nonlinear systems. The proposed new conditions work automatically and can deal with any system, independently of its complexity (state dimension, type of nonlinearity, etc). Simple examples illustrate both these conditions. In addition, the two new conditions are used to study the observability and the controllability properties of a lunar module. For this system, the dynamics exhibit an explicit time-dependence due to the variation of the weight and the variation of the moment of inertia. These variations are a consequence of the fuel consumption. To study the observability and the controllability properties of this system, the extended observability rank condition and the extended controllability rank condition introduced by this paper are required. The paper shows that, even under the constraint that the main rocket engine delivers constant power, the state is weakly locally controllable. Additionally, it is weakly locally observable up to the yaw angle.", "text_perturb": "This paper provides the extension of the observability rank condition and the extension of the controllability rank condition to time-varying nonlinear organisation. Previous conditions to check the state observability and controllability , only account for nonlinear scheme that do not explicitly depend on time , or , for time-varying scheme , they only account for the linear case. In this paper , the general analytic conditions make up provided. The paper shows that both these two new conditions ( the extended observability rank condition and the extended controllability rank condition ) abridge to the well known rank conditions for observability and controllability in the two simpler cases of time-varying linear systems and time-invariant nonlinear systems. The proposed new conditions work mechanically and can deal with any system , independently of its complexity ( state dimension , type of nonlinearity , etc ). Simple examples illustrate both these experimental condition. In addition , the two fresh conditions are used to study the observability and the controllability properties of a lunar module. For this system , the dynamics exhibit an explicit time-dependence due to the variation of the weight and the variation of the moment of inactiveness. These sport are a consequence of the fuel consumption. To study the observability and the controllability properties of this system , the lengthy observability rank condition and the lengthy controllability rank condition introduced by this paper are required. The paper shows that , even under the constraint that the main rocket locomotive engine delivers constant power , the state is weakly locally controllable. Additionally , it is weakly locally observable up to the yaw slant. ", "label": 1}
{"original_text": "Considering a short frame length, which is typical in Ultra-Reliable Low-Latency and massive Machine Type Communications, a trade-off exists between improving the performance of frame synchronization (FS) and improving the performance of information throughput. In this paper, we consider the case of continuous transmission over AWGN channels where the synchronization sequence is superimposed to the data symbols, as opposed to being added as a frame header. The advantage of this superposition is that the synchronization length is as long as the frame length. On the other hand, its power has to be traded-off not to degrade the code performance. We first provide the analysis of FS error probability using an approximation of the probability distribution of the overall received signal. Numerical evaluations show the tightness of our analytic results. Then we optimize the fraction of power allocated to the superimposed synchronization sequence in order to maximize the probability of receiving a frame without synchronization errors nor decoding errors. Comparison of the theoretical model predictions to a practical setup show very close optimal power allocation policies.", "text_perturb": "Considering a short frame length , which is typical in Ultra-Reliable Low-Latency and massive Machine Type Communications , a trade-off exists between ameliorate the performance of frame synchronization ( FS ) and ameliorate the performance of information throughput. In this paper , we study the case of continuous transmission over AWGN channels where the synchronization sequence is superimposed to the data symbols , as opposed to being added as a frame header. The reward of this superposition is that the synchronization length is as long as the frame length. On the other manus , its power has to be traded-off not to degrade the code performance. We first provide the analysis of FS error probability utilize an approximation of the probability distribution of the overall received signal. Numerical valuation show the tightness of our analytic results. Then we optimize the fraction of power allocated to the superimposed synchronization chronological sequence in order to maximize the probability of receiving a frame without synchronization errors nor decoding errors. Comparison of the theoretical model predictions to a practical setup show very close optimum power allocation policies. ", "label": 1}
{"original_text": "Instance-level video segmentation requires a solid integration of spatial and temporal information. However, current methods rely mostly on domain-specific information (online learning) to produce accurate instance-level segmentations. We propose a novel approach that relies exclusively on the integration of generic spatio-temporal attention cues. Our strategy, named Multi-Attention Instance Network (MAIN), overcomes challenging segmentation scenarios over arbitrary videos without modelling sequence- or instance-specific knowledge. We design MAIN to segment multiple instances in a single forward pass, and optimize it with a novel loss function that favors class agnostic predictions and assigns instance-specific penalties. We achieve state-of-the-art performance on the challenging Youtube-VOS dataset and benchmark, improving the unseen Jaccard and F-Metric by 6.8 and 12.7 respectively, while operating at real-time (30.3 FPS).", "text_perturb": "Instance-level tv segmentation requires a solid integration of spatial and temporal information. However , current methods rely mostly on domain-specific info ( online learning ) to produce accurate instance-level segmentations. We propose a novel approach path that relies exclusively on the integration of generic spatio-temporal attention cues. Our strategy , named Multi-Attention Instance Network ( MAIN ) , overcomes gainsay segmentation scenarios over arbitrary videos without modelling sequence- or instance-specific knowledge. We design MAIN to segment multiple instances in a single forward pass , and optimize it with a novel loss function that favors class agnostic predictions and depute instance-specific penalties. We achieve state-of-the-art operation on the challenging Youtube-VOS dataset and benchmark , improving the unseen Jaccard and F-Metric by 6. 8 and 12. 7 respectively , while operate on at real-time ( 30. 3 fps ). ", "label": 1}
{"original_text": "We analyse the way in which the principle that 'the whole is greater than the sum of its parts' manifests itself with phenomena of visual perception. For this investigation we use insights and techniques coming from quantum cognition, and more specifically we are inspired by the correspondence of this principle with the phenomenon of the conjunction effect in human cognition. We identify entities of meaning within artefacts of visual perception and rely on how such entities are modelled for corpuses of texts such as the webpages of the World-Wide Web for our study of how they appear in phenomena of visual perception. We identify concretely the conjunction effect in visual artefacts and analyse its structure in the example of a photograph. We also analyse quantum entanglement between different aspects of meaning in artefacts of visual perception. We confirm its presence by showing that well elected experiments on images retrieved accordingly by Google Images give rise to probabilities and expectation values violating the Clauser Horne Shimony Holt version of Bell's inequalities. We point out how this approach can lead to a mathematical description of the meaning content of a visual artefact such as a photograph.", "text_perturb": "We analyse the way in which the principle that 'the whole is greater than the sum of its parts ' manifests itself with phenomena of ocular perception. For this investigation we use insights and techniques coming from quantum cognition , and more specifically we are inspired by the correspondence of this principle with the phenomenon of the alignment effect in human cognition. We identify entities of meaning within artefacts of visual perception and rely on how such entities are modelled for corpuses of texts such as the webpage of the World-Wide Web for our study of how they appear in phenomena of visual perception. We identify concretely the conjunction effect in visual artefacts and analyse its social structure in the example of a photograph. We also analyse quantum entanglement between different aspects of meaning in artefact of visual perception. We confirm its presence by showing that well elected experiments on images retrieved accordingly by Google Images give rise to probabilities and expectation values violating the Clauser Horne Shimony Holt version of Bell 's inequality. We point out how this advance can lead to a mathematical description of the meaning content of a visual artefact such as a photograph. ", "label": 1}
{"original_text": "Verification of PCTL properties of MDPs with convex uncertainties has been investigated recently by Puggelli et al. However, model checking algorithms typically suffer from state space explosion. In this paper, we address probabilistic bisimulation to reduce the size of such an MDPs while preserving PCTL properties it satisfies. We discuss different interpretations of uncertainty in the models which are studied in the literature and that result in two different definitions of bisimulations. We give algorithms to compute the quotients of these bisimulations in time polynomial in the size of the model and exponential in the uncertain branching. Finally, we show by a case study that large models in practice can have small branching and that a substantial state space reduction can be achieved by our approach.", "text_perturb": "Verification of PCTL properties of MDPs with convex uncertainties bear been investigated recently by Puggelli et al. However , model checking algorithms typically suffer from state quad explosion. In this newspaper , we address probabilistic bisimulation to reduce the size of such an MDPs while preserving PCTL properties it satisfies. We discuss different interpretations of uncertainty in the exemplar which are studied in the literature and that result in two different definitions of bisimulations. We give algorithms to cipher the quotients of these bisimulations in time polynomial in the size of the model and exponential in the uncertain branching. Finally , we show by a case study that large models in drill can have small branching and that a substantial state space reduction can be achieved by our approach. ", "label": 1}
{"original_text": "Higher-order probabilistic programming languages allow programmers to write sophisticated models in machine learning and statistics in a succinct and structured way, but step outside the standard measure-theoretic formalization of probability theory. Programs may use both higher-order functions and continuous distributions, or even define a probability distribution on functions. But standard probability theory does not handle higher-order functions well: the category of measurable spaces is not cartesian closed. Here we introduce quasi-Borel spaces. We show that these spaces: form a new formalization of probability theory replacing measurable spaces; form a cartesian closed category and so support higher-order functions; form a well-pointed category and so support good proof principles for equational reasoning; and support continuous probability distributions. We demonstrate the use of quasi-Borel spaces for higher-order functions and probability by: showing that a well-known construction of probability theory involving random functions gains a cleaner expression; and generalizing de Finetti's theorem, that is a crucial theorem in probability theory, to quasi-Borel spaces.", "text_perturb": "Higher-order probabilistic programming languages allow programmers to write sophisticated models in simple machine learning and statistics in a succinct and structured way , but step outside the standard measure-theoretic formalization of probability theory. Programs may use both higher-order functions and continuous distributions , or even define a probability dispersion on functions. But standard probability theory does not handle higher-order functions well : the category of mensurable spaces is not cartesian closed. Here we introduce quasi-Borel spaces. We show that these spaces : work a new formalization of probability theory replacing measurable spaces ; work a cartesian closed category and so support higher-order functions ; work a well-pointed category and so support good proof principles for equational reasoning ; and support continuous probability distributions. We demonstrate the use of quasi-Borel spaces for higher-order functions and probability by : showing that a well-known construction of probability hypothesis involving random functions gains a cleaner expression ; and generalizing de Finetti 's theorem , that is a crucial theorem in probability hypothesis , to quasi-Borel spaces. ", "label": 1}
{"original_text": "In tensor completion, the latent nuclear norm is commonly used to induce low-rank structure, while substantially failing to capture the global information due to the utilization of unbalanced unfolding scheme. To overcome this drawback, a new latent nuclear norm equipped with a more balanced unfolding scheme is defined for low-rank regularizer. Moreover, the new latent nuclear norm together with the Frank-Wolfe (FW) algorithm is developed as an efficient completion method by utilizing the sparsity structure of observed tensor. Specifically, both FW linear subproblem and line search only need to access the observed entries, by which we can instead maintain the sparse tensors and a set of small basis matrices during iteration. Most operations are based on sparse tensors, and the closed-form solution of FW linear subproblem can be obtained from rank-one SVD. We theoretically analyze the space-complexity and time-complexity of the proposed method, and show that it is much more efficient over other norm-based completion methods for higher-order tensors. Extensive experimental results of visual-data inpainting demonstrate that the proposed method is able to achieve state-of-the-art performance at smaller costs of time and space, which is very meaningful for the memory-limited equipment in practical applications.", "text_perturb": "In tensor completion , the latent nuclear norm is commonly used to induce low-rank structure , while substantially give out to capture the global information due to the utilization of unbalanced unfolding scheme. To whelm this drawback , a new latent nuclear norm equipped with a more balanced unfolding scheme is defined for low-rank regularizer. Moreover , the new latent nuclear norm together with the Frank-Wolfe ( FW ) algorithm is developed as an efficient completion method acting by utilizing the sparsity structure of observed tensor. Specifically , both FW linear subproblem and line search exclusively need to access the observed entries , by which we can instead maintain the sparse tensors and a set of small basis matrices during iteration. Most operations embody based on sparse tensors , and the closed-form solution of FW linear subproblem can be obtained from rank-one SVD. We theoretically analyze the space-complexity and time-complexity of the proposed method , and show that it is lots more efficient over other norm-based completion methods for higher-order tensors. Extensive experimental results of visual-data inpainting demonstrate that the proposed method is able to achieve state-of-the-art performance at smaller costs of clock time and space , which is very meaningful for the memory-limited equipment in practical applications. ", "label": 1}
{"original_text": "In recent years, automatic video caption generation has attracted considerable attention. This paper focuses on the generation of Japanese captions for describing human actions. While most currently available video caption datasets have been constructed for English, there is no equivalent Japanese dataset. To address this, we constructed a large-scale Japanese video caption dataset consisting of 79,822 videos and 399,233 captions. Each caption in our dataset describes a video in the form of \"who does what and where.\" To describe human actions, it is important to identify the details of a person, place, and action. Indeed, when we describe human actions, we usually mention the scene, person, and action. In our experiments, we evaluated two caption generation methods to obtain benchmark results. Further, we investigated whether those generation methods could specify \"who does what and where.\" Keywords video captioning, caption generation, Japanese caption dataset, human action understanding", "text_perturb": "In recent years , automatic video caption generation ingest attracted considerable attention. This paper focuses on the generation of nipponese captions for describing human actions. While most currently available video caption datasets have equal constructed for English , there is no equivalent Japanese dataset. To address this , we constructed a large-scale Japanese video legend dataset consisting of 79,822 videos and 399,233 captions. Each caption in our dataset describes a video in the variant of `` who does what and where. `` To describe human actions , it is important to key out the details of a person , place , and action. Indeed , when we describe human actions , we usually mention the scene , someone , and action. In our experiments , we evaluated two caption contemporaries methods to obtain benchmark results. Further , we investigated whether those generation methods could peg down `` who does what and where. `` Keywords video captioning , caption generation , japanese caption dataset , human action understanding", "label": 1}
{"original_text": "In cognitive radio (CR) technology, the trend of sensing is no longer to only detect the presence of active primary users. A large number of applications demand for more comprehensive knowledge on primary user behaviors in spatial, temporal, and frequency domains. To satisfy such requirements, we study the statistical relationship among primary users by introducing a Bayesian network (BN) based framework. How to learn such a BN structure is a long standing issue, not fully understood even in the statistical learning community. Besides, another key problem in this learning scenario is that the CR has to identify how many variables are in the BN, which is usually considered as prior knowledge in statistical learning applications. To solve such two issues simultaneously, this paper proposes a BN structure learning scheme consisting of an efficient structure learning algorithm and a blind variable identification scheme. The proposed approach incurs significantly lower computational complexity compared with previous ones, and is capable of determining the structure without assuming much prior knowledge about variables. With this result, cognitive users could efficiently understand the statistical pattern of primary networks, such that more efficient cognitive protocols could be designed across different network layers.", "text_perturb": "In cognitive radio ( CR ) applied science , the trend of sensing is no longer to only detect the presence of active primary users. A large number of applications demand for more comprehensive knowledge on primary user behavior in spatial , temporal , and frequency domains. To satisfy such requirements , we study the statistical relationship among primary users by introducing a Bayesian meshwork ( BN ) based framework. How to learn such a BN structure is a long standing issue , not fully understood still in the statistical learning community. Besides , another key problem in this learning scenario is that the CR has to identify how many variables are in the BN , which is usually deliberate as prior knowledge in statistical learning applications. To solve such two issues simultaneously , this paper purpose a BN structure learning scheme consisting of an efficient structure learning algorithm and a blind variable identification scheme. The proposed approach incurs significantly lower computational complexity compared with previous ones , and is able of determining the structure without assuming much prior knowledge about variables. With this result , cognitive users could efficiently understand the statistical pattern of primary networks , such that more efficient cognitive protocols could represent designed across different network layers. ", "label": 1}
{"original_text": "Retrieving videos of a particular person with face image as query via hashing technique has many important applications. While face images are typically represented as vectors in Euclidean space, characterizing face videos with some robust set modeling techniques (e.g. covariance matrices as exploited in this study, which reside on Riemannian manifold), has recently shown appealing advantages. This hence results in a thorny heterogeneous spaces matching problem. Moreover, hashing with handcrafted features as done in many existing works is clearly inadequate to achieve desirable performance for this task. To address such problems, we present an end-to-end Deep Heterogeneous Hashing (DHH) method that integrates three stages including image feature learning, video modeling, and heterogeneous hashing in a single framework, to learn unified binary codes for both face images and videos. To tackle the key challenge of hashing on manifold, a well-studied Riemannian kernel mapping is employed to project data (i.e. covariance matrices) into Euclidean space and thus enables to embed the two heterogeneous representations into a common Hamming space, where both intra-space discriminability and inter-space compatibility are considered. To perform network optimization, the gradient of the kernel mapping is innovatively derived via structured matrix backpropagation in a theoretically principled way. Experiments on three challenging datasets show that our method achieves quite competitive performance compared with existing hashing methods.", "text_perturb": "Retrieving videos of a particular person with face image as query via hashing technique has many important application. While face images are typically comprise as vectors in Euclidean space , characterizing face videos with some robust set modeling techniques ( e. g force. covariance matrices as exploited in this study , which reside on Riemannian manifold ) , has recently shown appealing vantage. This hence results in a thorny heterogeneous spaces matching trouble. Moreover , hash with handcrafted features as done in many existing works is clearly inadequate to achieve desirable performance for this task. To address such problems , we present an end-to-end Deep Heterogeneous Hashing ( DHH ) method that integrates three stages including image feature learning , video modeling , and heterogeneous hashing in a single model , to learn unified binary codes for both face images and videos. To tackle the key challenge of hashing on manifold , a well-studied Riemannian kernel function is employed to project data ( i. einsteinium. covariance matrices ) into Euclidean space and thus enables to embed the two heterogeneous representations into a unwashed Hamming space , where both intra-space discriminability and inter-space compatibility are considered. To perform network optimization , the gradient of the kernel mapping is innovatively derived via structured ground substance backpropagation in a theoretically principled way. Experiments on three challenging datasets show that our method achieves quite an competitive performance compared with existing hashing methods. ", "label": 1}
{"original_text": "Many users communicate with chatbots and AI assistants in order to help them with various tasks. A key component of the assistant is the ability to understand and answer a user's natural language questions for question-answering (QA). Because data can be usually stored in a structured manner, an essential step involves turning a natural language question into its corresponding query language. However, in order to train most natural language-to-query-language state-of-the-art models, a large amount of training data is needed first. In most domains, this data is not available and collecting such datasets for various domains can be tedious and time-consuming. In this work, we propose a novel method for accelerating the training dataset collection for developing the natural language-to-query-language machine learning models. Our system allows one to generate conversational multi-term data, where multiple turns define a dialogue session, enabling one to better utilize chatbot interfaces. We train two current state-of-the-art NL-to-QL models, on both an SQL and SPARQL-based datasets in order to showcase the adaptability and efficacy of our created data.", "text_perturb": "Many users communicate with chatbots and AI assistants in order to help them with various task. A key component of the assistant is the ability to understand and answer a user 's natural lyric questions for question-answering ( QA ). Because data can constitute usually stored in a structured manner , an essential step involves turning a natural language question into its corresponding query language. However , in order to train most natural language-to-query-language state-of-the-art models , a large sum of money of training data is needed first. In most domains , this data is not available and collecting such datasets for various domains sack be tedious and time-consuming. In this work , we propose a novel method for accelerating the grooming dataset collection for developing the natural language-to-query-language machine learning models. Our system allows one to generate conversational multi-term information , where multiple turns define a dialogue session , enabling one to better utilize chatbot interfaces. We train two current state-of-the-art NL-to-QL manakin , on both an SQL and SPARQL-based datasets in order to showcase the adaptability and efficacy of our created data. ", "label": 1}
{"original_text": "Constraint automata are an adaptation of Buchi-automata that process data words where the data comes from some relational structure S. Every transition of such an automaton comes with constraints in terms of the relations of S. A transition can only be fired if the current and the next data values satisfy all constraints of this transition. These automata have been used in the setting where S is a linear order for deciding constraint LTL with constraints over S. In this paper, S is the infinitely branching infinite order tree T. We provide a PSPACE algorithm for emptiness of T -constraint automata. This result implies PSPACE -completeness of the satisfiability and the model checking problem for constraint LTL with constraints over T.", "text_perturb": "Constraint automata are an adjustment of Buchi-automata that process data words where the data comes from some relational structure S. Every transition of such an automaton amount with constraints in terms of the relations of S. A transition can only be fired if the current and the next data value satisfy all constraints of this transition. These automata have been used in the setting where S is a one dimensional order for deciding constraint LTL with constraints over S. In this paper , S personify the infinitely branching infinite order tree T. We provide a PSPACE algorithm for emptiness of T -constraint golem. This result implies PSPACE -completeness of the satisfiability and the good example checking problem for constraint LTL with constraints over T. ", "label": 1}
{"original_text": "In several combinatorial optimization problems arising in cryptography and design theory, the admissible solutions must often satisfy a balancedness constraint, such as being represented by bitstrings with a fixed number of ones. For this reason, several works in the literature tackling these optimization problems with Genetic Algorithms (GA) introduced new balanced crossover operators which ensure that the offspring has the same balancedness characteristics of the parents. However, the use of such operators has never been thoroughly motivated, except for some generic considerations about search space reduction. In this paper, we undertake a rigorous statistical investigation on the effect of balanced and unbalanced crossover operators against three optimization problems from the area of cryptography and coding theory: nonlinear balanced Boolean functions, binary Orthogonal Arrays (OA) and bent functions. In particular, we consider three different balanced crossover operators (each with two variants: \"left-to-right\" and \"shuffled, two of which have never been published before, and compare their performances with classic one-point crossover. We are able to confirm that the balanced crossover operators performs better than all three balanced crossover operators. Furthermore, in two out of three crossovers, the \"left-to-right\" version performs better than the \"shuffled\" version.", "text_perturb": "In several combinatorial optimization problems arising in cryptography and design theory , the admissible solutions must often satisfy a balancedness constraint , such as being symbolize by bitstrings with a fixed number of ones. For this reason , several industrial plant in the literature tackling these optimization problems with Genetic Algorithms ( GA ) introduced new balanced crossover operators which ensure that the offspring has the same balancedness characteristics of the parents. However , the use of such operators has never been thoroughly motivate , except for some generic considerations about search space reduction. In this paper , we undertake a rigorous statistical investigation on the effect of balanced and unbalanced crossover operators against three optimization problem from the area of cryptography and coding theory : nonlinear balanced Boolean functions , binary Orthogonal Arrays ( OA ) and bent functions. In particular , we weigh three different balanced crossover operators ( each with two variants : `` left-to-right '' and `` shuffled , two of which have never been published before , and compare their performances with classic one-point crossover. We are able to confirm that the balanced crossover operators performs better than all three equilibrate crossover operators. Furthermore , in two out of three crossovers , the `` left-to-right '' rendering performs better than the `` shuffled '' rendering. ", "label": 1}
{"original_text": "Most state-of-the-art semantic segmentation approaches only achieve high accuracy in good conditions. In practically-common but less-discussed adverse environmental conditions, their performance can decrease enormously. Existing studies usually cast the handling of segmentation in adverse conditions as a separate post-processing step after signal restoration, making the segmentation performance largely depend on the quality of restoration. In this paper, we propose a novel deep-learning framework to tackle semantic segmentation and image restoration in adverse environmental conditions in a holistic manner. The proposed approach contains two components: Semantically-Guided Adaptation, which exploits semantic information from degraded images to refine the segmentation; and Exemplar-Guided Synthesis, which restores images from semantic label maps given degraded exemplars as the guidance. Our method cooperatively leverages the complementarity and interdependence of low-level restoration and high-level segmentation in adverse environmental conditions. Extensive experiments on various datasets demonstrate that our approach can not only improve the accuracy of semantic segmentation with degradation cues, but also boost the perceptual quality and structural similarity of image restoration with semantic guidance.", "text_perturb": "Most state-of-the-art semantic segmentation approaches merely achieve high accuracy in good conditions. In practically-common but less-discussed untoward environmental conditions , their performance can decrease enormously. Existing studies usually cast the handling of segmentation in adverse conditions as a separate post-processing step after signal return , making the segmentation performance largely depend on the quality of return. In this paper , we propose a novel deep-learning framework to tackle semantic segmentation and image restoration in adverse environmental weather in a holistic manner. The proposed approach contains two components : Semantically-Guided Adaptation , which exploits semantic information from demean images to refine the segmentation ; and Exemplar-Guided Synthesis , which restores images from semantic label maps given degraded exemplars as the guidance. Our method cooperatively leverages the complementarity and interdependence of low level restoration and high-level segmentation in adverse environmental conditions. Extensive experiments on various datasets demonstrate that our approach can not only improve the accuracy of semantic segmentation with degradation cues , but also boost the perceptual quality and structural law of similarity of image restoration with semantic guidance. ", "label": 1}
{"original_text": "Inference on a large-scale knowledge graph (KG) is of great importance for KG applications like question answering. The path-based reasoning models can leverage much information over paths other than pure triples in the KG, which face several challenges: all the existing path-based methods are data-driven, lacking explainability for path representation. Besides, some methods either consider only relational paths or ignore the heterogeneity between entities and relations both contained in paths, which cannot capture the rich semantics of paths well. To address the above challenges, in this work, we propose a novel joint semantics and data-driven path representation that balances explainability and generalization in the framework of KG embedding. More specifically, we inject horn rules to obtain the condensed paths by the transparent and explainable path composition procedure. The entity converter is designed to transform the entities along paths into the representations in the semantic level similar to relations for reducing the heterogeneity between entities and relations, in which the KGs both with and without type information are considered. Our proposed model is evaluated on two classes of tasks: link prediction and path query answering task. The experimental results show that it has a significant performance gain over several different state-of-the-art baselines.", "text_perturb": "Inference on a large-scale knowledge graph ( KG ) is of great importance for KG lotion like question answering. The path-based reasoning models can leverage much information over paths other than pure triples in the KG , which face several challenges : all the exist path-based methods are data-driven , lacking explainability for path representation. Besides , some methods either consider alone relational paths or ignore the heterogeneity between entities and relations both contained in paths , which can not capture the rich semantics of paths well. To address the above challenges , in this work , we propose a refreshing joint semantics and data-driven path representation that balances explainability and generalization in the framework of KG embedding. More specifically , we inject horn dominion to obtain the condensed paths by the transparent and explainable path composition procedure. The entity converter is designed to transform the entities along paths into the representations in the semantic level similar to relations for reducing the heterogeneity between entities and relations , in which the KGs both with and without type information follow considered. Our proposed model is evaluated on two classes of tasks : link prediction and path enquiry answering task. The experimental results show that it has a significant public presentation gain over several different state-of-the-art baselines. ", "label": 1}
{"original_text": "Neural network models have been very successful at achieving high accuracy on natural language inference (NLI) tasks. However, as demonstrated in recent literature, when tested on some simple adversarial examples, most of the models suffer a significant drop in performance. This raises the concern about the robustness of NLI models. In this paper, we propose to make NLI models robust by incorporating external knowledge to the attention mechanism using a simple transformation. We apply the new attention to two popular types of NLI models: one is Transformer encoder, and the other is a decomposable model, and show that our method can significantly improve their robustness. Moreover, when combined with BERT pretraining, our method achieves the human-level performance on the adversarial SNLI data set.", "text_perturb": "Neural network models have been real successful at achieving high accuracy on natural language inference ( NLI ) tasks. However , as demonstrated in recent literature , when tested on some simple adversarial examples , most of the models suffer a significant drop in operation. This raises the vexation about the robustness of NLI models. In this paper , we declare oneself to make NLI models robust by incorporating external knowledge to the attention mechanism using a simple transformation. We apply the new attention to two popular types of NLI modelling : one is Transformer encoder , and the other is a decomposable model , and show that our method can significantly improve their robustness. Moreover , when combined with BERT pretraining , our method attain the human-level performance on the adversarial SNLI data set. ", "label": 1}
{"original_text": "Self-adaptive software systems (SASS) are equipped with feedback loops to adapt autonomously to changes of the software or environment. In established fields, such as embedded software, sophisticated approaches have been developed to systematically study feedback loops early during the development. In order to cover the particularities of feedback, techniques like one-way and in-the-loop simulation and testing have been included. However, a related approach to systematically test SASS is currently lacking. In this paper we therefore propose a systematic testing scheme for SASS that allows engineers to test the feedback loops early in the development by exploiting architectural runtime models. These models that are available early in the development are commonly used by the activities of a feedback loop at runtime and they provide a suitable high-level abstraction to describe test inputs as well as expected test results. We further outline our ideas with some initial evaluation results by means of a small case study.", "text_perturb": "Self-adaptive software systems ( SASS ) are equipped with feedback loops to adapt autonomously to variety of the software or environment. In established fields , such as embedded package , sophisticated approaches have been developed to systematically study feedback loops early during the development. In order to cover the particularities of feedback , techniques like one-way and in-the-loop pretense and testing have been included. However , a related approach to systematically test SASS equal currently lacking. In this paper we therefore propose a systematic testing scheme for SASS that allows engineers to test the feedback loops early in the development by exploiting architectural runtime poser. These models that are available former in the development are commonly used by the activities of a feedback loop at runtime and they provide a suitable high-level abstraction to describe test inputs as well as expected test results. We further draft our ideas with some initial evaluation results by means of a small case study. ", "label": 1}
{"original_text": "Low-power potential of mixed-signal design makes it an alluring option to accelerate Deep Neural Networks (DNNs). However, mixed-signal circuitry suffers from limited range for information encoding, susceptibility to noise, and Analog to Digital (AD) conversion overheads. This paper aims to address these challenges by offering and leveraging the insight that a vector dot-product (the basic operation in DNNs) can be bit-partitioned into groups of spatially parallel low-bitwidth operations, and interleaved across multiple elements of the vectors. As such, the building blocks of our accelerator become a group of wide, yet low-bitwidth multiply-accumulate units that operate in the analog domain and share a single AD converter. The low-bitwidth operation tackles the encoding range limitation and facilitates noise mitigation. Moreover, we utilize the switched-capacitor design for our bit-level reformulation of DNN operations. The proposed switched-capacitor circuitry performs the group multiplications in the charge domain and accumulates the results of the group in its capacitors over multiple cycles. The capacitive accumulation combined with wide bit-partitioned operations alleviate the need for AD conversion per operation. With such mathematical reformulation and its switched-capacitor implementation, we define a 3D-stacked microarchitecture, dubbed tlass 1 footnote 1 1 footnote 1 tlass: B it-Partitioned and I nterleaved Hi erarchy of W ide Acceleration through E lectrical Charge - pronounced Bee Hive - that leverages clustering and hierarchical design to best utilize power-efficiency of the mixed-signal domain and 3D stacking. For ten DNN benchmarks, tlass delivers speedupOverTetris speedup over a leading purely-digital 3D-stacked accelerator etris, with a mere of less than 0.5 accuracy loss achieved by careful treatment of noise, computation error, and various forms of variation. Compared to RTX 2080 TI with tensor cores and Titan Xp GPUs, all with 8-bit execution, tlass offers perfWattOverRTX and perfWattOverTitan higher Performance-per-Watt, respectively. ihiwe also outperforms other leading digital and analog accelerators in power efficiency. The results suggest that tlass is an effective initial step in a road that combines mathematics, circuits, and architecture.", "text_perturb": "Low-power potential of mixed-signal design nominate it an alluring option to accelerate Deep Neural Networks ( DNNs ). However , mixed-signal circuitry suffers from limited range for information encoding , susceptibility to noise , and Analog to Digital ( advert ) conversion overheads. This paper aims to address these challenges by offering and leveraging the insight that a vector dot-product ( the basic operation in DNNs ) can be bit-partitioned into groups of spatially parallel low-bitwidth operations , and interleave across multiple elements of the vectors. As such , the building blocks of our accelerator become a group of wide , yet low-bitwidth multiply-accumulate units that operate in the analog domain and portion a single AD converter. The low-bitwidth operation tackles the encoding range limitation and facilitates noise moderation. Moreover , we utilize the switched-capacitor blueprint for our bit-level reformulation of DNN operations. The proposed switched-capacitor circuitry performs the group multiplications in the charge domain of a function and accumulates the results of the group in its capacitors over multiple cycles. The capacitive accumulation combined with wide bit-partitioned operations relieve the need for AD conversion per operation. With such mathematical reformulation and its switched-capacitor implementation , we define a 3D-stacked microarchitecture , dubbed tlass 1 footnote 1 1 footnote 1 tlass : B it-Partitioned and I nterleaved Hi erarchy of W ide Acceleration through E lectrical cathexis - pronounced Bee Hive - that leverages clustering and hierarchical design to best utilize power-efficiency of the mixed-signal domain and 3D stacking. For ten DNN benchmarks , tlass delivers speedupOverTetris speedup over a in the lead purely-digital 3D-stacked accelerator etris , with a mere of less than 0. 5 accuracy loss achieved by careful discussion of noise , computation error , and various forms of variation. Compared to RTX 2080 TI with tensor cores and giant Xp GPUs , all with 8-bit execution , tlass offers perfWattOverRTX and perfWattOverTitan higher Performance-per-Watt , respectively. ihiwe also outperforms other leading digital and linear accelerators in power efficiency. The results suggest that tlass is an effective initial footprint in a road that combines mathematics , circuits , and architecture. ", "label": 1}
{"original_text": "Testing Deep Neural Network (DNN) models has become more important than ever with the increasing usage of DNN models in safety-critical domains such as autonomous cars. The traditional approach of testing DNNs is to create a test set, which is a random subset of the dataset about the problem of interest. This kind of approach is not enough for testing most of the real-world scenarios since these traditional test sets do not include corner cases, while a corner case input is generally considered to introduce erroneous behaviors. Recent works on adversarial input generation, data augmentation, and coverage-guided fuzzing (CGF) have provided new ways to extend traditional test sets. Among those, CGF aims to produce new test inputs by fuzzing existing ones to achieve high coverage on a test adequacy criterion (i.e. coverage criterion). Given that the subject test adequacy criterion is a well-established one, CGF can potentially find error inducing inputs for different underlying reasons. In this paper, we propose a novel CGF solution for structural testing of DNNs. The proposed fuzzer employs Monte Carlo Tree Search to drive the coverage-guided search in the pursuit of achieving high coverage. Our evaluation shows that the inputs generated by our method result in higher coverage than the inputs produced by the previously introduced coverage-guided fuzzing techniques.", "text_perturb": "essay Deep Neural Network ( DNN ) models has become more important than ever with the increasing usage of DNN models in safety-critical domains such as autonomous cars. The traditional approach of testing DNNs equal to create a test set , which equal a random subset of the dataset about the problem of interest. This kind of approach is non enough for testing most of the real-world scenarios since these traditional test sets do non include corner cases , while a corner case input is generally considered to introduce erroneous behaviors. Recent works on adversarial input generation , data augmentation , and coverage-guided fuzzing ( CGF ) have provided new direction to extend traditional test sets. Among those , CGF aims to produce new test inputs by fuzzing existing ones to achieve high coverage on a test adequacy measure ( i. due east. coverage touchstone ). Given that the subject test adequacy criterion is a well-established one , CGF displace potentially find error inducing inputs for different underlying reasons. In this paper , we propose a refreshing CGF solution for structural testing of DNNs. The purpose fuzzer employs Monte Carlo Tree Search to drive the coverage-guided search in the pursuit of achieving high coverage. Our evaluation shows that the inputs generated by our method acting result in higher coverage than the inputs produced by the previously introduced coverage-guided fuzzing techniques. ", "label": 1}
{"original_text": "The ICASSP 2021 Acoustic Echo Cancellation Challenge is intended to stimulate research in the area of acoustic echo cancellation (AEC), which is an important part of speech enhancement and still a top issue in audio communication and conferencing systems. Many recent AEC studies report good performance on synthetic datasets where the train and test samples come from the same underlying distribution. However, the AEC performance often degrades significantly on real recordings. Also, most of the conventional objective metrics such as echo return loss enhancement (ERLE) and perceptual evaluation of speech quality (PESQ) do not correlate well with subjective speech quality tests in the presence of background noise and reverberation found in realistic environments. In this challenge, we open source two large datasets to train AEC models under both single talk and double talk scenarios. These datasets consist of recordings from more than 2,500 real audio devices and human speakers in real environments, as well as a synthetic dataset. We open source an online subjective test framework based on ITU-T P.808 for researchers to quickly test their results. The winners of this challenge will be selected based on the average P.808 Mean Opinion Score (MOS) achieved across all different single talk and double talk scenarios.", "text_perturb": "The ICASSP 2021 Acoustic Echo Cancellation Challenge is intended to stimulate research in the area of acoustic echo cancellation ( AEC ) , which is an important part of speech enhancement and still a top issue in audio communication and conferencing arrangement. Many recent AEC studies report good performance on synthetic datasets where the wagon train and test samples come from the same underlying distribution. However , the AEC public presentation often degrades significantly on real recordings. likewise , most of the conventional objective metrics such as echo return loss enhancement ( ERLE ) and perceptual evaluation of speech quality ( PESQ ) do not correlate well with subjective speech quality tests in the presence of background noise and reverberation found in realistic environments. In this challenge , we open source two large datasets to train AEC models under both single talk and two fold talk scenarios. These datasets consist of transcription from more than 2,500 real audio devices and human speakers in real environments , as well as a synthetic dataset. We open source an online subjective test theoretical account based on ITU-T P. 808 for researcher to quickly test their results. The winners of this challenge will personify selected based on the average P. 808 Mean Opinion Score ( MOS ) achieved across all different single public lecture and double public lecture scenarios. ", "label": 1}
{"original_text": "Knuth (1990) introduced the class of nested formulas and showed that their satisfiability can be decided in polynomial time. We show that, parameterized by the size of a smallest strong backdoor set to the base class of nested formulas, checking the satisfiability of any CNF formula is fixed-parameter tractable. Thus, for any k 0, the satisfiability problem can be solved in polynomial time for any formula F for which there exists a variable set B of size at most k such that for every truth assignment t to B, the formula F [ t ] is nested; moreover, the degree of the polynomial is independent of k. Our algorithm uses the grid-minor theorem of Robertson and Seymour (1986) to either find that the incidence graph of the formula has bounded treewidth - a case that is solved using model checking for monadic second order logic - or to find many vertex-disjoint obstructions in the incidence graph. For the latter case, new combinatorial arguments are used to find a small backdoor set. Combining both cases leads to an approximation algorithm producing a strong backdoor set whose size is upper bounded by a function of the optimum. Going through all assignments to this set of variables and using Knuth's algorithm, the satisfiability of the input formula is decided.", "text_perturb": "Knuth ( 1990 ) introduced the class of nested formulas and showed that their satisfiability can make up decided in polynomial time. We show that , parameterized by the size of a smallest impregnable backdoor set to the base class of nested formulas , checking the satisfiability of any CNF formula is fixed-parameter tractable. Thus , for any k 0 , the satisfiability problem can be solved in polynomial time for any formula F for which there exists a variable set B of size at most k such that for every truth assignment t to B , the formula F [ t ] is cuddle ; moreover , the degree of the polynomial is independent of k. Our algorithm uses the grid-minor theorem of Robertson and Seymour ( 1986 ) to either find that the incidence graph of the formula has bounded treewidth - a case that is solved using model checking for monadic second gild logic - or to find many vertex-disjoint obstructions in the incidence graph. For the latter case , new combinatorial arguments are used to find a modest backdoor set. Combining both cases leads to an approximation algorithmic rule producing a strong backdoor set whose size is upper bounded by a function of the optimum. Going through all assignments to this set of variables and using Knuth 's algorithm , the satisfiability of the input recipe is decided. ", "label": 1}
{"original_text": "In recent years, sequence-to-sequence models have been very effective for end-to-end grammatical error correction (GEC). As creating human-annotated parallel corpus for GEC is expensive and time-consuming, there has been work on artificial corpus generation with the aim of creating sentences that contain realistic grammatical errors from grammatically correct sentences. In this paper, we investigate the impact of using recent neural models for generating errors to help neural models to correct errors. We conduct a battery of experiments on the effect of data size, models, and comparison with a rule-based approach.", "text_perturb": "In recent years , sequence-to-sequence models take in been very effective for end-to-end grammatical error correction ( GEC ). As creating human-annotated parallel corpus for GEC is expensive and time-consuming , there has been work on stilted corpus generation with the aim of creating sentences that contain realistic grammatical errors from grammatically correct sentences. In this paper , we investigate the impingement of using recent neural models for generating errors to help neural models to correct errors. We conduct a battery of experiments on the effect of data size , models , and comparison with a rule-based attack. ", "label": 1}
{"original_text": "The explosion in workload complexity and the recent slow-down in Moore's law scaling call for new approaches towards efficient computing. Researchers are now beginning to use recent advances in machine learning in software optimizations, augmenting or replacing traditional heuristics and data structures. However, the space of machine learning for computer hardware architecture is only lightly explored. In this paper, we demonstrate the potential of deep learning to address the von Neumann bottleneck of memory performance. We focus on the critical problem of learning memory access patterns, with the goal of constructing accurate and efficient memory prefetchers. We relate contemporary prefetching strategies to n-gram models in natural language processing, and show how recurrent neural networks can serve as a drop-in replacement. On a suite of challenging benchmark datasets, we find that neural networks consistently demonstrate superior performance in terms of precision and recall. This work represents the first step towards practical neural-network based prefetching, and opens a wide range of exciting directions for machine learning in computer architecture research.", "text_perturb": "The plosion in workload complexity and the recent slow-down in Moore 's law scaling call for new approaches towards efficient computing. Researchers are now beginning to use late advances in machine learning in software optimizations , augmenting or replacing traditional heuristics and data structures. However , the quad of machine learning for computer hardware architecture is only lightly explored. In this paper , we demonstrate the potential of deep learning to address the von Neumann constriction of memory performance. We focus on the critical job of learning memory access patterns , with the goal of constructing accurate and efficient memory prefetchers. We relate contemporary prefetching strategies to n-gram models in natural language processing , and evince how recurrent neural networks can serve as a drop-in replacement. On a suite of challenging benchmark datasets , we find that neural networks consistently demonstrate superior performance in terminal figure of precision and recall. This work represents the first step towards practical neural-network based prefetching , and opens a wide cooking stove of exciting directions for machine learning in computer architecture research. ", "label": 1}
{"original_text": "Although deep-learning-based methods have markedly improved the performance of speech separation over the past few years, it remains an open question how to integrate multi-channel signals for speech separation. We propose two methods, namely, early-fusion and late-fusion methods, to integrate multi-channel information based on the time-domain audio separation network, which has been proven effective in single-channel speech separation. We also propose channel-sequential-transfer learning, which is a transfer learning framework that applies the parameters trained for a lower-channel network as the initial values of a higher-channel network. For fair comparison, we evaluated our proposed methods using a spatialized version of the wsj0-2mix dataset, which is open-sourced. It was found that our proposed methods can outperform multi-channel deep clustering and improve the performance proportionally to the number of microphones. It was also proven that the performance of the late-fusion method is consistently higher than that of the single-channel method regardless of the angle difference between speakers.", "text_perturb": "Although deep-learning-based methods have markedly improved the performance of speech interval over the past few years , it remains an open question how to integrate multi-channel signals for speech interval. We propose two method acting , namely , early-fusion and late-fusion method acting , to integrate multi-channel information based on the time-domain audio separation network , which has been proven effective in single-channel speech separation. We also propose channel-sequential-transfer learning , which is a transfer learning model that applies the parameters trained for a lower-channel network as the initial values of a higher-channel network. For fair comparison , we evaluated our proposed methods using a spatialized version of the wsj0-2mix dataset , which follow open-sourced. It was found that our proposed methods can outperform multi-channel deep clustering and improve the performance proportionately to the number of microphones. It was also proven that the performance of the late-fusion method is consistently mellow than that of the single-channel method regardless of the angle difference between speakers. ", "label": 1}
{"original_text": "Proportional-Integral-Derivative (PID) scheme is the most commonly used algorithm for designing the controllers for unmanned aerial vehicles (UAVs). However, tuning PID gains is a non trivial task. A number of methods have been developed for tuning the PID gains for UAV systems. However, these methods do not handle wind disturbances, which is a major concern for small UAVs. In this paper, we propose a new method for determining optimized PID gains in the H 2 optimal control framework, which achieves improved wind disturbance rejection. The proposed method compares the classical PID control law with the H 2 optimal controller to determine the H 2 optimal PID gains, and involves solving a convex optimization problem. The proposed controller is tested in two scenarios, namely, vertical velocity control, and vertical position control. The results are compared with the existing LQR based PID tuning method.", "text_perturb": "Proportional-Integral-Derivative ( PID ) scheme is the most commonly used algorithm for designing the controllers for unmanned ethereal vehicles ( UAVs ). However , tuning PID gains is a non trivial undertaking. A turn of methods have been developed for tuning the PID gains for UAV systems. notwithstanding , these methods do not handle wind disturbances , which is a major concern for small UAVs. In this composition , we propose a new method for determining optimized PID gains in the H 2 optimal control framework , which achieves improved wind disturbance rejection. The proposed method compares the classical PID control law with the H 2 optimal comptroller to determine the H 2 optimal PID gains , and involves solving a convex optimization problem. The proposed controller is tested in two scenarios , namely , erect velocity control , and erect position control. The results are compared with the existing LQR base PID tuning method. ", "label": 1}
{"original_text": "In this paper, network of agents with identical dynamics is considered. The agents are assumed to be fed by self and neighboring output measurements, while the states are not available for measuring. Viewing distributed estimation as dual to the distributed LQR problem, a distributed observer is proposed by exploiting two complementary distributed LQR methods. The first consists of a bottom-up approach in which optimal interactions between self-stabilizing agents are defined so as to minimize an upper bound of the global LQR criterion. In the second (top-down) approach, the centralized optimal LQR controller is approximated by a distributed control scheme whose stability is guaranteed by the stability margins of LQR control. In this paper, distributed observer which minimizes an upper bound of a deterministic performance criterion, is proposed by solving a dual LQR problem using bottom-up approach. The cost function is defined by considering minimum-energy estimation theory where the weighting matrices have deterministic interpretation. The presented results are useful for designing optimal or near-optimal distributed controlestimation schemes.", "text_perturb": "In this paper , network of agents with monovular dynamics is considered. The agents are assumed to represent fed by self and neighboring output measurements , while the states are not available for measuring. Viewing distributed estimation as dual to the distributed LQR problem , a distributed percipient is proposed by exploiting two complementary distributed LQR methods. The first consists of a bottom-up approach in which optimal interactions between self-stabilizing agents are defined so as to minimize an upper bound of the world wide LQR criterion. In the second ( top-down ) approach , the centralized optimal LQR controller is approximated by a distributed ascendancy scheme whose stability is guaranteed by the stability margins of LQR ascendancy. In this paper , distributed observer which minimizes an upper bound of a deterministic performance criterion , is proposed by work a dual LQR problem using bottom-up approach. The cost function is defined by deal minimum-energy estimation theory where the weighting matrices have deterministic interpretation. The presented results are useful for plan optimal or near-optimal distributed controlestimation schemes. ", "label": 1}
{"original_text": "We present five variants of the standard Long Short-term Memory (LSTM) recurrent neural networks by uniformly reducing blocks of adaptive parameters in the gating mechanisms. For simplicity, we refer to these models as LSTM1, LSTM2, LSTM3, LSTM4, and LSTM5, respectively. Such parameter-reduced variants enable speeding up data training computations and would be more suitable for implementations onto constrained embedded platforms. We comparatively evaluate and verify our five variant models on the classical MNIST dataset and demonstrate that these variant models are comparable to a standard implementation of the LSTM model while using less number of parameters. Moreover, we observe that in some cases the standard LSTM's accuracy performance will drop after a number of epochs when using the ReLU nonlinearity; in contrast, however, LSTM3, LSTM4 and LSTM5 will retain their performance.", "text_perturb": "We present five variants of the standard Long Short-term Memory ( LSTM ) recurrent neural networks by uniformly reducing blocks of adaptative parameters in the gating mechanisms. For simplicity , we bear on to these models as LSTM1 , LSTM2 , LSTM3 , LSTM4 , and LSTM5 , respectively. Such parameter-reduced variants enable speeding up data training computations and would be more suitable for implementations onto constrained embedded weapons platform. We comparatively evaluate and verify our five variant models on the classical MNIST dataset and demonstrate that these variant models are comparable to a standard implementation of the LSTM model while using less number of parameter. Moreover , we observe that in some cases the received LSTM 's accuracy performance will drop after a number of epochs when using the ReLU nonlinearity ; in contrast , however , LSTM3 , LSTM4 and LSTM5 will retain their performance. ", "label": 1}
{"original_text": "Path signatures are powerful nonparametric tools for time series analysis, shown to form a universal and characteristic feature map for Euclidean valued time series data. We lift the theory of path signatures to the setting of Lie group valued time series, adapting these tools for time series with underlying geometric constraints. We prove that this generalized path signature is universal and characteristic. To demonstrate universality, we analyze the human action recognition problem in computer vision, using S O (3) representations for the time series, providing comparable performance to other shallow learning approaches, while offering an easily interpretable feature set. We also provide a two-sample hypothesis test for Lie group-valued random walks to illustrate its characteristic property. Finally we provide algorithms and a Julia implementation of these methods.", "text_perturb": "Path signatures are powerful nonparametric tools for time series analysis , shown to form a universal and characteristic feature mathematical function for Euclidean valued time series data. We lift the theory of path theme song to the setting of Lie group valued time series , adapting these tools for time series with underlying geometric constraints. We turn out that this generalized path signature is universal and characteristic. To demonstrate universality , we analyze the human action recognition problem in computer vision , using S O ( 3 ) representations for the time series , providing comparable performance to other shallow learning approaches , while offering an easily explainable feature set. We as well provide a two-sample hypothesis test for Lie group-valued random walks to illustrate its characteristic property. Finally we provide algorithms and a Julia implementation of these method. ", "label": 1}
{"original_text": "Consider the problem of sampling sequentially from a finite number of N 2 populations, specified by random variables X I k, I 1, ..., N, and k 1, 2, ...; where X I k denotes the outcome from population I the k t h time it is sampled. It is assumed that for each fixed i, {X I k } k 1 is a sequence of i.i.d. normal random variables, with unknown mean m I and unknown variance s I 2. The objective is to have a policy p for deciding from which of the N populations to sample from at any time t 1, 2, ... so as to maximize the expected sum of outcomes of n total samples or equivalently to minimize the regret due to lack on information of the parameters m I and s I 2. In this paper, we present a simple inflated sample mean (ISM) index policy that is asymptotically optimal in the sense of Theorem 4 below. This resolves a standing open problem from . Additionally, finite horizon regret bounds are given 1 1 footnote 1 Substantial portion of the results reported here were derived independently by Cowan and Katehakis, and by Honda.", "text_perturb": "Consider the job of sampling sequentially from a finite number of N 2 populations , specified by random variables X I k , I 1 ,. . . , due north , and k 1 , 2 ,. . . ; where X I k denotes the outcome from population I the k t h time it cost sampled. It is assumed that for each fixed i , { ex I k } k 1 is a sequence of i. iodine. . normal random variable quantity , with unknown mean m I and unknown variance s I 2. The objective is to have a insurance policy p for deciding from which of the N populations to sample from at any time t 1 , 2 ,. . . so as to maximize the expected sum of outcomes of n total samples or equivalently to minimize the regret due to lack on information of the parameter m I and s I 2. In this paper , we present a simple inflated sample mean value ( ISM ) index policy that is asymptotically optimal in the sense of Theorem 4 below. This resolves a digest open problem from. Additionally , finite horizon regret bounds are feed 1 1 footnote 1 Substantial portion of the results reported here were derived independently by Cowan and Katehakis , and by Honda. ", "label": 1}
{"original_text": "Long Term Evolution (LTE) is expanding its utilization in unlicensed band by deploying LTE Unlicensed (LTE-U) and Licensed Assisted Access LTE (LTE-LAA) technology. Smart Grid can take the advantages of unlicensed bands for achieving two-way communication between smart meters and utility data centers by using LTE-ULTE-LAA. However, both schemes must co-exist with the incumbent Wi-Fi system. In this paper, several co-existence schemes of Wi-Fi and LTE technology is comprehensively reviewed. The challenges of deploying LTE and Wi-Fi in the same band are clearly addressed based on the papers reviewed. Solution procedures and techniques to resolve the challenging issues are discussed in a short manner. The performance of various network architectures such as listen- before-talk (LBT) based LTE, carrier sense multiple access with collision avoidance (CSMACA) based Wi-Fi is briefly compared. Finally, an attempt is made to implement these proposed LTE-Wi-Fi models in smart grid technology.", "text_perturb": "Long Term Evolution ( LTE ) is expanding its utilization in unlicensed dance band by deploying LTE Unlicensed ( LTE-U ) and Licensed Assisted Access LTE ( LTE-LAA ) technology. Smart Grid can take the advantages of unlicensed bands for achieving two-way communication between smart beat and utility data centers by using LTE-ULTE-LAA. However , both scheme must co-exist with the incumbent Wi-Fi system. In this paper , several co-existence system of Wi-Fi and LTE technology is comprehensively reviewed. The challenges of deploying LTE and Wi-Fi in the same striation are clearly addressed based on the papers reviewed. Solution procedures and techniques to resolve the challenging issues be discussed in a short manner. The performance of various network architectures such as listen- before-talk ( LBT ) based LTE , carrier sense multiple access with hit avoidance ( CSMACA ) based Wi-Fi is briefly compared. Finally , an attempt is made to implement these offer LTE-Wi-Fi models in smart grid technology. ", "label": 1}
{"original_text": "The technological advancements of recent years have steadily increased the complexity of vehicle-internal software systems, and the ongoing development towards autonomous driving will further aggravate this situation. This is leading to a level of complexity that is pushing the limits of existing vehicle software architectures and system designs. By changing the software structure to a service-based architecture, companies in other domains successfully managed the rising complexity and created a more agile and future-oriented development process. This paper presents a case-study investigating the feasibility and possible effects of changing the software architecture for a complex driver assistance function to a microservice architecture. The complete procedure is described, starting with the description of the software-environment and the corresponding requirements, followed by the implementation, and the final testing. In addition, this paper provides a high-level evaluation of the microservice architecture for the automotive use-case. The results show that microservice architectures can reduce complexity and time-consuming process steps and make the automotive software systems prepared for upcoming challenges as long as the principles of microservice architectures are carefully followed.", "text_perturb": "The technological advancements of late years have steadily increased the complexity of vehicle-internal software systems , and the ongoing development towards autonomous driving will further aggravate this situation. This is leading to a level of complexity that is pushing the limit point of existing vehicle software architectures and system designs. By changing the software structure to a service-based architecture , companies in other domains successfully managed the come up complexity and created a more agile and future-oriented development process. This paper presents a case-study investigating the feasibility and possible effects of changing the software program architecture for a complex driver assistance function to a microservice architecture. The complete procedure is described , starting with the description of the software-environment and the corresponding requirements , followed by the implementation , and the final examination. In addition , this paper provides a high-level evaluation of the microservice computer architecture for the automotive use-case. The results show that microservice architecture can reduce complexity and time-consuming process steps and make the automotive software systems prepared for upcoming challenges as long as the principles of microservice architecture are carefully followed. ", "label": 1}
{"original_text": "Background: COVID-19 pandemics has challenged emergency response systems worldwide, with widespread reports of essential services breakdown and collapse of health care structure. A critical element involves essential workforce management since current protocols recommend release from duty for symptomatic individuals, including essential personnel. Testing capacity is also problematic in several countries, where diagnosis demand outnumbers available local testing capacity. Purpose: This work describes a machine learning model derived from hemogram exam data performed in symptomatic patients and how they can be used to predict qRT-PCR test results. Methods: A Naive-Bayes model for machine learning is proposed for handling different scarcity scenarios, including managing symptomatic essential workforce and absence of diagnostic tests. Hemogram result data was used to predict qRT-PCR results in situations where the latter was not performed, or results are not yet available. Adjusts in assumed prior probabilities allow fine-tuning of the model, according to actual prediction context. Results: Proposed models can predict COVID-19 qRT-PCR results in symptomatic individuals with high accuracy, sensitivity and specificity. Data assessment can be performed in an individual or simultaneous basis, according to desired outcome. Based on hemogram data and background scarcity context, resource distribution is significantly optimized when model-based patient selection is observed, compared to random choice. The model can help manage testing deficiency and other critical circumstances. Conclusions: Machine learning models can be derived from widely available, quick, and inexpensive exam data in order to predict qRT-PCR results used in COVID-19 diagnosis. These models can be used to assist strategic decision-making in resource scarcity scenarios, including personnel shortage, lack of medical resources, and testing insufficiency.", "text_perturb": "Background : COVID-19 pandemics has gainsay emergency response systems worldwide , with widespread reports of essential services breakdown and collapse of health care structure. A critical component involves essential workforce management since current protocols recommend release from duty for symptomatic individuals , including essential personnel. Testing capacity is too problematic in several countries , where diagnosis demand outnumbers available local testing capacity. Purpose : This piece of work describes a machine learning model derived from hemogram exam data performed in symptomatic patients and how they can be used to predict qRT-PCR test results. Methods : A Naive-Bayes model for machine learning is pop the question for handling different scarcity scenarios , including managing symptomatic essential workforce and absence of diagnostic tests. Hemogram result data was used to predict qRT-PCR results in situations where the latter was not performed , or results are not yet uncommitted. Adjusts in assumed prior probabilities allow fine-tuning of the model , according to actual forecasting context. outcome : Proposed models can predict COVID-19 qRT-PCR results in symptomatic individuals with high accuracy , sensitivity and specificity. Data assessment can be performed in an individual or simultaneous basis , according to desired termination. Based on hemogram data and background scarcity context , resource distribution represent significantly optimized when model-based patient selection represent observed , compared to random choice. The model can help manage testing deficiency and other critical consideration. Conclusions : Machine learning models can be derived from widely available , quick , and inexpensive exam data in order to predict qRT-PCR results used in COVID-19 diagnosing. These models can be used to assist strategic decision-making in resource scarceness scenarios , including personnel shortage , lack of medical resources , and testing insufficiency. ", "label": 1}
{"original_text": "Recent research on Automatic Chord Extraction (ACE) has focused on the improvement of models based on machine learning. However, most models still fail to take into account the prior knowledge underlying the labeling alphabets (chord labels). Furthermore, recent works have shown that ACE performances have reached a glass ceiling. Therefore, this prompts the need to focus on other aspects of the task, such as the introduction of musical knowledge in the representation, the improvement of the models towards more complex chord alphabets and the development of more adapted evaluation methods. In this paper, we propose to exploit specific properties and relationships between chord labels in order to improve the learning of statistical ACE models. Hence, we analyze the interdependence of the representations of chords and their associated distances, the precision of the chord alphabets, and the impact of performing alphabet reduction before or after training the model. Furthermore, we propose new training losses based on musical theory. We show that these improve the results of ACE systems based on Convolutional Neural Networks. By analyzing our results, we uncover a set of related insights on ACE tasks based on statistical models, and also formalize the musical meaning of some classification errors.", "text_perturb": "Recent research on Automatic Chord Extraction ( ACE ) has focused on the improvement of role model based on machine learning. However , most mannikin still fail to take into account the prior knowledge underlying the labeling alphabets ( chord labels ). Furthermore , recent works have shown that ACE performances have reached a glass cap. Therefore , this prompts the need to focus on other aspects of the task , such as the introduction of musical knowledge in the representation , the improvement of the models towards more complex chord alphabets and the development of to a greater extent adapted evaluation methods. In this newspaper , we propose to exploit specific properties and relationships between chord labels in order to improve the learning of statistical ACE models. Hence , we analyze the interdependence of the representations of chords and their associated distances , the precision of the chord alphabets , and the impact of performing alphabet reduction before or after training the framework. Furthermore , we propose modern training losses based on musical theory. We show that these improve the results of ACE systems based on Convolutional Neural net. By analyzing our results , we uncover a set of related insights on ACE tasks based on statistical models , and also formalise the musical meaning of some classification errors. ", "label": 1}
{"original_text": "The goal of minimizing misclassification error on a training set is often just one of several real-world goals that might be defined on different datasets. For example, one may require a classifier to also make positive predictions at some specified rate for some subpopulation (fairness), or to achieve a specified empirical recall. Other real-world goals include reducing churn with respect to a previously deployed model, or stabilizing online training. In this paper we propose handling multiple goals on multiple datasets by training with dataset constraints, using the ramp penalty to accurately quantify costs, and present an efficient algorithm to approximately optimize the resulting non-convex constrained optimization problem. Experiments on both benchmark and real-world industry datasets demonstrate the effectiveness of our approach.", "text_perturb": "The goal of minimizing misclassification error on a training hardening is often just one of several real-world goals that might be defined on different datasets. For model , one may require a classifier to also make positive predictions at some specified rate for some subpopulation ( fairness ) , or to achieve a specified empirical recall. Other real-world goals include lose weight churn with respect to a previously deployed model , or stabilizing online training. In this paper we propose handling multiple goals on multiple datasets by training with dataset constraints , using the ramp penalty to accurately quantify costs , and give an efficient algorithm to approximately optimize the resulting non-convex constrained optimization problem. Experiments on both benchmark and real-world industriousness datasets demonstrate the effectiveness of our approach. ", "label": 1}
{"original_text": "Real-world audio recordings are often degraded by factors such as noise, reverberation, and equalization distortion. This paper introduces HiFi-GAN, a deep learning method to transform recorded speech to sound as though it had been recorded in a studio. We use an end-to-end feed-forward WaveNet architecture, trained with multi-scale adversarial discriminators in both the time domain and the time-frequency domain. It relies on the deep feature matching losses of the discriminators to improve the perceptual quality of enhanced speech. The proposed model generalizes well to new speakers, new speech content, and new environments. It significantly outperforms state-of-the-art baseline methods in both objective and subjective experiments.", "text_perturb": "Real-world audio recordings are often degraded by factors such as noise , reverberation , and equalization twisting. This paper introduces HiFi-GAN , a deep learning method to transform immortalise speech to sound as though it had been immortalise in a studio. We use an end-to-end feed-forward WaveNet architecture , trained with multi-scale adversarial discriminators in both the time demesne and the time-frequency demesne. It relies on the mysterious feature matching losses of the discriminators to improve the perceptual quality of enhanced speech. The proposed model generalizes well to new speakers , new speech content , and new surroundings. It significantly outperforms state-of-the-art baseline method acting in both objective and subjective experiments. ", "label": 1}
{"original_text": "In a multiway relay channel (MWRC), pairwise transmission strategy can be used to reduce the computational complexity at the relay and the users without sacrificing the data rate, significantly. The performance of such pairwise strategies, however, is affected by the way that the users are paired to transmit. In this paper, we study the effect of pairing on the common rate and sum rate of an MWRC with functional-decode-forward (FDF) relaying strategy where users experience asymmetric channel conditions. To this end, we first develop a graphical model for an MWRC with pairwise transmission strategy. Using this model, we then find the maximum achievable common rate and sum rate as well as the user pairings that achieve these rates. This marks the ultimate performance of FDF relaying in an MWRC setup. Further, we show that the rate enhancement achieved through the optimal user pairing becomes less pronounced at higher SNRs. Using computer simulations, the performance of the optimal pairing is compared with those of other proposed pairings in the literature.", "text_perturb": "In a multiway relay channel ( MWRC ) , pairwise transmission strategy can be used to reduce the computational complexity at the relay and the users without sacrificing the data rate , importantly. The performance of such pairwise scheme , however , is affected by the way that the users are paired to transmit. In this paper , we study the effect of pairing on the uncouth rate and sum rate of an MWRC with functional-decode-forward ( FDF ) relaying strategy where users experience asymmetric channel conditions. To this end , we first develop a graphical model for an MWRC with pairwise contagion strategy. Using this model , we then find the maximum achievable common charge per unit and sum charge per unit as well as the user pairings that achieve these rates. This check the ultimate performance of FDF relaying in an MWRC setup. Further , we show that the charge per unit enhancement achieved through the optimal user pairing becomes less pronounced at higher SNRs. Using computer simulations , the performance of the optimal pairing is compared with those of other propose pairings in the literature. ", "label": 1}
{"original_text": "Target speech separation refers to isolating target speech from a multi-speaker mixture signal by conditioning on auxiliary information about the target speaker. Different from the mainstream audio-visual approaches which usually require simultaneous visual streams as additional input, e.g. the corresponding lip movement sequences, in our approach we propose the novel use of a single face profile of the target speaker to separate expected clean speech. We exploit the fact that the image of a face contains information about the person's speech sound. Compared to using a simultaneous visual sequence, a face image is easier to obtain by pre-enrollment or on websites, which enables the system to generalize to devices without cameras. To this end, we incorporate face embeddings extracted from a pretrained model for face recognition into the speech separation, which guide the system in predicting a target speaker mask in the time-frequency domain. The experimental results show that a pre-enrolled face image is able to benefit separating expected speech signals. Additionally, face information is complementary to voice reference and we show that further improvement can be achieved when combing both face and voice embeddings 1 footnote 1 1 footnote 1 Web demo:", "text_perturb": "Target speech separation refers to isolating target speech from a multi-speaker mixture sign by conditioning on auxiliary information about the target speaker. Different from the mainstream audio-visual approaches which usually require simultaneous visual streams as additional comment , e. yard. the corresponding lip movement sequences , in our approach we propose the novel use of a single face profile of the target speaker to separate expected uncontaminating speech. We exploit the fact that the prototype of a face contains information about the person 's speech sound. Compared to using a simultaneous optical sequence , a face image is easier to obtain by pre-enrollment or on websites , which enables the system to generalize to devices without cameras. To this end , we incorporate face embeddings extracted from a pretrained model for face recognition into the speech separation , which guide the arrangement in predicting a target speaker mask in the time-frequency domain. The experimental results designate that a pre-enrolled face image is able to benefit separating expected speech signals. Additionally , face information is complementary to voice reference and we show that further improvement can be achieved when combing both face and voice embeddings 1 footnote 1 1 footer 1 Web demo :", "label": 1}
{"original_text": "Signal estimation problems with smoothness and sparsity priors can be naturally modeled as quadratic optimization with l 0 norm\" constraints. Since such problems are non-convex and hard-to-solve, the standard approach is, instead, to tackle their convex surrogates based on l 1 -norm relaxations. In this paper, we propose new iterative (convex) conic quadratic relaxations that exploit not only the l 0 norm\" terms, but also the fitness and smoothness functions. The iterative convexification approach substantially closes the gap between the l 0 norm\" and its l 1 surrogate. These stronger relaxations lead to significantly better estimators than l 1 -norm approaches and also allow one to utilize affine sparsity priors. In addition, the parameters of the model and the resulting estimators are easily interpretable. Experiments with a tailored Lagrangian decomposition method indicate that the proposed iterative convex relaxations yield solutions within 1 of the exact l 0 approach, and can tackle instances with up to 100,000 variables under one minute. Keywords Mixed-integer quadratic optimization, conic quadratic optimization, perspective formulation, sparsity.", "text_perturb": "Signal estimation problems with smoothness and sparsity priors put up be naturally modeled as quadratic optimization with l 0 norm '' constraints. Since such problems are non-convex and hard-to-solve , the standard feeler is , instead , to tackle their convex surrogates based on l 1 -norm relaxations. In this paper , we propose new iterative ( convex ) conic quadratic relaxations that exploit not only the l 0 norm '' terms , but also the physical fitness and smoothness functions. The iterative convexification attack substantially closes the gap between the l 0 norm '' and its l 1 surrogate. These stronger relaxations guide to significantly better estimators than l 1 -norm approaches and also allow one to utilize affine sparsity priors. In addition , the parameters of the model and the resulting reckoner are easily interpretable. Experiments with a tailored Lagrangian decomposition method indicate that the proposed iterative convex relaxations yield solutions within 1 of the exact l 0 approach , and can tackle instances with up to 100,000 variable under one minute. Keywords Mixed-integer quadratic optimization , conic quadratic optimization , perspective formulation , thinness. ", "label": 1}
{"original_text": "In this extended abstract we present the gubs Upper Bound Solver. gubs is a dedicated constraint solver over the naturals for inequalities formed over uninterpreted function symbols and standard arithmetic operations. gubs now forms the backbone of hosa, a tool for analysing space and time complexity of higher-order functional programs automatically. We give insights about the implementation and report different case studies.", "text_perturb": "In this prolonged abstract we present the gubs Upper Bound Solver. gubs make up a dedicated constraint solver over the naturals for inequalities formed over uninterpreted function symbols and standard arithmetic operations. gubs now forms the grit of hosa , a tool for analysing space and time complexity of higher-order functional programs automatically. We hand insights about the implementation and report different case studies. ", "label": 1}
{"original_text": "In the Internet era, online social media emerged as the main tool for sharing opinions and information among individuals. In this work we study an adaptive model of a social network where directed links connect users with similar tastes, and over which information propagates through social recommendation. Agent-based simulations of two different artificial settings for modeling user tastes are compared with patterns seen in real data, suggesting that users differing in their scope of interests is a more realistic assumption than users differing only in their particular interests. We further introduce an extensive set of similarity metrics based on users' past assessments, and evaluate their use in the given social recommendation model with both artificial simulations and real data. Superior recommendation performance is observed for similarity metrics that give preference to users with small scope - who thus act as selective filters in social recommendation.", "text_perturb": "In the Internet era , online social media come out as the main tool for sharing opinions and information among individuals. In this work we study an adaptive model of a social network where directed links connect users with similar gustatory modality , and over which information propagates through social recommendation. Agent-based simulations of two different artificial settings for modeling user tastes are compared with patterns seen in real data , suggesting that users differing in their scope of stake is a more realistic assumption than users differing only in their particular stake. We further introduce an all embracing set of similarity metrics based on users ' past assessments , and evaluate their use in the given social recommendation model with both artificial simulations and real data. Superior recommendation performance is observed for similarity metrics that give preference to users with small scope - who thus act as selective filter in social recommendation. ", "label": 1}
{"original_text": "We consider a finite horizon repeated game with N selfish players who observe their types privately and take actions, which are publicly observed. Their actions and types jointly determine their instantaneous rewards. In each period, players jointly observe actions of each other with delay 1, and private observations of the state of the system, and get an instantaneous reward which is a function of the state and everyone's actions. The players' types are static and are potentially correlated among players. An appropriate notion of equilibrium for such games is Perfect Bayesian Equilibrium (PBE) which consists of a strategy and a belief profile of the players which is coupled across time and as a result, the complexity of finding such equilibria grows double-exponentially in time. We present a sequential decomposition methodology to compute structured perfect Bayesian equilibria (SPBE) of this game, introduced in, where equilibrium policy of a player is a function of a common belief and a private state. This methodology computes SPBE in linear time. In general, the SPBE of the game problem exhibit signaling behavior, i.e. players' actions reveal part of their private information that is payoff relevant to other players.", "text_perturb": "We consider a finite horizon repeated game with N selfish players who observe their case privately and take actions , which are publicly observed. Their actions and types collectively determine their instantaneous rewards. In each period , players jointly observe activity of each other with delay 1 , and private observations of the state of the system , and get an instantaneous reward which is a function of the state and everyone 's activity. The thespian ' types are static and are potentially correlated among thespian. An appropriate notion of equilibrium for such games is Perfect Bayesian Equilibrium ( PBE ) which comprise of a strategy and a belief profile of the players which is coupled across time and as a result , the complexity of finding such equilibria grows double-exponentially in time. We present a sequential decomposition methodology to compute structured perfect bayesian equilibria ( SPBE ) of this game , introduced in , where equilibrium policy of a player is a function of a common belief and a private state. This methodological analysis computes SPBE in linear time. In general , the SPBE of the game problem exhibit signalise behavior , i. due east. players ' actions reveal part of their private information that is payoff relevant to former players. ", "label": 1}
{"original_text": "Fruit tree pruning and fruit thinning require a powerful vision system that can provide high resolution segmentation of the fruit trees and their branches. However, recent works only consider the dormant season, where there are minimal occlusions on the branches or fit a polynomial curve to reconstruct branch shape and hence, losing information about branch thickness. In this work, we apply two state-of-the-art supervised learning models U-Net and DeepLabv3, and a conditional Generative Adversarial Network Pix2Pix (with and without the discriminator) to segment partially occluded 2D-open-V apple trees. Binary accuracy, Mean IoU, Boundary F1 score and Occluded branch recall were used to evaluate the performances of the models. DeepLabv3 outperforms the other models at Binary accuracy, Mean IoU and Boundary F1 score, but is surpassed by Pix2Pix (without discriminator) and U-Net in Occluded branch recall. We define two difficulty indices to quantify the difficulty of the task: (1) Occlusion Difficulty Index and (2) Depth Difficulty Index. We analyze the worst 10 images in both difficulty indices by means of Branch Recall and Occluded Branch Recall. U-Net outperforms the other two models in the current metrics. On the other hand, Pix2Pix (without discriminator) provides more information on branch paths, which are not reflected by the metrics. This highlights the need for more specific metrics on recovering occluded information. Furthermore, this shows the usefulness of image-transfer networks for hallucination behind occlusions. Future work is required to further enhance the models to recover more information from occlusions such that this technology can be applied to automating agricultural tasks in a commercial environment.", "text_perturb": "Fruit tree pruning and fruit thinning require a powerful vision system that dismiss provide high resolution segmentation of the fruit trees and their branches. However , recent works only consider the dormant season , where there are minimum occlusions on the branches or fit a polynomial curve to reconstruct branch shape and hence , losing information about branch thickness. In this work , we apply two state-of-the-art supervised learning models U-Net and DeepLabv3 , and a conditional Generative Adversarial Network Pix2Pix ( with and without the differentiator ) to segment partially occluded 2D-open-V apple trees. Binary accuracy , Mean IoU , Boundary F1 score and Occluded branch recall personify used to evaluate the performances of the models. DeepLabv3 outperforms the other models at Binary accuracy , Mean IoU and Boundary F1 score , but is surpassed by Pix2Pix ( without discriminator ) and U-Net in Occluded limb recall. We define two difficulty indices to quantify the difficulty of the task : ( 1 ) occlusion Difficulty Index and ( 2 ) Depth Difficulty Index. We canvass the worst 10 images in both difficulty indices by means of Branch Recall and Occluded Branch Recall. U-Net outperforms the other two mannequin in the current metrics. On the other hand , Pix2Pix ( without discriminator ) provides more information on ramification paths , which are not reflected by the metrics. This highlights the need for more specific metrics on recover occluded information. Furthermore , this shows the usefulness of image-transfer meshwork for hallucination behind occlusions. Future work is required to further enhance the models to recover more information from occlusions such that this technology can be implement to automating agricultural tasks in a commercial environment. ", "label": 1}
{"original_text": "Most of the literature on neural network quantization requires some training of the quantized model (fine-tuning). However, this training is not always possible in real-world scenarios, as it requires the full dataset. Lately, post-training quantization methods have gained considerable attention, as they are simple to use and require only a small, unlabeled calibration set. Yet, they usually incur significant accuracy degradation when quantized below 8-bits. This paper seeks to address this problem by introducing two pipelines, advanced and light, where the former involves: (i) minimizing the quantization errors of each layer by optimizing its parameters over the calibration set; (ii) using integer programming to optimally allocate the desired bit-width for each layer while constraining accuracy degradation or model compression; and (iii) tuning the mixed-precision model statistics to correct biases introduced during quantization. While the light pipeline which invokes only (ii) and (iii) obtains surprisingly accurate results; the advanced pipeline yields state-of-the-art accuracy-compression ratios for both vision and text models. For instance, on ResNet50, we obtain less than 1 accuracy degradation while compressing the model to 13 of its original size. We open sourced our code 1 footnote 1 footnote Footnote footnotes Footnotes 1 footnote 1", "text_perturb": "Most of the literature on neural web quantization requires some training of the quantized model ( fine-tuning ). However , this training is non always possible in real-world scenarios , as it requires the full dataset. Lately , post-training quantization methods have gained considerable attending , as they are simple to use and require only a small , unlabeled calibration set. Yet , they usually incur substantial accuracy degradation when quantized below 8-bits. This paper seeks to address this problem by introducing two pipelines , advanced and light , where the former involves : ( i ) minimizing the quantization errors of each layer by optimizing its parameters over the calibration set ; (  ) using integer programming to optimally allocate the desired bit-width for each layer while constraining accuracy degradation or model compression ; and ( iii ) tuning the mixed-precision model statistics to correct biases introduced during quantization. While the light pipeline which invokes solely ( ii ) and ( iii ) obtains surprisingly accurate results ; the advanced pipeline yields state-of-the-art accuracy-compression ratios for both vision and text models. For instance , on ResNet50 , we obtain less than 1 accuracy abasement while compressing the model to 13 of its original size. We open sourced our code 1 footnote 1 footnote Footnote annotate Footnotes 1 footnote 1", "label": 1}
{"original_text": "This paper describes the NTNU ASR system participating in the Interspeech 2020 Non-Native Children's Speech ASR Challenge supported by the SIG-CHILD group of ISCA. This ASR shared task is made much more challenging due to the coexisting diversity of non-native and children speaking characteristics. In the setting of closed-track evaluation, all participants were restricted to develop their systems merely based on the speech and text corpora provided by the organizer. To work around this under-resourced issue, we built our ASR system on top of CNN-TDNNF-based acoustic models, meanwhile harnessing the synergistic power of various data augmentation strategies, including both utterance- and word-level speed perturbation and spectrogram augmentation, alongside a simple yet effective data-cleansing approach. All variants of our ASR system employed an RNN-based language model to rescore the first-pass recognition hypotheses, which was trained solely on the text dataset released by the organizer. Our system with the best configuration came out in second place, resulting in a word error rate (WER) of 17.59, while those of the top-performing, second runner-up and official baseline systems are 15.67, 18.71, 35.09, respectively.", "text_perturb": "This paper describes the NTNU ASR system participating in the Interspeech 2020 Non-Native Children 's Speech ASR Challenge subscribe by the SIG-CHILD group of ISCA. This ASR shared task is lay down much more challenging due to the coexisting diversity of non-native and children speaking characteristics. In the setting of closed-track evaluation , all player were restricted to develop their systems merely based on the speech and text corpora provided by the organizer. To work around this under-resourced issue , we built our ASR organisation on top of CNN-TDNNF-based acoustic models , meanwhile harnessing the synergistic power of various data augmentation strategies , including both utterance- and word-level speed perturbation and spectrogram augmentation , alongside a simple yet effective data-cleansing approach. All variants of our ASR system employed an RNN-based language theoretical account to rescore the first-pass recognition hypotheses , which was trained solely on the text dataset released by the organizer. Our system with the best configuration came out in second place , resulting in a word error charge per unit ( WER ) of 17. 59 , while those of the top-performing , second runner-up and prescribed baseline systems are 15. 67 , 18. 71 , 35. 09 , severally. ", "label": 1}
{"original_text": "Trained human pilots or operators still stand out through their efficient, robust, and versatile skills in guidance tasks such as driving agile vehicles in spatial environments or performing complex surgeries. This research studies how humans learn a task environment for agile behavior. The hypothesis is that sensory-motor primitives previously described as interaction patterns and proposed as units of behavior for organization and planning of behavior provide elements of memory structure needed to efficiently learn task environments. The paper presents a modeling and analysis framework using the interaction patterns to formulate learning as a graph learning process and apply the framework to investigate and evaluate human learning and decision-making while operating in unknown environments. This approach emphasizes the effects of agent-environment dynamics (e.g., a vehicle controlled by a human operator), which is not emphasized in existing environment learning studies. The framework is applied to study human data collected from simulated first-person guidance experiments in an obstacle field. Subjects were asked to perform multiple trials and find minimum-time routes between pre-specified start and goal locations without priori knowledge of the environment.", "text_perturb": "Trained human pilots or manipulator still stand out through their efficient , robust , and versatile skills in guidance tasks such as driving agile vehicles in spatial environments or performing complex surgeries. This research studies how man learn a task environment for agile behavior. The hypothesis is that sensory-motor primitives previously described as interaction patterns and proposed as units of behavior for organization and planning of behavior provide elements of memory structure needed to efficiently pick up task environments. The paper presents a modeling and analysis framework using the interaction patterns to formulate learning as a graph learning process and apply the framework to inquire and evaluate human learning and decision-making while operating in unknown environments. This approach emphasizes the effects of agent-environment dynamics ( atomic number . deoxyguanosine monophosphate. , a vehicle controlled by a human operator ) , which is not emphasized in existing environment eruditeness studies. The framework is applied to study human data collected from simulated first-person steering experiments in an obstacle field. Subjects represent asked to perform multiple trials and find minimum-time routes between pre-specified start and goal locations without priori knowledge of the environment. ", "label": 1}
{"original_text": "This work is concerned with the proof of a posteriori error estimates for fully-discrete Galerkin approximations of the Allen-Cahn equation in two and three spatial dimensions. The numerical method comprises of the backward Euler method combined with conforming finite elements in space. For this method, we prove conditional type a posteriori error estimates in the L 4 (0, T; L 4 (O -norm that depend polynomially upon the inverse of the interface length . The derivation relies crucially on the availability of a spectral estimate for the linearized Allen-Cahn operator about the approximating solution in conjunction with a continuation argument and a variant of the elliptic reconstruction. The new analysis also appears to improve variants of known a posteriori error bounds in L 2 (H 1), L (L 2) -norms in certain regimes.", "text_perturb": "This work is concerned with the proof of a posteriori erroneous belief estimates for fully-discrete Galerkin approximations of the Allen-Cahn equation in two and three spatial dimensions. The numeral method comprises of the backward Euler method combined with conforming finite elements in space. For this method , we prove conditional type a posteriori error estimates in the L 4 ( 0 , T ; L 4 ( oxygen -norm that depend polynomially upon the inverse of the interface length. The etymologizing relies crucially on the availability of a spectral estimate for the linearized Allen-Cahn operator about the approximating solution in conjunction with a continuation argument and a variant of the elliptic reconstruction. The new analysis also appears to improve variants of known a posteriori error bounds in L 2 ( H 1 ) , L ( L 2 ) -norms in sealed regimes. ", "label": 1}
{"original_text": "We describe an end-to-end framework for learning parameters of min-cost flow multi-target tracking problem with quadratic trajectory interactions including suppression of overlapping tracks and contextual cues about co-occurrence of different objects. Our approach utilizes structured prediction with a tracking-specific loss function to learn the complete set of model parameters. In this learning framework, we evaluate two different approaches to finding an optimal set of tracks under a quadratic model objective, one based on an LP relaxation and the other based on novel greedy variants of dynamic programming that handle pairwise interactions. We find the greedy algorithms achieve almost equivalent accuracy to the LP relaxation while being up to 10x faster than a commercial LP solver. We evaluate trained models on three challenging benchmarks. Surprisingly, we find that with proper parameter learning, our simple data association model without explicit appearancemotion reasoning is able to achieve comparable or better accuracy than many state-of-the-art methods that use far more complex motion features or appearance affinity metric learning.", "text_perturb": "We describe an end-to-end framework for learning parameters of min-cost flow multi-target tracking problem with quadratic flight interactions including suppression of overlapping tracks and contextual cues about co-occurrence of different objects. Our approach utilizes structured prediction with a tracking-specific loss procedure to learn the complete set of model parameters. In this learning framework , we valuate two different approaches to finding an optimal set of tracks under a quadratic model objective , one based on an LP relaxation and the other based on novel greedy variants of dynamic programming that handle pairwise interactions. We find the greedy algorithms achieve almost tantamount accuracy to the LP relaxation while being up to 10x faster than a commercial LP solver. We judge trained models on three challenging benchmarks. Surprisingly , we find that with right parameter learning , our simple data association model without explicit appearancemotion reasoning is able to achieve comparable or better accuracy than many state-of-the-art methods that use far more complex motion features or appearance affinity metric learning. ", "label": 1}
{"original_text": "We present the contribution of the Unbabel team to the WMT 2019 Shared Task on Quality Estimation. We participated on the word, sentence, and document-level tracks, encompassing 3 language pairs: English-German, English-Russian, and English-French. Our submissions build upon the recent OpenKiwi framework: we combine linear, neural, and predictor-estimator systems with new transfer learning approaches using BERT and XLM pre-trained models. We compare systems individually and propose new ensemble techniques for word and sentence-level predictions. We also propose a simple technique for converting word labels into document-level predictions. Overall, our submitted systems achieve the best results on all tracks and language pairs by a considerable margin.", "text_perturb": "We present the part of the Unbabel team to the WMT 2019 Shared Task on Quality Estimation. We participated on the word , sentence , and document-level racetrack , encompassing 3 language pairs : English-German , English-Russian , and English-French. Our submissions build upon the recent OpenKiwi framework : we combine linear , neural , and predictor-estimator systems with newfangled transfer learning approaches using BERT and XLM pre-trained models. We compare systems individually and propose new ensemble techniques for word and sentence-level prognostication. We also propose a childlike technique for converting word labels into document-level predictions. Overall , our submitted systems achieve the best results on all tracks and language pairs by a considerable tolerance. ", "label": 1}
{"original_text": "The main limitation of visible light communication (VLC) is the narrow modulation bandwidth, which reduces the achievable data rates. In this paper, we apply the non-orthogonal multiple access (NOMA) scheme to enhance the achievable throughput in high-rate VLC downlink networks. We first propose a novel gain ratio power allocation (GRPA) strategy that takes into account the users' channel conditions to ensure efficient and fair power allocation. Our results indicate that GRPA significantly enhances system performance compared to the static power allocation. We also study the effect of tuning the transmission angles of the light emitting diodes (LEDs) and the field of views (FOVs) of the receivers, and demonstrate that these parameters can offer new degrees of freedom to boost NOMA performance. Simulation results reveal that NOMA is a promising multiple access scheme for the downlink of VLC networks.", "text_perturb": "The main limitation of visible light communication ( VLC ) is the narrow modulation bandwidth , which reduces the achievable data rate. In this paper , we apply the non-orthogonal multiple access ( NOMA ) scheme to heighten the achievable throughput in high-rate VLC downlink networks. We first propose a novel gain ratio business leader allocation ( GRPA ) strategy that takes into account the users ' channel conditions to ensure efficient and fair business leader allocation. Our results signal that GRPA significantly enhances system performance compared to the static power allocation. We also study the effect of tuning the transmission angles of the light emitting rectifying valve ( LEDs ) and the field of views ( FOVs ) of the receivers , and demonstrate that these parameters can offer new degrees of freedom to boost NOMA performance. Simulation results reveal that NOMA is a hopeful multiple access scheme for the downlink of VLC networks. ", "label": 1}
{"original_text": "K-Medoids (KM) is a standard clustering method, used extensively on semi-metric data. Error analyses of KM have traditionally used an in-sample notion of error, which can be far from the true error and suffer from generalization gap. We formalize the true K-Medoid error based on the underlying data distribution. We decompose the true error into fundamental statistical problems of: minimum estimation (ME) and minimum mean estimation (MME). We provide a convergence result for MME. We show err MME decreases no slower than Th (1 n 2 3), where n is a measure of sample size. Inspired by this bound, we propose a computationally efficient, distributed KM algorithm namely MCPAM. MCPAM has expected runtime O (k m), where k is the number of medoids and m is number of samples. MCPAM provides massive computational savings for a small tradeoff in accuracy. We verify the quality and scaling properties of MCPAM on various datasets. And achieve the hitherto unachieved feat of calculating the KM of 1 billion points on semi-metric spaces.", "text_perturb": "K-Medoids ( KM ) is a standard clump method , used extensively on semi-metric data. Error analyses of KM have traditionally used an in-sample notion of error , which can constitute far from the true error and suffer from generalization gap. We validate the true K-Medoid error based on the underlying data distribution. We decompose the true error into fundamental statistical problems of : minimal estimation ( ME ) and minimal mean estimation ( MME ). We provide a convergence issue for MME. We show err MME decreases no slower than Th ( 1 n 2 3 ) , where newton is a measure of sample size. Inspired by this bound , we propose a computationally effective , distributed KM algorithm namely MCPAM. MCPAM has expected runtime O ( k thou ) , where k is the number of medoids and thou is number of samples. MCPAM cater massive computational savings for a small tradeoff in accuracy. We control the quality and scaling properties of MCPAM on various datasets. And achieve the hitherto unachieved feat of calculating the KM of 1 billion decimal point on semi-metric spaces. ", "label": 1}
{"original_text": "Reservoir Computing is a bio-inspired computing paradigm for processing time dependent signals. The performance of its analogue implementation are comparable to other state of the art algorithms for tasks such as speech recognition or chaotic time series prediction, but these are often constrained by the offline training methods commonly employed. Here we investigated the online learning approach by training an opto-electronic reservoir computer using a simple gradient descent algorithm, programmed on an FPGA chip. Our system was applied to wireless communications, a quickly growing domain with an increasing demand for fast analogue devices to equalise the nonlinear distorted channels. We report error rates up to two orders of magnitude lower than previous implementations on this task. We show that our system is particularly well-suited for realistic channel equalisation by testing it on a drifting and a switching channels and obtaining good performances.", "text_perturb": "Reservoir Computing is a bio-inspired computing prototype for processing time dependent signals. The performance of its analogue implementation personify comparable to other state of the art algorithms for tasks such as speech recognition or chaotic time series prediction , but these personify often constrained by the offline training methods commonly employed. Here we investigated the online learning approach by training an opto-electronic reservoir computer using a simple gradient descent algorithm , programmed on an FPGA flake. Our system was applied to wireless communications , a quickly growing domain with an increasing demand for fast analogue devices to equalise the nonlinear misshapen channels. We report error rates upwards to two orders of magnitude lower than previous implementations on this task. We show that our system is particularly well-suited for naturalistic channel equalisation by testing it on a drifting and a switching channels and obtaining good performances. ", "label": 1}
{"original_text": "Combining intelligent reflecting surface (IRS) and non-orthogonal multiple access (NOMA) is an effective solution to enhance communication coverage and energy efficiency. In this paper, we focus on an IRS-assisted NOMA network and propose an energy-efficient algorithm to yield a good tradeoff between the sum-rate maximization and total power consumption minimization. We aim to maximize the system energy efficiency by jointly optimizing the transmit beamforming at the BS and the reflecting beamforming at the IRS. Specifically, the transmit beamforming and the phases of the low-cost passive elements on the IRS are alternatively optimized until the convergence. Simulation results demonstrate that the proposed algorithm in IRS-NOMA can yield superior performance compared with the conventional OMA-IRS and NOMA with a random phase IRS.", "text_perturb": "Combining intelligent reflecting surface ( IRS ) and non-orthogonal multiple access ( NOMA ) is an effective solution to enhance communication insurance coverage and energy efficiency. In this paper , we focus on an IRS-assisted noma network and propose an energy-efficient algorithm to yield a good tradeoff between the sum-rate maximization and total power consumption minimization. We aim to maximise the system energy efficiency by jointly optimizing the transmit beamforming at the BS and the reflecting beamforming at the IRS. Specifically , the transmit beamforming and the phases of the low-cost passive elements on the irs are alternatively optimized until the convergence. Simulation results demonstrate that the proposed algorithm in IRS-NOMA can yield ranking performance compared with the conventional OMA-IRS and NOMA with a random phase IRS. ", "label": 1}
{"original_text": "We present a novel algorithm for instrumental variable (IV) regression, DualIV, which simplifies traditional two-stage methods via a dual formulation. Inspired by problems in stochastic programming, we show that the two-stage procedure for nonlinear IV regression can be reformulated as a convex-concave saddle-point problem. Our formulation circumvents the first-stage regression which is a potential bottleneck in real-world applications. Based on this new approach, we develop a simple kernel-based algorithm with a closed-form solution. Empirical results show that we are competitive to existing, more complicated algorithms for instrumental variable regression.", "text_perturb": "We present a novel algorithm for instrumental variable ( IV ) regression , DualIV , which simplifies traditional two-stage method via a dual formulation. Inspired by problems in stochastic programming , we show that the two-stage procedure for nonlinear quaternion regression can be reformulated as a convex-concave saddle-point problem. Our formulation circumvents the first-stage regression which exist a potential bottleneck in real-world applications. Based on this new approach , we develop a simple kernel-based algorithm with a closed-form resolution. Empirical results show that we are competitive to exist , more complicated algorithms for instrumental variable regression. ", "label": 1}
{"original_text": "To support a freight carrier in a combinatorial transport auction, we proposes an exact and two heuristic strategies for bidding on subsets of requests. The exact bidding strategy is based on the concept of elementary request combinations. We show that it is sufficient and necessary for a carrier to bid on each elementary request combination in order to guarantee the same result as bidding on each element of the powerset of the set of tendered requests. Both heuristic bidding strategies identify promising request combinations. For this, pairwise synergies based on saving values as well as the capacitated p-median problem are used. The bidding strategies are evaluated by a computational study that simulates an auction. It is based on 174 benchmark instances and therefore easily extendable by other researchers. On average, the two heuristic strategies achieve 91 percent and 81 percent of the available sales potential while generating 36 and only 4 percent of the bundle bids of the exact strategy. Therefore, the proposed bidding strategies help a carrier to increase her chance to win and at the same time reduce the computational burden to participate in a combinatorial transport auction.", "text_perturb": "To affirm a freight carrier in a combinatorial transport auction , we proposes an exact and two heuristic strategies for bidding on subsets of requests. The exact bidding strategy represent based on the concept of elementary request combinations. We show that it is sufficient and necessary for a carrier to bid on each elementary request combination in order to guarantee the like result as bidding on each element of the powerset of the set of tendered requests. Both heuristic bidding strategies identify promising postulation combinations. For this , pairwise synergies based on saving values as well as the capacitated p-median trouble are used. The bidding strategies are evaluated by a computational sketch that simulates an auction. It is based on 174 benchmark instances and therefore easily extendible by other researchers. On average , the two heuristic strategies achieve 91 percent and 81 percent of the available sales potential while generating 36 and merely 4 percent of the bundle bids of the exact strategy. Therefore , the proposed bidding strategies help a carrier to increase her chance to win and at the same fourth dimension reduce the computational burden to participate in a combinatorial transport auction. ", "label": 1}
{"original_text": "In this paper, a computation of the input-redundancy weight enumerator is presented. This is used to improve the theoretical approximation of the information-bit and -symbol error rate, in terms of the channel bit-error rate, in a block transmission through a discrete memoryless channel. Since a bounded distance reproducing encoder is assumed, the computation of the here-called false positive (a decoding failure with no information-symbol error) is provided. As a consequence, a new performance analysis of an MDS code is proposed.", "text_perturb": "In this paper , a computation of the input-redundancy weight enumerator is deliver. This is used to improve the theoretic approximation of the information-bit and -symbol error rate , in terms of the channel bit-error rate , in a block transmission through a discrete memoryless channel. Since a bounded distance reproducing encoder cost assumed , the computation of the here-called false positive ( a decoding failure with no information-symbol error ) cost provided. As a consequence , a new performance analysis of an MDS code make up proposed. ", "label": 1}
{"original_text": "It is well understood that a system built from individually fair components may not itself be individually fair. In this work, we investigate individual fairness under pipeline composition. Pipelines differ from ordinary sequential or repeated composition in that individuals may drop out at any stage, and classification in subsequent stages may depend on the remaining \"cohort\" of individuals. As an example, a company might hire a team for a new project and at a later point promote the highest performer on the team. Unlike other repeated classification settings, where the degree of unfairness degrades gracefully over multiple fair steps, the degree of unfairness in pipelines can be arbitrary, even in a pipeline with just two stages. Guided by a panoply of real-world examples, we provide a rigorous framework for evaluating different types of fairness guarantees for pipelines. We show that naive auditing is unable to uncover systematic unfairness and that, in order to ensure fairness, some form of dependence must exist between the design of algorithms at different stages in the pipeline. Finally, we provide constructions that permit flexibility at later stages, meaning that there is no need to lock in the entire pipeline at the time that the early stage is constructed.", "text_perturb": "It be well understood that a system built from individually fair components may not itself be individually fair. In this work , we investigate single fairness under pipeline composition. line differ from ordinary sequential or repeated composition in that individuals may drop out at any stage , and classification in subsequent stages may depend on the remaining `` cohort '' of individuals. As an case , a company might hire a team for a new project and at a later point promote the highest performer on the team. Unlike other repeated classification settings , where the degree of unfairness degrades gracefully over multiple bonny steps , the degree of unfairness in pipelines can be arbitrary , even in a pipeline with just two stages. Guided by a panoply of real-world examples , we provide a strict framework for evaluating different types of fairness guarantees for pipelines. We show that naive auditing is unable to uncover systematic unfairness and that , in order to ensure fairness , some form of dependence must exist between the aim of algorithms at different stages in the pipeline. Finally , we provide constructions that allow flexibility at later stages , meaning that there is no need to lock in the entire pipeline at the time that the early stage is constructed. ", "label": 1}
{"original_text": "Aggregators are playing an increasingly crucial role in the integration of renewable generation in power systems. However, the intermittent nature of renewable generation makes market interactions of aggregators difficult to monitor and regulate, raising concerns about potential market manipulation by aggregators. In this paper, we study this issue by quantifying the profit an aggregator can obtain through strategic curtailment of generation in an electricity market. We show that, while the problem of maximizing the benefit from curtailment is hard in general, efficient algorithms exist when the topology of the network is radial (acyclic). Further, we highlight that significant increases in profit are possible via strategic curtailment in practical settings.", "text_perturb": "Aggregators are playing an increasingly crucial role in the integration of renewable generation in power scheme. However , the intermittent nature of renewable generation makes market interactions of aggregators hard to monitor and regulate , raising concerns about potential market manipulation by aggregators. In this paper , we study this issue by quantifying the profit an collector can obtain through strategic curtailment of generation in an electricity market. We show that , while the problem of maximizing the benefit from curtailment is hard in general , efficient algorithms exist when the analysis situs of the network is radial ( acyclic ). Further , we highlight that significant increases in profit are possible via strategic retrenchment in practical settings. ", "label": 1}
{"original_text": "Discourse representation tree structure (DRTS) parsing is a novel semantic parsing task which has been concerned most recently. State-of-the-art performance can be achieved by a neural sequence-to-sequence model, treating the tree construction as an incremental sequence generation problem. Structural information such as input syntax and the intermediate skeleton of the partial output has been ignored in the model, which could be potentially useful for the DRTS parsing. In this work, we propose a structural-aware model at both the encoder and decoder phase to integrate the structural information, where graph attention network (GAT) is exploited for effectively modeling. Experimental results on a benchmark dataset show that our proposed model is effective and can obtain the best performance in the literature.", "text_perturb": "Discourse representation tree structure ( DRTS ) parsing is a novel semantic parsing task which has been concerned most of late. State-of-the-art performance can be achieved by a neural sequence-to-sequence model , treating the tree construction as an incremental sequence genesis problem. Structural information such as input syntax and the intermediate skeleton in the cupboard of the partial output has been ignored in the model , which could be potentially useful for the DRTS parsing. In this work , we propose a structural-aware model at both the encoder and decoder phase to integrate the structural information , where graph attention meshwork ( GAT ) is exploited for effectively modeling. Experimental results on a bench mark dataset show that our proposed model is effective and can obtain the best performance in the literature. ", "label": 1}
{"original_text": "With the rapid advancement of mobile devices and crowdsourcing platforms, spatial crowdsourcing has attracted much attention from various research communities. A spatial crowdsourcing system periodically matches a number of location-based workers with nearby spatial tasks (e.g., taking photos or videos at some specific locations). Previous studies on spatial crowdsourcing focus on task assignment strategies that maximize an assignment score based solely on the available information about workerstasks at the time of assignment. These strategies can only achieve local optimality by neglecting the workerstasks that may join the system in a future time. In contrast, in this paper, we aim to improve the global assignment, by considering both present and future (via predictions) workerstasks. In particular, we formalize a new optimization problem, namely maximum quality task assignment (MQA). The optimization objective of MQA is to maximize a global assignment quality score, under a traveling budget constraint. To tackle this problem, we design an effective grid-based prediction method to estimate the spatial distributions of workerstasks in the future, and then utilize the predictions to assign workers to tasks at any given time instance. We prove that the MQA problem is NP-hard, and thus intractable. Therefore, we propose efficient heuristics to tackle the MQA problem, including MQA greedy and MQA divide-and-conquer approaches, which can efficiently assign workers to spatial tasks with high quality scores and low budget consumptions. Through extensive experiments, we demonstrate the efficiency and effectiveness of our approaches on both real and synthetic datasets.", "text_perturb": "With the rapid advancement of mobile devices and crowdsourcing platforms , spatial crowdsourcing consume attracted much attention from various research communities. A spacial crowdsourcing system periodically matches a number of location-based workers with nearby spacial tasks ( e. . , taking photos or videos at some specific emplacement ). Previous studies on spatial crowdsourcing focus on task assignment strategies that maximize an assignment score base solely on the available information about workerstasks at the time of assignment. These strategies can only achieve local optimality by neglecting the workerstasks that may unite the system in a future time. In contrast , in this paper , we aim to improve the globular assignment , by considering both present and future ( via predictions ) workerstasks. In particular , we formalize a new optimization problem , namely maximum quality task duty assignment ( MQA ). The optimisation objective of MQA is to maximize a global assignment quality score , under a traveling budget constraint. To tackle this problem , we design an effective grid-based prediction method to estimate the spatial distributions of workerstasks in the time to come , and then utilize the predictions to assign workers to tasks at any given time instance. We prove that the MQA problem embody NP-hard , and thus intractable. Therefore , we propose efficient heuristics to tackle the MQA problem , including MQA greedy and MQA divide-and-conquer approaches , which can efficiently assign doer to spatial tasks with high quality scores and low budget consumptions. Through extensive experiments , we demonstrate the efficiency and effectiveness of our approaches on both genuine and synthetic datasets. ", "label": 1}
{"original_text": "Deep learning methods are increasingly being used with neuroimaging data like structural and function magnetic resonance imaging (MRI) to predict the diagnosis of neuropsychiatric and neurological disorders. For psychiatric disorders in particular, it is believed that one of the most promising modality is the resting-state functional MRI (rsfMRI), which captures the intrinsic connectivity between regions in the brain. Because rsfMRI data points are inherently high-dimensional (1M), it is impossible to process the entire input in its raw form. In this paper, we propose a very simple transformation of the rsfMRI images that captures all of the temporal dynamics of the signal but sub-samples its spatial extent. As a result, we use a very simple 1-D convolutional network which is fast to train, requires minimal preprocessing and performs at par with the state-of-the-art on the classification of Autism spectrum disorders.", "text_perturb": "Deep learning methods are progressively being used with neuroimaging data like structural and function magnetic resonance imaging ( MRI ) to predict the diagnosis of neuropsychiatric and neurological disorders. For psychiatric disorders in particular , it cost believed that one of the most promising modality cost the resting-state functional MRI ( rsfMRI ) , which captures the intrinsic connectivity between regions in the brain. Because rsfMRI data points are inherently high-dimensional ( 1M ) , it is impossible to process the intact input in its raw form. In this paper , we propose a very simple transformation of the rsfMRI images that captures all of the temporal dynamics of the signal but sub-samples its spacial extent. As a result , we use a real simple 1-D convolutional network which is fast to train , requires minimal preprocessing and performs at par with the state-of-the-art on the classification of Autism spectrum disorders. ", "label": 1}
{"original_text": "In this paper, we propose a characterization of chordal bipartite graphs and an efficient enumeration algorithm for chordal bipartite induced subgraphs. A chordal bipartite graph is a bipartite graph without induced cycles with length six or more. It is known that the incident graph of a hypergraph is chordal bipartite graph if and only if the hypergraph is b -acyclic. As the main result of our paper, we show that a graph G is chordal bipartite if and only if there is a special vertex elimination ordering for G, called CBEO. Moreover, we propose an algorithm ECB which enumerates all chordal bipartite induced subgraphs in O (k t D 2) time per solution on average, where k is the degeneracy, t is the maximum size of K t, t as an induced subgraph, and D is the degree. ECB achieves constant amortized time enumeration for bounded degree graphs.", "text_perturb": "In this paper , we propose a characterization of chordal bipartite graphs and an efficient enumeration algorithmic program for chordal bipartite induced subgraphs. A chordal bipartite graph is a bipartite graph without induced cycles with distance six or more. It is known that the incident graphical record of a hypergraph is chordal bipartite graphical record if and only if the hypergraph is b -acyclic. As the main result of our paper , we show that a graph  is chordal bipartite if and only if there is a special vertex elimination ordering for  , called CBEO. Moreover , we propose an algorithm ECB which enumerates all chordal bipartite induced subgraphs in O ( k t D 2 ) time per solution on average , where k is the degeneracy , t is the maximal size of K t , t as an induced subgraph , and D is the degree. ECB achieves never ending amortized time enumeration for bounded degree graphs. ", "label": 1}
{"original_text": "We study knowledge-grounded dialogue generation with pre-trained language models. To leverage the redundant external knowledge under capacity constraint, we propose equipping response generation defined by a pre-trained language model with a knowledge selection module, and an unsupervised approach to jointly optimizing knowledge selection and response generation with unlabeled dialogues. Empirical results on two benchmarks indicate that our model can significantly outperform state-of-the-art methods in both automatic evaluation and human judgment.", "text_perturb": "We study knowledge-grounded dialogue generation with pre-trained language fashion model. To leverage the redundant external knowledge under capacity restraint , we propose equipping response generation defined by a pre-trained language model with a knowledge selection module , and an unsupervised approach to jointly optimizing knowledge selection and response generation with unlabeled dialogues. Empirical results on two benchmarks indicate that our model can importantly outperform state-of-the-art methods in both automatic evaluation and human judgment. ", "label": 1}
{"original_text": "Fingerprint verification systems are becoming ubiquitous in everyday life. This trend is propelled especially by the proliferation of mobile devices with fingerprint sensors such as smartphones and tablet computers, and fingerprint verification is increasingly applied for authenticating financial transactions. In this study we describe a novel attack vector against fingerprint verification systems which we coin skilled impostor attack. We show that existing protocols for performance evaluation of fingerprint verification systems are flawed and as a consequence of this, the system's real vulnerability is systematically underestimated. We examine a scenario in which a fingerprint verification system is tuned to operate at false acceptance rate of 0.1 using the traditional verification protocols with random impostors (zero-effort attacks). We demonstrate that an active and intelligent attacker can achieve a chance of success in the area of 89 or more against this system by performing skilled impostor attacks. We describe a new protocol for evaluating fingerprint verification performance in order to improve the assessment of potential and limitations of fingerprint recognition systems. This new evaluation protocol enables a more informed decision concerning the operating threshold in practical applications and the respective trade-off between security (low false acceptance rates) and usability (low false rejection rates). The skilled impostor attack is a general attack concept which is independent of specific databases or comparison algorithms. The proposed protocol relying on skilled impostor attacks can directly be applied for evaluating the verification performance of other biometric modalities such as e.g. iris, face, ear, finger vein, gait or speaker recognition.", "text_perturb": "Fingerprint verification systems represent becoming ubiquitous in everyday life. This trend is propelled especially by the proliferation of mobile devices with fingerprint sensors such as smartphones and tablet computers , and fingerprint verification is increasingly applied for authenticating fiscal transactions. In this study we describe a new attack vector against fingerprint verification systems which we coin skilled impostor attack. We show that existing protocols for execution evaluation of fingerprint verification systems are flawed and as a consequence of this , the system 's real vulnerability is systematically underestimated. We examine a scenario in which a fingermark verification system is tuned to operate at false acceptance rate of 0. 1 habituate the traditional verification protocols with random impostors ( zero-effort attacks ). We demonstrate that an active and intelligent attacker can achieve a chance of success in the area of 89 or more against this system by do skilled impostor attacks. We describe a new protocol for evaluating fingerprint verification performance in order to improve the assessment of possible and limitations of fingerprint recognition systems. This new evaluation protocol enables a to a greater extent informed decision concerning the operating threshold in practical applications and the respective trade-off between security ( low false acceptance rates ) and usability ( low false rejection rates ). The skilled impostor attack is a general attack concept which is independent of specific database or comparison algorithms. The proposed communications protocol relying on skilled impostor attacks can directly be applied for evaluating the verification performance of other biometric modalities such as e. one thousand. iris , face , ear , finger vein , pace or speaker recognition. ", "label": 1}
{"original_text": "We analyze the local Rademacher complexity of empirical risk minimization (ERM) -based multi-label learning algorithms, and in doing so propose a new algorithm for multi-label learning. Rather than using the trace norm to regularize the multi-label predictor, we instead minimize the tail sum of the singular values of the predictor in multi-label learning. Benefiting from the use of the local Rademacher complexity, our algorithm, therefore, has a sharper generalization error bound and a faster convergence rate. Compared to methods that minimize over all singular values, concentrating on the tail singular values results in better recovery of the low-rank structure of the multi-label predictor, which plays an import role in exploiting label correlations. We propose a new conditional singular value thresholding algorithm to solve the resulting objective function. Empirical studies on real-world datasets validate our theoretical results and demonstrate the effectiveness of the proposed algorithm.", "text_perturb": "We analyze the local Rademacher complexity of empirical risk minimization ( ERM ) -based multi-label scholarship algorithms , and in doing so propose a new algorithm for multi-label scholarship. Rather than using the touch norm to regularize the multi-label predictor , we instead minimize the tail sum of the singular values of the predictor in multi-label learning. Benefiting from the use of the local Rademacher complexness , our algorithm , therefore , has a sharper generalization error bound and a faster convergence rate. Compared to methods that minimize over all singular values , concentrating on the tail singular values results in honorable recovery of the low-rank structure of the multi-label predictor , which plays an import role in exploiting label correlations. We propose a unexampled conditional singular value thresholding algorithm to solve the resulting objective function. Empirical studies on real-world datasets validate our theoretical results and demonstrate the effectiveness of the nominate algorithm. ", "label": 1}
{"original_text": "We introduce Fluid Annotation, an intuitive human-machine collaboration interface for annotating the class label and outline of every object and background region in an image 1 footnote 1 1 footnote 1 Live demo of the interface is available at fluidann.appspot.com. Fluid annotation is based on three principles: (I) Strong Machine-Learning aid. We start from the output of a strong neural network model, which the annotator can edit by correcting the labels of existing regions, adding new regions to cover missing objects, and removing incorrect regions. The edit operations are also assisted by the model. (II) Full image annotation in a single pass. As opposed to performing a series of small annotation tasks in isolation (,), we propose a unified interface for full image annotation in a single pass. (III) Empower the annotator. We empower the annotator to choose what to annotate and in which order. This enables concentrating on what the machine does not already know, i.e. putting human effort only on the errors it made. This helps using the annotation budget effectively. Through extensive experiments on the COCOStuff dataset (,), we demonstrate that Fluid Annotation leads to accurate annotations very efficiently, taking 3 x less annotation time than the popular LabelMe interface (,).", "text_perturb": "We introduce Fluid Annotation , an intuitive human-machine collaboration interface for annotating the class label and outline of every object and background realm in an image 1 footnote 1 1 footnote 1 Live demo of the interface is available at fluidann. appspot. com. fluid annotation is based on three principles : ( I ) Strong Machine-Learning aid. We start from the output of a strong neural network model , which the annotator can edit by correcting the labels of existing regions , adding new regions to traverse missing objects , and removing incorrect regions. The edit operations are also attend to by the model. ( II ) full phase of the moon image annotation in a single pass. As opposed to performing a series of humble annotation tasks in isolation ( , ) , we propose a unified interface for full image annotation in a single pass. ( III ) indue the annotator. We empower the annotator to opt what to annotate and in which order. This enables concentrating on what the car does not already know , i. tocopherol. position human effort only on the errors it made. This help using the annotation budget effectively. Through extensive experiments on the COCOStuff dataset ( , ) , we demonstrate that Fluid Annotation leads to accurate annotations real efficiently , taking 3 x less annotation time than the popular LabelMe interface ( , ). ", "label": 1}
{"original_text": "Consider the task of performing a sequence of searches in a binary search tree. After each search, an algorithm is allowed to arbitrarily restructure the tree, at a cost proportional to the amount of restructuring performed. The cost of an execution is the sum of the time spent searching and the time spent optimizing those searches with restructuring operations. This notion was introduced by Sleator and Tarjan in (JACM, 1985), along with an algorithm and a conjecture. The algorithm, Splay, is an elegant procedure for performing adjustments while moving searched items to the top of the tree. The conjecture, called dynamic optimality, is that the cost of splaying is always within a constant factor of the optimal algorithm for performing searches. The conjecture stands to this day. In this work, we attempt to lay the foundations for a proof of the dynamic optimality conjecture. Central to our methods are simulation embeddings and approximate monotonicity. A simulation embedding maps each execution to a list of keys that induces a target algorithm to simulate the execution. Approximately monotone algorithms are those whose cost does not increase by more than a constant factor when keys are removed from the list. As we shall see, approximately monotone algorithms with simulation embeddings are dynamically optimal. Building on these ideas: item 1st item We construct a simulation embedding for Splay by inducing Splay to perform arbitrary subtree transformations. Thus, if Splay is approximately monotone then it is dynamically optimal. We also show that approximate monotonicity is a necessary condition for dynamic optimality. (Section) item 2nd item We show that if Splay is dynamically optimal, then with respect to optimal cost, its additive overhead is at most linear in the sum of initial tree size and the number of requests. (Section) item 3rd item We prove that a known lower bound on optimal execution cost by Wilber is approximately monotone. (Section and Appendix) item 4th item We speculate about how one might establish dynamic optimality by adapting the proof of approximate monotonicity from the lower bound to Splay. (Section) item 5th item We demonstrate that two related conjectures, traversal and deque, also follow if Splay is approximately monotone, and that many results in this paper extend to a broad class of \"path-based\" algorithms. (Section) Appendix generalizes the tree transformations used to build simulation embeddings, and Appendix includes proofs of selected pieces of \"folklore\" that have appeared throughout the literature.", "text_perturb": "Consider the project of performing a sequence of searches in a binary search tree. After each search , an algorithm is allowed to arbitrarily restructure the sir herbert beerbohm tree , at a cost proportional to the amount of restructuring performed. The cost of an execution is the sum of the time drop searching and the time spent optimizing those searches with restructuring operations. This notion live introduced by Sleator and Tarjan in ( JACM , 1985 ) , along with an algorithm and a conjecture. The algorithm , splay , is an elegant procedure for performing adjustments while moving searched items to the top of the tree. The conjecture , visit dynamic optimality , is that the cost of splaying is always within a constant factor of the optimal algorithm for performing searches. The hypothesis stands to this day. In this work , we attempt to lay the foundations for a proof of the dynamical optimality conjecture. Central to our methods embody simulation embeddings and approximate monotonicity. A simulation embedding maps each execution to a list of keys that induces a aim algorithm to simulate the execution. Approximately monotone algorithms are those whose cost does not increase by more than than a constant factor when keys are removed from the list. As we shall realise , approximately monotone algorithms with simulation embeddings are dynamically optimal. Building on these ideas : item 1st item We construct a simulation embedding for Splay by inducing Splay to do arbitrary subtree transformations. Thus , if Splay is approximately monotone then it is dynamically optimum. We likewise show that approximate monotonicity is a necessary condition for dynamic optimality. ( Section ) item 2nd item We show that if Splay cost dynamically optimal , then with respect to optimal cost , its additive overhead cost at most linear in the sum of initial tree size and the number of requests. ( Section ) item 3rd item We prove that a know lower bound on optimal execution cost by Wilber is approximately monotone. ( Section and Appendix ) item 4th item We speculate about how one might establish dynamic optimality by adapting the proof of approximate monotonicity from the lower saltation to Splay. ( Section ) item 5th item We demonstrate that two related conjectures , traversal and deque , also follow if Splay is approximately monotonic , and that many results in this paper extend to a broad class of `` path-based '' algorithms. ( Section ) Appendix infer the tree transformations used to build simulation embeddings , and Appendix includes proofs of selected pieces of `` folklore '' that have appeared throughout the literature. ", "label": 1}
{"original_text": "Existing works on control of tractor-trailers systems only consider the kinematics model without taking dynamics into account. Also, most of them treat the issue as a pure control theory problem whose solutions are difficult to implement. This paper presents a trajectory tracking control approach for a full-scale industrial tractor-trailers vehicle composed of a car-like tractor and arbitrary number of passive full trailers. To deal with dynamic effects of trailing units, a force sensor is innovatively installed at the connection between the tractor and the first trailer to measure the forces acting on the tractor. The tractor's dynamic model that explicitly accounts for the measured forces is derived. A tracking controller that compensates the pullingpushing forces in real time and simultaneously drives the system onto desired trajectories is proposed. The propulsion map between throttle opening and the propulsion force is proposed to be modeled with a fifth-order polynomial. The parameters are estimated by fitting experimental data, in order to provide accurate driving force. Stability of the control algorithm is rigorously proved by Lyapunov methods. Experiments of full-size vehicles are conducted to validate the performance of the control approach.", "text_perturb": "Existing works on control of tractor-trailers systems only consider the kinematics mannikin without taking dynamics into account. Also , most of them treat the issue as a pure control possibility problem whose solutions are difficult to implement. This paper presents a trajectory tracking control advance for a full-scale industrial tractor-trailers vehicle composed of a car-like tractor and arbitrary number of passive full trailers. To deal with dynamic effects of trailing units , a force sensor is innovatively installed at the connection between the tractor and the first laggard to measure the forces acting on the tractor. The tractor 's dynamic model that explicitly account for the measured forces is derived. A tracking controller that repair the pullingpushing forces in real time and simultaneously drives the system onto desired trajectories is proposed. The propulsion map between throttle porta and the propulsion force is proposed to be modeled with a fifth-order polynomial. The parameters exist estimated by fitting experimental data , in order to provide accurate driving force. Stability of the control algorithm is strictly proved by Lyapunov methods. Experiments of life sized vehicles are conducted to validate the performance of the control approach. ", "label": 1}
{"original_text": "Asking effective questions is a powerful social skill. In this paper we seek to build computational models that learn to discriminate effective questions from ineffective ones. Armed with such a capability, future advanced systems can evaluate the quality of questions and provide suggestions for effective question wording. We create a large-scale, real-world dataset that contains over 400,000 questions collected from Reddit \"Ask Me Anything\" threads. Each thread resembles an online press conference where questions compete with each other for attention from the host. This dataset enables the development of a class of computational models for predicting whether a question will be answered. We develop a new convolutional neural network architecture with variable-length context and demonstrate the efficacy of the model by comparing it with state-of-the-art baselines and human judges.", "text_perturb": "Asking effective questions is a powerful social attainment. In this composition we seek to build computational models that learn to discriminate effective questions from ineffective ones. Armed with such a capability , future advanced systems can evaluate the quality of questions and provide suggestions for effectual question wording. We create a large-scale , real-world dataset that contains over 400,000 questions collected from Reddit `` Ask maine Anything '' threads. Each thread resemble an online press conference where questions compete with each other for attention from the host. This dataset enables the growth of a class of computational models for predicting whether a question will be answered. We make grow a new convolutional neural network architecture with variable-length context and demonstrate the efficacy of the model by comparing it with state-of-the-art baselines and human judges. ", "label": 1}
{"original_text": "In this work, we build a generic architecture of Convolutional Neural Networks to discover empirical properties of neural networks. Our first contribution is to introduce a state-of-the-art framework that depends upon few hyper parameters and to study the network when we vary them. It has no max pooling, no biases, only 13 layers, is purely convolutional and yields up to 95.4 and 79.6 accuracy respectively on CIFAR10 and CIFAR100. We show that the nonlinearity of a deep network does not need to be continuous, non expansive or point-wise, to achieve good performance. We show that increasing the width of our network permits being competitive with very deep networks. Our second contribution is an analysis of the contraction and separation properties of this network. Indeed, a 1-nearest neighbor classifier applied on deep features progressively improves with depth, which indicates that the representation is progressively more regular. Besides, we defined and analyzed local support vectors that separate classes locally. All our experiments are reproducible and code is available online, based on TensorFlow.", "text_perturb": "In this work , we build a generic computer architecture of Convolutional Neural Networks to discover empirical properties of neural networks. Our first contribution is to introduce a state-of-the-art framework that depends upon few hyper parameters and to canvas the network when we vary them. It take no max pooling , no biases , only 13 layers , is purely convolutional and yields up to 95. 4 and 79. 6 accuracy respectively on CIFAR10 and CIFAR100. We show that the nonlinearity of a deep network does not need to be uninterrupted , non expansive or point-wise , to achieve good performance. We show that increasing the width of our network permits exist competitive with very deep networks. Our second contribution is an analysis of the contraction and detachment properties of this network. Indeed , a 1-nearest neighbor classifier applied on deep features increasingly improves with depth , which indicates that the representation is increasingly more regular. Besides , we defined and analyzed local backup vectors that separate classes locally. All our experiments are reproducible and code cost available online , based on TensorFlow. ", "label": 1}
{"original_text": "Understanding the interactions between different combinatorial optimisation problems in real-world applications is a challenging task. Recently, the traveling thief problem (TTP), as a combination of the classical traveling salesperson problem and the knapsack problem, has been introduced to study these interactions in a systematic way. We investigate the underlying non-linear packing while traveling (PWT) problem of the TTP where items have to be selected along a fixed route. We give an exact dynamic programming approach for this problem and a fully polynomial time approximation scheme (FPTAS) when maximising the benefit that can be gained over the baseline travel cost. Our experimental investigations show that our new approaches outperform current state-of-the-art approaches on a wide range of benchmark instances.", "text_perturb": "Understanding the interactions between different combinatorial optimization problems in real-world applications is a challenging task. Recently , the traveling thief trouble ( TTP ) , as a combination of the classical traveling salesperson trouble and the knapsack trouble , has been introduced to study these interactions in a systematic way. We investigate the underlying non-linear packing while move around ( PWT ) problem of the TTP where items have to be selected along a fixed route. We give an exact dynamic programing approach for this problem and a fully polynomial time approximation scheme ( FPTAS ) when maximising the benefit that can be gained over the baseline travel cost. Our experimental investigations show that our newfangled approaches outperform current state-of-the-art approaches on a wide range of benchmark instances. ", "label": 1}
{"original_text": "The paper presents a new, robust control algorithm for position trajectory tracking in a 3D space, dedicated to underactuated airships. In order to take into account real characteristics of such vehicles, and to reflect practically motivated constraints, the algorithm assumes a highly uncertain system dynamics model. The tracking problem is solved in a uniform way, without dividing it into subtasks considered in 2D spaces, thanks to the introduction of an auxiliary tracking error. The proposed controller is based on the sliding mode approach. Its stability is investigated using Lyapunov theorem. Numerical simulations are conducted in order to verify properties of a closed-loop system for a generic model of the airship. Performance of the control system is examined via experiments in various scenarios using a prototype airship. The obtained results indicate that the control objectives are satisfied in practice with a reasonable accuracy. Moreover, it is shown that the controller is robust to some bounded additive measurement perturbations and delays in the control loop.", "text_perturb": "The paper presents a new , robust control algorithm for position trajectory tracking in a 3D space , devote to underactuated airships. In order to take into account real characteristics of such vehicles , and to reflect practically motivated constraints , the algorithmic rule assumes a highly uncertain system dynamics model. The tracking problem is solved in a uniform way , without dividing it into subtasks considered in 2D spaces , thanks to the introduction of an auxiliary tracking fault. The proposed controller make up based on the sliding mode approach. Its stability is investigated using Lyapunov theorem. Numerical simulations are conducted in order to verify properties of a closed-loop system for a generic model of the dirigible. Performance of the control system is examined via experiments in various scenarios using a prototype dirigible. The obtained results indicate that the control objectives are satisfied in practice with a reasonable truth. Moreover , it is shown that the controller is robust to some bounded additive measurement perturbations and hold in the control loop. ", "label": 1}
{"original_text": "Wireless Sensor Networks (WSNs) with their dynamic applications gained a tremendous attention of researchers. Constant monitoring of critical situations attracted researchers to utilize WSNs at vast platforms. The main focus in WSNs is to enhance network life-time as much as one could, for efficient and optimal utilization of resources. Different approaches based upon clustering are proposed for optimum functionality. Network life-time is always related with energy of sensor nodes deployed at remote areas for constant and fault tolerant monitoring. In this work, we propose Quadrature-LEACH (Q-LEACH) for homogenous networks which enhances stability period, network life-time and throughput quiet significantly.", "text_perturb": "Wireless Sensor Networks ( WSNs ) with their dynamic applications take in a tremendous attention of researchers. Constant monitoring of critical situations attracted researchers to utilize WSNs at vast political platform. The main focus in WSNs is to enhance network life-time as much as one could , for efficient and optimum utilization of resources. Different approach path based upon clustering are proposed for optimum functionality. Network life-time is always related with energy of sensor nodes deployed at remote sphere for constant and fault tolerant monitoring. In this work , we propose Quadrature-LEACH ( Q-LEACH ) for homogenous networks which enhances stability period , mesh life-time and throughput quiet significantly. ", "label": 1}
{"original_text": "Video Object Segmentation (VOS) is an active research area of the visual domain. One of its fundamental sub-tasks is semi-supervised one-shot learning: given only the segmentation mask for the first frame, the task is to provide pixel-accurate masks for the object over the rest of the sequence. Despite much progress in the last years, we noticed that many of the existing approaches lose objects in longer sequences, especially when the object is small or briefly occluded. In this work, we build upon a sequence-to-sequence approach that employs an encoder-decoder architecture together with a memory module for exploiting the sequential data. We further improve this approach by proposing a model that manipulates multi-scale spatio-temporal information using memory-equipped skip connections. Furthermore, we incorporate an auxiliary task based on distance classification which greatly enhances the quality of edges in segmentation masks. We compare our approach to the state of the art and show considerable improvement in the contour accuracy metric and the overall segmentation accuracy.", "text_perturb": "Video target Segmentation ( VOS ) is an active research area of the visual domain. One of its fundamental sub-tasks is semi-supervised one-shot learning : given only the segmentation mask for the first frame , the task is to provide pixel-accurate masks for the object over the remainder of the sequence. Despite much progress in the last years , we point out that many of the existing approaches lose objects in longer sequences , especially when the object is small or briefly occluded. In this work , we build upon a sequence-to-sequence approach that employs an encoder-decoder architecture together with a memory module for exploiting the sequent data. We further improve this approach by proposing a model that manipulates multi-scale spatio-temporal information using memory-equipped omission connections. Furthermore , we incorporate an auxiliary task based on distance classification which greatly enhances the quality of edges in division masks. We compare our approach to the state of the art and show considerable improvement in the contour accuracy metrical and the overall segmentation accuracy. ", "label": 1}
{"original_text": "Hidden Markov chains are widely applied statistical models of stochastic processes, from fundamental physics and chemistry to finance, health, and artificial intelligence. The hidden Markov processes they generate are notoriously complicated, however, even if the chain is finite state: no finite expression for their Shannon entropy rate exists, as the set of their predictive features is generically infinite. As such, to date one cannot make general statements about how random they are nor how structured. Here, we address the first part of this challenge by showing how to efficiently and accurately calculate their entropy rates. We also show how this method gives the minimal set of infinite predictive features. A sequel addresses the challenge's second part on structure.", "text_perturb": "Hidden Markov chains are wide applied statistical models of stochastic processes , from fundamental physics and chemistry to finance , health , and artificial intelligence. The hidden Markov processes they generate are notoriously rarify , however , even if the chain is finite state : no finite expression for their Shannon entropy rate exists , as the set of their predictive features is generically infinite. As such , to date one can non make general statements about how random they are nor how structured. Here , we address the first part of this challenge by showing how to efficiently and accurately calculate their randomness rates. We also show how this method gives the minimal set of infinite predictive feature article. A sequel addresses the challenge 's second voice on structure. ", "label": 1}
{"original_text": "The wide acceptance of Internet of Things (IoT) for both household and industrial applications is accompanied by several security concerns. A major security concern is their probable abuse by adversaries towards their malicious intent. Understanding and analyzing IoT malicious behaviors is crucial, especially with their rapid growth and adoption in wide-range of applications. Among the variety of employed techniques, static and dynamic analyses are the most common approaches to detect and classify malware. Given the limited scalability of dynamic analysis, static analysis, such as the use of Control Flow Graph (CFG) -based features, is widely used by machine learning algorithms for malware analysis and detection. However, recent studies have shown that machine learning-based approaches are susceptible to adversarial attacks by adding junk codes to the binaries, for example, with an intention to fool those machine learning or deep learning-based detection systems. Realizing the importance of addressing this challenge, this study proposes a malware detection system that is robust to adversarial attacks. To do so, examine the performance of the state-of-the-art methods against adversarial IoT software crafted using the graph embedding and augmentation techniques. In particular, we study the robustness of such methods against two black-box adversarial methods, GEA and SGEA, to generate Adversarial Examples (AEs) with reduced overhead, and keeping their practicality intact. Our comprehensive experimentation with GEA-based AEs show the relation between misclassification and the graph size of the injected sample. Upon optimization and with small perturbation, by use of SGEA, all the IoT malware samples are misclassified as benign. This highlights the vulnerability of current detection systems under adversarial settings. With the landscape of possible adversarial attacks, we then propose DL-FHMC, a fine-grained hierarchical learning approach for malware detection and classification, that is robust to AEs with a capability to detect 88.52 of the malicious AEs.", "text_perturb": "The wide acceptance of Internet of Things ( IoT ) for both household and industrial coating is accompanied by several security concerns. A major security concern is their likely abuse by adversaries towards their malicious intent. Understanding and analyzing IoT malicious behaviors is crucial , especially with their speedy growth and adoption in wide-range of applications. Among the variety of employed technique , static and dynamic analyses are the most common approaches to detect and classify malware. Given the limited scalability of dynamic analytic thinking , static analytic thinking , such as the use of Control Flow Graph ( CFG ) -based features , is widely used by machine learning algorithms for malware analytic thinking and detection. However , recent studies have shown that machine learning-based approaches are susceptible to adversarial attacks by adding junk codes to the binaries , for exercise , with an intention to fool those machine learning or deep learning-based detection systems. Realizing the importance of addressing this challenge , this study proposes a malware detection scheme that is robust to adversarial attacks. To do so , examine the performance of the state-of-the-art methods against adversarial IoT software crafted using the graph embedding and augmentation proficiency. In particular , we study the robustness of such methods against two black-box adversarial methods , GEA and SGEA , to yield Adversarial Examples ( AEs ) with reduced overhead , and keeping their practicality intact. Our comprehensive experimentation with GEA-based AEs show the coitus between misclassification and the graph size of the injected sample. Upon optimization and with small perturbation , by function of SGEA , all the IoT malware samples are misclassified as benign. This highlights the vulnerability of current detection systems under adversarial stage setting. With the landscape of possible adversarial attacks , we then propose DL-FHMC , a fine-grained hierarchical acquisition approach for malware detection and classification , that is robust to AEs with a capability to detect 88. 52 of the malicious AEs. ", "label": 1}
{"original_text": "Cyber is the newest domain of war, and the topic of cyber warfare is one that is receiving increasing attention. Research efforts into cyber warfare are extensive, covering a range of issues such as legality, cyber weapons and deterrence. Despite all of the research activity around cyber warfare, one aspect has been largely overlooked: the restoration of peace and security in its aftermath. In this article, we present the argument that cyber warfare will threaten civilian peace and security long after a conflict has ended, and that existing peace operations will be required to evolve in order to address this threat. We explore how existing UN peacekeeping operations could be adapted, in ways that would be both feasible and valuable towards maintaining and restoring peace in a region. We conclude that the path to cyber peacekeeping will not be easy, but that it is an evolution that must begin today so that we can be prepared for the conflicts of the future.", "text_perturb": "Cyber is the newest domain of war , and the topic of cyber warfare is one that is receiving increasing care. Research efforts into cyber warfare equal extensive , covering a range of issues such as legality , cyber weapons and deterrence. Despite all of the research activity around cyber warfare , one aspect has been mostly overlooked : the restoration of peace and security in its aftermath. In this article , we present the debate that cyber warfare will threaten civilian peace and security long after a conflict has ended , and that existing peace operations will be required to evolve in order to address this threat. We explore how existing UN peacekeeping operations could constitute adapted , in ways that would constitute both feasible and valuable towards maintaining and restoring peace in a region. We conclude that the itinerary to cyber peacekeeping will not be easy , but that it is an evolution that must begin today so that we can be prepared for the conflicts of the future. ", "label": 1}
{"original_text": "We consider the problem of reconstructing a rank-one matrix from a revealed subset of its entries when some of the revealed entries are corrupted with perturbations that are unknown and can be arbitrarily large. It is not known which revealed entries are corrupted. We propose a new algorithm combining alternating minimization with extreme-value filtering and provide sufficient and necessary conditions to recover the original rank-one matrix. In particular, we show that our proposed algorithm is optimal when the set of revealed entries is given by an Erdos-Renyi random graph. These results are then applied to the problem of classification from crowdsourced data under the assumption that while the majority of the workers are governed by the standard single-coin David-Skene model (i.e., they output the correct answer with a certain probability), some of the workers can deviate arbitrarily from this model. In particular, the \"adversarial\" workers could even make decisions designed to make the algorithm output an incorrect answer. Extensive experimental results show our algorithm for this problem, based on rank-one matrix completion with perturbations, outperforms all other state-of-the-art methods in such an adversarial scenario. 1 footnote 1 1 footnote 1 The code is available on", "text_perturb": "We consider the problem of reconstructing a rank-one matrix from a revealed subset of its entries when some of the revealed entries are vitiate with perturbations that are unknown and can be arbitrarily large. It is not known which revealed entries live corrupted. We propose a new algorithm combining alternating minimisation with extreme-value filtering and provide sufficient and necessary conditions to recover the original rank-one matrix. In particular , we show that our proposed algorithm follow optimal when the set of revealed entries follow given by an Erdos-Renyi random graph. These results are and then applied to the problem of classification from crowdsourced data under the assumption that while the majority of the workers are governed by the standard single-coin David-Skene model ( i. eastward. , they output the correct response with a certain probability ) , some of the workers can deviate arbitrarily from this model. In particular , the `` adversarial '' workers could even make decisions plan to make the algorithm output an incorrect answer. Extensive experimental results show our algorithm for this problem , based on rank-one matrix completion with disruption , outperforms all other state-of-the-art methods in such an adversarial scenario. 1 footnote 1 1 footer 1 The code is available on", "label": 1}
{"original_text": "The tight upper bound on the state complexity of the reverse of R -trivial and J -trivial regular languages of the state complexity n is 2 - n 1. The witness is ternary for R -trivial regular languages and n 1) -ary for J -trivial regular languages. In this paper, we prove that the bound can be met neither by a binary R -trivial regular language nor by a J -trivial regular language over an n 2) -element alphabet. We provide a characterization of tight bounds for R -trivial regular languages depending on the state complexity of the language and the size of its alphabet. We show the tight bound for J -trivial regular languages over an n 2) -element alphabet and a few tight bounds for binary J -trivial regular languages. The case of J -trivial regular languages over an n k) -element alphabet, for 2 k - n 3, is open.", "text_perturb": "The tight upper bound on the state complexity of the reverse of R -trivial and J -trivial regular languages of the state complexity nitrogen is 2 - nitrogen 1. The witness is ternary for R -trivial regular oral communication and n 1 ) -ary for J -trivial regular oral communication. In this paper , we prove that the edge can be met neither by a binary R -trivial regular language nor by a J -trivial regular language over an n 2 ) -element alphabet. We ply a characterization of tight bounds for R -trivial regular languages depending on the state complexity of the language and the size of its alphabet. We show the slopped bound for J -trivial regular languages over an n 2 ) -element alphabet and a few slopped bounds for binary J -trivial regular languages. The case of J -trivial regular languages over an n grand ) -element alphabet , for 2 grand - n 3 , is open. ", "label": 1}
{"original_text": "We establish that first-order methods avoid saddle points for almost all initializations. Our results apply to a wide variety of first-order methods, including gradient descent, block coordinate descent, mirror descent and variants thereof. The connecting thread is that such algorithms can be studied from a dynamical systems perspective in which appropriate instantiations of the Stable Manifold Theorem allow for a global stability analysis. Thus, neither access to second-order derivative information nor randomness beyond initialization is necessary to provably avoid saddle points.", "text_perturb": "We establish that first-order method avoid saddle points for almost all initializations. Our results apply to a wide variety of first-order methods , including gradient descent , block coordinate descent , mirror descent and variation thereof. The connecting thread is that such algorithm can be studied from a dynamical systems perspective in which appropriate instantiations of the Stable Manifold Theorem allow for a global stability analysis. Thus , neither entree to second-order derivative information nor randomness beyond initialization is necessary to provably avoid saddle points. ", "label": 1}
{"original_text": "We study the problem of testing identity against a given distribution with a focus on the high confidence regime. More precisely, given samples from an unknown distribution p over n elements, an explicitly given distribution q, and parameters 0 e, d 1, we wish to distinguish, with probability at least - 1 d, whether the distributions are identical versus e -far in total variation distance. Most prior work focused on the case that d O (1), for which the sample complexity of identity testing is known to be Th (n e 2). Given such an algorithm, one can achieve arbitrarily small values of d via black-box amplification, which multiplies the required number of samples by Th (log (1 d. We show that black-box amplification is suboptimal for any d o (1), and give a new identity tester that achieves the optimal sample complexity. Our new upper and lower bounds show that the optimal sample complexity of identity testing is Th (1 e 2 (n log (1 d) log (1 d for any n, e, and d. For the special case of uniformity testing, where the given distribution is the uniform distribution U n over the domain, our new tester is surprisingly simple: to test whether p U n versus d T V (p, U n) e, we simply threshold d T V (p, U n), where p is the empirical probability distribution. The fact that this simple \"plug-in\" estimator is sample-optimal is surprising, even in the constant d case. Indeed, it was believed that such a tester would not attain sublinear sample complexity even for constant values of e and d. An important contribution of this work lies in the analysis techniques that we introduce in this context. First, we exploit an underlying strong convexity property to bound from below the expectation gap in the completeness and soundness cases. Second, we give a new, fast method for obtaining provably correct empirical estimates of the true worst-case failure probability for a broad class of uniformity testing statistics over all possible input distributions - including all previously studied statistics for this problem. We believe that our novel analysis techniques will be useful for other distribution testing problems as well.", "text_perturb": "We study the problem of testing identity operator against a given distribution with a focus on the high confidence regime. More precisely , given samples from an unknown dispersion p over n elements , an explicitly given dispersion q , and parameters 0 e , d 1 , we wish to distinguish , with probability at least - 1 d , whether the distributions are identical versus e -far in total variation distance. most prior work focused on the case that d O ( 1 ) , for which the sample complexity of identity testing is known to be Th ( n e 2 ). Given such an algorithm , one can achieve arbitrarily small values of d via black-box amplification , which multiplies the required number of samples by atomic number  ( log ( 1 d. We show that black-box amplification is suboptimal for any five hundred o ( 1 ) , and give a new identity tester that achieves the optimal sample complexity. Our new upper and lower bounds show that the optimal sample complexity of identity examination is Th ( 1 e 2 ( n log ( 1 d ) log ( 1 d for any n , e , and d. For the special case of uniformity testing , where the given distribution is the uniform distribution U n over the domain , our new tester is surprisingly simple : to test whether p U n versus d T quint ( p , U n ) e , we simply threshold d T quint ( p , U n ) , where p is the empirical probability distribution. The fact that this simple `` plug-in '' estimator is sample-optimal is surprising , yet in the constant d case. Indeed , it was believed that such a tester would non attain sublinear sample complexity even for constant values of e and d. An important contribution of this work lies in the analysis proficiency that we introduce in this context. First , we tap an underlying strong convexity property to bound from below the expectation gap in the completeness and soundness cases. Second , we give a new , fast method for obtaining provably correct empirical estimates of the true worst-case failure probability for a broad class of uniformity testing statistics over all possible stimulus distributions - including all previously studied statistics for this problem. We believe that our novel analysis techniques leave be useful for other distribution testing problems as well. ", "label": 1}
{"original_text": "Learning disentangled representations of high-dimensional data is currently an active research area. However, compared to the field of computer vision, less work has been done for speech processing. In this paper, we provide a review of two representative efforts on this topic and propose the novel concept of fine-grained disentangled speech representation learning.", "text_perturb": "Learning disentangled representations of high-dimensional data is presently an active research area. However , equate to the field of computer vision , less work has been done for speech processing. In this paper , we provide a review of two representative efforts on this topic and propose the refreshing concept of fine-grained disentangled speech representation learning. ", "label": 1}
{"original_text": "We give an approximate formula of the distribution of the largest eigenvalue of real Wishart matrices by the expected Euler characteristic method for the general dimension. The formula is expressed in terms of a definite integral with parameters. We derive a differential equation satisfied by the integral for the x 2 2 matrix case and perform a numerical analysis of it.", "text_perturb": "We give an approximate formula of the distribution of the largest eigenvalue of literal Wishart matrices by the expected Euler characteristic method for the general dimension. The pattern is expressed in terms of a definite integral with parameters. We derive a differential equation satisfy by the integral for the x 2 2 matrix case and perform a numerical analysis of it. ", "label": 1}
{"original_text": "In this work, we propose the use of a Natural User Interface (NUI) through body gestures using the open source library OpenPose, looking for a more dynamic and intuitive way to control a drone. For the implementation, we use the Robotic Operative System (ROS) to control and manage the different components of the project. Wrapped inside ROS, OpenPose (OP) processes the video obtained in real-time by a commercial drone, allowing to obtain the user's pose. Finally, the keypoints from OpenPose are obtained and translated, using geometric constraints, to specify high-level commands to the drone. Real-time experiments validate the full strategy.", "text_perturb": "In this work , we advise the use of a Natural User Interface ( NUI ) through body gestures using the open source library OpenPose , looking for a more dynamic and intuitive way to control a drone. For the implementation , we use the Robotic Operative System ( ROS ) to control and contend the different components of the project. Wrapped inside ROS , OpenPose ( OP ) processes the video obtained in real-time by a commercial drone , allowing to obtain the user 's airs. Finally , the keypoints from OpenPose are obtained and translated , habituate geometric constraints , to specify high-level commands to the drone. real time experiments validate the full strategy. ", "label": 1}
{"original_text": "Continuous input signals like images and time series that are irregularly sampled or have missing values are challenging for existing deep learning methods. Coherently defined feature representations must depend on the values in unobserved regions of the input. Drawing from the work in probabilistic numerics, we propose Probabilistic Numeric Convolutional Neural Networks which represent features as Gaussian processes (GPs), providing a probabilistic description of discretization error. We then define a convolutional layer as the evolution of a PDE defined on this GP, followed by a nonlinearity. This approach also naturally admits steerable equivariant convolutions under e.g. the rotation group. In experiments we show that our approach yields a 3 x reduction of error from the previous state of the art on the SuperPixel-MNIST dataset and competitive performance on the medical time series dataset PhysioNet2012.", "text_perturb": "Continuous input signals like images and metre series that are irregularly sampled or have missing values are challenging for existing deep learning methods. Coherently fix feature representations must depend on the values in unobserved regions of the input. Drawing from the work in probabilistic numerics , we propose Probabilistic Numeric Convolutional Neural meshing which represent features as Gaussian processes ( GPs ) , providing a probabilistic description of discretization error. We then delimit a convolutional layer as the evolution of a PDE defined on this GP , followed by a nonlinearity. This approach also naturally admits steerable equivariant convolutions under due east. gm. the rotation mathematical group. In experiments we demo that our approach yields a 3 x reduction of error from the previous state of the art on the SuperPixel-MNIST dataset and competitive performance on the medical time series dataset PhysioNet2012. ", "label": 1}
{"original_text": "In current deep learning paradigms, local training or the Standalone framework tends to result in overfitting and thus poor generalizability. This problem can be addressed by Distributed or Federated Learning (FL) that leverages a parameter server to aggregate model updates from individual participants. However, most existing Distributed or FL frameworks have overlooked an important aspect of participation: collaborative fairness. In particular, all participants can receive the same or similar models, regardless of their contributions. To address this issue, we investigate the collaborative fairness in FL, and propose a novel Collaborative Fair Federated Learning (CFFL) framework which utilizes reputation to enforce participants to converge to different models, thus achieving fairness without compromising the predictive performance. Extensive experiments on benchmark datasets demonstrate that CFFL achieves high fairness, delivers comparable accuracy to the Distributed framework, and outperforms the Standalone framework. Our code is available on github.", "text_perturb": "In current deep learning paradigms , local training or the Standalone framework incline to result in overfitting and thus poor generalizability. This problem can be addressed by Distributed or Federated Learning ( FL ) that leverage a parameter server to aggregate model updates from individual participants. However , most existing circularise or FL frameworks have overlooked an important aspect of participation : collaborative fairness. In fussy , all participants can receive the same or similar models , regardless of their contributions. To address this issue , we investigate the collaborative fairness in florida , and propose a novel Collaborative Fair Federated Learning ( CFFL ) framework which utilizes reputation to enforce participants to converge to different models , thus achieving fairness without compromising the predictive performance. Extensive experiments on benchmark datasets demonstrate that CFFL achieves high fairness , delivers comparable accuracy to the Distributed model , and outperforms the Standalone model. Our code is useable on github. ", "label": 1}
{"original_text": "Our goal is to predict the location of the next crime in a crime series, based on the identified previous offenses in the series. We build a predictive model called Next Hit Predictor (NHP) that finds the most likely location of the next serial crime via a carefully designed risk model. The risk model follows the paradigm of a self-exciting point process which consists of a background crime risk and triggered risks stimulated by previous offenses in the series. Thus, NHP creates a risk map for a crime series at hand. To train the risk model, we formulate a convex learning objective that considers pairwise rankings of locations and use stochastic gradient descent to learn the optimal parameters. Next Hit Predictor incorporates both spatial-temporal features and geographical characteristics of prior crime locations in the series. Next Hit Predictor has demonstrated promising results on decades' worth of serial crime data collected by the Crime Analysis Unit of the Cambridge Police Department in Massachusetts, USA.", "text_perturb": "Our destination is to predict the location of the next crime in a crime series , based on the identified previous offenses in the series. We build a predictive model called Next Hit Predictor ( NHP ) that finds the almost likely location of the next serial crime via a carefully designed risk model. The risk model follows the paradigm of a self-exciting point process which consists of a background crime risk and trip risks stimulated by previous offenses in the series. Thus , NHP creates a risk map for a criminal offence series at hand. To train the risk model , we excogitate a convex learning objective that considers pairwise rankings of locations and use stochastic gradient descent to learn the optimal parameters. Next Hit Predictor incorporates both spatial-temporal features and geographical characteristics of prior crime locations in the serial. Next Hit prognosticator has demonstrated promising results on decades ' worth of serial crime data collected by the Crime Analysis Unit of the Cambridge Police Department in Massachusetts , USA. ", "label": 1}
{"original_text": "Les robots trouvent de nouvelles applications dans notre vie de tous les jours et interagissent de plus en plus etroitement avec leurs utilisateurs humains. Cependant, malgre une longue tradition de recherche, les architectures cognitives existantes restent souvent trop generiques et pas assez adaptees aux besoins specifiques de l'Interaction sociale Humain-Robot, comme la gestion des emotions, du langage, des normes sociales, etc. Dans cet article, nous presentons CAIO, une architecture Cognitive et Affective Orientee Interaction. Elle permet aux robots de raisonner sur les etats mentaux (y compris les emotions) et d'agir physiquement, emotionnellement et verbalement.", "text_perturb": "lupus erythematosus robots trouvent de nouvelles applications dans notre vie de tous les jours et interagissent de plus en plus etroitement avec leurs utilisateurs humains. Cependant , malgre une longue custom de recherche , les architectures cognitives existantes restent souvent trop generiques et pas assez adaptees aux besoins specifiques de l'Interaction sociale Humain-Robot , comme la gestion des emotions , du langage , des normes sociales , etc. Dans cet article , nous presentons CAIO , une computer architecture Cognitive et Affective Orientee Interaction. Elle permet aux robots de raisonner tyre les etats mentaux ( y compris les emotions ) et d'agir physiquement , emotionnellement et verbalement. ", "label": 1}
{"original_text": "Although deep learning has achieved appealing results on several machine learning tasks, most of the models are deterministic at inference, limiting their application to single-modal settings. We propose a novel general-purpose framework for conditional generation in multimodal spaces, that uses latent variables to model generalizable learning patterns while minimizing a family of regression cost functions. At inference, the latent variables are optimized to find optimal solutions corresponding to multiple output modes. Compared to existing generative solutions, our approach demonstrates faster and stable convergence, and can learn better representations for downstream tasks. Importantly, it provides a simple generic model that can beat highly engineered pipelines tailored using domain expertise on a variety of tasks, while generating diverse outputs. Our codes will be released.", "text_perturb": "Although deep learning has achieved appealing results on several machine learning tasks , most of the models are deterministic at inference , limiting their application to single-modal context. We propose a novel general-purpose framework for conditional generation in multimodal spaces , that utilize latent variables to model generalizable learning patterns while minimizing a family of regression cost functions. At inference , the latent variables be optimized to find optimal solutions corresponding to multiple output modes. Compared to existing generative solutions , our approach demonstrates faster and stable convergence , and can learn better representations for downstream labor. Importantly , it provides a simple generic model that can beat highly engineered pipelines tailored utilise domain expertise on a variety of tasks , while generating diverse outputs. Our code will be released. ", "label": 1}
{"original_text": "The classical method of determining the atomic structure of complex molecules by analyzing diffraction patterns is currently undergoing drastic developments. Modern techniques for producing extremely bright and coherent X-ray lasers allow a beam of streaming particles to be intercepted and hit by an ultrashort high energy X-ray beam. Through machine learning methods the data thus collected can be transformed into a three-dimensional volumetric intensity map of the particle itself. The computational complexity associated with this problem is very high such that clusters of data parallel accelerators are required. We have implemented a distributed and highly efficient algorithm for inversion of large collections of diffraction patterns targeting clusters of hundreds of GPUs. With the expected enormous amount of diffraction data to be produced in the foreseeable future, this is the required scale to approach real time processing of data at the beam site. Using both real and synthetic data we look at the scaling properties of the application and discuss the overall computational viability of this exciting and novel imaging technique.", "text_perturb": "The classical method of determining the atomic structure of complex molecules by analyzing diffraction patterns is presently undergoing drastic developments. bodoni font techniques for producing extremely bright and coherent X-ray lasers allow a beam of streaming particles to be intercepted and hit by an ultrashort high energy X-ray beam. Through machine learning methods the data thus collected can be transformed into a three-dimensional volumetric intensity single valued function of the particle itself. The computational complexity associated with this problem is real high such that clusters of data parallel accelerators are required. We have enforce a distributed and highly efficient algorithm for inversion of large collections of diffraction patterns targeting clusters of hundreds of GPUs. With the await enormous amount of diffraction data to be produced in the foreseeable future , this is the required scale to approach real time processing of data at the beam site. Using both real and synthetic data we look at the grading properties of the application and discuss the overall computational viability of this exciting and novel imaging technique. ", "label": 1}
{"original_text": "In this paper, using the stochastic geometry theory, we present a framework for analyzing the performance of device-to-device (D2D) communications underlaid uplink (UL) cellular networks. In our analysis, we consider a D2D mode selection criterion based on an energy threshold for each user equipment (UE). Specifically, a UE will operate in a cellular mode, if its received signal strength from the strongest base station (BS) is large than a threshold b. Otherwise, it will operate in a D2D mode. Furthermore, we consider a generalized log-normal shadowing in our analysis. The coverage probability and the area spectral efficiency (ASE) are derived for both the cellular network and the D2D one. Through our theoretical and numerical analyses, we quantify the performance gains brought by D2D communications and provide guidelines of selecting the parameters for network operations.", "text_perturb": "In this paper , using the stochastic geometry theory , we present a framework for psychoanalyze the performance of device-to-device ( D2D ) communications underlaid uplink ( UL ) cellular networks. In our analysis , we weigh a D2D mode selection criterion based on an energy threshold for each user equipment ( UE ). specifically , a UE will operate in a cellular mode , if its received signal strength from the strongest base station ( BS ) is large than a threshold b. Otherwise , it will operate in a D2D mode. Furthermore , we study a generalized log-normal shadowing in our analysis. The insurance coverage probability and the area spectral efficiency ( ASE ) are derived for both the cellular network and the D2D one. Through our theoretical and numerical analyses , we quantify the performance gains brought by D2D communications and provide guidelines of selecting the parameters for network surgical procedure. ", "label": 1}
{"original_text": "Protection equipment is used to prevent damage to induction motor loads by isolating them from power systems in the event of severe faults. Modeling the response of induction motor loads and their protection is vital for power system planning and operation, especially in understanding system's dynamic performance and stability after a fault occurs. Induction motors are usually equipped with several types of protection with different operation mechanisms, making it challenging to develop adequate yet not overly complex protection models and determine their parameters for aggregate induction motor models. This paper proposes an optimization-based nonlinear regression framework to determine protection model parameters for aggregate induction motor loads in commercial buildings. Using a mathematical abstraction, the task of determining a suitable set of parameters for the protection model in composite load models is formulated as a nonlinear regression problem. Numerical examples are provided to illustrate the application of the framework. Sensitivity studies are presented to demonstrate the impact of lack of available motor load information on the accuracy of the protection models.", "text_perturb": "Protection equipment is used to prevent damage to induction motor loads by isolating them from power systems in the event of severe faulting. Modeling the response of induction motor loads and their protection is vital for power system planning and operation , especially in understanding system 's dynamic performance and constancy after a fault occurs. Induction motors are usually equipped with several types of protection with different operation mechanisms , making it challenging to develop adequate yet not to a fault complex protection models and determine their parameters for aggregate induction motor models. This paper proposes an optimization-based nonlinear regression framework to determine protection model parameter for aggregate induction motor loads in commercial buildings. Using a mathematical abstraction , the task of determining a suitable set of parameters for the protection model in composite load models is formulated as a nonlinear retrogression problem. Numerical examples comprise provided to illustrate the application of the framework. Sensitivity studies are presented to demonstrate the impact of lack of available motor load information on the accuracy of the protection modelling. ", "label": 1}
{"original_text": "Owing to several applications in large scale learning and vision problems, fast submodular function minimization (SFM) has become a critical problem. Theoretically, unconstrained SFM can be performed in polynomial time. However, these algorithms are typically not practical. In 1976, Wolfe proposed an algorithm to find the minimum Euclidean norm point in a polytope, and in 1980, Fujishige showed how Wolfe's algorithm can be used for SFM. For general submodular functions, this Fujishige-Wolfe minimum norm algorithm seems to have the best empirical performance. Despite its good practical performance, very little is known about Wolfe's minimum norm algorithm theoretically. To our knowledge, the only result is an exponential time analysis due to Wolfe himself. In this paper we give a maiden convergence analysis of Wolfe's algorithm. We prove that in t iterations, Wolfe's algorithm returns an O (1 t) -approximate solution to the min-norm point on any polytope. We also prove a robust version of Fujishige's theorem which shows that an O (1 n 2) -approximate solution to the min-norm point on the base polytope implies exact submodular minimization. As a corollary, we get the first pseudo-polynomial time guarantee for the Fujishige-Wolfe minimum norm algorithm for unconstrained submodular function minimization.", "text_perturb": "Owing to several applications in large scale learning and vision problems , fast submodular map minimization ( SFM ) has become a critical problem. Theoretically , unconstrained SFM tin be performed in polynomial time. However , these algorithms are typically not practical. In 1976 , Wolfe proposed an algorithm to find the minimum Euclidean norm point in a polytope , and in 1980 , Fujishige showed how Wolfe 's algorithm can be utilise for SFM. For general submodular functions , this Fujishige-Wolfe minimum norm algorithm seems to have the best empiric performance. Despite its good practical carrying into action , very little is known about Wolfe 's minimum norm algorithm theoretically. To our knowledge , the lone result is an exponential time analysis due to Wolfe himself. In this paper we return a maiden convergence analysis of Wolfe 's algorithm. We prove that in t iterations , Wolfe 's algorithm returns an group o ( 1 t ) -approximate solution to the min-norm point on any polytope. We also try out a robust version of Fujishige 's theorem which shows that an O ( 1 n 2 ) -approximate solution to the min-norm point on the base polytope implies exact submodular minimization. As a corollary , we get the first pseudo-polynomial prison term guarantee for the Fujishige-Wolfe minimum norm algorithm for unconstrained submodular function minimization. ", "label": 1}
{"original_text": "As interest in quantum computing grows, there is a pressing need for standardized API's so that algorithm designers, circuit designers, and physicists can be provided a common reference frame for designing, executing, and optimizing experiments. There is also a need for a language specification that goes beyond gates and allows users to specify the time dynamics of a quantum experiment and recover the time dynamics of the output. In this document we provide a specification for a common interface to backends (simulators and experiments) and a standarized data structure (Qobj - quantum object) for sending experiments to those backends via Qiskit. We also introduce OpenPulse, a language for specifying pulse level control (i.e. control of the continuous time dynamics) of a general quantum device independent of the specific hardware implementation. Contents", "text_perturb": "As interest in quantum computing grows , there is a pressing need for standardized API 's so that algorithm designers , circuit designers , and physicists can be provided a common reference frame for designing , executing , and optimize experiments. There follow also a need for a language specification that goes beyond gates and allows users to specify the time dynamics of a quantum experiment and recover the time dynamics of the output. In this document we provide a specification for a common interface to backends ( simulators and experimentation ) and a standarized data structure ( Qobj - quantum object ) for sending experimentation to those backends via Qiskit. We also introduce OpenPulse , a language for specifying pulse degree control ( i. eastward. control of the continuous time dynamic ) of a general quantum device independent of the specific hardware implementation. contents", "label": 1}
{"original_text": "We propose a system to develop a basic automatic speech recognizer (ASR) for Cantonese, a low-resource language, through transfer learning of Mandarin, a high-resource language. We take a time-delayed neural network trained on Mandarin, and perform weight transfer of several layers to a newly initialized model for Cantonese. We experiment with the number of layers transferred, their learning rates, and pretraining i-vectors. Key findings are that this approach allows for quicker training time with less data. We find that for every epoch, log-probability is smaller for transfer learning models compared to a Cantonese-only model. The transfer learning models show slight improvement in CER.", "text_perturb": "We propose a system to develop a basic automatic speech recognizer ( ASR ) for Cantonese , a low-resource linguistic communication , through transfer learning of Mandarin , a high-resource linguistic communication. We take a time-delayed neural network trained on Mandarin , and perform weight transfer of respective layers to a newly initialized model for Cantonese. We experiment with the number of layers transferred , their learning charge per unit , and pretraining i-vectors. primal findings are that this approach allows for quicker training time with less data. We recover that for every epoch , log-probability is smaller for transfer learning models compared to a Cantonese-only model. The transfer learning models show little improvement in CER. ", "label": 1}
{"original_text": "We outline a detection method for adversarial inputs to deep neural networks. By viewing neural network computations as graphs upon which information flows from input space to output distribution, we compare the differences in graphs induced by different inputs. Specifically, by applying persistent homology to these induced graphs, we observe that the structure of the most persistent subgraphs which generate the first homology group differ between adversarial and unperturbed inputs. Based on this observation, we build a detection algorithm that depends only on the topological information extracted during training. We test our algorithm on MNIST and achieve 98 detection adversary accuracy with F 1 -score 0.98.", "text_perturb": "We outline a signal detection method for adversarial inputs to deep neural networks. By viewing neural network computations as graphical record upon which information flows from input space to output distribution , we compare the differences in graphical record induced by different inputs. Specifically , by applying persistent homology to these induced graphical record , we observe that the structure of the most persistent subgraphs which generate the first homology group differ between adversarial and unperturbed inputs. Based on this watching , we build a detection algorithm that depends only on the topological information extracted during training. We test our algorithmic rule on MNIST and achieve 98 detection adversary accuracy with F 1 -score 0. 98. ", "label": 1}
{"original_text": "In this paper, we propose a novel algorithm for matching faces with temporal variations caused due to age progression. The proposed generative adversarial network algorithm is a unified framework that combines facial age estimation and age-separated face verification. The key idea of this approach is to learn the age variations across time by conditioning the input image on the subject's gender and the target age group to which the face needs to be progressed. The loss function accounts for reducing the age gap between the original image and generated face image as well as preserving the identity. Both visual fidelity and quantitative evaluations demonstrate the efficacy of the proposed architecture on different facial age databases for age-separated face recognition.", "text_perturb": "In this paper , we propose a novel algorithm for matching faces with temporal variations caused due to old age progression. The proposed generative adversarial network algorithm is a unified framework that combines facial age estimate and age-separated face verification. The key idea of this approach is to learn the age variations across time by conditioning the input image on the subject 's sexuality and the target age group to which the face needs to be progressed. The loss function accounts for reducing the age gap between the original image and generated face image as well as continue the identity. Both visual fidelity and quantitative evaluations demonstrate the efficacy of the proposed architecture on different facial age databases for age-separated typeface recognition. ", "label": 1}
{"original_text": "The key challenge in multiagent learning is learning a best response to the behaviour of other agents, which may be non-stationary: if the other agents adapt their strategy as well, the learning target moves. Disparate streams of research have approached non-stationarity from several angles, which make a variety of implicit assumptions that make it hard to keep an overview of the state of the art and to validate the innovation and significance of new works. This survey presents a coherent overview of work that addresses opponent-induced non-stationarity with tools from game theory, reinforcement learning and multi-armed bandits. Further, we reflect on the principle approaches how algorithms model and cope with this non-stationarity, arriving at a new framework and five categories (in increasing order of sophistication): ignore, forget, respond to target models, learn models, and theory of mind. A wide range of state-of-the-art algorithms is classified into a taxonomy, using these categories and key characteristics of the environment (e.g., observability) and adaptation behaviour of the opponents (e.g., smooth, abrupt). To clarify even further we present illustrative variations of one domain, contrasting the strengths and limitations of each category. Finally, we discuss in which environments the different approaches yield most merit, and point to promising avenues of future research.", "text_perturb": "The key challenge in multiagent learning is learning a best response to the behaviour of other federal agent , which may be non-stationary : if the other federal agent adapt their strategy as well , the learning target moves. Disparate streams of research give approached non-stationarity from several angles , which make a variety of implicit assumptions that make it hard to keep an overview of the state of the art and to validate the innovation and significance of new works. This survey presents a coherent overview of work that addresses opponent-induced non-stationarity with prick from game theory , reinforcement learning and multi-armed bandits. Further , we reflect on the rule approaches how algorithms model and cope with this non-stationarity , arriving at a new framework and five categories ( in increasing order of sophistication ) : ignore , forget , respond to target models , learn models , and theory of mind. A wide range of state-of-the-art algorithms is classified into a taxonomy , using these categories and key characteristics of the surroundings ( e. m. , observability ) and adaptation behaviour of the opponents ( e. gramme. , smooth , abrupt ). To clarify even farther we present illustrative variations of one domain , contrasting the strengths and limitations of each category. Finally , we discourse in which environments the different approaches yield most merit , and point to promising avenues of future research. ", "label": 1}
{"original_text": "Multi-objective gradient methods are becoming the standard for solving multi-objective problems. Among others, they show promising results in developing multi-objective recommender systems with both correlated and uncorrelated objectives. Classic multi-gradient descent usually relies on the combination of the gradients, not including the computation of first and second moments of the gradients. This leads to a brittle behavior and misses important areas in the solution space. In this work, we create a multi-objective Adamize method that leverage the benefits of the Adam optimizer in single-objective problems. This corrects and stabilizes the gradients of every objective before calculating a common gradient descent vector that optimizes all the objectives simultaneously. We evaluate the benefits of Multi-objective Adamize on two multi-objective recommender systems and for three different objective combinations, both correlated or uncorrelated. We report significant improvements, measured with three different Pareto front metrics: hypervolume, coverage, and spacing. Finally, we show that the Adamized Pareto front strictly dominates the previous one on multiple objective pairs.", "text_perturb": "Multi-objective gradient methods are becoming the standard for solving multi-objective trouble. Among others , they show promising results in developing multi-objective recommender systems with both correlated and uncorrelated object lens. Classic multi-gradient descent usually relies on the combination of the gradients , not including the computation of foremost and second moments of the gradients. This leads to a brittle behavior and misses important areas in the solution infinite. In this work , we create a multi-objective Adamize method that leverage the welfare of the Adam optimizer in single-objective problems. This corrects and stabilizes the gradients of every objective before calculating a common gradient descent transmitter that optimizes all the objectives simultaneously. We evaluate the benefits of Multi-objective Adamize on two multi-objective recommender systems and for three different nonsubjective combinations , both correlated or uncorrelated. We report significant improvements , measured with three different vilfredo pareto front metrics : hypervolume , coverage , and spacing. Finally , we show that the Adamized Pareto front strictly dominates the late one on multiple objective pairs. ", "label": 1}
{"original_text": "This work introduces Conditional Image Retrieval (CIR) systems: IR methods that can efficiently specialize to specific subsets of images on the fly. These systems broaden the class of queries IR systems support, and eliminate the need for expensive re-fitting to specific subsets of data. Specifically, we adapt tree-based K-Nearest Neighbor (KNN) data-structures to the conditional setting by introducing additional inverted-index data-structures. This speeds conditional queries and does not slow queries without conditioning. We present two new datasets for evaluating the performance of CIR systems and evaluate a variety of design choices. As a motivating application, we present an algorithm that can explore shared semantic content between works of art of vastly different media and cultural origin. Finally, we demonstrate that CIR data-structures can identify Generative Adversarial Network (GAN) \"blind spots\": areas where GANs fail to properly model the true data distribution.", "text_perturb": "This work introduces Conditional Image Retrieval ( CIR ) systems : IR methods that can efficiently specialize to specific subsets of images on the tent flap. These systems broaden the class of queries IR systems support , and eliminate the need for expensive re-fitting to specific subset of data. Specifically , we adapt tree-based K-Nearest Neighbor ( KNN ) data-structures to the conditional setting by introducing extra inverted-index data-structures. This speeds conditional queries and does non slow queries without conditioning. We present two new datasets for evaluating the performance of CIR systems and evaluate a variety of design pick. As a motivating application , we present an algorithm that force out explore shared semantic content between works of art of vastly different media and cultural origin. Finally , we demonstrate that CIR data-structures dismiss identify Generative Adversarial Network ( GAN ) `` blind spots '' : areas where GANs fail to properly model the true data distribution. ", "label": 1}
{"original_text": "Wireless sensor networks (WSN), i.e. networks of autonomous, wireless sensing nodes spatially deployed over a geographical area, are often faced with acquisition of spatially sparse fields. In this paper, we present a novel bandwidthenergy efficient CS scheme for acquisition of spatially sparse fields in a WSN. The paper contribution is twofold. Firstly, we introduce a sparse, structured CS matrix and we analytically show that it allows accurate reconstruction of bidimensional spatially sparse signals, such as those occurring in several surveillance application. Secondly, we analytically evaluate the energy and bandwidth consumption of our CS scheme when it is applied to data acquisition in a WSN. Numerical results demonstrate that our CS scheme achieves significant energy and bandwidth savings wrt state-of-the-art approaches when employed for sensing a spatially sparse field by means of a WSN.", "text_perturb": "Wireless detector networks ( WSN ) , i. east. networks of autonomous , wireless sensing nodes spatially deployed over a geographical orbit , are often faced with acquisition of spatially sparse fields. In this paper , we present a novel bandwidthenergy efficient degree celsius scheme for acquisition of spatially sparse fields in a WSN. The paper contribution represent twofold. Firstly , we introduce a sparse , structured CS matrix and we analytically show that it leave accurate reconstruction of bidimensional spatially sparse signals , such as those occurring in several surveillance application. Secondly , we analytically evaluate the energy and bandwidth consumption of our CS dodge when it is applied to data acquisition in a WSN. Numerical results demonstrate that our CS scheme achieves significant energy and bandwidth economy wrt state-of-the-art approaches when employed for sensing a spatially sparse field by means of a WSN. ", "label": 1}
{"original_text": "A source model of key sharing between three users is considered in which each pair of them wishes to agree on a secret key hidden from the remaining user. There are rate-limited public channels for communications between the users. We give an inner bound on the secret key capacity region in this framework. Moreover, we investigate a practical setup in which localization information of the users as the correlated observations are exploited to share pairwise keys between the users. The inner and outer bounds of the key capacity region are analyzed in this setup for the case of i.i.d. Gaussian observations.", "text_perturb": "A source model of key sharing between three users is considered in which each dyad of them wishes to agree on a secret key hidden from the remaining user. There be rate-limited public channels for communications between the users. We give an inner bound on the privy key capacity region in this framework. Moreover , we investigate a practical apparatus in which localization information of the users as the correlated observations are exploited to share pairwise keys between the users. The inner and outer bounds of the key capacity region are analyzed in this apparatus for the case of i. atomic number . five hundred. gaussian observations. ", "label": 1}
{"original_text": "As technologies become more and more pervasive, there is a need for considering the affective dimension of interaction with computer systems to make them more human-like. Current demands for this matter include accurate emotion recognition, reliable emotion modeling, and use of unobtrusive, easily accessible and preferably wearable measurement devices. While AI methods provide many possibilities for better affective information processing, it is not a common scenario for both emotion recognition and modeling to be integrated in the design phase. To address this concern, we propose a new approach based on affective design patterns in the context of video games, together with summary of experiments conducted to test the preliminary hypotheses.", "text_perturb": "As technologies become more and more pervasive , there is a need for considering the emotive dimension of interaction with computer systems to make them more human-like. Current demands for this matter include accurate emotion recognition , honest emotion modeling , and use of unobtrusive , easily accessible and preferably wearable measurement devices. While AI methods provide many possibilities for better affective information processing , it is not a common scenario for both emotion recognition and modeling to be integrated in the design stage. To address this concern , we propose a new approach based on affective design patterns in the context of video plot , together with summary of experiments conducted to test the preliminary hypotheses. ", "label": 1}
{"original_text": "Based on the hurricane struking Puerto Rico in 2017, we developed a transportable disaster response system \"DroneGo\" featuring a drone fleet capable of delivering medical package and videoing roads. Covering with genetic algorithm and a biased random walk model mimicing a drunk man to explore feasible routes on a field with altitude and road information. A proposal mechanism guaranteeing stochasticity and an objective function biasing randomness are combined. The results shown high performance though time-consuming.", "text_perturb": "Based on the hurricane struking Puerto Rico in 2017 , we developed a movable disaster response system `` DroneGo '' featuring a drone fleet capable of delivering medical package and videoing roads. Covering with genetic algorithm and a biased random walk model mimic a drunk man to explore feasible routes on a field with altitude and road information. A proposal mechanism guaranteeing stochasticity and an documentary function biasing randomness are combined. The results shown high carrying into action though time-consuming. ", "label": 1}
{"original_text": "How can we compute the pseudoinverse of a sparse feature matrix efficiently and accurately for solving optimization problems? A pseudoinverse is a generalization of a matrix inverse, which has been extensively utilized as a fundamental building block for solving linear systems in machine learning. However, an approximate computation, let alone an exact computation, of pseudoinverse is very time-consuming due to its demanding time complexity, which limits it from being applied to large data. In this paper, we propose FastPI (Fast PseudoInverse), a novel incremental singular value decomposition (SVD) based pseudoinverse method for sparse matrices. Based on the observation that many real-world feature matrices are sparse and highly skewed, FastPI reorders and divides the feature matrix and incrementally computes low-rank SVD from the divided components. To show the efficacy of proposed FastPI, we apply them in real-world multi-label linear regression problems. Through extensive experiments, we demonstrate that FastPI computes the pseudoinverse faster than other approximate methods without loss of accuracy. Results imply that our method efficiently computes the low-rank pseudoinverse of a large and sparse matrix that other existing methods cannot handle with limited time and space.", "text_perturb": "How can we compute the pseudoinverse of a sparse feature matrix efficiently and accurately for solving optimization problems ? A pseudoinverse is a generalization of a matrix inverse , which have been extensively utilized as a fundamental building block for solving linear systems in machine learning. However , an approximate computation , let alone an exact computation , of pseudoinverse is very time-consuming due to its demanding time complexity , which limits it from being applied to orotund data. In this paper , we propose FastPI ( Fast PseudoInverse ) , a novel incremental singular value decomposition ( SVD ) based pseudoinverse method for sparse ground substance. Based on the observation that many real-world characteristic matrices are sparse and highly skewed , FastPI reorders and divides the characteristic matrix and incrementally computes low-rank SVD from the divided components. To show the efficacy of purport FastPI , we apply them in real-world multi-label linear regression problems. Through extensive experiments , we demonstrate that FastPI computes the pseudoinverse quicker than other approximate methods without loss of accuracy. Results imply that our method efficiently computes the low-rank pseudoinverse of a large and sparse matrix that former existing methods can not handle with limited time and space. ", "label": 1}
{"original_text": "Training multi-agent systems (MAS) to achieve realistic equilibria gives us a useful tool to understand and model real-world systems. We consider a general sum partially observable Markov game where agents of different types share a single policy network, conditioned on agent-specific information. This paper aims at i) formally understanding equilibria reached by such agents, and ii) matching emergent phenomena of such equilibria to real-world targets. Parameter sharing with decentralized execution has been introduced as an efficient way to train multiple agents using a single policy network. However, the nature of resulting equilibria reached by such agents is not yet understood: we introduce the novel concept of Shared equilibrium as a symmetric pure Nash equilibrium of a certain Functional Form Game (FFG) and prove convergence to the latter for a certain class of games using self-play. In addition, it is important that such equilibria satisfy certain constraints so that MAS are calibrated to real world data for practical use: we solve this problem by introducing a novel dual-Reinforcement Learning based approach that fits emergent behaviors of agents in a Shared equilibrium to externally-specified targets, and apply our methods to a n -player market example. We do so by calibrating parameters governing distributions of agent types rather than individual agents, which allows both behavior differentiation among agents and coherent scaling of the shared policy network to multiple agents.", "text_perturb": "direct multi-agent systems ( MAS ) to achieve realistic equilibria gives us a useful tool to understand and model real-world systems. We consider a general sum partially observable Markov game where agents of different character share a single policy network , conditioned on agent-specific information. This paper aims at i ) formally understanding equilibria reached by such agents , and ii ) matching emerging phenomena of such equilibria to real-world targets. Parameter sharing with decentralized implementation has been introduced as an efficient way to train multiple agents using a single policy network. However , the nature of resulting equilibria reached by such agents is not yet understood : we introduce the novel concept of Shared equilibrium as a symmetric pure Nash equilibrium of a certain Functional Form Game ( FFG ) and prove convergence to the latter for a certain class of games expend self-play. In addition , it is important that such equilibria satisfy certain constraints so that MAS are calibrated to real world data for practical use : we solve this problem by introducing a novel dual-Reinforcement Learning based approach that fits emergent behaviors of agents in a Shared equilibrium to externally-specified target , and apply our methods to a n -player market example. We do so by calibrating parameters governing distributions of agent types rather than item by item agents , which allows both behavior differentiation among agents and coherent scaling of the shared policy network to multiple agents. ", "label": 1}
{"original_text": "Learning a stable and generalizable centralized value function (CVF) is a crucial but challenging task in multi-agent reinforcement learning (MARL), as it has to deal with the issue that the joint action space increases exponentially with the number of agents in such scenarios. This paper proposes an approach, named SMIX (l), that uses an off-policy training to achieve this by avoiding the greedy assumption commonly made in CVF learning. As importance sampling for such off-policy training is both computationally costly and numerically unstable, we proposed to use the l -return as a proxy to compute the TD error. With this new loss function objective, we adopt a modified QMIX network structure as the base to train our model. By further connecting it with the Q (l) approach from an unified expectation correction viewpoint, we show that the proposed SMIX (l) is equivalent to Q (l) and hence shares its convergence properties, while without being suffered from the aforementioned curse of dimensionality problem inherent in MARL. Experiments on the StarCraft Multi-Agent Challenge (SMAC) benchmark demonstrate that our approach not only outperforms several state-of-the-art MARL methods by a large margin, but also can be used as a general tool to improve the overall performance of other CTDE-type algorithms by enhancing their CVFs.", "text_perturb": "Learning a stable and generalizable centralized time value function ( CVF ) is a crucial but challenging task in multi-agent reinforcement learning ( MARL ) , as it has to deal with the issue that the joint action space increases exponentially with the number of agents in such scenarios. This paper proposes an approach , named SMIX ( l ) , that utilise an off-policy training to achieve this by avoiding the greedy assumption commonly made in CVF learning. As importance sampling for such off-policy breeding is both computationally costly and numerically unstable , we proposed to use the l -return as a proxy to compute the TD error. With this new loss function objective , we adopt a modified QMIX network anatomical structure as the base to train our model. By further connecting it with the Q ( l ) approach from an unified expectation correction viewpoint , we show that the proposed SMIX ( l ) is equivalent to Q ( l ) and hence shares its convergence properties , while without being suffered from the aforementioned execration of dimensionality problem inherent in MARL. Experiments on the StarCraft Multi-Agent Challenge ( SMAC ) benchmark demonstrate that our approach not only outperforms several state of the art MARL methods by a large margin , but also can be used as a general tool to improve the overall performance of other CTDE-type algorithms by enhancing their CVFs. ", "label": 1}
{"original_text": "In syntax-guided synthesis (SyGuS), a synthesizer's goal is to automatically generate a program belonging to a grammar of possible implementations that meets a logical specification. We investigate a common limitation across state-of-the-art SyGuS tools that perform counterexample-guided inductive synthesis (CEGIS). We empirically observe that as the expressiveness of the provided grammar increases, the performance of these tools degrades significantly. We claim that this degradation is not only due to a larger search space, but also due to overfitting . We formally define this phenomenon and prove no-free-lunch theorems for SyGuS, which reveal a fundamental tradeoff between synthesizer performance and grammar expressiveness. A standard approach to mitigate overfitting in machine learning is to run multiple learners with varying expressiveness in parallel. We demonstrate that this insight can immediately benefit existing SyGuS tools. We also propose a novel single-threaded technique called hybrid enumeration that interleaves different grammars and outperforms the winner of the 2018 SyGuS competition (Inv track), solving more problems and achieving a 5 mean speedup.", "text_perturb": "In syntax-guided synthesis ( SyGuS ) , a synthesizer 's finish is to automatically generate a program belonging to a grammar of possible implementations that meets a logical specification. We inquire a common limitation across state-of-the-art SyGuS tools that perform counterexample-guided inductive synthesis ( CEGIS ). We empirically observe that as the expressiveness of the provided grammar increases , the performance of these tools degrades importantly. We claim that this degradation is not only due to a expectant search space , but also due to overfitting. We formally define this phenomenon and try no-free-lunch theorems for SyGuS , which reveal a fundamental tradeoff between synthesizer performance and grammar expressiveness. A standard approach to mitigate overfitting in machine learning comprise to run multiple learners with varying expressiveness in parallel. We demonstrate that this brainwave can immediately benefit existing SyGuS tools. We also propose a novel single-threaded technique called hybrid enumeration that interleaves different grammars and outperforms the winner of the 2018 SyGuS competition ( Inv track ) , solve more problems and achieving a 5 mean speedup. ", "label": 1}
{"original_text": "We present the first method for automatically mining code idioms from a corpus of previously written, idiomatic software projects. We take the view that a code idiom is a syntactic fragment that recurs across projects and has a single semantic role. Idioms may have metavariables, such as the body of a for loop. Modern IDEs commonly provide facilities for manually defining idioms and inserting them on demand, but this does not help programmers to write idiomatic code in languages or using libraries with which they are unfamiliar. We present Haggis, a system for mining code idioms that builds on recent advanced techniques from statistical natural language processing, namely, nonparametric Bayesian probabilistic tree substitution grammars. We apply Haggis to several of the most popular open source projects from GitHub. We present a wide range of evidence that the resulting idioms are semantically meaningful, demonstrating that they do indeed recur across software projects and that they occur more frequently in illustrative code examples collected from a QA site. Manual examination of the most common idioms indicate that they describe important program concepts, including object creation, exception handling, and resource management.", "text_perturb": "We submit the first method for automatically mining code idioms from a corpus of previously written , idiomatic software projects. We take the view that a code idiomatic expression is a syntactic fragment that recurs across projects and has a single semantic role. Idioms may have metavariables , such as the soundbox of a for loop. Modern IDEs commonly provide facilities for manually defining idioms and inserting them on demand , but this does not help programmers to write idiomatic code in languages or utilise libraries with which they are unfamiliar. We present Haggis , a system for mining code idioms that ramp up on recent advanced techniques from statistical natural language processing , namely , nonparametric Bayesian probabilistic tree substitution grammars. We go for Haggis to several of the most popular open source projects from GitHub. We present a wide range of evidence that the resulting dialect are semantically meaningful , demonstrating that they do indeed recur across software projects and that they occur more frequently in illustrative code examples collected from a QA site. Manual examination of the most common idioms indicate that they describe important programme concepts , including object creation , exception handling , and resource management. ", "label": 1}
{"original_text": "Aspect based sentiment analysis aims to identify the sentimental tendency towards a given aspect in text. Fine-tuning of pretrained BERT performs excellent on this task and achieves state-of-the-art performances. Existing BERT-based works only utilize the last output layer of BERT and ignore the semantic knowledge in the intermediate layers. This paper explores the potential of utilizing BERT intermediate layers to enhance the performance of fine-tuning of BERT. To the best of our knowledge, no existing work has been done on this research. To show the generality, we also apply this approach to a natural language inference task. Experimental results demonstrate the effectiveness and generality of the proposed approach.", "text_perturb": "Aspect based sentiment analysis aims to identify the sentimental tendency towards a given vista in text. Fine-tuning of pretrained BERT performs excellent on this task and achieves state of the art performances. Existing BERT-based works only utilize the final output layer of BERT and ignore the semantic knowledge in the intermediate layers. This paper explores the potential of utilizing BERT intermediate layers to raise the performance of fine-tuning of BERT. To the best of our knowledge , no existing work has been done on this enquiry. To bear witness the generality , we also apply this approach to a natural language inference task. Experimental results demonstrate the effectiveness and generality of the proposed approaching. ", "label": 1}
{"original_text": "[Context] Requirements quality can have a substantial impact on the effectiveness and efficiency of using requirements artifacts in a development process. Quantifiers such as \"at least,\" \"all,\" or \"exactly\" are common language constructs used to express requirements. Quantifiers can be formulated by affirmative phrases At least or negative phrases Not less than. [Problem] It is long assumed that negation in quantification negatively affects the readability of requirements, however, empirical research on these topics remains sparse. [Principal Idea] In a web-based experiment with 51 participants, we compare the impact of negations and quantifiers on readability in terms of reading effort, reading error rate and perceived reading difficulty of requirements. [Results] For 5 out of 9 quantifiers, our participants performed better on the affirmative phrase compared to the negative phrase. Only for one quantifier, the negative phrase was more effective. [Contribution] This research focuses on creating an empirical understanding of the effect of language in Requirements Engineering. It furthermore provides concrete advice on how to phrase requirements.", "text_perturb": "[ Context ] Requirements timbre can have a substantial impact on the effectiveness and efficiency of using requirements artifacts in a development process. Quantifiers such as `` at least , '' `` all , '' or `` exactly '' are unwashed language constructs used to express requirements. Quantifiers can be formulated by affirmative phrases At least or negative phrases Not to a lesser extent than. [ Problem ] It is long assumed that negation in quantification negatively affects the readability of requirements , however , empiric research on these topics remains sparse. [ Principal Idea ] In a web-based experiment with 51 participants , we compare the impact of negations and quantifiers on readability in condition of reading effort , reading error rate and perceived reading difficulty of requirements. [ Results ] For 5 out of 9 quantifiers , our participants performed better on the affirmative phrase equate to the negative phrase. Only for one quantifier , the negative idiomatic expression was more effective. [ Contribution ] This research focuses on creating an empirical understanding of the effect of linguistic process in Requirements Engineering. It furthermore provides concrete advice on how to articulate requirements. ", "label": 1}
{"original_text": "A generally intelligent agent must be able to teach itself how to solve problems in complex domains with minimal human supervision. Recently, deep reinforcement learning algorithms combined with self-play have achieved superhuman proficiency in Go, Chess, and Shogi without human data or domain knowledge. In these environments, a reward is always received at the end of the game; however, for many combinatorial optimization environments, rewards are sparse and episodes are not guaranteed to terminate. We introduce Autodidactic Iteration: a novel reinforcement learning algorithm that is able to teach itself how to solve the Rubik's Cube with no human assistance. Our algorithm is able to solve 100 of randomly scrambled cubes while achieving a median solve length of 30 moves - less than or equal to solvers that employ human domain knowledge.", "text_perturb": "A in general intelligent agent must be able to teach itself how to solve problems in complex domains with minimal human supervision. Recently , deep reinforcement read algorithms combined with self-play have achieved superhuman proficiency in Go , Chess , and Shogi without human data or domain knowledge. In these environments , a reward is eer received at the end of the game ; however , for many combinatorial optimization environments , rewards are sparse and episodes are not guaranteed to terminate. We introduce Autodidactic Iteration : a new reinforcement learning algorithm that is able to teach itself how to solve the Rubik 's Cube with no human assistance. Our algorithm is able to solve 100 of randomly scrambled cubes while achieving a median solve distance of 30 moves - less than or equal to solvers that employ human domain knowledge. ", "label": 1}
{"original_text": "Deep learning has dramatically improved the performance of speech recognition systems through learning hierarchies of features optimized for the task at hand. However, true end-to-end learning, where features are learned directly from waveforms, has only recently reached the performance of hand-tailored representations based on the Fourier transform. In this paper, we detail an approach to use convolutional filters to push past the inherent tradeoff of temporal and frequency resolution that exists for spectral representations. At increased computational cost, we show that increasing temporal resolution via reduced stride and increasing frequency resolution via additional filters delivers significant performance improvements. Further, we find more efficient representations by simultaneously learning at multiple scales, leading to an overall decrease in word error rate on a difficult internal speech test set by 20.7 relative to networks with the same number of parameters trained on spectrograms.", "text_perturb": "Deep learning has dramatically improved the performance of speech recognition systems through learning hierarchies of features optimized for the task at script. nevertheless , true end-to-end learning , where features are learned directly from waveforms , has only recently reached the performance of hand-tailored representations based on the Fourier transform. In this paper , we detail an approach to use convolutional filter to push past the inherent tradeoff of temporal and frequency resolution that exists for spectral representations. At increased computational cost , we show that increasing temporal resolution via reduced stride and increasing frequency resolution via additional filters delivers significant performance betterment. Further , we find more efficient representations by at the same time learning at multiple scales , leading to an overall decrease in word error rate on a difficult internal speech test set by 20. 7 relative to networks with the like number of parameters trained on spectrograms. ", "label": 1}
{"original_text": "We study the problem of joint information and energy transfer in a two-hop channel with a Radio frequency (RF) energy harvesting relay. We consider a finite battery size at the relay and deterministic energy loss in transmitting energy. In other words, to be able to send an energy-contained symbol, the relay must receive multiple energy-contained symbols. Thus, we face a kind of channel with memory. We model the energy saved in battery as channel state with the challenge that the receiver does not know the channel state. First, we consider the problem without any channel noise and derive an achievable rate. Next, we extend the results to the case with an independent and identically distributed noise in the second hop (the relay-receiver link).", "text_perturb": "We study the problem of joint information and energy transfer in a two-hop channel with a Radio absolute frequency ( RF ) energy harvesting relay. We consider a finite battery size of it at the relay and deterministic energy loss in transmitting energy. In early words , to be able to send an energy-contained symbol , the relay must receive multiple energy-contained symbols. thence , we face a kind of channel with memory. We model the energy saved in battery as channel state with the challenge that the liquidator does not know the channel state. First , we conceive the problem without any channel noise and derive an achievable rate. following , we extend the results to the case with an independent and identically distributed noise in the second hop ( the relay-receiver link ). ", "label": 1}
{"original_text": "We propose a flexible framework for clustering hypergraph-structured data based on recently proposed random walks utilizing edge-dependent vertex weights. When incorporating edge-dependent vertex weights (EDVW), a weight is associated with each vertex-hyperedge pair, yielding a weighted incidence matrix of the hypergraph. Such weightings have been utilized in term-document representations of text data sets. We explain how random walks with EDVW serve to construct different hypergraph Laplacian matrices, and then develop a suite of clustering methods that use these incidence matrices and Laplacians for hypergraph clustering. Using several data sets from real-life applications, we compare the performance of these clustering algorithms experimentally against a variety of existing hypergraph clustering methods. We show that the proposed methods produce higher-quality clusters and conclude by highlighting avenues for future work.", "text_perturb": "We propose a flexible framework for clustering hypergraph-structured data based on recently purport random walks utilizing edge-dependent vertex weights. When incorporating edge-dependent vertex weights ( EDVW ) , a weight is associated with each vertex-hyperedge pair , yield a weighted incidence matrix of the hypergraph. Such weightings have embody utilized in term-document representations of text data sets. We explain how random walks with EDVW serve to construct different hypergraph Laplacian ground substance , and then develop a suite of clustering methods that use these incidence ground substance and Laplacians for hypergraph clustering. Using several data sets from real-life applications , we equate the performance of these clustering algorithms experimentally against a variety of existing hypergraph clustering methods. We show that the proposed method produce higher-quality clusters and conclude by highlighting avenues for future work. ", "label": 1}
{"original_text": "This paper presents our system details and results of participation in the RDoC Tasks of BioNLP-OST 2019. Research Domain Criteria (RDoC) construct is a multi-dimensional and broad framework to describe mental health disorders by combining knowledge from genomics to behaviour. Non-availability of RDoC labelled dataset and tedious labelling process hinders the use of RDoC framework to reach its full potential in Biomedical research community and Healthcare industry. Therefore, Task-1 aims at retrieval and ranking of PubMed abstracts relevant to a given RDoC construct and Task-2 aims at extraction of the most relevant sentence from a given PubMed abstract. We investigate (1) attention based supervised neural topic model and SVM for retrieval and ranking of PubMed abstracts and, further utilize BM25 and other relevance measures for re-ranking, (2) supervised and unsupervised sentence ranking models utilizing multi-view representations comprising of query-aware attention-based sentence representation (QAR), bag-of-words (BoW) and TF-IDF. Our best systems achieved 1st rank and scored 0.86 mAP and 0.58 macro average accuracy in Task-1 and Task-2 respectively.", "text_perturb": "This paper presents our system details and final result of participation in the RDoC Tasks of BioNLP-OST 2019. Research field Criteria ( RDoC ) construct is a multi-dimensional and broad framework to describe mental health disorders by combining knowledge from genomics to behaviour. Non-availability of RDoC labelled dataset and tedious labelling process hinders the use of RDoC framework to reach its full potential in Biomedical research community and health care industry. consequently , Task-1 aims at retrieval and ranking of PubMed abstracts relevant to a given RDoC construct and Task-2 aims at extraction of the most relevant sentence from a given PubMed abstract. We investigate ( 1 ) attention based supervised neural topic model and SVM for retrieval and ranking of PubMed abstracts and , further utilize BM25 and other relevance measures for re-ranking , ( 2 ) supervised and unsupervised sentence ranking models utilize multi-view representations comprising of query-aware attention-based sentence representation ( QAR ) , bag-of-words ( BoW ) and TF-IDF. Our best systems achieved 1st social rank and scored 0. 86 mathematical function and 0. 58 macro average truth in Task-1 and Task-2 respectively. ", "label": 1}
{"original_text": "We investigate the problem of cost-optimal planning in ASP. Current ASP planners can be trivially extended to a cost-optimal one by adding weak constraints, but only for a given makespan (number of steps). It is desirable to have a planner that guarantees global optimality. In this paper, we present two approaches to addressing this problem. First, we show how to engineer a cost-optimal planner composed of two ASP programs running in parallel. Using lessons learned from this, we then develop an entirely new approach to cost-optimal planning, stepless planning, which is completely free of makespan. Experiments to compare the two approaches with the only known cost-optimal planner in SAT reveal good potentials for stepless planning in ASP. The paper is under consideration for acceptance in TPLP.", "text_perturb": "We investigate the problem of cost-optimal planning in ASP. Current ASP planners displace be trivially extended to a cost-optimal one by adding weak constraints , but only for a given makespan ( number of steps ). It is worthy to have a planner that guarantees global optimality. In this paper , we present two approaches to addressing this trouble. First , we show how to engineer a cost-optimal contriver composed of two ASP programs running in parallel. Using lessons learned from this , we then develop an entirely new approach to cost-optimal planning , stepless planning , which is whole free of makespan. Experiments to compare the two approaches with the only known cost-optimal planner in SAT reveal good potentiality for stepless planning in ASP. The paper represent under consideration for acceptance in TPLP. ", "label": 1}
{"original_text": "A software for managing simulation jobs and results, named \"OACIS,\" is presented. It controls a large number of simulation jobs executed in various remote servers, keeps these results in an organized way, and manages the analyses on these results. The software has a web browser front end, and users can submit various jobs to appropriate remote hosts from a web browser easily. After these jobs are finished, all the result files are automatically downloaded from the computational hosts and stored in a traceable way together with the logs of the date, host, and elapsed time of the jobs. Some visualization functions are also provided so that users can easily grasp the overview of the results distributed in a high-dimensional parameter space. Thus, OACIS is especially beneficial for the complex simulation models having many parameters for which a lot of parameter searches are required. By using API of OACIS, it is easy to write a code that automates parameter selection depending on the previous simulation results. A few examples of the automated parameter selection are also demonstrated.", "text_perturb": "A software for managing simulation chore and results , named `` OACIS , '' is presented. It controls a large turn of simulation jobs executed in various remote servers , keeps these results in an organized way , and manages the analyses on these results. The software suffer a web browser front end , and users can submit various jobs to appropriate remote hosts from a web browser easily. After these jobs are finished , all the result files are automatically downloaded from the computational hosts and store in a traceable way together with the logs of the date , host , and elapsed time of the jobs. Some visualization functions are also offer so that users can easily grasp the overview of the results distributed in a high-dimensional parameter space. hence , OACIS is especially beneficial for the complex simulation models having many parameters for which a lot of parameter searches are required. By using API of OACIS , it is light to write a code that automates parameter selection depending on the previous simulation results. A few lesson of the automated parameter selection are also demonstrated. ", "label": 1}
{"original_text": "Given a dataset V of points from some metric space, the popular k -center problem requires to identify a subset of k points (centers) in V minimizing the maximum distance of any point of V from its closest center. The robust formulation of the problem features a further parameter z and allows up to z points of V (outliers) to be disregarded when computing the maximum distance from the centers. In this paper, we focus on two important constrained variants of the robust k -center problem, namely, the Robust Matroid Center (RMC) problem, where the set of returned centers are constrained to be an independent set of a matroid of rank k built on V, and the Robust Knapsack Center (RKC) problem, where each element I V is given a positive weight w I 1 and the aggregate weight of the returned centers must be at most 1. We devise coreset-based strategies for the two problems which yield efficient sequential, MapReduce, and Streaming algorithms. More specifically, for any fixed 0, the algorithms return solutions featuring a (3) -approximation ratio, which is a mere additive term away from the 3-approximations achievable by the best known polynomial-time sequential algorithms for the two problems. Moreover, the algorithms obliviously adapt to the intrinsic complexity of the dataset, captured by its doubling dimension D. For wide ranges of the parameters k, z, , D, we obtain a sequential algorithm with running time linear in V , and MapReduceStreaming algorithms with few roundspasses and substantially sublinear localworking memory.", "text_perturb": "Given a dataset V of points from some metric space , the popular k -center problem need to identify a subset of k points ( centers ) in V minimizing the maximum distance of any point of V from its closest center. The robust formulation of the problem features a further parameter izzard and allows up to z points of V ( outliers ) to be disregarded when computing the maximum distance from the centers. In this paper , we focus on two important encumber variants of the robust k -center problem , namely , the Robust Matroid Center ( RMC ) problem , where the set of returned centers are encumber to be an independent set of a matroid of rank k built on V , and the Robust Knapsack Center ( RKC ) problem , where each element I V is given a positive weight w I 1 and the aggregate weight of the returned centers must be at most 1. We devise coreset-based strategies for the two problems which yield efficient serial , MapReduce , and Streaming algorithms. more specifically , for any fixed 0 , the algorithms return solutions featuring a ( 3 ) -approximation ratio , which is a mere additive term away from the 3-approximations achievable by the best known polynomial-time sequential algorithms for the two problems. Moreover , the algorithms obliviously adapt to the intrinsic complexness of the dataset , captured by its doubling dimension D. For wide ranges of the parameters k , z , , D , we obtain a sequential algorithm with running time linear in V , and MapReduceStreaming algorithms with few roundspasses and well sublinear localworking memory. ", "label": 1}
{"original_text": "Deep learning models, such as the fully convolutional network (FCN), have been widely used in 3D biomedical segmentation and achieved state-of-the-art performance. Multiple modalities are often used for disease diagnosis and quantification. Two approaches are widely used in the literature to fuse multiple modalities in the segmentation networks: early-fusion (which stacks multiple modalities as different input channels) and late-fusion (which fuses the segmentation results from different modalities at the very end). These fusion methods easily suffer from the cross-modal interference caused by the input modalities which have wide variations. To address the problem, we propose a novel deep learning architecture, namely OctopusNet, to better leverage and fuse the information contained in multi-modalities. The proposed framework employs a separate encoder for each modality for feature extraction and exploits a hyper-fusion decoder to fuse the extracted features while avoiding feature explosion. We evaluate the proposed OctopusNet on two publicly available datasets, i.e. ISLES-2018 and MRBrainS-2013. The experimental results show that our framework outperforms the commonly-used feature fusion approaches and yields the state-of-the-art segmentation accuracy.", "text_perturb": "Deep learning models , such as the fully convolutional network ( FCN ) , have been widely used in 3D biomedical segmentation and attain state-of-the-art performance. Multiple modalities are often used for disease diagnosing and quantification. Two approaches are widely used in the literature to fuse multiple modality in the segmentation networks : early-fusion ( which stacks multiple modality as different input channels ) and late-fusion ( which fuses the segmentation results from different modality at the very end ). These optical fusion methods easily suffer from the cross-modal interference caused by the input modalities which have wide variations. To address the problem , we propose a novel deep learning architecture , namely OctopusNet , to better leverage and fuse the information hold in multi-modalities. The proposed framework employs a separate encoder for each sensory system for feature extraction and exploits a hyper-fusion decoder to fuse the extracted features while avoiding feature explosion. We evaluate the nominate OctopusNet on two publicly available datasets , i. east. ISLES-2018 and MRBrainS-2013. The experimental results show that our framework outperforms the commonly-used feature article fusion approaches and yields the state-of-the-art segmentation accuracy. ", "label": 1}
{"original_text": "Given a graph G (V, E), A V, and integers k and l, the (A, l) -Path Packing problem asks to find k vertex-disjoint paths of length l that have endpoints in A and internal points in V A. We study the parameterized complexity of this problem with parameters A , l, k, treewidth, pathwidth, and their combinations. We present sharp complexity contrasts with respect to these parameters. Among other results, we show that the problem is polynomial-time solvable when l 3, while it is NP-complete for constant l 4. We also show that the problem is W[1hard parameterized by pathwidth A , while it is fixed-parameter tractable parameterized by treewidth l.", "text_perturb": "Given a graph G ( V , E ) , A V , and integers k and l , the ( A , l ) -Path Packing problem asks to find k vertex-disjoint paths of length l that cause endpoints in A and internal points in V A. We study the parameterized complexity of this problem with parameters A , l , special k , treewidth , pathwidth , and their combinations. We present sharp complexity contrasts with respect to these parametric quantity. Among other results , we bear witness that the problem is polynomial-time solvable when l 3 , while it is NP-complete for constant l 4. We also show that the problem is wolfram [ 1hard parameterized by pathwidth A , while it is fixed-parameter tractable parameterized by treewidth l. ", "label": 1}
{"original_text": "Given the constantly growing proliferation of false claims online in recent years, there has been also a growing research interest in automatically distinguishing false rumors from factually true claims. Here, we propose a general-purpose framework for fully-automatic fact checking using external sources, tapping the potential of the entire Web as a knowledge source to confirm or reject a claim. Our framework uses a deep neural network with LSTM text encoding to combine semantic kernels with task-specific embeddings that encode a claim together with pieces of potentially-relevant text fragments from the Web, taking the source reliability into account. The evaluation results show good performance on two different tasks and datasets: (i) rumor detection and (ii) fact checking of the answers to a question in community question answering forums.", "text_perturb": "Given the constantly growing proliferation of false claims online in recent years , there has been also a growing inquiry interest in automatically distinguishing false rumors from factually true claims. Here , we propose a general-purpose framework for fully-automatic fact checking using external sources , tapping the potential of the entire Web as a knowledge source to confirm or decline a claim. Our framework uses a deep neural network with LSTM text encoding to combine semantic nub with task-specific embeddings that encode a claim together with pieces of potentially-relevant text fragments from the Web , taking the source reliability into account. The evaluation results show good performance on two different tasks and datasets : ( i ) rumor detection and ( ii ) fact checking of the answers to a question in community question answering meeting place. ", "label": 1}
{"original_text": "This paper extends the problem of 2-dimensional palindrome search into the area of approximate matching. Using the Hamming distance as the measure, we search for 2D palindromes that allow up to k mismatches. We consider two different definitions of 2D palindromes and describe efficient algorithms for both of them. The first definition implies a square, while the second definition (also known as a centrosymmetric factor), can be any rectangular shape. Given a text of size x n m, the time complexity of the first algorithm is O (n m (log m log n k and for the second algorithm it is O (n m (log m k) o c c) where o c c is the size of the output.", "text_perturb": "This paper extends the problem of 2-dimensional palindrome hunting into the area of approximate matching. Using the Hamming distance as the measure , we search for 2D palindromes that allow upward to k mismatches. We consider two different definition of 2D palindromes and describe efficient algorithms for both of them. The first definition implies a square , while the second definition ( also known as a centrosymmetric factor ) , can be any orthogonal shape. Given a text of size x n megabyte , the time complexity of the first algorithm is O ( n megabyte ( log megabyte log n k and for the second algorithm it is O ( n megabyte ( log megabyte k ) o c c ) where o c c is the size of the output. ", "label": 1}
{"original_text": "This paper presents our solution to ACM MM challenge: Large-scale Human-centric Video Analysis in Complex Events (,); specifically, here we focus on Track3: Crowd Pose Tracking in Complex Events. Remarkable progress has been made in multi-pose training in recent years. However, how to track the human pose in crowded and complex environments has not been well addressed. We formulate the problem as several subproblems to be solved. First, we use a multi-object tracking method to assign human ID to each bounding box generated by the detection model. After that, a pose is generated to each bounding box with ID. At last, optical flow is used to take advantage of the temporal information in the videos and generate the final pose tracking result.", "text_perturb": "This paper presents our solution to ACM MM challenge : Large-scale Human-centric Video Analysis in Complex Events ( , ) ; specifically , hither we focus on Track3 : Crowd Pose Tracking in Complex Events. remarkable progress has been made in multi-pose training in recent years. However , how to track the human pose in crowded and complex environments has not been considerably addressed. We formulate the problem as several subproblems to personify solved. First , we use a multi-object tracking method to assign human ID to each bounding boxwood generated by the detection model. After that , a pose is generated to each bounding box seat with ID. At last , optical flow is used to take advantage of the temporal information in the videos and generate the final pose tracking effect. ", "label": 1}
{"original_text": "We propose a novel mathematical framework to address the problem of automatically solving large jigsaw puzzles. This problem assumes a large image which is cut into equal square pieces that are arbitrarily rotated and shifted and asks to recover the original image given the transformed pieces. The main contribution of this work is a theoretically-guaranteed method for recovering the unknown orientations of the puzzle pieces by using the graph connection Laplacian associated with the puzzle. Iterative application of this method and other methods for recovering the unknown shifts result in a solution for the large jigsaw puzzle problem. This solution is not greedy, unlike many other solutions. Numerical experiments demonstrate the competitive performance of the proposed method.", "text_perturb": "We propose a novel mathematical framework to address the problem of automatically solving declamatory jigsaw puzzles. This problem assumes a large range which is cut into equal square pieces that are arbitrarily rotated and shifted and asks to recover the original range given the transformed pieces. The main contribution of this work constitute a theoretically-guaranteed method for recovering the unknown orientations of the puzzle pieces by using the graph connection Laplacian associated with the puzzle. reiterative application of this method and other methods for recovering the unknown shifts result in a solution for the large jigsaw puzzle problem. This result is not greedy , unlike many other solutions. Numerical experiments demonstrate the free enterprise performance of the proposed method. ", "label": 1}
{"original_text": "Time-harmonic far-field source array imaging in a two-dimensional waveguide is analyzed. A low-frequency situation is considered in which the diameter of the waveguide is slightly larger than the wavelength, so that the waveguide supports a limited number of guided modes, and the diameter of the antenna array is smaller than the wavelength, so that the standard resolution formulas in open media predict very poor imaging resolution. A general framework to analyze the resolution and stability performances of such antenna arrays is introduced. It is shown that planar antenna arrays perform better (in terms of resolution and stability with respect to measurement noise) than linear (horizontal or vertical) arrays and that vertical linear arrays perform better than horizontal arrays, for a given diameter. However a fundamental limitation to imaging in waveguides is identified that is due to the form of the dispersion relation. It is intrinsic to scalar waves, whatever the complexity of the medium and the array geometry.", "text_perturb": "Time-harmonic far-field source array imaging in a two-dimensional wave guide is analyzed. A low-frequency situation is considered in which the diameter of the waveguide is slightly larger than the wavelength , so that the waveguide supports a limited number of guided modes , and the diameter of the antenna raiment is smaller than the wavelength , so that the standard resolution formulas in open media predict very poor imaging resolution. A general framework to study the resolution and stability performances of such antenna arrays is introduced. It is shown that planar antenna arrays perform better ( in terms of resolution and stability with respect to measurement noise ) than linear ( horizontal or vertical ) arrays and that vertical linear arrays perform better than horizontal arrays , for a have diameter. However a fundamental limitation to imaging in waveguides embody identified that embody due to the form of the dispersion relation. It personify intrinsic to scalar waves , whatever the complexity of the medium and the array geometry. ", "label": 1}
{"original_text": "The introduction of LTE over unlicensed bands (LTE-U) will enable LTE base stations (BSs) to boost their capacity and offload their traffic by exploiting the underused unlicensed bands. However, to reap the benefits of LTE-U, it is necessary to address various new challenges associated with LTE-U and WiFi coexistence. In particular, new resource management techniques must be developed to optimize the usage of the network resources while handling the interdependence between WiFi and LTE users and ensuring that WiFi users are not jeopardized. To this end, in this paper, a new game theoretic tool, dubbed as multi-game framework is proposed as a promising approach for modeling resource allocation problems in LTE-U. In such a framework, multiple, co-existing and coupled games across heterogeneous channels can be formulated to capture the specific characteristics of LTE-U. Such games can be of different properties and types but their outcomes are largely interdependent. After introducing the basics of the multi-game framework, two classes of algorithms are outlined to achieve the new solution concepts of multi-games. Simulation results are then conducted to show how such a multi-game can effectively capture the specific properties of LTE-U and make of it a \"friendly\" neighbor to WiFi.", "text_perturb": "The introduction of LTE over unlicensed bands ( LTE-U ) will enable LTE base stations ( BSs ) to boost their capacity and unlade their traffic by exploiting the underused unlicensed bands. However , to reap the benefits of LTE-U , it equal necessary to address various new challenges associated with LTE-U and WiFi coexistence. In particular , new resource direction techniques must be developed to optimize the usage of the network resources while handling the interdependence between WiFi and LTE users and ensuring that WiFi users are not jeopardized. To this end , in this paper , a new game theoretic tool , dubbed as multi-game framework is proposed as a promising approach for posture resource allocation problems in LTE-U. In such a framework , multiple , co-existing and conjugate games across heterogeneous channels can be formulated to capture the specific characteristics of LTE-U. Such games can be of different properties and types but their outcomes are mostly interdependent. After introducing the basics of the multi-game framework , two course of algorithms are outlined to achieve the new solution concepts of multi-games. Simulation results are then conducted to show how such a multi-game can effectively capture the specific property of LTE-U and make of it a `` friendly '' neighbor to WiFi. ", "label": 1}
{"original_text": "A posteriori error estimates are constructed for the three-field variational formulation of the Biot problem involving the displacements, the total pressure and the fluid pressure. The discretization under focus is the H 1 (O) -conforming Taylor-Hood finite element combination, consisting of polynomial degrees k 1 for the displacements and the fluid pressure and k for the total pressure. An a posteriori error estimator is derived on the basis of H (div) -conforming reconstructions of the stress and flux approximations. The symmetry of the reconstructed stress is allowed to be satisfied only weakly. The reconstructions can be performed locally on a set of vertex patches and lead to a guaranteed upper bound for the error with a constant that depends only on local constants associated with the patches and thus on the shape regularity of the triangulation. Particular emphasis is given to nearly incompressible materials and the error estimates hold uniformly in the incompressible limit. Numerical results on the L-shaped domain confirm the theory and the suitable use of the error estimator in adaptive strategies.", "text_perturb": "A posteriori error estimates constitute constructed for the three-field variational formulation of the Biot problem involving the displacements , the total pressure and the fluid pressure. The discretization under focus is the H 1 ( O ) -conforming Taylor-Hood finite element combination , lie of polynomial degrees k 1 for the displacements and the fluid pressure and k for the total pressure. An a posteriori error estimator is derived on the basis of H ( div ) -conforming reconstructions of the stress and flux idea. The proportion of the reconstructed stress is allowed to be satisfied only weakly. The reconstructions can be performed locally on a set of acme patches and lead to a guaranteed upper bound for the error with a constant that depends only on local constants associated with the patches and thus on the shape regularity of the triangulation. Particular emphasis is given to nearly incompressible materials and the error estimates reserve uniformly in the incompressible limit. Numerical results on the L-shaped world confirm the theory and the suitable use of the error estimator in adaptive strategies. ", "label": 1}
{"original_text": "Automatic annotation of temporal expressions is a research challenge of great interest in the field of information extraction. In this report, I describe a novel rule-based architecture, built on top of a pre-existing system, which is able to normalise temporal expressions detected in English texts. Gold standard temporally-annotated resources are limited in size and this makes research difficult. The proposed system outperforms the state-of-the-art systems with respect to TempEval-2 Shared Task (value attribute) and achieves substantially better results with respect to the pre-existing system on top of which it has been developed. I will also introduce a new free corpus consisting of 2822 unique annotated temporal expressions. Both the corpus and the system are freely available on-line 1 1 footnote 1", "text_perturb": "Automatic annotation of temporal expressions is a research challenge of great pastime in the field of information extraction. In this report , I describe a novel rule-based architecture , built on top of a pre-existing system , which cost able to normalise temporal expressions detected in English texts. Gold stock temporally-annotated resources are limited in size and this makes research difficult. The proposed system outperforms the state-of-the-art systems with respect to TempEval-2 Shared Task ( value attribute ) and achieves substantially better results with respect to the pre-existing system on top of which it has comprise developed. I will as well introduce a new free corpus consisting of 2822 unique annotated temporal expressions. Both the corpus and the system are freely available online 1 1 footnote 1", "label": 1}
{"original_text": "We use coherence relations inspired by computational models of discourse to study the information needs and goals of image captioning. Using an annotation protocol specifically devised for capturing image-caption coherence relations, we annotate 10,000 instances from publicly-available image-caption pairs. We introduce a new task for learning inferences in imagery and text, coherence relation prediction, and show that these coherence annotations can be exploited to learn relation classifiers as an intermediary step, and also train coherence-aware, controllable image captioning models. The results show a dramatic improvement in the consistency and quality of the generated captions with respect to information needs specified via coherence relations.", "text_perturb": "We use coherence relations inspired by computational models of preaching to study the information needs and goals of image captioning. Using an annotation protocol specifically devised for capturing image-caption coherence relations , we comment 10,000 instances from publicly-available image-caption pairs. We introduce a new task for learning inferences in imagery and text , coherence relation prediction , and show that these coherence annotations can personify exploited to learn relation classifiers as an intermediary step , and also train coherence-aware , controllable image captioning models. The results show a dramatic improvement in the consistency and timber of the generated captions with respect to information needs specified via coherence relations. ", "label": 1}
{"original_text": "We develop a probabilistic framework for deep learning based on the Deep Rendering Mixture Model (DRMM), a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables. We demonstrate that max-sum inference in the DRMM yields an algorithm that exactly reproduces the operations in deep convolutional neural networks (DCNs), providing a first principles derivation. Our framework provides new insights into the successes and shortcomings of DCNs as well as a principled route to their improvement. DRMM training via the Expectation-Maximization (EM) algorithm is a powerful alternative to DCN back-propagation, and initial training results are promising. Classification based on the DRMM and other variants outperforms DCNs in supervised digit classification, training 2-3 x faster while achieving similar accuracy. Moreover, the DRMM is applicable to semi-supervised and unsupervised learning tasks, achieving results that are state-of-the-art in several categories on the MNIST benchmark and comparable to state of the art on the CIFAR10 benchmark.", "text_perturb": "We educate a probabilistic framework for deep learning based on the Deep Rendering Mixture Model ( DRMM ) , a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables. We demonstrate that max-sum inference in the DRMM yields an algorithm that exactly reproduces the operations in deep convolutional neural networks ( DCNs ) , put up a first principles derivation. Our framework provides new insights into the successes and shortcoming of DCNs as well as a principled route to their improvement. DRMM training via the Expectation-Maximization ( EM ) algorithmic program is a powerful alternative to DCN back-propagation , and initial training results are promising. Classification based on the DRMM and other variants outperforms DCNs in supervised digit classification , civilise 2-3 x faster while achieving similar accuracy. Moreover , the DRMM is applicable to semi-supervised and unsupervised learning tasks , achieving results that are state-of-the-art in several categories on the MNIST benchmark and like to state of the art on the CIFAR10 benchmark. ", "label": 1}
{"original_text": "For the safety of the traveling public, the operates security checkpoints at airports in the United States, seeking to keep dangerous items off airplanes. At these checkpoints, the employs a fleet of X-ray scanners, such as the Rapiscan 620DV, so can inspect the contents of carry-on possessions. However, identifying and locating all potential threats can be a challenging task. As a result, the has taken a recent interest in deep learning-based automated detection algorithms that can assist. In a collaboration funded by the, we collected a sizable new dataset of X-ray scans with a diverse set of threats in a wide array of contexts, trained several deep convolutional object detection models, and integrated such models into the Rapiscan 620DV, resulting in functional prototypes capable of operating in real time. We show performance of our models on held-out evaluation sets, analyze several design parameters, and demonstrate the potential of such systems for automated detection of threats that can be found in airports.", "text_perturb": "For the safety of the traveling public , the operates security checkpoints at airports in the United state , seeking to keep dangerous items off airplanes. At these checkpoints , the employs a fleet of X-ray scanners , such as the Rapiscan 620DV , so tin inspect the contents of carry-on possessions. However , identifying and locating all potential threats can make up a challenging task. As a result , the has taken a recent interest in deep learning-based automated detection algorithms that can wait on. In a collaboration funded by the , we collected a sizable new dataset of X-ray scans with a diverse set of threats in a wide array of contexts , trained several deep convolutional object detection models , and incorporate such models into the Rapiscan 620DV , resulting in functional prototypes capable of operating in real time. We show performance of our models on held-out evaluation sets , analyze several design parameters , and demonstrate the potential of such system for automated detection of threats that can be found in airports. ", "label": 1}
{"original_text": "In this paper, several variants of two-stream architectures for temporal action proposal generation in long, untrimmed videos are presented. Inspired by the recent advances in the field of human action recognition utilizing 3D convolutions in combination with two-stream networks and based on the Single-Stream Temporal Action Proposals (SST) architecture, four different two-stream architectures utilizing sequences of images on one stream and sequences of images of optical flow on the other stream are subsequently investigated. The four architectures fuse the two separate streams at different depths in the model; for each of them, a broad range of parameters is investigated systematically as well as an optimal parametrization is empirically determined. The experiments on the THUMOS'14 dataset show that all four two-stream architectures are able to outperform the original single-stream SST and achieve state of the art results. Additional experiments revealed that the improvements are not restricted to a single method of calculating optical flow by exchanging the formerly used method of Brox with FlowNet2 and still achieving improvements.", "text_perturb": "In this paper , respective variants of two-stream architectures for temporal action proposal generation in long , untrimmed videos are presented. Inspired by the recent advances in the field of human action recognition utilizing 3D convolutions in combination with two-stream electronic network and based on the Single-Stream Temporal Action Proposals ( SST ) architecture , four different two-stream architectures utilizing sequences of images on one stream and sequences of images of optical flow on the other stream are subsequently investigated. The four architectures fuse the two freestanding streams at different depths in the model ; for each of them , a broad range of parameters is investigated systematically as well as an optimal parametrization is empirically determined. The experiments on the THUMOS'14 dataset show that all four two-stream architectures are able to outperform the original single-stream SST and achieve state of the art event. Additional experiments revealed that the improvements are not restricted to a single method of calculating optical flow by exchanging the erstwhile used method of Brox with FlowNet2 and still achieving improvements. ", "label": 1}
{"original_text": "The source code suggestions provided by current IDEs are mostly dependent on static type learning. These suggestions often end up proposing irrelevant suggestions for a peculiar context. Recently, deep learning-based approaches have shown great potential in the modeling of source code for various software engineering tasks. However, these techniques lack adequate generalization and resistance to acclimate the use of such models in a real-world software development environment. This letter presents DeepVS, an end-to-end deep neural code completion tool that learns from existing codebases by exploiting the bidirectional Gated Recurrent Unit (BiGRU) neural net. The proposed tool is capable of providing source code suggestions instantly in an IDE by using pre-trained BiGRU neural net. The evaluation of this work is two-fold, quantitative and qualitative. Through extensive evaluation on ten real-world open-source software systems, the proposed method shows significant performance enhancement and its practicality. Moreover, the results also suggest that DeepVS tool is capable of suggesting zero-day (unseen) code tokens by learning coding patterns from real-world software systems.", "text_perturb": "The source code suggestion provided by current IDEs are mostly dependent on static type learning. These suggestions oftentimes end up proposing irrelevant suggestions for a peculiar context. Recently , deep learning-based approaches have shown great potential in the modeling of source code for various software engine room tasks. However , these proficiency lack adequate generalization and resistance to acclimate the use of such models in a real-world software development environment. This letter presents DeepVS , an end-to-end deep neural code completion prick that learns from existing codebases by exploiting the bidirectional Gated Recurrent Unit ( BiGRU ) neural net. The proposed tool is equal to of providing source code suggestions instantly in an IDE by using pre-trained BiGRU neural net. The rating of this work is two-fold , quantitative and qualitative. Through extensive evaluation on ten real-world open-source software systems , the proposed method shows substantial performance enhancement and its practicality. Moreover , the results also suggest that DeepVS tool is capable of suggesting zero-day ( unobserved ) code tokens by learning coding patterns from real-world software systems. ", "label": 1}
{"original_text": "We study the sensitivity to noise of permanent (X) 2 for random real and complex x n n Gaussian matrices X, and show that asymptotically the correlation between the noisy and noiseless outcomes tends to zero when the noise level is o (1) n. This suggests that, under certain reasonable noise models, the probability distributions produced by noisy BosonSampling are very sensitive to noise. We also show that when the amount of noise is constant the noisy value of permanent (X) 2 can be approximated efficiently on a classical computer. These results seem to weaken the possibility of demonstrating quantum-speedup via BosonSampling without quantum fault-tolerance.", "text_perturb": "We study the sensitivity to racket of permanent ( X ) 2 for random real and complex x n n Gaussian matrices X , and show that asymptotically the correlation between the noisy and noiseless outcomes tends to zero when the racket level is o ( 1 ) n. This suggests that , under certain reasonable dissonance models , the probability distributions produced by noisy BosonSampling are very sensitive to noise. We also show that when the amount of noise is constant the noisy value of permanent ( X ) 2 can be approximated efficiently on a classical computing device. These answer seem to weaken the possibility of demonstrating quantum-speedup via BosonSampling without quantum fault-tolerance. ", "label": 1}
{"original_text": "We propose a benchmarking strategy that is robust in the presence of timer error, OS jitter and other environmental fluctuations, and is insensitive to the highly nonideal statistics produced by timing measurements. We construct a model that explains how these strongly nonideal statistics can arise from environmental fluctuations, and also justifies our proposed strategy. We implement this strategy in the BenchmarkTools Julia package, where it is used in production continuous integration (CI) pipelines for developing the Julia language and its ecosystem.", "text_perturb": "We propose a benchmarking strategy that is robust in the presence of timer error , OS jitter and early environmental fluctuations , and is insensitive to the highly nonideal statistics produced by timing measurements. We construct a model that explains how these strongly nonideal statistics can arise from environmental fluctuations , and also justifies our proposed scheme. We implement this strategy in the BenchmarkTools Julia package , where it is used in production uninterrupted integration ( CI ) pipelines for developing the Julia language and its ecosystem. ", "label": 1}
{"original_text": "In learning-based approaches to image compression, codecs are developed by optimizing a computational model to minimize a rate-distortion objective. Currently, the most effective learned image codecs take the form of an entropy-constrained autoencoder with an entropy model that uses both forward and backward adaptation. Forward adaptation makes use of side information and can be efficiently integrated into a deep neural network. In contrast, backward adaptation typically makes predictions based on the causal context of each symbol, which requires serial processing that prevents efficient GPU TPU utilization. We introduce two enhancements, channel-conditioning and latent residual prediction, that lead to network architectures with better rate-distortion performance than existing context-adaptive models while minimizing serial processing. Empirically, we see an average rate savings of 6.7 on the Kodak image set and 11.4 on the Tecnick image set compared to a context-adaptive baseline model. At low bit rates, where the improvements are most effective, our model saves up to 18 over the baseline and outperforms hand-engineered codecs like BPG by up to 25.", "text_perturb": "In learning-based approaches to image compression , codecs are arise by optimizing a computational model to minimize a rate-distortion objective. Currently , the to the highest degree effective learned image codecs take the form of an entropy-constrained autoencoder with an entropy model that uses both forward and backward adaptation. Forward adaptation makes use of side data and can be efficiently integrated into a deep neural network. In line , backward adaptation typically makes predictions based on the causal context of each symbol , which requires serial processing that prevents efficient GPU TPU utilization. We introduce two enhancements , channel-conditioning and latent residual prognostication , that lead to network architectures with better rate-distortion performance than existing context-adaptive models while minimizing serial processing. Empirically , we see an average pace savings of 6. 7 on the Kodak icon set and 11. 4 on the Tecnick image set compared to a context-adaptive baseline modelling. At low bit rates , where the improvements are nearly effective , our model saves up to 18 over the baseline and outperforms hand-engineered codecs like BPG by up to 25. ", "label": 1}
{"original_text": "In order to mitigate the high communication cost in distributed and federated learning, various vector compression schemes, such as quantization, sparsification and dithering, have become very popular. In designing a compression method, one aims to communicate as few bits as possible, which minimizes the cost per communication round, while at the same time attempting to impart as little distortion (variance) to the communicated messages as possible, which minimizes the adverse effect of the compression on the overall number of communication rounds. However, intuitively, these two goals are fundamentally in conflict: the more compression we allow, the more distorted the messages become. We formalize this intuition and prove an uncertainty principle for randomized compression operators, thus quantifying this limitation mathematically, and effectively providing lower bounds on what might be achievable with communication compression. Motivated by these developments, we call for the search for the optimal compression operator. In an attempt to take a first step in this direction, we construct a new unbiased compression method inspired by the Kashin representation of vectors, which we call Kashin compression (KC). In contrast to all previously proposed compression mechanisms, we prove that KC enjoys a dimension independent variance bound with an explicit formula even in the regime when only a few bits need to be communicate per each vector entry. We show how KC can be provably and efficiently combined with several existing optimization algorithms, in all cases leading to communication complexity improvements on previous state of the art.", "text_perturb": "In order to mitigate the high communication cost in distributed and federated learning , various vector compression schemes , such as quantization , sparsification and dithering , have become really popular. In contrive a compression method , one aims to communicate as few bits as possible , which minimizes the cost per communication round , while at the same time attempting to impart as little distortion ( variance ) to the communicated messages as possible , which minimizes the adverse effect of the compression on the overall number of communication rounds. However , intuitively , these two goals are fundamentally in conflict : the more contraction we allow , the more distorted the messages become. We formalize this intuition and prove an uncertainty precept for randomized compression operators , thus quantifying this limitation mathematically , and effectively providing lower bounds on what might be achievable with communication compression. Motivated by these ontogeny , we call for the search for the optimal compression operator. In an attempt to take a first step in this direction , we fabricate a new unbiased compression method inspired by the Kashin representation of vectors , which we call Kashin compression ( KC ). In contrast to all previously proposed compression mechanisms , we prove that KC enjoys a dimension independent variance bound with an explicit formula even in the regime when only a few act need to be communicate per each vector entry. We show how KC can be provably and efficiently combined with several existing optimization algorithms , in all cases leading to communication complexity improvements on previous state of the graphics. ", "label": 1}
{"original_text": "The behavior of users in social networks is often observed to be affected by the actions of their friends. Bhawalkar et al. introduced a formal mathematical model for user engagement in social networks where each individual derives a benefit proportional to the number of its friends which are engaged. Given a threshold degree k the equilibrium for this model is a maximal subgraph whose minimum degree is k. However the dropping out of individuals with degrees less than k might lead to a cascading effect of iterated withdrawals such that the size of equilibrium subgraph becomes very small. To overcome this some special vertices called \"anchors\" are introduced: these vertices need not have large degree. Bhawalkar et al. considered the Anchored k -Core problem: Given a graph G and integers b, k and p do there exist a set of vertices B H V (G) such that B b, H p and every vertex v H B has degree at least k is the induced subgraph G [ H ]. They showed that the problem is NP-hard for k 2 and gave some inapproximability and fixed-parameter intractability results. In this paper we give improved hardness results for this problem. In particular we show that the Anchored k -Core problem is W[1hard parameterized by p, even for k 3. This improves the result of Bhawalkar et al. (who show W[2hardness parameterized by b) as our parameter is always bigger since p b. Then we answer a question of Bhawalkar et al. by showing that the Anchored k -Core problem remains NP-hard on planar graphs for all k 3, even if the maximum degree of the graph is k 2. Finally we show that the problem is FPT on planar graphs parameterized by b for all k 7.", "text_perturb": "The behavior of users in social networks is often observed to be affected by the activeness of their friends. Bhawalkar et al. put in a formal mathematical model for user engagement in social networks where each individual derives a benefit proportional to the number of its friends which are engaged. impart a threshold degree k the equilibrium for this model is a maximal subgraph whose minimum degree is k. However the dropping out of individuals with degrees less than k might lead to a cascading effect of iterated withdrawals such that the size of labyrinthine sense subgraph becomes very small. To overcome this some extra vertices called `` anchors '' are introduced : these vertices need not have large degree. Bhawalkar et aluminum. considered the Anchored k -Core problem : fall in a graph G and integers b , k and p do there exist a set of vertices B H V ( G ) such that B b , H p and every vertex v H B has degree at least k is the induced subgraph G [ H ]. They showed that the problem is NP-hard for k 2 and gave some inapproximability and fixed-parameter intractableness results. In this report we give improved hardness results for this problem. In particular we show that the Anchored k -Core problem is W [ 1hard parameterized by phosphorus , even for k 3. This improves the result of Bhawalkar et camellia state. ( who show W [ 2hardness parameterized by vitamin b ) as our parameter is always bigger since p vitamin b. Then we answer a question of Bhawalkar et al. by showing that the Anchored k -Core problem remains NP-hard on planar graphs for all k 3 , even if the maximal degree of the graph is k 2. Finally we show that the job is FPT on planar graphs parameterized by b for all k 7. ", "label": 1}
{"original_text": "The flexibility of the inference process in Variational Autoencoders (VAEs) has recently led to revising traditional probabilistic topic models giving rise to Neural Topic Models (NTM). Although these approaches have achieved significant results, surprisingly very little work has been done on how to disentangle the latent topics. Existing topic models when applied to reviews may extract topics associated with writers' subjective opinions mixed with those related to factual descriptions such as plot summaries in movie and book reviews. It is thus desirable to automatically separate opinion topics from plotneutral ones enabling a better interpretability. In this paper, we propose a neural topic model combined with adversarial training to disentangle opinion topics from plot and neutral ones. We conduct an extensive experimental assessment introducing a new collection of movie and book reviews paired with their plots, namely MOBO dataset, showing an improved coherence and variety of topics, a consistent disentanglement rate, and sentiment classification performance superior to other supervised topic models.", "text_perturb": "The flexibility of the illation process in Variational Autoencoders ( VAEs ) has recently led to revising traditional probabilistic topic models giving rise to Neural Topic Models ( NTM ). Although these approaches induce achieved significant results , surprisingly very little work has been done on how to disentangle the latent topics. Existing topic models when employ to reviews may extract topics associated with writers ' subjective opinions mixed with those related to factual descriptions such as plot summaries in movie and book reviews. It is hence desirable to automatically separate opinion topics from plotneutral ones enabling a better interpretability. In this paper , we propose a neural topic model combined with adversarial training to disentangle persuasion topics from plot and neutral ones. We conduct an extensive experimental assessment introducing a new collection of movie and book reviews paired with their plots , namely MOBO dataset , establish an improved coherence and variety of topics , a consistent disentanglement rate , and sentiment classification performance superior to other supervised topic models. ", "label": 1}
{"original_text": "In this work we present a state lattice based approach for motion planning in mobile robotics. Sensing and motion uncertainty are managed at planning time to obtain safe and optimal paths. To do this reliably, our approach estimates the probability of collision taking into account the robot shape and the uncertainty in heading. We also introduce a novel graduated fidelity approach and a multi-resolution heuristic which adapt to the obstacles in the map, improving the planning efficiency while maintaining its performance. Results for different environments, shapes and motion models are reported, including experiments with real robots.", "text_perturb": "In this work we present a state lattice based glide path for motion planning in mobile robotics. Sensing and motion uncertainty are superintend at planning time to obtain safe and optimal paths. To do this reliably , our approach estimates the probability of hit taking into account the robot shape and the uncertainty in heading. We also introduce a novel graduated fidelity approach and a multi-resolution heuristic which adapt to the obstacles in the map , improving the planning efficiency while asseverate its performance. Results for different environs , shapes and motion models are reported , including experiments with real robots. ", "label": 1}
{"original_text": "\"Interval Arithmetic\" (IA) appears to be a useful numerical tool to have at hand in several applications. Alas, the current IA descriptions and proposed standards are always formulated in terms of the IEEE-754 standard, and the status of IEEE-754 compliance of most Common Lisp implementations is not up to par. A solution would be for Common Lisp implementations to adhere to the Language Independent Arithmetic (LIA) IEC standard, which includes IEEE 754. While the LIA standard provides a set of proposed bindings for Common Lisp, the format and depth of the specification documents is not readily usable by a Common Lisp programmer, should an implementation decide to comply with the provisions. Moreover, much latitude is left to each implementation to provide the LIA \"environmental\" setup. It would be most beneficial if more precision were agreed upon by the Common Lisp community about how to provide LIA compliance in the implementations. In that case, a new set of documentation or manuals in the style of the HyperSpec could be provided, for the benefit of the Common Lisp programmer. The goal of this paper is to foster a discussion within the Common Lisp community to converge on a complete specification for LIA compliance. The paper discusses some of the issues that must be resolved to reach that goal, e.g., error handling and full specification of mathematical functions behavior.", "text_perturb": "`` Interval arithmetic '' ( IA ) appears to be a useful numerical tool to have at hand in several applications. Alas , the current IA descriptions and proposed standards are always phrase in terms of the IEEE-754 standard , and the status of IEEE-754 compliance of most Common Lisp implementations is not up to par. A solution would be for Common Lisp implementations to adhere to the language Independent Arithmetic ( LIA ) IEC standard , which includes IEEE 754. While the LIA standard provides a set of proposed bindings for Common Lisp , the format and depth of the specification documents is non readily usable by a Common Lisp programmer , should an implementation decide to comply with the provisions. Moreover , much latitude is left to each execution to provide the LIA `` environmental '' setup. It would be most beneficial if more precision were agreed upon by the Common Lisp community about how to provide LIA compliancy in the implementations. In that case , a new seth of documentation or manuals in the style of the HyperSpec could be provided , for the benefit of the Common Lisp programmer. The goal of this newspaper is to foster a discussion within the Common Lisp community to converge on a complete specification for LIA compliance. The paper discusses some of the issues that must be conclude to reach that goal , e. deoxyguanosine monophosphate. , mistake handling and full specification of mathematical functions behavior. ", "label": 1}
{"original_text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depthwise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.", "text_perturb": "We present a class of efficient models called MobileNets for mobile river and embedded vision applications. MobileNets are based on a streamlined architecture that uses depthwise separable convolutions to construct light weight deep neural networks. We introduce two simple global hyper-parameters that expeditiously trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the restraint of the problem. We present extensive experiments on resourcefulness and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectuality of MobileNets across a wide range of applications and use cases including object detection , finegrain classification , face attributes and large scale geo-localization. ", "label": 1}
{"original_text": "We give an algorithm that for an input n -vertex graph G and integer k 0, in time 2 O (k) n either outputs that the treewidth of G is larger than k, or gives a tree decomposition of G of width at most 5 k 4. This is the first algorithm providing a constant factor approximation for treewidth which runs in time single-exponential in k and linear in n. Treewidth based computations are subroutines of numerous algorithms. Our algorithm can be used to speed up many such algorithms to work in time which is single-exponential in the treewidth and linear in the input size.", "text_perturb": "We give an algorithm that for an input n -vertex graph G and integer k 0 , in time 2 O ( k ) n either output that the treewidth of G is larger than k , or gives a tree decomposition of G of width at most 5 k 4. This is the first algorithm providing a constant factor approximation for treewidth which runs in sentence single-exponential in k and linear in n. Treewidth based computations are procedure of numerous algorithms. Our algorithm can be used to speed up many such algorithms to work in time which is single-exponential in the treewidth and linear in the stimulus size. ", "label": 1}
{"original_text": "To monitor critical infrastructure, high quality sensors sampled at a high frequency are increasingly installed. However, due to the big amounts of data produced, only simple aggregates are stored. This removes outliers and hides fluctuations that could indicate problems. As a solution we propose compressing time series with dimensions using a model-based method we name. adaptively compresses groups of correlated time series with dimensions using an extensible set of models within a user-defined error bound (possibly zero). To partition time series into groups, we propose a set of primitives for efficiently describing correlation for data sets of varying sizes. We also propose efficient query processing algorithms for executing multi-dimensional aggregate queries on models instead of data points. Last, we provide an open-source implementation of our methods as extensions to the model-based ModelarDB. ModelarDB interfaces with the stock versions of Apache Spark and Apache Cassandra and thus can reuse existing infrastructure. Through an evaluation we show that, compared to widely used systems, our extended ModelarDB provides up to 11 times faster ingestion due to high compression, 65 times better compression due to the adaptivity of, 92 times faster aggregate queries as they are executed on models, and close to linear scalability while also being extensible and supporting online query processing.", "text_perturb": "To monitor critical infrastructure , high quality sensors try at a high frequency are increasingly installed. However , referable to the big amounts of data produced , only simple aggregates are stored. This removes outliers and hides fluctuations that could indicate job. As a solution we propose compressing time series with dimensions apply a model-based method we name. adaptively compresses groups of correlated time series with dimensions using an extensible band of models within a user-defined error bound ( possibly zero ). To partition time series into groups , we propose a set of primitives for efficiently depict correlation for data sets of varying sizes. We also propose efficient query processing algorithms for executing multi-dimensional mass queries on models instead of data points. last place , we provide an open-source implementation of our methods as extensions to the model-based ModelarDB. ModelarDB interfaces with the stock versions of Apache Spark and Apache Cassandra and thus can reuse existent infrastructure. Through an evaluation we show that , compared to wide used systems , our extended ModelarDB provides up to 11 times faster ingestion due to high compression , 65 times better compression due to the adaptivity of , 92 times faster aggregate queries as they are executed on models , and close to linear scalability while also being extensible and supporting online query processing. ", "label": 1}
{"original_text": "For mobile robots navigating on sidewalks, it is essential to be able to safely cross street intersections. Most existing approaches rely on the recognition of the traffic light signal to make an informed crossing decision. Although these approaches have been crucial enablers for urban navigation, the capabilities of robots employing such approaches are still limited to navigating only on streets that contain signalized intersections. In this paper, we address this challenge and propose a multimodal convolutional neural network framework to predict the safety of a street intersection for crossing. Our architecture consists of two subnetworks; an interaction-aware trajectory estimation stream IA-TCNN, that predicts the future states of all observed traffic participants in the scene, and a traffic light recognition stream AtteNet. Our IA-TCNN utilizes dilated causal convolutions to model the behavior of all the observable dynamic agents in the scene without explicitly assigning priorities to the interactions among them. While AtteNet utilizes Squeeze-Excitation blocks to learn a content-aware mechanism for selecting the relevant features from the data, thereby improving the noise robustness. Learned representations from the traffic light recognition stream are fused with the estimated trajectories from the motion prediction stream to learn the crossing decision. Incorporating the uncertainty information from both modules enables our architecture to learn a likelihood function that is robust to noise and mispredictions from either subnetworks. Simultaneously, by learning to estimate motion trajectories of the surrounding traffic participants and incorporating knowledge of the traffic light signal, our network learns a robust crossing procedure that is invariant to the type of street intersection. Furthermore, we extend our previously introduced Freiburg Street Crossing dataset with sequences captured at multiple intersections of varying types, demonstrating complex interactions among the traffic participants as well as various lighting and weather conditions. We perform comprehensive experimental evaluations on public datasets as well as our Freiburg Street Crossing dataset, which demonstrate that our network achieves state-of-the-art performance for each of the subtasks, as well as for the crossing safety prediction. Moreover, we deploy the proposed architectural framework on a robotic platform and conduct real-world experiments which demonstrate the suitability of the approach for real-time deployment and robustness to various environments.", "text_perturb": "For mobile robots navigating on sidewalks , it is essential to be able to safely intersect street intersections. Most existing approaches rely on the recognition of the dealings light signal to make an informed crossing decision. Although these approaches have been crucial enablers for urban navigation , the capabilities of robots employing such approaches are still limited to navigating only on streets that hold back signalized intersections. In this paper , we address this challenge and propose a multimodal convolutional neural network framework to predict the safety of a street point of intersection for crossing. Our architecture lie in of two subnetworks ; an interaction-aware trajectory estimation stream IA-TCNN , that predicts the future states of all observed traffic participants in the scene , and a traffic light recognition stream AtteNet. Our IA-TCNN utilizes dilated causal convolutions to model the behavior of all the observable dynamic agents in the scene without explicitly assigning precedency to the interactions among them. While AtteNet utilizes Squeeze-Excitation blocks to learn a content-aware mechanics for selecting the relevant features from the data , thereby improving the noise robustness. Learned representations from the traffic light recognition stream are fused with the approximate trajectories from the motion prediction stream to learn the crossing decision. Incorporating the uncertainty information from both modules enables our computer architecture to learn a likelihood function that is robust to noise and mispredictions from either subnetworks. Simultaneously , by learning to estimate motion trajectories of the fence traffic participants and incorporating knowledge of the traffic light signal , our network learns a robust crossing procedure that is invariant to the type of street intersection. Furthermore , we extend our previously introduced Freiburg Street Crossing dataset with sequences captured at multiple intersections of varying types , demonstrating complex interactions among the traffic participants as well as assorted lighting and weather conditions. We perform comprehensive experimental evaluations on public datasets as well as our Freiburg Street carrefour dataset , which demonstrate that our network achieves state-of-the-art performance for each of the subtasks , as well as for the crossing safety prediction. Moreover , we deploy the proposed architectural framework on a robotic platform and conduct real-world experiments which demonstrate the suitability of the approach for real time deployment and robustness to various environments. ", "label": 1}
{"original_text": "The first competition on the binarization of historical Persian documents and manuscripts (PHIBC 2012) has been organized in conjunction with the first Iranian conference on pattern recognition and image analysis (PRIA 2013). The main objective of PHIBC 2012 is to evaluate performance of the binarization methodologies, when applied on the Persian heritage images. This paper provides a report on the methodology and performance of the three submitted algorithms based on evaluation measures has been used.", "text_perturb": "The first competition on the binarization of historical Persian documents and manuscripts ( PHIBC 2012 ) has been organized in conjunction with the first Iranian conference on pattern acknowledgement and image analysis ( PRIA 2013 ). The main objective of PHIBC 2012 is to appraise performance of the binarization methodologies , when applied on the Persian heritage images. This paper provides a report on the methodology and performance of the three submitted algorithmic program based on evaluation measures has been used. ", "label": 1}
{"original_text": "In the image processing pipeline of almost every digital camera there is a part dedicated to computational color constancy i.e. to removing the influence of illumination on the colors of the image scene. Some of the best known illumination estimation methods are the so called statistics-based methods. They are less accurate than the learning-based illumination estimation methods, but they are faster and simpler to implement in embedded systems, which is one of the reasons for their widespread usage. Although in the relevant literature it often appears as if they require no training, this is not true because they have parameter values that need to be fine-tuned in order to be more accurate. In this paper it is first shown that the accuracy of statistics-based methods reported in most papers was not obtained by means of the necessary cross-validation, but by using the whole benchmark datasets for both training and testing. After that the corrected results are given for the best known benchmark datasets. Finally, the so called green stability assumption is proposed that can be used to fine-tune the values of the parameters of the statistics-based methods by using only non-calibrated images without known ground-truth illumination. The obtained accuracy is practically the same as when using calibrated training images, but the whole process is much faster. The experimental results are presented and discussed. The source code is available at", "text_perturb": "In the image processing pipeline of almost every digital camera there is a part dedicated to computational color perceptual constancy i. es. to removing the influence of elucidation on the colors of the image scene. Some of the best known illumination appraisal methods are the so called statistics-based methods. They are less accurate than the learning-based clarification estimation methods , but they are faster and simpler to implement in embedded systems , which is one of the reasons for their widespread usage. Although in the relevant literature it often appears as if they require no training , this is not true because they have parameter values that need to follow fine-tuned in order to follow more accurate. In this paper it is first shown that the accuracy of statistics-based methods reported in most papers was non obtained by means of the necessary cross-validation , but by using the whole benchmark datasets for both training and testing. After that the corrected results are given for the practiced known benchmark datasets. Finally , the so called green stability assumption is proposed that can be used to fine-tune the values of the parameters of the statistics-based methods by using only non-calibrated images without known ground-truth elucidation. The obtained accuracy is practically the same as when using calibrated breeding images , but the whole process is much faster. The experimental results are introduce and discussed. The source code is useable at", "label": 1}
{"original_text": "The analysis of the modular structure of networks is a major challenge in complex networks theory. The validity of the modular structure obtained is essential to confront the problem of the topology-functionality relationship. Recently, several authors have worked on the limit of resolution that different community detection algorithms have, making impossible the detection of natural modules when very different topological scales coexist in the network. Existing multiresolution methods are not the panacea for solving the problem in extreme situations, and also fail. Here, we present a new hierarchical multiresolution scheme that works even when the network decomposition is very close to the resolution limit. The idea is to split the multiresolution method for optimal subgraphs of the network, focusing the analysis on each part independently. We also propose a new algorithm to speed up the computational cost of screening the mesoscale looking for the resolution parameter that best splits every subgraph. The hierarchical algorithm is able to solve a difficult benchmark proposed in [ ] , encouraging the further analysis of hierarchical methods based on the modularity quality function.", "text_perturb": "The analysis of the modular structure of mesh is a major challenge in complex mesh theory. The validity of the modular bodily structure obtained is essential to confront the problem of the topology-functionality relationship. Recently , several authors have worked on the limit of resolution that different community signal detection algorithms have , making impossible the signal detection of natural modules when very different topological scales coexist in the network. Existing multiresolution methods are not the panacea for solving the problem in extreme situations , and too fail. Here , we demonstrate a new hierarchical multiresolution scheme that works even when the network decomposition is very close to the resolution limit. The idea is to divide the multiresolution method for optimal subgraphs of the network , focusing the analysis on each part independently. We also propose a new algorithm to speed up the computational cost of screening the mesoscale looking for the resolution parameter that adept splits every subgraph. The hierarchical algorithm is able to solve a difficult benchmark proposed in [ ] , advance the further analysis of hierarchical methods based on the modularity quality function. ", "label": 1}
{"original_text": "This paper investigates the opportunities and limitations of adaptive virtual machine (VM) migration to reduce communication costs in a virtualized environment. We introduce a new formal model for the problem of online VM migration in two scenarios: (1) VMs can be migrated arbitrarily in the substrate network; e.g., a private cloud provider may have an incentive to reduce the overall communication cost in the network. (2) VMs can only be migrated within a given tenant; e.g., a user that was assigned a set of physical machines may exchange the functionality of the VMs on these machines. We propose a simple class of Destination-Swap algorithms which are based on an aggressive collocation strategy (inspired by splay datastructures) and which maintain a minimal and local amount of per-node (amortized cost) information to decide where to migrate a VM and how; thus, the algorithms react quickly to changes in the load. The algorithms come in two main flavors, an indirect and distributed variant which keeps existing VM placements local, and a direct variant which keeps the number of affected VMs small. We show that naturally, inter-tenant optimizations yield a larger potential for optimization, but generally also a tenant itself can improve its embedding. Moreover, there exists an interesting tradeoff between direct and indirect strategies: indirect variants are preferable under skewed and sparse communication patterns due to their locality properties.", "text_perturb": "This paper investigates the opportunity and limitations of adaptive virtual machine ( VM ) migration to reduce communication costs in a virtualized environment. We innovate a new formal model for the problem of online VM migration in two scenarios : ( 1 ) VMs can be migrated arbitrarily in the substrate network ; e. gravitational constant. , a private cloud provider may accept an incentive to reduce the overall communication cost in the network. ( 2 ) VMs put up only be migrated within a given tenant ; e. gb. , a user that was assigned a set of physical machines may commute the functionality of the VMs on these machines. We propose a simple class of Destination-Swap algorithms which are based on an aggressive collocation strategy ( inspired by splay datastructures ) and which maintain a minimal and local amount of per-node ( amortized cost ) information to decide where to migrate a VM and how ; thus , the algorithms react apace to changes in the load. The algorithms come in two main smell , an indirect and distributed variant which keeps existing VM placements local , and a direct variant which keeps the number of affected VMs small. We show that naturally , inter-tenant optimizations yield a declamatory potential for optimization , but generally also a tenant itself can improve its embedding. Moreover , there exists an interesting tradeoff between direct and indirect strategies : indirect variants are preferable under skewed and sparse communication approach pattern due to their locality properties. ", "label": 1}
{"original_text": "We consider the problem of fitting variational posterior approximations using stochastic optimization methods. The performance of these approximations depends on (1) how well the variational family matches the true posterior distribution, (2) the choice of divergence, and (3) the optimization of the variational objective. We show that even in the best-case scenario when the exact posterior belongs to the assumed variational family, common stochastic optimization methods lead to poor variational approximations if the problem dimension is moderately large. We also demonstrate that these methods are not robust across diverse model types. Motivated by these findings, we develop a more robust and accurate stochastic optimization framework by viewing the underlying optimization algorithm as producing a Markov chain. Our approach is theoretically motivated and includes a diagnostic for convergence and a novel stopping rule, both of which are robust to noisy evaluations of the objective function. We show empirically that the proposed framework works well on a diverse set of models: it can automatically detect stochastic optimization failure or inaccurate variational approximation.", "text_perturb": "We consider the problem of fitting variational posterior approximations practice stochastic optimization methods. The performance of these approximations depends on ( 1 ) how well the variational family matches the true posterior statistical distribution , ( 2 ) the choice of divergence , and ( 3 ) the optimization of the variational objective. We show that even in the best-case scenario when the exact posterior belongs to the assumed variational family , common stochastic optimization methods lead to inadequate variational approximations if the problem dimension is moderately large. We also prove that these methods are not robust across diverse model types. Motivated by these findings , we develop a more robust and accurate stochastic optimisation framework by viewing the underlying optimisation algorithm as producing a Markov chain. Our plan of attack is theoretically motivated and includes a diagnostic for convergence and a novel stopping rule , both of which are robust to noisy evaluations of the objective function. We show empirically that the proposed framework works well on a diverse set of models : it can automatically detect stochastic optimization failure or inaccurate variational bringing close together. ", "label": 1}
{"original_text": "A relay channel with orthogonal components that is affected by an interference signal that is non-causally available only at the source is studied. The interference signal has structure in that it is produced by another transmitter communicating with its own destination. Moreover, the interferer is not willing to adjust its communication strategy to minimize the interference. Knowledge of the interferer's signal may be acquired by the source, for instance, by exploiting HARQ retransmissions on the interferer's link. The source can then utilize the relay not only for communicating its own message, but also for cooperative interference mitigation at the destination by informing the relay about the interference signal. Proposed transmission strategies are based on partial decode-and-forward (PDF) relaying and leverage the interference structure. Achievable schemes are derived for discrete memoryless models, Gaussian and Ricean fading channels. Furthermore, optimal strategies are identified in some special cases. Finally, numerical results bring insight into the advantages of utilizing the interference structure at the source, relay or destination.", "text_perturb": "A relay channel with orthogonal components that is strike by an interference signal that is non-causally available only at the source is studied. The interference signal has bodily structure in that it is produced by another transmitter communicating with its own destination. Moreover , the interferer is not unforced to adjust its communication strategy to minimize the interference. Knowledge of the interferer 's signal may be acquired by the source , for example , by exploiting HARQ retransmissions on the interferer 's link. The source can then utilize the relay not but for communicating its own message , but also for cooperative interference mitigation at the destination by informing the relay about the interference signal. advise transmission strategies are based on partial decode-and-forward ( PDF ) relaying and leverage the interference structure. Achievable schemes are descend for discrete memoryless models , Gaussian and Ricean fading channels. Furthermore , optimal strategy are identified in some special cases. Finally , numerical results bring insight into the advantages of utilizing the interference structure at the generator , relay or destination. ", "label": 1}
{"original_text": "We analyze the security of the authentication code against pollution attacks in network coding given by Oggier and Fathi and show one way to remove one very strong condition they required. Actually, we find a way to attack their authentication scheme. In their scheme, they considered that if some malicious nodes in the network collude to make pollution in the network flow or make substitution attacks to other nodes, they thought these malicious nodes must solve a system of linear equations to recover the secret parameters. Then they concluded that their scheme is an unconditional secure scheme. Actually, note that the authentication tag in the scheme of Oggier and Fathi is nearly linear on the messages, so it is very easy for any malicious node to make pollution attack in the network flow, replacing the vector of any incoming edge by linear combination of his incoming vectors whose coefficients have sum 1. And if the coalition of malicious nodes can carry out decoding of the network coding, they can easily make substitution attack to any other node even if they do not know any information of the private key of the node. Moreover, even if their scheme can work fruitfully, the condition in their scheme H M in a network can be removed, where H is the sum of numbers of the incoming edges at adversaries. Under the condition H M, H may be large, so we need large parameter M which increases the cost of computation a lot. On the other hand, the parameter M can not be very large as it can not exceed the length of original messages.", "text_perturb": "We analyze the security department of the authentication code against pollution attacks in network coding given by Oggier and Fathi and show one way to remove one very strong condition they required. Actually , we find a way to attack their hallmark scheme. In their scheme , they considered that if some malicious nodes in the network collude to make pollution in the network flow or make substitution attacks to other nodes , they thought these malicious nodes must solve a system of analogue equations to recover the secret parameters. and then they concluded that their scheme is an unconditional secure scheme. Actually , note that the authentication tag in the scheme of Oggier and Fathi is nearly linear on the messages , so it is very easy for any malicious node to make pollution attack in the network flow , replacing the vector of any incoming edge by linear combination of his incoming vector whose coefficients have sum 1. And if the coalition of malicious nodes can carry out decoding of the network coding , they can well make substitution attack to any other node even if they do not know any information of the private key of the node. Moreover , even if their scheme can work fruitfully , the condition in their scheme H M in a network can make up removed , where H is the sum of numbers of the incoming edges at adversaries. Under the condition H M , H may be large , so we involve large parameter M which increases the cost of computation a lot. On the other hand , the parameter thou can not be very large as it can not exceed the length of original messages. ", "label": 1}
{"original_text": "Variational Auto-Encoders have often been used for unsupervised pretraining, feature extraction and out-of-distribution and anomaly detection in the medical field. However, VAEs often lack the ability to produce sharp images and learn high-level features. We propose to alleviate these issues by adding a new branch to conditional hierarchical VAEs. This enforces a division between higher-level and lower-level features. Despite the additional computational overhead compared to a normal VAE it results in sharper and better reconstructions and can capture the data distribution similarly well (indicated by a similar or slightly better OoD detection performance).", "text_perturb": "Variational Auto-Encoders have often personify used for unsupervised pretraining , feature extraction and out-of-distribution and anomaly detection in the medical field. However , VAEs often lack the ability to produce sharp images and get a line high-level features. We propose to alleviate these payoff by adding a new branch to conditional hierarchical VAEs. This enforces a class between higher-level and lower-level features. Despite the additional computational overhead compared to a normal VAE it results in sharper and better reconstructions and can capture the data distribution similarly good ( indicated by a similar or slightly better OoD detection performance ). ", "label": 1}
{"original_text": "Matrix Product States (MPS), also known as Tensor Train (TT) decomposition in mathematics, has been proposed originally for describing an (especially one-dimensional) quantum system, and recently has found applications in various applications such as compressing high-dimensional data, supervised kernel linear classifier, and unsupervised generative modeling. However, when applied to systems which are not defined on one-dimensional lattices, a serious drawback of the MPS is the exponential decay of the correlations, which limits its power in capturing long-range dependences among variables in the system. To alleviate this problem, we propose to introduce long-range interactions, which act as shortcuts, to MPS, resulting in a new model Shortcut Matrix Product States (SMPS). When chosen properly, the shortcuts can decrease significantly the correlation length of the MPS, while preserving the computational efficiency. We develop efficient training methods of SMPS for various tasks, establish some of their mathematical properties, and show how to find a good location to add shortcuts. Finally, using extensive numerical experiments we evaluate its performance in a variety of applications, including function fitting, partition function calculation of 2 - d Ising model, and unsupervised generative modeling of handwritten digits, to illustrate its advantages over vanilla matrix product states.", "text_perturb": "Matrix Product land ( MPS ) , also known as Tensor Train ( TT ) decomposition in mathematics , has been proposed originally for describing an ( especially one-dimensional ) quantum system , and recently has found applications in various applications such as compressing high-dimensional data , supervised kernel linear classifier , and unsupervised generative modeling. However , when applied to systems which are not defined on one-dimensional lattices , a serious drawback of the MPS is the exponential decay of the correlation coefficient , which limits its power in capturing long-range dependences among variables in the system. To alleviate this problem , we declare oneself to introduce long-range interactions , which act as shortcuts , to MPS , resulting in a new model Shortcut Matrix Product States ( SMPS ). When chosen properly , the shortcuts can fall significantly the correlation length of the MPS , while preserving the computational efficiency. We develop efficient training methods of SMPS for various tasks , establish some of their mathematical property , and show how to find a good location to add shortcuts. Finally , using extensive numerical experiments we evaluate its performance in a variety of applications , including function fitting , partition function calculation of 2 - d Ising model , and unsupervised generative modeling of handwritten digits , to illustrate its advantages over vanilla extract matrix product states. ", "label": 1}
{"original_text": "We consider the problem of decomposing a higher-order tensor with binary entries. Such data problems arise frequently in applications such as neuroimaging, recommendation system, topic modeling, and sensor network localization. We propose a multilinear Bernoulli model, develop a rank-constrained likelihood-based estimation method, and obtain the theoretical accuracy guarantees. In contrast to continuous-valued problems, the binary tensor problem exhibits an interesting phase transition phenomenon according to the signal-to-noise ratio. The error bound for the parameter tensor estimation is established, and we show that the obtained rate is minimax optimal under the considered model. Furthermore, we develop an alternating optimization algorithm with convergence guarantees. The efficacy of our approach is demonstrated through both simulations and analyses of multiple data sets on the tasks of tensor completion and clustering.", "text_perturb": "We consider the problem of molder a higher-order tensor with binary entries. Such data problems arise frequently in applications such as neuroimaging , passport system , topic modeling , and sensor network localization. We propose a multilinear Bernoulli mannequin , develop a rank-constrained likelihood-based estimation method , and obtain the theoretical accuracy guarantees. In contrast to continuous-valued problems , the binary tensor problem exhibits an interesting phase transition phenomenon harmonize to the signal-to-noise ratio. The error boundary for the parameter tensor estimation is established , and we show that the obtained rate is minimax optimal under the considered model. furthermore , we develop an alternating optimization algorithm with convergence guarantees. The efficaciousness of our approach is demonstrated through both simulations and analyses of multiple data sets on the tasks of tensor completion and clustering. ", "label": 1}
{"original_text": "This paper considers a network of stochastic evidence accumulators, each represented by a drift-diffusion model accruing evidence towards a decision in continuous time by observing a noisy signal and by exchanging information with other units according to a fixed communication graph. We bring into focus the relationship between the location of each unit in the communication graph and its certainty as measured by the inverse of the variance of its state. We show that node classification according to degree distributions or geodesic distances cannot faithfully capture node ranking in terms of certainty. Instead, all possible paths connecting each unit with the rest in the network must be incorporated. We make this precise by proving that node classification according to information centrality provides a rank ordering with respect to node certainty, thereby affording a direct interpretation of the certainty level of each unit in terms of the structural properties of the underlying communication graph.", "text_perturb": "This paper considers a network of stochastic grounds accumulators , each represented by a drift-diffusion model accruing grounds towards a decision in continuous time by observing a noisy signal and by exchanging information with other units according to a fixed communication graph. We bring into focus the relationship between the location of each unit in the communication graph and its sure thing as measured by the inverse of the variance of its state. We show that node classification according to degree distributions or geodesic distances can not reliably capture node ranking in terms of certainty. Instead , all possible paths connecting each unit with the rest in the network must comprise incorporated. We make this precise by proving that node classification according to information centrality provides a rank ordering with respect to node certainty , thereby affording a direct interpretation of the certainty level of each unit in term of the structural properties of the underlying communication graph. ", "label": 1}
{"original_text": "A shortcoming of existing reachability approaches for nonlinear systems is the poor scalability with the number of continuous state variables. To mitigate this problem we present a simulation-based approach where we first sample a number of trajectories of the system and next establish bounds on the convergence or divergence between the samples and neighboring trajectories. We compute these bounds using contraction theory and reduce the conservatism by partitioning the state vector into several components and analyzing contraction properties separately in each direction. Among other benefits this allows us to analyze the effect of constant but uncertain parameters by treating them as state variables and partitioning them into a separate direction. We next present a numerical procedure to search for weighted norms that yield a prescribed contraction rate, which can be incorporated in the reachability algorithm to adjust the weights to minimize the growth of the reachable set.", "text_perturb": "A shortcoming of live reachability approaches for nonlinear systems is the poor scalability with the number of continuous state variables. To mitigate this problem we present a simulation-based approach where we first sample a number of trajectories of the arrangement and next establish bounds on the convergence or divergence between the samples and neighboring trajectories. We compute these bounds using contraction theory and reduce the conservatism by partitioning the state vector into various components and analyzing contraction properties separately in each direction. Among other benefits this allows us to analyze the effect of constant but uncertain parameters by regale them as state variables and partitioning them into a separate direction. We next present a numerical procedure to search for weighted norms that yield a official contraction rate , which can be incorporated in the reachability algorithm to adjust the weights to minimize the growth of the reachable set. ", "label": 1}
{"original_text": "Robotic apple harvesting has received much research attention in the past few years due to growing shortage and rising cost in labor. One key enabling technology towards automated harvesting is accurate and robust apple detection, which poses great challenges as a result of the complex orchard environment that involves varying lighting conditions and foliagebranch occlusions. This letter reports on the development of a novel deep learning-based apple detection framework named DeepApple. Specifically, we first collect a comprehensive apple orchard dataset for 'Gala' and 'Blondee' apples, using a color camera, under different lighting conditions (sunny vs. overcast and front lighting vs. back lighting). We then develop a novel suppression Mask R-CNN for apple detection, in which a suppression branch is added to the standard Mask R-CNN to suppress non-apple features generated by the original network. Comprehensive evaluations are performed, which show that the developed suppression Mask R-CNN network outperforms state-of-the-art models with a higher F1-score of 0.905 and a detection time of 0.25 second per frame on a standard desktop computer.", "text_perturb": "automatic apple harvesting has received much research attention in the past few years due to growing shortage and rising cost in labor. One key enable technology towards automated harvesting is accurate and robust apple detection , which poses great challenges as a result of the complex orchard environment that involves varying lighting conditions and foliagebranch occlusions. This letter of the alphabet reports on the development of a novel deep learning-based apple detection framework named DeepApple. Specifically , we first collect a comprehensive apple orchard dataset for 'Gala ' and 'Blondee ' apples , using a colouring camera , under different lighting conditions ( sunny vs. overcast and front lighting quintuplet. back perch ). We then develop a novel suppression Mask R-CNN for apple spotting , in which a suppression branch is added to the standard Mask R-CNN to suppress non-apple features generated by the original network. comprehensive evaluations are performed , which show that the developed suppression Mask R-CNN network outperforms state-of-the-art models with a higher F1-score of 0. 905 and a spotting time of 0. 25 second per frame on a standard screen background computer. ", "label": 1}
{"original_text": "To date, most studies on spam have focused only on the spamming phase of the spam cycle and have ignored the harvesting phase, which consists of the mass acquisition of email addresses. It has been observed that spammers conceal their identity to a lesser degree in the harvesting phase, so it may be possible to gain new insights into spammers' behavior by studying the behavior of harvesters, which are individuals or bots that collect email addresses. In this paper, we reveal social networks of spammers by identifying communities of harvesters with high behavioral similarity using spectral clustering. The data analyzed was collected through Project Honey Pot, a distributed system for monitoring harvesting and spamming. Our main findings are (1) that most spammers either send only phishing emails or no phishing emails at all, (2) that most communities of spammers also send only phishing emails or no phishing emails at all, and (3) that several groups of spammers within communities exhibit coherent temporal behavior and have similar IP addresses. Our findings reveal some previously unknown behavior of spammers and suggest that there is indeed social structure between spammers to be discovered.", "text_perturb": "To date , most studies on spam have focused only on the spamming phase of the spam cycle and have ignored the harvesting phase , which consists of the mass acquisition of electronic mail addresses. It has been observed that spammers conceal their identity to a lesser degree in the harvesting phase , so it may be possible to gain new insights into spammers ' behavior by studying the behavior of harvesters , which comprise individuals or bots that collect email addresses. In this paper , we reveal social networks of spammers by identifying communities of harvesters with high pitched behavioral similarity using spectral clustering. The data analyzed was collected through Project Honey Pot , a distributed system for monitoring harvest home and spamming. Our main findings are ( 1 ) that most spammers either transmit only phishing emails or no phishing emails at all , ( 2 ) that most communities of spammers also transmit only phishing emails or no phishing emails at all , and ( 3 ) that several groups of spammers within communities exhibit coherent temporal behavior and have similar IP addresses. Our findings reveal some previously unknown behaviour of spammers and suggest that there is indeed social structure between spammers to be discovered. ", "label": 1}
{"original_text": "We briefly introduce two submissions to the Illumination Estimation Challenge, in the Int'l Workshop on Color Vision, affiliated to the 11th Int'l Symposium on Image and Signal Processing and Analysis. The fourier-transform-based submission is ranked 3rd, and the statistical Gray-pixel-based one ranked 6th.", "text_perturb": "We briefly introduce two submissions to the Illumination Estimation Challenge , in the Int ' l shop on Color Vision , affiliated to the 11th Int ' l Symposium on Image and Signal Processing and Analysis. The fourier-transform-based compliance is ranked 3rd , and the statistical Gray-pixel-based one ranked 6th. ", "label": 1}
{"original_text": "This paper introduces the variational Renyi bound (VR) that extends traditional variational inference to Renyi's a -divergences. This new family of variational methods unifies a number of existing approaches, and enables a smooth interpolation from the evidence lower-bound to the log (marginal) likelihood that is controlled by the value of a that parametrises the divergence. The reparameterization trick, Monte Carlo approximation and stochastic optimisation methods are deployed to obtain a tractable and unified framework for optimisation. We further consider negative a values and propose a novel variational inference method as a new special case in the proposed framework. Experiments on Bayesian neural networks and variational auto-encoders demonstrate the wide applicability of the VR bound.", "text_perturb": "This paper introduces the variational Renyi bound ( VR ) that poke out traditional variational inference to Renyi 's a -divergences. This new family of variational methods unifies a number of existing approaches , and enables a smooth interpolation from the evidence lower-bound to the logarithm ( marginal ) likelihood that is controlled by the value of a that parametrises the divergence. The reparameterization trick , three card monte Carlo approximation and stochastic optimisation methods are deployed to obtain a tractable and unified framework for optimisation. We further study negative a values and propose a novel variational inference method as a new special case in the proposed framework. Experiments on Bayesian neuronic networks and variational auto-encoders demonstrate the wide applicability of the VR bound. ", "label": 1}
{"original_text": "Different neural networks trained on the same dataset often learn similar input-output mappings with very different weights. Is there some correspondence between these neural network solutions? For linear networks, it has been shown that different instances of the same network architecture encode the same representational similarity matrix, and their neural activity patterns are connected by orthogonal transformations. However, it is unclear if this holds for non-linear networks. Using a shared response model, we show that different neural networks encode the same input examples as different orthogonal transformations of an underlying shared representation. We test this claim using both standard convolutional neural networks and residual networks on CIFAR10 and CIFAR100.", "text_perturb": "Different neural networks prepare on the same dataset often learn similar input-output mappings with very different weights. Is there some agreement between these neural network solutions ? For linear networks , it has been shown that different instances of the same network architecture encode the same representational similarity matrix , and their neural activity patterns are connected by orthogonal transformations. However , it is unclear if this holds for non-linear web. Using a shared response model , we show that unlike neural networks encode the same input examples as unlike orthogonal transformations of an underlying shared representation. We test this claim using both standard convolutional neural meshwork and residual meshwork on CIFAR10 and CIFAR100. ", "label": 1}
{"original_text": "Speech processing systems rely on robust feature extraction to handle phonetic and semantic variations found in natural language. While techniques exist for desensitizing features to common noise patterns produced by Speech-to-Text (STT) and Text-to-Speech (TTS) systems, the question remains how to best leverage state-of-the-art language models (which capture rich semantic features, but are trained on only written text) on inputs with ASR errors. In this paper, we present Telephonetic, a data augmentation framework that helps robustify language model features to ASR corrupted inputs. To capture phonetic alterations, we employ a character-level language model trained using probabilistic masking. Phonetic augmentations are generated in two stages: a TTS encoder (Tacotron 2, WaveGlow) and a STT decoder (DeepSpeech). Similarly, semantic perturbations are produced by sampling from nearby words in an embedding space, which is computed using the BERT language model. Words are selected for augmentation according to a hierarchical grammar sampling strategy. Telephonetic is evaluated on the Penn Treebank (PTB) corpus, and demonstrates its effectiveness as a bootstrapping technique for transferring neural language models to the speech domain. Notably, our language model achieves a test perplexity of 37.49 on PTB, which to our knowledge is state-of-the-art among models trained only on PTB.", "text_perturb": "Speech processing systems rely on robust feature extraction to handle phonic and semantic variations found in natural language. While techniques exist for desensitizing feature film to common noise patterns produced by Speech-to-Text ( STT ) and Text-to-Speech ( TTS ) systems , the question remains how to best leverage state-of-the-art language models ( which capture rich semantic feature film , but are trained on only written text ) on inputs with ASR errors. In this paper , we present Telephonetic , a data augmentation framework that helps robustify language model lineament to ASR corrupted inputs. To capture phonetic alterations , we employ a character-level language modelling trained using probabilistic masking. Phonetic augmentations are generated in two leg : a TTS encoder ( Tacotron 2 , WaveGlow ) and a STT decoder ( DeepSpeech ). Similarly , semantic perturbations are get by sampling from nearby words in an embedding space , which is computed using the BERT language model. Words are selected for augmentation according to a hierarchical grammar sampling scheme. Telephonetic is evaluated on the Penn Treebank ( PTB ) corpus , and demonstrates its effectuality as a bootstrapping technique for transferring neural language models to the speech domain. Notably , our language poser achieves a test perplexity of 37. 49 on PTB , which to our knowledge be state-of-the-art among models trained only on PTB. ", "label": 1}
{"original_text": "Building on , we propose two new probing tasks analyzing factual knowledge stored in Pretrained Language Models (PLMs). (1) Negation. We find that PLMs do not distinguish between negated Birds cannot [MASK and non-negated Birds can [MASK cloze questions. (2) Mispriming. Inspired by priming methods in human psychology, we add \"misprimes\" to cloze questions Talk? Birds can [MASK. We find that PLMs are easily distracted by misprimes. These results suggest that PLMs still have a long way to go to adequately learn human-like factual knowledge.", "text_perturb": "building on , we propose two new probing tasks analyzing factual knowledge stored in Pretrained Language Models ( PLMs ). ( 1 ) negation. We find that PLMs do not distinguish between negated Birds can not [ masquerade party and non-negated Birds can [ masquerade party cloze questions. ( 2 ) Mispriming. Inspired by priming methods in human psychology , we add `` misprimes '' to cloze questions Talk ? shuttlecock can [ MASK. We find that PLMs are well distracted by misprimes. These results suggest that PLMs still have a long way to go to adequately learn human-like factual noesis. ", "label": 1}
{"original_text": "We propose a new artificial-noise aided hybrid time-switchingpower-splitting scheme for orthogonal frequency-division multiplexing (OFDM) systems to securely transmit data and transfer energy to a legitimate receiving node. In our proposed scheme, the cyclic prefix has two more benefits in addition to the cancellation of the inter-symbol interference between the OFDM blocks. Firstly, it enables the legitimate transmitter to send artificial-noise (AN) vectors in a way such that the interference can be canceled at the legitimate receiver prior to information decoding. Secondly, its power is used to energize the legitimate receiver. We optimize the cyclic prefix length, the time-switching and power-splitting parameters, and the power allocation ratio between the data and AN signals at the legitimate transmitter to maximize the average secrecy rate subject to a constraint on the average energy transfer rate at the legitimate receiver. Our numerical results demonstrate that our proposed scheme can achieve up to 23 average secrecy rate gain relative to a pure power-splitting scheme.", "text_perturb": "We propose a raw artificial-noise aided hybrid time-switchingpower-splitting scheme for orthogonal frequency-division multiplexing ( OFDM ) systems to securely transmit data and transfer energy to a legitimate receiving node. In our purpose scheme , the cyclic prefix has two more benefits in addition to the cancellation of the inter-symbol interference between the OFDM blocks. Firstly , it enables the licit transmitter to send artificial-noise ( AN ) vectors in a way such that the interference can be canceled at the licit receiver prior to information decoding. second , its power is used to energize the legitimate receiver. We optimize the cyclic prefix length , the time-switching and power-splitting parameters , and the power allocation ratio between the data and AN signals at the legitimate transmitter to maximize the average secrecy rate subject to a constraint on the average energy transfer rate at the legitimate liquidator. Our numeral results demonstrate that our proposed scheme can achieve up to 23 average secrecy rate gain relative to a pure power-splitting scheme. ", "label": 1}
{"original_text": "In Reasoning about Action and Planning, one synthesizes the agent plan by taking advantage of the assumption on how the environment works (that is, one exploits the environment's effects, its fairness, its trajectory constraints). In this paper we study this form of synthesis in detail. We consider assumptions as constraints on the possible strategies that the environment can have in order to respond to the agent's actions. Such constraints may be given in the form of a planning domain (or action theory), as linear-time formulas over infinite or finite runs, or as a combination of the two. We argue though that not all assumption specifications are meaningful: they need to be consistent, which means that there must exist an environment strategy fulfilling the assumption in spite of the agent actions. For such assumptions, we study how to do synthesisplanning for agent goals, ranging from a classical reachability to goal on traces specified in LTL and LTLfLDLf, characterizing the problem both mathematically and algorithmically.", "text_perturb": "In Reasoning about Action and Planning , one synthesizes the agent architectural plan by taking advantage of the assumption on how the environment works ( that is , one exploits the environment 's effects , its fairness , its trajectory constraints ). In this paper we study this strain of synthesis in detail. We consider assumptions as constraints on the possible strategies that the environment can have in orderliness to respond to the agent 's actions. Such constraints may be given in the form of a planning domain ( or natural process theory ) , as linear-time formulas over infinite or finite runs , or as a combination of the two. We argue though that not all supposal specifications are meaningful : they need to be consistent , which means that there must exist an environment strategy fulfilling the supposal in spite of the agent actions. For such assumptions , we study how to do synthesisplanning for agent goals , ranging from a classical reachability to finish on traces specified in LTL and LTLfLDLf , characterizing the problem both mathematically and algorithmically. ", "label": 1}
{"original_text": "In this paper, an approach of estimating signal parameters via rotational invariance technique (ESPRIT) is proposed for two-dimensional (2-D) localization of incoherently distributed (ID) sources in large-scalemassive multiple-input multiple-output (MIMO) systems. The traditional ESPRIT-based methods are valid only for one-dimensional (1-D) localization of the ID sources. By contrast, in the proposed approach the signal subspace is constructed for estimating the nominal azimuth and elevation direction-of-arrivals and the angular spreads. The proposed estimator enjoys closed-form expressions and hence it bypasses the searching over the entire feasible field. Therefore, it imposes significantly lower computational complexity than the conventional 2-D estimation approaches. Our analysis shows that the estimation performance of the proposed approach improves when the large-scalemassive MIMO systems are employed. The approximate Cramer-Rao bound of the proposed estimator for the 2-D localization is also derived. Numerical results demonstrate that albeit the proposed estimation method is comparable with the traditional 2-D estimators in terms of performance, it benefits from a remarkably lower computational complexity.", "text_perturb": "In this paper , an approach of estimating signal parameters via rotational invariance technique ( esprit ) is proposed for two-dimensional ( 2-D ) localization of incoherently distributed ( ID ) sources in large-scalemassive multiple-input multiple-output ( MIMO ) systems. The traditional ESPRIT-based methods are valid only for unidimensional ( 1-D ) localization of the ID sources. By contrast , in the proposed approach the signal subspace is constructed for estimating the nominal azimuth and peak direction-of-arrivals and the angular spreads. The proposed estimator savor closed-form expressions and hence it bypasses the searching over the entire feasible field. Therefore , it imposes significantly lower computational complexity than the formal 2-D estimation approaches. Our depth psychology shows that the estimation performance of the proposed approach improves when the large-scalemassive MIMO systems are employed. The approximate Cramer-Rao bound of the proposed estimator for the 2-D localization is also educe. Numerical results demonstrate that albeit the proposed estimation method is comparable with the traditional 2-D estimators in terms of performance , it benefits from a unco lower computational complexity. ", "label": 1}
{"original_text": "Polarimetric synthetic aperture radar (PolSAR) image segmentation is currently of great importance in image processing for remote sensing applications. However, it is a challenging task due to two main reasons. Firstly, the label information is difficult to acquire due to high annotation costs. Secondly, the speckle effect embedded in the PolSAR imaging process remarkably degrades the segmentation performance. To address these two issues, we present a contextual PolSAR image semantic segmentation method in this paper. With a newly defined channel-wise consistent feature set as input, the three-dimensional discrete wavelet transform (3D-DWT) technique is employed to extract discriminative multi-scale features that are robust to speckle noise. Then Markov random field (MRF) is further applied to enforce label smoothness spatially during segmentation. By simultaneously utilizing 3D-DWT features and MRF priors for the first time, contextual information is fully integrated during the segmentation to ensure accurate and smooth segmentation. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on three real benchmark PolSAR image data sets. Experimental results indicate that the proposed method achieves promising segmentation accuracy and preferable spatial consistency using a minimal number of labeled pixels.", "text_perturb": "Polarimetric synthetic aperture radar ( PolSAR ) image segmentation follow currently of great importance in image processing for remote sensing applications. However , it is a thought provoking task due to two main reasons. Firstly , the label information is difficult to acquire due to high annotation price. Secondly , the speckle effect embedded in the PolSAR imaging process remarkably degrades the cleavage performance. To address these two issues , we present a contextual PolSAR image semantic segmentation method in this newspaper. With a newly defined channel-wise consistent feature set as input , the three-dimensional discrete wavelet transform ( 3D-DWT ) technique is employed to pull out discriminative multi-scale features that are robust to speckle noise. Then Markov random field ( MRF ) is further applied to apply label smoothness spatially during segmentation. By simultaneously utilizing 3D-DWT features and MRF priors for the first time , contextual entropy is fully integrated during the segmentation to ensure accurate and smooth segmentation. To demonstrate the effectiveness of the proposed method , we conduct extensive experiments on three actual benchmark PolSAR image data sets. Experimental results indicate that the proposed method achieves promising segmentation accuracy and preferable spatial consistency using a minimal phone number of labeled pixels. ", "label": 1}
{"original_text": "We study the following variant of the classic bin packing problem. The input is a set of items I {1, ..., N } with corresponding sizes s 1, ..., s N (0, 1 ], partitioned into n groups G 1, ..., G n. The goal is to pack the items in a minimum number of unit size bins, such that no two items of the same group are packed in the same bin. This group bin packing (GBP) problem, also known as bin packing with clique-graph conflicts, has natural applications in storing file replicas, security in cloud computing and signal distribution. In this paper, we present an asymptotic polynomial time approximation scheme (APTAS) for group bin packing, thus improving the best known ratio of 2. In particular, for any instance I and a fixed e (0, 1), our scheme packs the items in at most (1 e) O P T (I) 1 bins, where O P T (I) is the minimum number of bins required for packing the instance.", "text_perturb": "We study the following variant of the definitive bin packing problem. The input follow a set of items I { 1 ,. . . , N } with corresponding sizes s 1 ,. . . , s N ( 0 , 1 ] , partitioned into n group G 1 ,. . . , G newton. The goal is to load down the items in a minimum number of unit size bins , such that no two items of the same group are packed in the same bin. This group bin packing ( GBP ) problem , also known as bin packing with clique-graph conflicts , has born applications in storing file replicas , security in cloud computing and signal distribution. In this paper , we present an asymptotic polynomial time approximation scheme ( APTAS ) for chemical group bin packing , thus improving the best known ratio of 2. In particular , for any instance I and a fixed atomic number  ( 0 , 1 ) , our scheme packs the items in at most ( 1 atomic number  ) O P T ( I ) 1 bins , where O P T ( I ) is the minimum number of bins required for packing the instance. ", "label": 1}
{"original_text": "In this paper, we present a novel approach to machine reading comprehension for the MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a question with exact text spans in a passage, the MS-MARCO dataset defines the task as answering a question from multiple passages and the words in the answer are not necessary in the passages. We therefore develop an extraction-then-synthesis framework to synthesize answers from extraction results. Specifically, the answer extraction model is first employed to predict the most important sub-spans from the passage as evidence, and the answer synthesis model takes the evidence as additional features along with the question and passage to further elaborate the final answers. We build the answer extraction model with state-of-the-art neural networks for single passage reading comprehension, and propose an additional task of passage ranking to help answer extraction in multiple passages. The answer synthesis model is based on the sequence-to-sequence neural networks with extracted evidences as features. Experiments show that our extraction-then-synthesis method outperforms state-of-the-art methods.", "text_perturb": "In this paper , we present a novel approaching to machine reading comprehension for the MS-MARCO dataset. Unlike the SQuAD dataset that train to answer a question with exact text spans in a passage , the MS-MARCO dataset defines the task as answering a question from multiple passages and the words in the answer are not necessary in the passages. We therefore develop an extraction-then-synthesis framework to synthesise answers from extraction results. Specifically , the answer extraction model is first employed to predict the most important sub-spans from the passage as evidence , and the answer synthesis model takes the evidence as additional features along with the doubt and passage to further elaborate the final answers. We build the answer extraction model with state-of-the-art neural networks for single passage reading inclusion , and propose an additional task of passage ranking to help answer extraction in multiple passages. The resolution synthesis model is based on the sequence-to-sequence neural networks with extracted evidences as features. Experiments show that our extraction-then-synthesis method surpass state-of-the-art methods. ", "label": 1}
{"original_text": "Model-based reinforcement learning (RL) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL. However, the theoretical understanding of such methods has been rather limited. This paper introduces a novel algorithmic framework for designing and analyzing model-based RL algorithms with theoretical guarantees. We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the expected reward. The meta-algorithm iteratively builds a lower bound of the expected reward based on the estimated dynamical model and sample trajectories, and then maximizes the lower bound jointly over the policy and the model. The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires no explicit uncertainty quantification. Instantiating our framework with simplification gives a variant of model-based RL algorithms Stochastic Lower Bounds Optimization (SLBO). Experiments demonstrate that SLBO achieves state-of-the-art performance when only one million or fewer samples are permitted on a range of continuous control benchmark tasks. 1 footnote 1 1 footnote 1 The source code of this work is available at", "text_perturb": "Model-based strengthener learning ( RL ) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL. However , the theoretical understanding of such methods has been rather circumscribed. This paper introduces a novel algorithmic framework for project and analyzing model-based RL algorithms with theoretical guarantees. We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the look reward. The meta-algorithm iteratively builds a lower bound of the expected reinforcement based on the estimated dynamical model and sample trajectories , and then maximizes the lower bound jointly over the policy and the model. The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires no expressed uncertainty quantification. Instantiating our framework with simplification gives a variant of model-based RL algorithms Stochastic Lower boundary Optimization ( SLBO ). Experiments demonstrate that SLBO achieves state of the art performance when only one million or fewer samples are permitted on a range of continuous control benchmark tasks. 1 footnote 1 1 footnote 1 The source codification of this work is available at", "label": 1}
{"original_text": "Autonomous intelligent agent research is a domain situated at the forefront of artificial intelligence. Interest-based negotiation (IBN) is a form of negotiation in which agents exchange information about their underlying goals, with a view to improve the likelihood and quality of a offer. In this paper we model and verify a multi-agent argumentation scenario of resource sharing mechanism to enable resource sharing in a distributed system. We use IBN in our model wherein agents express their interests to the others in the society to gain certain resources.", "text_perturb": "Autonomous intelligent federal agent research is a domain situated at the forefront of artificial intelligence. Interest-based negotiation ( IBN ) is a form of negotiation in which agents exchange information about their underlying goals , with a vista to improve the likelihood and quality of a offer. In this paper we model and verify a multi-agent argumentation scenario of resource apportion mechanism to enable resource apportion in a distributed system. We use IBN in our model wherein agents evince their interests to the others in the society to gain certain resources. ", "label": 1}
{"original_text": "Machine learning models are known to perpetuate the biases present in the data, but oftentimes these biases aren't known until after the models are deployed. We present the Visual Bias Extraction (ViBE) Tool that assists in the investigation of a visual dataset, surfacing potential dataset biases along three dimensions: (1) object-based, (2) gender-based, and (3) geography-based. Object-based biases relate to things like size, context, or diversity of object representation in the dataset; gender-based metrics aim to reveal the stereotypical portrayal of people of different genders within the dataset, with future iterations of our tool extending the analysis to additional axes of identity; geography-based analysis considers the representation of different geographic locations. Our tool is designed to shed light on the dataset along these three axes, allowing both dataset creators and users to gain a better understanding of what exactly is portrayed in their dataset. The responsibility then lies with the tool user to determine which of the revealed biases may be problematic, taking into account the cultural and historical context, as this is difficult to determine automatically. Nevertheless, the tool also provides actionable insights that may be helpful for mitigating the revealed concerns. Overall, our work allows for the machine learning bias problem to be addressed early in the pipeline at the dataset stage. ViBE is available at", "text_perturb": "machine learning models are known to perpetuate the biases present in the data , but oftentimes these biases are n't known until after the models are deployed. We present the Visual Bias Extraction ( ViBE ) joyride that assists in the investigation of a visual dataset , surfacing potential dataset biases along three dimensions : ( 1 ) object-based , ( 2 ) gender-based , and ( 3 ) geography-based. Object-based diagonal relate to things like size , context , or diversity of object representation in the dataset ; gender-based metrics aim to reveal the stereotypical portrayal of people of different genders within the dataset , with future iterations of our tool extending the analysis to additional axes of identity ; geography-based analysis considers the representation of different geographic locations. Our tool is designed to shed light on the dataset along these three axes , allowing both dataset creators and users to gain a better understanding of what exactly is depict in their dataset. The responsibility then lies with the tool exploiter to determine which of the revealed biases may be problematic , taking into account the cultural and historical context , as this is difficult to determine automatically. Nevertheless , the tool also provides actionable insights that may be helpful for mitigating the revealed fear. Overall , our work allows for the machine learning bias job to be addressed early in the pipeline at the dataset stage. ViBE follow available at", "label": 1}
{"original_text": "Behavior planning is known to be one of the basic cognitive functions, which is essential for any cognitive architecture of any control system used in robotics. At the same time most of the widespread planning algorithms employed in those systems are developed using only approaches and models of Artificial Intelligence and don't take into account numerous results of cognitive experiments. As a result, there is a strong need for novel methods of behavior planning suitable for modern cognitive architectures aimed at robot control. One such method is presented in this work and is studied within a special class of navigation task called smart relocation task. The method is based on the hierarchical two-level model of abstraction and knowledge representation, e.g. symbolic and subsymbolic. On the symbolic level sign world model is used for knowledge representation and hierarchical planning algorithm, MAP, is utilized for planning. On the subsymbolic level the task of path planning is considered and solved as a graph search problem. Interaction between both planners is examined and inter-level interfaces and feedback loops are described. Preliminary experimental results are presented.", "text_perturb": "Behavior planning is known to be one of the basic cognitive functions , which is essential for any cognitive architecture of any ascendance system used in robotics. At the same time most of the widespread planning algorithms employed in those systems are spring up using only approaches and models of Artificial Intelligence and do n't take into account numerous results of cognitive experiments. As a result , there is a strong need for novel methods of behavior planning suitable for modern cognitive computer architecture aimed at robot control. One such method is presented in this work and is studied within a special class of navigation task called smart move task. The method is based on the hierarchical two-level model of generalisation and knowledge representation , e. g force. emblematical and subsymbolic. On the symbolic level sign earth model is used for knowledge representation and hierarchical planning algorithm , MAP , is utilized for planning. On the subsymbolic level the task of path planning constitute considered and solved as a graph search problem. Interaction between both planners is examined and inter-level user interface and feedback loops are described. Preliminary data based results are presented. ", "label": 1}
{"original_text": "Ranking data arises in a wide variety of application areas but remains difficult to model, learn from, and predict. Datasets often exhibit multimodality, intransitivity, or incomplete rankings - particularly when generated by humans - yet popular probabilistic models are often too rigid to capture such complexities. In this work we leverage recent progress on similar challenges in discrete choice modeling to form flexible and tractable choice-based models for ranking data. We study choice representations , maps from rankings (complete or top- k) to collections of choices, as a way of forming ranking models from choice models. We focus on the repeated selection ( R S) choice representation, first used to form the Plackett-Luce ranking model from the conditional multinomial logit choice model. We fully characterize, for a prime number of alternatives, the choice representations that admit ranking distributions with unit normalization, a desirably property that greatly simplifies maximum likelihood estimation. We further show that only specific minor variations on repeated selection exhibit this property. Our choice-based ranking models provide higher out-of-sample likelihood when compared to Plackett-Luce and Mallows models on a broad collection of ranking tasks including food preferences, ranked-choice elections, car racing, and search engine relevance tasks.", "text_perturb": "Ranking data arises in a wide variety of application areas but remains difficult to simulate , learn from , and predict. Datasets often exhibit multimodality , intransitivity , or uncompleted rankings - particularly when generated by humans - yet popular probabilistic models are often too rigid to capture such complexities. In this work we leverage recent progress on similar challenges in discrete selection modeling to form flexible and tractable choice-based models for ranking data. We study choice representations , maps from rankings ( complete or top- k ) to collections of choices , as a mode of forming ranking models from choice models. We focus on the repeated selection ( R S ) choice representation , first used to form the Plackett-Luce ranking fashion model from the conditional multinomial logit choice fashion model. We fully characterize , for a prime number of alternatives , the choice histrionics that admit ranking distributions with unit normalization , a desirably property that greatly simplifies maximum likelihood estimation. We further show that only specific minor variations on repeated extract exhibit this property. Our choice-based ranking models provide high out-of-sample likelihood when compared to Plackett-Luce and Mallows models on a broad collection of ranking tasks including food preferences , ranked-choice elections , car racing , and search engine relevance tasks. ", "label": 1}
{"original_text": "In this position paper we present a novel approach to neurobiologically plausible implementation of emotional reactions and behaviors for real-time autonomous robotic systems. The working metaphor we use is the \"day\" and \"night\" phases of mammalian life. During the \"day\" phase a robotic system stores the inbound information and is controlled by the light-weight rule-based system in real time. In contrast to that, during the \"night\" phase the stored information is been transferred to the supercomputing system to update the realistic neural network: emotional and behavioral strategies.", "text_perturb": "In this position paper we pose a novel approach to neurobiologically plausible implementation of emotional reactions and behaviors for real-time autonomous robotic systems. The working metaphor we employ is the `` day '' and `` night '' phases of mammalian life. During the `` day '' phase a robotic system stores the inbound entropy and is controlled by the light-weight rule-based system in real time. In contrast to that , during the `` night '' phase the stored information is been transferred to the supercomputing system to update the realistic neural electronic network : emotional and behavioral strategies. ", "label": 1}
{"original_text": "Word embeddings are now a standard technique for inducing meaning representations for words. For getting good representations, it is important to take into account different senses of a word. In this paper, we propose a mixture model for learning multi-sense word embeddings. Our model generalizes the previous works in that it allows to induce different weights of different senses of a word. The experimental results show that our model outperforms previous models on standard evaluation tasks.", "text_perturb": "Word embeddings are now a standard proficiency for inducing meaning representations for words. For getting good representations , it is important to take into account different common sense of a word. In this paper , we nominate a mixture model for learning multi-sense word embeddings. Our model generalise the previous works in that it allows to induce different weights of different senses of a word. The experimental results register that our model outperforms previous models on standard evaluation tasks. ", "label": 1}
{"original_text": "This paper provides a comparative analysis of impedance models for power electronic converters and systems for the purpose of stability investigations. Such models can be divided into either decoupled models or matrix models. A decoupled impedance model is highly appealing since the Single-Input-Single-Output (SISO) structure makes the analysis and result interpretation very simple. On the other hand, matrix impedance models are more accurate, and in some cases necessary. Previous works have applied various approximations to obtain decoupled models, and both the dq - and sequence domains have been used. This paper introduces the terms decoupled and semi-decoupled impedance models in order to have a clear classification of the available approximations. The accuracy of 4 decoupled impedance models are discussed based on the concept of Mirror Frequency Coupling (MFC). By definition the decoupled models based on sequence domain impedances will be exact for systems without MFC. In the general case, they are expected to be more accurate than the decoupled dq -impedance models. The paper defines a norm to measure the degree of coupling in the impedance matrices. This norm equals the error in the eigenvalue loci between the matrix and semi-decoupled models. This can also be viewed as the error in the semi-decoupled Nyquist plot. An example case study consisting of a grid-connected VSC with current controller and PLL is used to compare the different methods. It is found that decoupled and semi-decoupled models in the dq -domain are only applicable in grids with very low XR-ratio. Furthermore, it is concluded that the decoupled model in the sequence domain gives close to equal results as the semi-decoupled model.", "text_perturb": "This paper provides a comparative analysis of impedance models for power electronic converters and organization for the purpose of stability investigations. Such mannikin can be divided into either decoupled mannikin or matrix mannikin. A decoupled impedance model is highly appealing since the Single-Input-Single-Output ( SISO ) structure piddle the analysis and result interpretation very simple. On the other hand , intercellular substance impedance models are more accurate , and in some cases necessary. Previous works suffer applied various approximations to obtain decoupled models , and both the dq - and sequence domains suffer been used. This paper introduces the terms decoupled and semi-decoupled impedance models in rescript to have a clear classification of the available approximations. The accuracy of 4 decoupled impedance models are discussed based on the concept of Mirror absolute frequency Coupling ( MFC ). By definition the decoupled models based on sequence domain impedances will be exact for system of rules without MFC. In the general case , they are await to be more accurate than the decoupled dq -impedance models. The paper define a norm to measure the degree of coupling in the impedance matrices. This norm equals the mistake in the eigenvalue loci between the matrix and semi-decoupled models. This can also be see as the error in the semi-decoupled Nyquist plot. An example case study consisting of a grid-connected VSC with current controller and PLL follow used to compare the different methods. It is found that decoupled and semi-decoupled models in the dq -domain are entirely applicable in grids with very low XR-ratio. Furthermore , it personify concluded that the decoupled model in the sequence domain gives close to equal results as the semi-decoupled model. ", "label": 1}
{"original_text": "Context: In C, low-level errors, such as buffer overflow and use-after-free, are a major problem, as they cause security vulnerabilities and hard-to-find bugs. C lacks automatic checks, and programmers cannot apply defensive programming techniques because objects (e.g., arrays or structs) lack run-time information about bounds, lifetime, and types. Inquiry: Current approaches to tackling low-level errors include dynamic tools, such as bounds or type checkers, that check for certain actions during program execution. If they detect an error, they typically abort execution. Although they track run-time information as part of their runtimes, they do not expose this information to programmers. Approach: We devised an introspection interface that allows C programmers to access run-time information and to query object bounds, object lifetimes, object types, and information about variadic arguments. This enables library writers to check for invalid input or program states and thus, for example, to implement custom error handling that maintains system availability and does not terminate on benign errors. As we assume that introspection is used together with a dynamic tool that implements automatic checks, errors that are not handled in the application logic continue to cause the dynamic tool to abort execution. Knowledge: Using the introspection interface, we implemented a more robust, source-compatible version of the C standard library that validates parameters to its functions. The library functions react to otherwise undefined behavior; for example, they can detect lurking flaws, handle unterminated strings, check format string arguments, and set errno when they detect benign usage errors. Grounding: Existing dynamic tools maintain run-time information that can be used to implement the introspection interface, and we demonstrate its implementation in Safe Sulong, an interpreter and dynamic bug-finding tool for C that runs on a Java Virtual Machine and can thus easily expose relevant run-time information. Importance: Using introspection in user code is a novel approach to tackling the long-standing problem of low-level errors in C. As new approaches are lowering the performance overhead of run-time information maintenance, the usage of dynamic runtimes for C could become more common, which could ultimately facilitate a more widespread implementation of such an introspection interface.", "text_perturb": "Context : In C , low-level errors , such as buffer zone overflow and use-after-free , are a major problem , as they cause security vulnerabilities and hard-to-find bugs. C lacks automatic checks , and programmers fire not apply defensive programming techniques because objects ( e. constant of gravitation. , arrays or structs ) lack run-time information about bounds , lifespan , and types. Inquiry : Current approaches to tackling low-level errors include dynamic tools , such as bounds or type checkers , that check for certain actions during syllabus execution. If they find an error , they typically abort execution. Although they track run-time information as part of their runtimes , they do not queer this information to programmers. Approach : We devised an introspection interface that allows C programmers to access run-time information and to query object bounds , object life , object types , and information about variadic arguments. This enables library writers to check for invalid input or program country and thus , for example , to implement custom error handling that maintains system availability and does not terminate on benign errors. As we assume that introspection is used together with a dynamic tool that implements automatic checks , errors that are non handled in the application logic continue to cause the dynamic tool to abort execution. Knowledge : Using the introspection interface , we implemented a more robust , source-compatible version of the light speed standard library that validates parameters to its functions. The library single valued function react to otherwise undefined behavior ; for example , they can detect lurking flaws , handle unterminated strings , check format string arguments , and set errno when they detect benign usage errors. Grounding : Existing dynamic tools maintain run-time information that can be used to go through the introspection interface , and we demonstrate its implementation in Safe Sulong , an interpreter and dynamic bug-finding tool for C that runs on a Java Virtual Machine and can thus easily expose relevant run-time information. Importance : Using introspection in user code equal a novel approach to tackling the long-standing problem of low-level errors in C. As new approaches are lowering the performance overhead of run-time selective information maintenance , the usage of dynamic runtimes for C could become more common , which could ultimately facilitate a more widespread implementation of such an introspection interface. ", "label": 1}
{"original_text": "The ability to determine what parts of objects and surfaces people touch as they go about their daily lives would be useful in understanding how the COVID-19 virus spreads. To determine whether a person has touched an object or surface using visual data, images, or videos, is a hard problem. Computer vision 3D reconstruction approaches project objects and the human body from the 2D image domain to 3D and perform 3D space intersection directly. However, this solution would not meet the accuracy requirement in applications due to projection error. Another standard approach is to train a neural network to infer touch actions from the collected visual data. This strategy would require significant amounts of training data to generalize over scale and viewpoint variations. A different approach to this problem is to identify whether a person has touched a defined object. In this work, we show that the solution to this problem can be straightforward. Specifically, we show that the contact between an object and a static surface can be identified by projecting the object onto the static surface through two different viewpoints and analyzing their 2D intersection. The object contacts the surface when the projected points are close to each other; we call this cross view projection consistency. Instead of doing 3D scene reconstruction or transfer learning from deep networks, a mapping from the surface in the two camera views to the surface space is the only requirement. For planar space, this mapping is the Homography transformation. This simple method can be easily adapted to real-life applications. In this paper, we apply our method to do office occupancy detection for studying the COVID-19 transmission pattern from an office desk in a meeting room using the contact information.", "text_perturb": "The ability to determine what parts of objects and surfaces people touch as they go about their daily liveliness would be useful in understanding how the COVID-19 virus spreads. To determine whether a person let touched an object or surface using visual data , images , or videos , is a hard problem. information processing system vision 3D reconstruction approaches project objects and the human body from the 2D image domain to 3D and perform 3D space intersection directly. nevertheless , this solution would not meet the accuracy requirement in applications due to projection error. Another standard approach constitute to train a neural network to infer touch actions from the collected visual data. This strategy would require significant amounts of preparation data to generalize over scale and viewpoint variations. A different approach to this problem is to identify whether a individual has touched a defined object. In this work , we show that the root to this problem can be straightforward. Specifically , we show that the contact between an object and a electrostatic surface can be identified by projecting the object onto the electrostatic surface through two different viewpoints and analyzing their 2D intersection. The object contacts the surface when the stick out points are close to each other ; we call this cross view projection consistency. Instead of doing 3D scene reconstruction or transfer learning from deep networks , a mapping from the surface in the two camera views to the surface space is the only requisite. For planar space , this mathematical function is the Homography transformation. This simple method can be easily conform to real-life applications. In this paper , we utilise our method to do office occupancy detection for studying the COVID-19 transmission pattern from an office desk in a meeting room using the contact information. ", "label": 1}
{"original_text": "There is a significant amount of online human activity which is either clandestine or illicit in nature, and hence where individuals operate under fear of exposure or capture. Yet there is little theoretical understanding of what models best describe the resulting dynamics. Here we address this gap, by analyzing the evolutionary dynamics of the supporters behind the 95 pro-ISIS online communities (i.e. self-organized social media groups) that appeared recently on a global social media site. We show that although they do not follow a conventional (i.e. size-based) preferential attachment (PA) model, their dynamical evolution can be explained by a new variant that we introduce here, which we refer to as active attraction model (AA). This AA model takes into account the locality and group heterogeneity which undoubtedly feature in humans' online behavior under pressure, but which are not contained in conventional PA models. The AA model captures both group-specific and macroscopic observations over all size ranges - as opposed to just the tail for large groups or groups' initial growth - suggesting that heterogeneity and locality play a crucial role in the dynamics of online extremist support. We derive approximate expressions for the group size distributions in two simple systems that involve simultaneously the mechanisms of group joining (governed by either PA or AA), group leaving, and account banning, and show how these processes influence the group size distributions. We believe this work will serve in helping understand a broad spectrum of online human activities which are either clandestine or illicit in nature, and hence where individuals operate under fear of exposure or capture.", "text_perturb": "There is a significant amount of online human activity which is either clandestine or illicit in nature , and hence where soul operate under fear of exposure or capture. nevertheless there is little theoretical understanding of what models best describe the resulting dynamics. Here we address this gap , by analyzing the evolutionary kinetics of the supporters behind the 95 pro-ISIS online communities ( i. tocopherol. self-organized social medium groups ) that appeared recently on a global social medium site. We show that although they do non follow a conventional ( i. eastward. size-based ) preferential attachment ( PA ) model , their dynamical evolution can be explained by a new variant that we introduce here , which we refer to as participating attraction model ( AA ). This AA model ask into account the locality and group heterogeneity which undoubtedly feature in humans ' online behavior under pressure , but which are not contained in conventional PA models. The AA model captures both group-specific and macroscopic observations over all size ranges - as oppose to just the tail for large groups or groups ' initial growth - suggesting that heterogeneity and locality play a crucial role in the dynamics of online extremist support. We derive approximate expressions for the chemical group size distributions in two simple systems that involve simultaneously the mechanisms of chemical group joining ( governed by either PA or AA ) , chemical group leaving , and account banning , and show how these processes influence the chemical group size distributions. We believe this work will serve in helping understand a broad spectrum of online human activities which are either clandestine or illicit in nature , and hence where individuals operate under fear of vulnerability or capture. ", "label": 1}
{"original_text": "We present UDify, a multilingual multi-task model capable of accurately predicting universal part-of-speech, morphological features, lemmas, and dependency trees simultaneously for all 124 Universal Dependencies treebanks across 75 languages. By leveraging a multilingual BERT self-attention model pretrained on 104 languages, we found that fine-tuning it on all datasets concatenated together with simple softmax classifiers for each UD task can meet or exceed state-of-the-art UPOS, UFeats, Lemmas, (and especially) UAS, and LAS scores, without requiring any recurrent or language-specific components. We evaluate UDify for multilingual learning, showing that low-resource languages benefit the most from cross-linguistic annotations. We also evaluate for zero-shot learning, with results suggesting that multilingual training provides strong UD predictions even for languages that neither UDify nor BERT have ever been trained on. Code for UDify is available at", "text_perturb": "We present UDify , a multilingual multi-task model capable of accurately predicting universal part-of-speech , morphological features , lemmas , and dependency trees simultaneously for all 124 Universal Dependencies treebanks across 75 linguistic communication. By leveraging a multilingual BERT self-attention model pretrained on 104 languages , we found that fine-tuning it on all datasets concatenated in concert with simple softmax classifiers for each UD task can meet or exceed state-of-the-art UPOS , UFeats , Lemmas , ( and especially ) UAS , and LAS scores , without requiring any recurrent or language-specific components. We evaluate UDify for multilingual learnedness , showing that low-resource languages benefit the most from cross-linguistic annotations. We also evaluate for zero-shot learning , with results suggesting that multilingual training provides strong UD forecasting even for languages that neither UDify nor BERT have ever been trained on. Code for UDify is available at", "label": 1}
{"original_text": "The task of Multi-choice Machine Reading Comprehension (MMRC) aims to select the correct answer from a set of options based on a given passage and question. In generally, neural pre-trained models are employed to predict the correct answer from options. In this paper, we simply reconstruct multi-choice to single-choice by training a binary classification model to classify whether the answer is correct. We adopted the Ti-one machine learning platform provided by Tencent Cloud with its built-in AutoML and multi-machine communication acceleration framework to complete our experiments.Experimental results on the RACE dataset demonstrate that our approach achieves significantly improvements. Finally, as we relax the constraints on data format, we take a data augmentation method by introducing other formats QA datasets and achieve a new state of the art performance.", "text_perturb": "The chore of Multi-choice Machine Reading Comprehension ( MMRC ) aims to select the correct answer from a set of options based on a given passage and question. In generally , neural pre-trained models are employed to portend the correct answer from options. In this paper , we simply reconstruct multi-choice to single-choice by direct a binary classification model to classify whether the answer is correct. We adopted the Ti-one machine learning platform provided by Tencent Cloud with its built-in AutoML and multi-machine communication quickening framework to complete our experiments. Experimental result on the RACE dataset demonstrate that our approach achieves significantly improvements. Finally , as we relax the constraints on data format , we take a data augmentation method by introducing other formats QA datasets and achieve a modern state of the art performance. ", "label": 1}
{"original_text": "A new spin wavelet transform on the sphere is proposed to analyse the polarisation of the cosmic microwave background (CMB), a spin - 2 signal observed on the celestial sphere. The scalar directional scale-discretised wavelet transform on the sphere is extended to analyse signals of arbitrary spin. The resulting spin scale-discretised wavelet transform probes the directional intensity of spin signals. A procedure is presented using this new spin wavelet transform to recover E- and B-mode signals from partial-sky observations of CMB polarisation.", "text_perturb": "A new spin riffle transform on the sphere is proposed to analyse the polarisation of the cosmic microwave background ( CMB ) , a spin - 2 signal observed on the celestial sphere. The scalar directional scale-discretised wavelet transform on the sphere is extended to analyse signals of arbitrary tailspin. The resulting spin scale-discretised wavelet transform probes the directional intensity of twist signals. A procedure is presented using this new spin rippling transform to recover E- and B-mode signals from partial-sky observations of CMB polarisation. ", "label": 1}
{"original_text": "Visual Place Recognition (VPR) is the ability to correctly recall a previously visited place under changing viewpoints and appearances. A large number of handcrafted and deep-learning-based VPR techniques exist, where the former suffer from appearance changes and the latter have significant computational needs. In this paper, we present a new handcrafted VPR technique that achieves state-of-the-art place matching performance under challenging conditions. Our technique combines the best of 2 existing trainingless VPR techniques, SeqSLAM and CoHOG, which are each robust to conditional and viewpoint changes, respectively. This blend, namely ConvSequential-SLAM, utilises sequential information and block-normalisation to handle appearance changes, while using regional-convolutional matching to achieve viewpoint-invariance. We analyse content-overlap in-between query frames to find a minimum sequence length, while also re-using the image entropy information for environment-based sequence length tuning. State-of-the-art performance is reported in contrast to 8 contemporary VPR techniques on 4 public datasets. Qualitative insights and an ablation study on sequence length are also provided.", "text_perturb": "Visual Place Recognition ( VPR ) is the ability to aright recall a previously visited place under changing viewpoints and appearances. A large number of handcrafted and deep-learning-based VPR techniques exist , where the former suffer from appearance changes and the latter have significant computational want. In this paper , we present a new handcrafted VPR technique that achieves state of the art place matching performance under challenging conditions. Our technique combines the dependable of 2 existing trainingless VPR techniques , SeqSLAM and CoHOG , which are each robust to conditional and viewpoint changes , respectively. This blend , namely ConvSequential-SLAM , utilises sequential information and block-normalisation to handle appearance modification , while using regional-convolutional matching to achieve viewpoint-invariance. We analyse content-overlap in-between query frames to find a minimum sequence duration , while also re-using the image entropy information for environment-based sequence duration tuning. State-of-the-art performance be reported in contrast to 8 contemporary VPR techniques on 4 public datasets. Qualitative insights and an ablation study on sequence length are also supply. ", "label": 1}
{"original_text": "In this paper, we discuss the way advanced machine learning techniques allow physicists to perform in-depth studies of the realistic operating modes of the detectors during the stage of their design. Proposed approach can be applied to both design concept (CDR) and technical design (TDR) phases of future detectors and existing detectors if upgraded. The machine learning approaches may speed up the verification of the possible detector configurations and will automate the entire detector RD, which is often accompanied by a large number of scattered studies. We present the approach of using machine learning for detector RD and its optimisation cycle with an emphasis on the project of the electromagnetic calorimeter upgrade for the LHCb detector . The spatial reconstruction and time of arrival properties for the electromagnetic calorimeter were demonstrated.", "text_perturb": "In this paper , we discuss the way advanced machine learning technique allow physicists to perform in-depth studies of the realistic operating modes of the detectors during the stage of their design. Proposed approach can be applied to both design concept ( CDR ) and technical design ( TDR ) phases of future detectors and live detectors if upgraded. The machine learning approaches may quicken up the verification of the possible detector configurations and will automate the entire detector RD , which is often accompanied by a large number of scattered studies. We present the coming of using machine learning for detector RD and its optimisation cycle with an emphasis on the project of the electromagnetic calorimeter upgrade for the LHCb detector. The spatial reconstruction and metre of arrival properties for the electromagnetic calorimeter were demonstrated. ", "label": 1}
{"original_text": "The majority of works in distributed storage networks assume a simple network model with a collection of identical storage nodes with the same communication cost between the nodes. In this paper, we consider a realistic multi-rack distributed data storage network and present a code design framework for this model. Considering the cheaper data transmission within the racks, our code construction method is able to locally repair the nodes failure within the same rack by using only the survived nodes in the same rack. However, in the case of severe failure patterns when the information content of the survived nodes is not sufficient to repair the failures, other racks will participate in the repair process. By employing the criteria of our multi-rack storage code, we establish a linear programming bound on the size of the code in order to maximize the code rate.", "text_perturb": "The majority of works in distributed storage networks assume a simple net model with a collection of identical storage nodes with the same communication cost between the nodes. In this newspaper publisher , we consider a realistic multi-rack distributed data storage network and present a code design framework for this model. think the cheaper data transmission within the racks , our code construction method is able to locally repair the nodes failure within the same rack by using only the survived nodes in the same rack. However , in the case of severe failure patterns when the information content of the survived nodes is not sufficient to repair the failures , other wheel will participate in the repair process. By employing the criteria of our multi-rack storage code , we establish a linear programming bound on the sizing of the code in order to maximize the code rate. ", "label": 1}
{"original_text": "We consider the problem of deciding the satisfiability of quantifier-free formulas in the theory of finite sets with cardinality constraints. Sets are a common high-level data structure used in programming; thus, such a theory is useful for modeling program constructs directly. More importantly, sets are a basic construct of mathematics and thus natural to use when formalizing the properties of computational systems. We develop a calculus describing a modular combination of a procedure for reasoning about membership constraints with a procedure for reasoning about cardinality constraints. Cardinality reasoning involves tracking how different sets overlap. For efficiency, we avoid considering Venn regions directly, as done in previous work. Instead, we develop a novel technique wherein potentially overlapping regions are considered incrementally as needed, using a graph to track the interaction among the different regions. The calculus has been designed to facilitate its implementation within SMT solvers based on the DPLL (T) architecture. Our experimental results demonstrate that the new techniques are competitive with previous techniques and can scale much better on certain classes of problems.", "text_perturb": "We consider the problem of deciding the satisfiability of quantifier-free formulas in the theory of finite sets with cardinality restraint. Sets are a common high-level data structure used in programming ; thus , such a theory is useful for pose program constructs directly. More importantly , sets are a basic concept of mathematics and thus natural to use when formalizing the properties of computational systems. We develop a calculus describing a modular combination of a procedure for reasoning about rank constraints with a procedure for reasoning about cardinality constraints. Cardinality reasoning involves tracking how different sets overlap. For efficiency , we avoid considering Venn realm directly , as done in previous work. Instead , we develop a novel technique wherein potentially overlapping realm are considered incrementally as needed , using a graph to track the interaction among the different realm. The calculus has been plan to facilitate its implementation within SMT solvers based on the DPLL ( T ) architecture. Our experimental results demonstrate that the new techniques are competitive with previous techniques and can scale much better on certain socio economic class of problems. ", "label": 1}
{"original_text": "We present and analyze a numerical method to solve the time-dependent linear Pauli equation in three space-dimensions. The Pauli equation is a \"semi-relativistic\" generalization of the Schrodinger equation for 2-spinors which accounts both for magnetic fields and for spin, the latter missing in predeeding work on the linear magnetic Schrodinger equation. We use a four operator splitting in time, prove stability and convergence of the method and derive error estimates as well as meshing strategies for the case of given time-independent electromagnetic potentials linear\" case), thus providing a generalization of previous results for the magnetic Schrodinger equation. Some proof of concept examples of numerical simulations are presented.", "text_perturb": "We present and analyze a numerical method to resolve the time-dependent linear Pauli equation in three space-dimensions. The Pauli equation is a `` semi-relativistic '' generalization of the Schrodinger equation for 2-spinors which accounts both for magnetic theatre of operations and for spin , the latter missing in predeeding work on the linear magnetic Schrodinger equation. We use a four operator splitting in time , prove stability and convergence of the method and derive error estimates as well as meshing strategies for the case of given time-independent electromagnetic potentials linear '' case ) , thus providing a stimulus generalization of previous results for the magnetic Schrodinger equation. Some proof of concept examples of numerical simulations are gift. ", "label": 1}
{"original_text": "In Natural Language (NL) applications, there is often a mismatch between what the NL interface is capable of interpreting and what a lay user knows how to express. This work describes a novel natural language interface that reduces this mismatch by refining natural language input through successive, automatically generated semi-structured templates. In this paper we describe how our approach, called SKATE, uses a neural semantic parser to parse NL input and suggest semi-structured templates, which are recursively filled to produce fully structured interpretations. We also show how SKATE integrates with a neural rule-generation model to interactively suggest and acquire commonsense knowledge. We provide a preliminary coverage analysis of SKATE for the task of story understanding, and then describe a current business use-case of the tool in a specific domain: COVID-19 policy design.", "text_perturb": "In Natural linguistic process ( NL ) applications , there is often a mismatch between what the NL interface is capable of interpreting and what a lay user knows how to express. This work describes a novel natural language user interface that reduces this mismatch by refining natural language input through successive , automatically generated semi-structured templates. In this paper we describe how our approach , predict SKATE , uses a neural semantic parser to parse NL input and suggest semi-structured templates , which are recursively filled to produce fully structured interpretations. We as well show how SKATE integrates with a neural rule-generation model to interactively suggest and acquire commonsense knowledge. We allow a preliminary coverage analysis of SKATE for the task of story understanding , and then describe a current business use-case of the tool in a specific domain : COVID-19 policy design. ", "label": 1}
{"original_text": "Scenario discovery is the process of finding areas of interest, commonly referred to as scenarios, in data spaces resulting from simulations. For instance, one might search for conditions - which are inputs of the simulation model - where the system under investigation is unstable. A commonly used algorithm for scenario discovery is PRIM. It yields scenarios in the form of hyper-rectangles which are human-comprehensible. When the simulation model has many inputs, and the simulations are computationally expensive, PRIM may not produce good results, given the affordable volume of data. So we propose a new procedure for scenario discovery - we train an intermediate statistical model which generalizes fast, and use it to label (a lot of) data for PRIM. We provide the statistical intuition behind our idea. Our experimental study shows that this method is much better than PRIM itself. Specifically, our method reduces the number of simulations runs necessary by 75 on average.", "text_perturb": "Scenario find is the process of finding areas of interest , commonly referred to as scenarios , in data spaces resulting from simulations. For instance , one might research for conditions - which are inputs of the simulation model - where the system under investigation is unstable. A commonly used algorithmic program for scenario discovery is PRIM. It cede scenarios in the form of hyper-rectangles which are human-comprehensible. When the simulation model has many inputs , and the simulations are computationally expensive , PRIM may not make good results , given the affordable volume of data. So we propose a new procedure for scenario discovery - we direct an intermediate statistical model which generalizes fast , and use it to label ( a lot of ) data for PRIM. We supply the statistical intuition behind our idea. Our experimental study shows that this method is practically better than PRIM itself. specifically , our method reduces the number of simulations runs necessary by 75 on average. ", "label": 1}
{"original_text": "We present a dictionary-based approach to racism detection in Dutch social media comments, which were retrieved from two public Belgian social media sites likely to attract racist reactions. These comments were labeled as racist or non-racist by multiple annotators. For our approach, three discourse dictionaries were created: first, we created a dictionary by retrieving possibly racist and more neutral terms from the training data, and then augmenting these with more general words to remove some bias. A second dictionary was created through automatic expansion using a word2vec model trained on a large corpus of general Dutch text. Finally, a third dictionary was created by manually filtering out incorrect expansions. We trained multiple Support Vector Machines, using the distribution of words over the different categories in the dictionaries as features. The best-performing model used the manually cleaned dictionary and obtained an F-score of 0.46 for the racist class on a test set consisting of unseen Dutch comments, retrieved from the same sites used for the training set. The automated expansion of the dictionary only slightly boosted the model's performance, and this increase in performance was not statistically significant. The fact that the coverage of the expanded dictionaries did increase indicates that the words that were automatically added did occur in the corpus, but were not able to meaningfully impact performance. The dictionaries, code, and the procedure for requesting the corpus are available at: Keywords Racism, word2vec, Dictionary-based Approaches, Computational Stylometry", "text_perturb": "We present a dictionary-based feeler to racism detection in Dutch social media comments , which were retrieved from two public Belgian social media sites likely to attract racist reactions. These comments were labeled as racialist or non-racist by multiple annotators. For our approach , three discourse dictionaries were created : first , we created a dictionary by retrieving possibly racist and more neutral terms from the training datum , and then augmenting these with more general words to remove some bias. A second dictionary was created through automatic elaboration using a word2vec model trained on a large corpus of general Dutch text. Finally , a third dictionary was create by manually filtering out incorrect expansions. We trained multiple Support Vector Machines , using the distribution of words over the different categories in the dictionary as features. The best-performing model used the manually cleanse dictionary and obtained an F-score of 0. 46 for the racist class on a test bent consisting of unseen Dutch comments , retrieved from the same sites used for the training bent. The automated expansion of the dictionary only slimly boosted the model 's performance , and this increase in performance was not statistically significant. The fact that the coverage of the expanded dictionaries practice increase indicates that the words that were automatically added practice occur in the corpus , but were not able to meaningfully impact performance. The dictionaries , computer code , and the procedure for requesting the corpus are available at : Keywords Racism , word2vec , Dictionary-based Approaches , Computational Stylometry", "label": 1}
{"original_text": "In this paper we develop a new family of Ordered Weighted Averaging (OWA) operators. Weight vector is obtained from a desired orness of the operator. Using Faulhaber's formulas we obtain direct and simple expressions for the weight vector without any iteration loop. With the exception of one weight, the remaining follow a straight line relation. As a result, a fast and robust algorithm is developed. The resulting weight vector is suboptimal according with the Maximum Entropy criterion, but it is very close to the optimal. Comparisons are done with other procedures.", "text_perturb": "In this paper we rise a new family of Ordered Weighted Averaging ( OWA ) operators. Weight vector is obtained from a in demand orness of the operator. Using Faulhaber 's formulas we hold direct and simple expressions for the weight vector without any iteration loop. With the exception of one weight , the remaining stick with a straight line relation. As a solvent , a fast and robust algorithm is developed. The resulting weight transmitter is suboptimal according with the Maximum Entropy criterion , but it is very close to the optimal. comparison are done with other procedures. ", "label": 1}
{"original_text": "This work investigates the consensus problem for multi-agent nonlinear systems through the distributed real-time nonlinear receding horizon control methodology. With this work, we develop a scheme to reach the consensus for nonlinear multi agent systems under fixed directedundirected graph (s) without the need of any linearization techniques. For this purpose, the problem of consensus is converted into an optimization problem and is directly solved by the backwards sweep Riccati method to generate the control protocol which results in a non-iterative algorithm. Stability analysis is conducted to provide convergence guarantees of proposed scheme. In addition, an extension to the leader-following consensus of nonlinear multi-agent systems is presented. Several examples are provided to validate and demonstrate the effectiveness of the presented scheme and the corresponding theoretical results.", "text_perturb": "This work investigates the consensus problem for multi-agent nonlinear systems through the distributed real-time nonlinear receding horizon ascendency methodology. With this work , we develop a scheme to reach the consensus for nonlinear multi factor systems under fixed directedundirected graph ( s ) without the need of any linearization techniques. For this purpose , the problem of consensus is converted into an optimization problem and is directly solve by the backwards sweep Riccati method to generate the control protocol which results in a non-iterative algorithm. Stability analysis is conducted to provide convergence guarantee of proposed scheme. In addition , an propagation to the leader-following consensus of nonlinear multi-agent systems is presented. Several examples are provided to validate and demonstrate the effectiveness of the presented scheme and the corresponding theoretical solution. ", "label": 1}
{"original_text": "When we try to solve a system of linear equations, we can consider a simple iterative algorithm in which an equation including only one variable is chosen at each step, and the variable is fixed to the value satisfying the equation. The dynamics of this algorithm is captured by the peeling algorithm. Analyses of the peeling algorithm on random hypergraphs are required for many problems, e.g., the decoding threshold of low-density parity check codes, the inverting threshold of Goldreich's pseudorandom generator, the load threshold of cuckoo hashing, etc. In this work, we deal with random hypergraphs including superlinear number of hyperedges, and derive the tight threshold for the succeeding of the peeling algorithm. For the analysis, Wormald's method of differential equations, which is commonly used for analyses of the peeling algorithm on random hypergraph with linear number of hyperedges, cannot be used due to the superlinear number of hyperedges. A new method called the evolution of the moment generating function is proposed in this work.", "text_perturb": "When we try to solve a system of linear equations , we can consider a simple iterative algorithm in which an equation including only one variable is pick out at each step , and the variable is fixed to the value satisfying the equation. The dynamics of this algorithmic program is captured by the peeling algorithmic program. Analyses of the peeling algorithm on random hypergraphs are required for many problems , einsteinium. gb. , the decoding doorsill of low-density parity check codes , the inverting doorsill of Goldreich 's pseudorandom generator , the load doorsill of cuckoo hashing , etc. In this work , we deal with random hypergraphs including superlinear number of hyperedges , and derive the nasty threshold for the succeeding of the peeling algorithm. For the analysis , Wormald 's method of differential equations , which is commonly expend for analyses of the peeling algorithm on random hypergraph with linear number of hyperedges , can not be expend due to the superlinear number of hyperedges. A new method called the evolution of the import generating function is proposed in this work. ", "label": 1}
{"original_text": "Conventional approaches to image de-fencing suffer from non-robust fence detection and are limited to processing images of static scenes. In this position paper, we propose an automatic de-fencing algorithm for images of dynamic scenes. We divide the problem of image de-fencing into the tasks of automated fence detection, motion estimation and fusion of data from multiple frames of a captured video of the dynamic scene. Fences are detected automatically using two approaches, namely, employing Gabor filter and a machine learning method. We cast the fence removal problem in an optimization framework, by modeling the formation of the degraded observations. The inverse problem is solved using split Bregman technique assuming total variation of the de-fenced image as the regularization constraint.", "text_perturb": "Conventional approaches to image de-fencing suffer from non-robust fence detection and are limited to processing images of still scenes. In this position paper , we propose an automatic de-fencing algorithmic program for images of dynamic scenes. We divide the problem of image de-fencing into the tasks of automated fence detection , motion estimation and fusion of data from multiple frames of a captured tv of the dynamic scene. Fences are detected mechanically using two approaches , namely , employing Gabor filter and a machine learning method. We cast the fence removal trouble in an optimization framework , by modeling the formation of the degraded observations. The inverse problem is solved using disunited Bregman technique assuming total variation of the de-fenced image as the regularization constraint. ", "label": 1}
{"original_text": "Modelling the physical properties of everyday objects is a fundamental prerequisite for autonomous robots. We present a novel generative adversarial network (Defo-Net), able to predict body deformations under external forces from a single RGB-D image. The network is based on an invertible conditional Generative Adversarial Network (IcGAN) and is trained on a collection of different objects of interest generated by a physical finite element model simulator. Defo-Net inherits the generalisation properties of GANs. This means that the network is able to reconstruct the whole 3-D appearance of the object given a single depth view of the object and to generalise to unseen object configurations. Contrary to traditional finite element methods, our approach is fast enough to be used in real-time applications. We apply the network to the problem of safe and fast navigation of mobile robots carrying payloads over different obstacles and floor materials. Experimental results in real scenarios show how a robot equipped with an RGB-D camera can use the network to predict terrain deformations under different payload configurations and use this to avoid unsafe areas.", "text_perturb": "Modelling the physical properties of everyday objects is a key prerequisite for autonomous robots. We present a novel generative adversarial network ( Defo-Net ) , able to predict body deformations under international forces from a single RGB-D image. The network is based on an invertible conditional Generative Adversarial Network ( IcGAN ) and is trained on a collection of dissimilar objects of interest generated by a physical finite element model simulator. Defo-Net inherits the generalisation properties of GANs. This means that the electronic network is able to reconstruct the whole 3-D appearance of the object given a single depth view of the object and to generalise to unseen object configurations. Contrary to traditional finite element method acting , our approach is fast enough to be used in real-time applications. We apply the network to the job of safe and fast navigation of mobile robots carrying payloads over different obstacles and floor materials. observational results in real scenarios show how a robot equipped with an RGB-D camera can use the network to predict terrain deformations under different payload configurations and use this to avoid unsafe areas. ", "label": 1}
{"original_text": "Both feature selection and hyperparameter tuning are key tasks in machine learning. Hyperparameter tuning is often useful to increase model performance, while feature selection is undertaken to attain sparse models. Sparsity may yield better model interpretability and lower cost of data acquisition, data handling and model inference. While sparsity may have a beneficial or detrimental effect on predictive performance, a small drop in performance may be acceptable in return for a substantial gain in sparseness. We therefore treat feature selection as a multi-objective optimization task. We perform hyperparameter tuning and feature selection simultaneously because the choice of features of a model may influence what hyperparameters perform well. We present, benchmark, and compare two different approaches for multi-objective joint hyperparameter optimization and feature selection: The first uses multi-objective model-based optimization. The second is an evolutionary NSGA-II-based wrapper approach to feature selection which incorporates specialized sampling, mutation and recombination operators. Both methods make use of parameterized filter ensembles. While model-based optimization needs fewer objective evaluations to achieve good performance, it incurs computational overhead compared to the NSGA-II, so the preferred choice depends on the cost of evaluating a model on given data.", "text_perturb": "Both feature selection and hyperparameter tuning are key project in machine learning. Hyperparameter tuning is often useful to increase model functioning , while feature selection is undertaken to attain sparse models. Sparsity may yield better model interpretability and lower cost of information acquisition , information handling and model inference. While sparsity may have a beneficial or detrimental effect on predictive performance , a small drib in performance may be acceptable in return for a substantial gain in sparseness. We therefore treat feature selection as a multi-objective optimization job. We perform hyperparameter tuning and feature selection simultaneously because the choice of features of a manakin may influence what hyperparameters perform well. We present , benchmark , and compare two different approaches for multi-objective joint hyperparameter optimization and feature pick : The first uses multi-objective model-based optimization. The second is an evolutionary NSGA-II-based wrapper approach to feature survival of the fittest which incorporates specialized sampling , mutation and recombination operators. Both method make use of parameterized filter ensembles. While model-based optimization needs fewer objective evaluations to achieve good performance , it obtain computational overhead compared to the NSGA-II , so the preferred choice depends on the cost of evaluating a model on given data. ", "label": 1}
{"original_text": "QoS-aware networking applications such as real-time streaming and video surveillance systems require nearly fixed average end-to-end delay over long periods to communicate efficiently, although may tolerate some delay variations in short periods. This variability exhibits complex dynamics that makes rate control of such applications a formidable task. This paper addresses rate allocation for heterogeneous QoS-aware applications that preserves the long-term end-to-end delay constraint while, similar to Dynamic Network Utility Maximization (DNUM), strives to achieve the maximum network utility aggregated over a fixed time interval. Since capturing temporal dynamics in QoS requirements of sources is allowed in our system model, we incorporate a novel time-coupling constraint in which delay-sensitivity of sources is considered such that a certain end-to-end average delay for each source over a pre-specified time interval is satisfied. We propose DA-DNUM algorithm, as a dual-based solution, which allocates source rates for the next time interval in a distributed fashion, given the knowledge of network parameters in advance. To overcome the slow convergence of dual-based DA-DNUM algorithm, we propose another fast alternative solution based on the recently-proposed distributed Newton method. Also, we extend and address the problem in a case that the problem data is not known fully in advance to capture more realistic scenarios. Through numerical experiments, we show that DA-DNUM gains higher average link utilization and a wider range of feasible scenarios in comparison with the best, to our knowledge, rate control schemes that may guarantee such constraints on delay.", "text_perturb": "QoS-aware networking applications such as real-time streaming and video surveillance systems require nearly fixed average end-to-end delay over long periods to pass on efficiently , although may tolerate some delay variations in short periods. This variability exhibit complex dynamics that makes rate control of such applications a formidable task. This paper addresses rate allocation for heterogeneous QoS-aware applications that preserves the long-term end-to-end delay constraint while , similar to Dynamic Network Utility Maximization ( DNUM ) , strives to accomplish the maximum network utility aggregated over a fixed time interval. Since capturing temporal dynamics in QoS requirements of sources is allowed in our system model , we incorporate a novel time-coupling constraint in which delay-sensitivity of sources is considered such that a certain end-to-end average holdup for each source over a pre-specified time interval is satisfied. We propose DA-DNUM algorithm , as a dual-based solution , which allocates germ rates for the next time interval in a distributed fashion , given the knowledge of network parameters in advance. To overcome the slow convergence of dual-based DA-DNUM algorithm , we propose another fast alternate solution based on the recently-proposed distributed Newton method. Also , we extend and address the problem in a case that the problem data is not known in full in advance to capture more realistic scenarios. Through numerical experiments , we show that DA-DNUM gains higher average link utilization and a wider range of feasible scenarios in comparison with the unspoilt , to our knowledge , rate control schemes that may guarantee such constraints on delay. ", "label": 1}
{"original_text": "Natural images can be regarded as residing in a manifold that is embedded in a higher dimensional Euclidean space. Generative Adversarial Networks (GANs) try to learn the distribution of the real images in the manifold to generate samples that look real. But the results of existing methods still exhibit many unpleasant artifacts and distortions even for the cases where the desired ground truth target images are available for supervised learning such as in single image super resolution (SISR). We probe for ways to alleviate these problems for supervised GANs in this paper. We explicitly apply the Lipschitz Continuity Condition (LCC) to regularize the GAN. An encoding network that maps the image space to a new optimal latent space is derived from the LCC, and it is used to augment the GAN as a coupling component. The LCC is also converted to new regularization terms in the generator loss function to enforce local invariance. The GAN is optimized together with the encoding network in an attempt to make the generator converge to a more ideal and disentangled mapping that can generate samples more faithful to the target images. When the proposed models are applied to the single image super resolution problem, the results outperform the state of the art.", "text_perturb": "Natural images can be regarded as residing in a manifold that is embedded in a gamey dimensional Euclidean space. Generative Adversarial Networks ( GANs ) try to learn the distribution of the real images in the manifold to father samples that look real. But the results of existing methods still exhibit many unpleasant artifacts and distortions even for the cases where the desired ground truth target images are available for supervised learning such as in single ikon super resolution ( SISR ). We probe for means to alleviate these problems for supervised GANs in this paper. We explicitly utilise the Lipschitz Continuity Condition ( LCC ) to regularize the GAN. An encoding network that map out the image space to a new optimal latent space is derived from the LCC , and it is used to augment the GAN as a coupling component. The LCC is also converted to new regularization terms in the generator loss function to enforce local invariableness. The GAN is optimise together with the encoding network in an attempt to make the generator converge to a more ideal and disentangled mapping that can generate samples more faithful to the target images. When the proposed models are applied to the single image super resolving power problem , the results outperform the state of the art. ", "label": 1}
{"original_text": "In this paper we study decomposition methods based on separable approximations for minimizing the augmented Lagrangian. In particular, we study and compare the Diagonal Quadratic Approximation Method (DQAM) of Mulvey and Ruszczynski and the Parallel Coordinate Descent Method (PCDM) of Richtarik and Takac. We show that the two methods are equivalent for feasibility problems up to the selection of a single step-size parameter. Furthermore, we prove an improved complexity bound for PCDM under strong convexity, and show that this bound is at least 8 (L ' - L) o 1) 2 times better than the best known bound for DQAM, where o is the degree of partial separability and L ' and - L are the maximum and average of the block Lipschitz constants of the gradient of the quadratic penalty appearing in the augmented Lagrangian.", "text_perturb": "In this paper we study decomposition methods based on separable estimate for minimizing the augmented Lagrangian. In particular , we study and compare the Diagonal Quadratic Approximation method acting ( DQAM ) of Mulvey and Ruszczynski and the Parallel Coordinate Descent method acting ( PCDM ) of Richtarik and Takac. We present that the two methods are equivalent for feasibility problems up to the selection of a single step-size parameter. Furthermore , we prove an improved complexity bound for PCDM under strong convexity , and show that this bound personify at least 8 ( L ' - L ) o 1 ) 2 times better than the best known bound for DQAM , where o personify the degree of partial separability and L ' and - L are the maximum and average of the block Lipschitz constants of the gradient of the quadratic penalty appearing in the augmented Lagrangian. ", "label": 1}
{"original_text": "This study addresses the problem of identifying the meaning of unknown words or entities in a discourse with respect to the word embedding approaches used in neural language models. We proposed a method for on-the-fly construction and exploitation of word embeddings in both the input and output layers of a neural model by tracking contexts. This extends the dynamic entity representation used in and incorporates a copy mechanism proposed independently by and . In addition, we construct a new task and dataset called Anonymized Language Modeling for evaluating the ability to capture word meanings while reading. Experiments conducted using our novel dataset show that the proposed variant of RNN language model outperformed the baseline model. Furthermore, the experiments also demonstrate that dynamic updates of an output layer help a model predict reappearing entities, whereas those of an input layer are effective to predict words following reappearing entities.", "text_perturb": "This study addresses the problem of identifying the meaning of unknown book or entities in a discourse with respect to the word embedding approaches used in neural language models. We proposed a method for on-the-fly expression and exploitation of word embeddings in both the input and output layers of a neural model by tracking contexts. This extends the dynamic entity representation used in and comprise a copy mechanism proposed independently by and. In addition , we construct a new task and dataset called Anonymized Language Modeling for evaluating the ability to fascinate word meanings while reading. Experiments conducted using our fresh dataset show that the proposed variant of RNN language model outperformed the baseline model. Furthermore , the experiments also demonstrate that dynamic updates of an output stratum help a model predict reappearing entities , whereas those of an input stratum are effective to predict words following reappearing entities. ", "label": 1}
{"original_text": "We propose a decentralized game-theoretic framework for dynamic task allocation problems for multi-agent systems. In our problem formulation, the agents' utilities depend on both the rewards and the costs associated with the successful completion of the tasks assigned to them. The rewards reflect how likely is for the agents to accomplish their assigned tasks whereas the costs reflect the effort needed to complete these tasks (this effort is determined by the solution of corresponding optimal control problems). The task allocation problem considered herein corresponds to a dynamic game whose solution depends on the states of the agents in contrast with classic static (or single-act) game formulations. We propose a greedy solution approach in which the agents negotiate with each other to find a mutually agreeable (or individually rational) task assignment profile based on evaluations of the task utilities that reflect their current states. We illustrate the main ideas of this work by means of extensive numerical simulations.", "text_perturb": "We propose a deconcentrate game-theoretic framework for dynamic task allocation problems for multi-agent systems. In our problem formulation , the agents ' utilities depend on both the rewards and the costs associated with the successful completion of the tasks attribute to them. The rewards reflect how likely is for the agents to accomplish their assigned tasks whereas the costs reflect the effort needed to complete these tasks ( this effort is determined by the solution of corresponding optimum control problems ). The task allocation problem considered herein corresponds to a dynamic secret plan whose solution depends on the states of the agents in contrast with classic static ( or single-act ) secret plan formulations. We propose a greedy solution approach in which the agents negotiate with each other to find a mutually agreeable ( or individually rational ) task designation profile based on evaluations of the task utilities that reflect their current states. We exemplify the main ideas of this work by means of extensive numerical simulations. ", "label": 1}
{"original_text": "We propose probabilistic models that can extrapolate learning curves of iterative machine learning algorithms, such as stochastic gradient descent for training deep networks, based on training data with variable-length learning curves. We study instantiations of this framework based on random forests and Bayesian recurrent neural networks. Our experiments show that these models yield better predictions than state-of-the-art models from the hyperparameter optimization literature when extrapolating the performance of neural networks trained with different hyperparameter settings.", "text_perturb": "We propose probabilistic models that can extrapolate learning curve ball of iterative machine learning algorithms , such as stochastic gradient descent for training deep networks , based on training data with variable-length learning curve ball. We study instantiations of this framework based on random forests and Bayesian recurrent neural web. Our experiments show that these models yield better predictions than state-of-the-art models from the hyperparameter optimization literature when extrapolating the carrying out of neural networks trained with different hyperparameter settings. ", "label": 1}
{"original_text": "Vehicle-to-everything (V2X) communication and services have been garnering significant interest from different stakeholders as part of future intelligent transportation systems (ITSs). This is due to the many benefits they offer. However, many of these services have stringent performance requirements, particularly in terms of the delaylatency. Multi-accessmobile edge computing (MEC) has been proposed as a potential solution for such services by bringing them closer to vehicles. Yet, this introduces a new set of challenges such as where to place these V2X services, especially given the limit computation resources available at edge nodes. To that end, this work formulates the problem of optimal V2X service placement (OVSP) in a hybrid coreedge environment as a binary integer linear programming problem. To the best of our knowledge, no previous work considered the V2X service placement problem while taking into consideration the computational resource availability at the nodes. Moreover, a low-complexity greedy-based heuristic algorithm named \"Greedy V2X Service Placement Algorithm\" (G-VSPA) was developed to solve this problem. Simulation results show that the OVSP model successfully guarantees and maintains the QoS requirements of all the different V2X services. Additionally, it is observed that the proposed G-VSPA algorithm achieves close to optimal performance while having lower complexity.", "text_perturb": "Vehicle-to-everything ( V2X ) communication and services have be garnering significant interest from different stakeholders as part of future intelligent transportation systems ( ITSs ). This is imputable to the many benefits they offer. yet , many of these services have stringent performance requirements , particularly in terms of the delaylatency. Multi-accessmobile edge computing ( MEC ) has been proposed as a potential solution for such overhaul by bringing them closer to vehicles. Yet , this introduces a new set of challenges such as where to place these V2X services , especially make the limit computation resources available at edge nodes. To that end , this workplace formulates the problem of optimal V2X service placement ( OVSP ) in a hybrid coreedge environment as a binary integer linear programming problem. To the better of our knowledge , no previous work considered the V2X service placement problem while taking into consideration the computational resource availability at the nodes. Moreover , a low-complexity greedy-based heuristic algorithm named `` Greedy V2X Service Placement Algorithm '' ( G-VSPA ) was developed to work this problem. simulation results show that the OVSP model successfully guarantees and maintains the QoS requirements of all the different V2X services. Additionally , it is observed that the proposed G-VSPA algorithmic program achieves close to optimal performance while having lower complexity. ", "label": 1}
{"original_text": "Semantic parsing is the task of transforming sentences from natural language into formal representations of predicate-argument structures. Under this research area, frame-semantic parsing has attracted much interest. This parsing approach leverages the lexical information defined in FrameNet to associate marked predicates or targets with semantic frames, thereby assigning semantic roles to sentence components based on pre-specified frame elements in FrameNet. In this paper, a deep neural network architecture known as Positional Attention-based Frame Identification with BERT (PAFIBERT) is presented as a solution to the frame identification subtask in frame-semantic parsing. Although the importance of this subtask is well-established, prior research has yet to find a robust solution that works satisfactorily for both in-domain and out-of-domain data. This study thus set out to improve frame identification in light of recent advancements of language modeling and transfer learning in natural language processing. The proposed method is partially empowered by BERT, a pre-trained language model that excels at capturing contextual information in texts. By combining the language representation power of BERT with a position-based attention mechanism, PAFIBERT is able to attend to target-specific contexts in sentences for disambiguating targets and associating them with the most suitable semantic frames. Under various experimental settings, PAFIBERT outperformed existing solutions by a significant margin, achieving new state-of-the-art results for both in-domain and out-of-domain benchmark test sets.", "text_perturb": "Semantic parsing is the task of transforming sentences from instinctive language into formal representations of predicate-argument structures. Under this research area , frame-semantic parsing has attract much interest. This parsing approach leverages the lexical information defined in FrameNet to affiliate marked predicates or targets with semantic frames , thereby assigning semantic roles to sentence components based on pre-specified frame elements in FrameNet. In this paper , a deep neural network architecture known as Positional Attention-based Frame Identification with BERT ( PAFIBERT ) is presented as a solution to the bod identification subtask in frame-semantic parsing. Although the grandness of this subtask is well-established , prior research has yet to find a robust solution that works satisfactorily for both in-domain and out-of-domain data. This study so set out to improve frame identification in light of recent advancements of language modeling and transfer learning in natural language processing. The proposed method constitute partially empowered by BERT , a pre-trained language model that excels at capturing contextual information in texts. By combining the language representation power of BERT with a position-based attention mechanism , PAFIBERT is able to attend to target-specific circumstance in sentences for disambiguating targets and associating them with the most suitable semantic frames. Under various experimental settings , PAFIBERT outperformed existing solutions by a significant margin , achieving new state-of-the-art result for both in-domain and out-of-domain benchmark test sets. ", "label": 1}
{"original_text": "In recent years, deep learning has made tremendous progress in a number of fields that were previously out of reach for artificial intelligence. The successes in these problems has led researchers to consider the possibilities for intelligent systems to tackle a problem that humans have only recently themselves considered: program synthesis. This challenge is unlike others such as object recognition and speech translation, since its abstract nature and demand for rigor make it difficult even for human minds to attempt. While it is still far from being solved or even competitive with most existing methods, neural program synthesis is a rapidly growing discipline which holds great promise if completely realized. In this paper, we start with exploring the problem statement and challenges of program synthesis. Then, we examine the fascinating evolution of program induction models, along with how they have succeeded, failed and been reimagined since. Finally, we conclude with a contrastive look at program synthesis and future research recommendations for the field.", "text_perturb": "In recent years , deep learning has made tremendous progress in a number of fields that were previously out of reach for artificial intelligence operation. The successes in these problems throw led researchers to consider the possibilities for intelligent systems to tackle a problem that humans have only recently themselves considered : program synthesis. This challenge is unlike others such as object recognition and speech translation , since its abstract nature and requirement for rigor make it difficult even for human minds to attempt. While it is still far from being solved or even competitive with most existing methods , neural program synthesis is a rapidly growing discipline which holds great promise if completely substantiate. In this paper , we start with exploring the problem statement and challenges of program deductive reasoning. Then , we examine the fascinating evolution of program induction example , along with how they have succeeded , failed and been reimagined since. Finally , we conclude with a contrastive looking at program synthesis and future research recommendations for the field. ", "label": 1}
{"original_text": "The analysis techniques of system log messages (syslog messages) have a long history from when the syslog mechanism was invented. Typically, the analysis consists of two parts, one is a message template generation, and the other is finding something interesting using the messages classified by the inferred templates. It is important to generate better templates to achieve better, precise, or convincible analysis results. In this paper, we propose a classification methodology using the length of words of each message. Our method is suitable for online template generation because it does not require two-pass analysis to generate template messages, that is an important factor considering increasing amount of log messages produced by a large number of system components such as cloud infrastructure.", "text_perturb": "The analysis techniques of system log messages ( syslog messages ) have a longsighted history from when the syslog mechanism was invented. typically , the analysis consists of two parts , one is a message template generation , and the other is finding something interesting using the messages classified by the inferred templates. It is important to generate better templet to achieve better , precise , or convincible analysis results. In this paper , we propose a categorization methodology using the length of words of each message. Our method is suitable for online template generation because it does non require two-pass analysis to generate template messages , that is an important factor considering increasing amount of log messages produced by a large number of system components such as cloud infrastructure. ", "label": 1}
{"original_text": "We present an improved combinatorial algorithm for the computation of equilibrium prices in the linear Arrow-Debreu model. For a market with n agents and integral utilities bounded by U, the algorithm runs in O (n 7 log 3 (n U time. This improves upon the previously best algorithm of Ye by a factor of O (n). The algorithm refines the algorithm described by Duan and Mehlhorn and improves it by a factor of O (n 3). The improvement comes from a better understanding of the iterative price adjustment process, the improved balanced flow computation for nondegenerate instances, and a novel perturbation technique for achieving nondegeneracy.", "text_perturb": "We present an improved combinative algorithm for the computation of equilibrium prices in the linear Arrow-Debreu model. For a market with n agents and integral utilities bounded by U , the algorithm runs in O ( n 7 logarithm 3 ( n U time. This improves upon the previously best algorithm of Ye by a factor of O ( normality ). The algorithm refines the algorithm trace by Duan and Mehlhorn and improves it by a factor of O ( n 3 ). The improvement comes from a better understanding of the iterative price adjustment process , the improved balanced flow computation for nondegenerate instances , and a new perturbation technique for achieving nondegeneracy. ", "label": 1}
{"original_text": "Introducing factors, that is to say, word features such as linguistic information referring to the source tokens, is known to improve the results of neural machine translation systems in certain settings, typically in recurrent architectures. This study proposes enhancing the current state-of-the-art neural machine translation architecture, the Transformer, so that it allows to introduce external knowledge. In particular, our proposed modification, the Factored Transformer, uses factors, either linguistic or semantic, that insert additional knowledge into the machine translation system. Apart from using different kinds of features, we study the effect of different architectural configurations. Specifically, we analyze the performance of combining words and features at the embedding level or at the encoder level, and we experiment with two different combination strategies. With the best-found configuration, we show improvements of 0.8 BLEU over the baseline Transformer in the IWSLT German-to-English task. Moreover, we experiment with the more challenging FLoRes English-to-Nepali benchmark, which includes both extremely low-resourced and very distant languages, and obtain an improvement of 1.2 BLEU. These improvements are achieved with linguistic and not with semantic information.", "text_perturb": "Introducing factors , that is to say , word features such as linguistic information referring to the source tokens , is known to improve the results of neural machine translation systems in certain setting , typically in recurrent architectures. This study proposes enhancing the current state-of-the-art neural machine translation architecture , the Transformer , so that it allows to introduce external noesis. In particular , our proposed modification , the Factored Transformer , uses factors , either linguistic or semantic , that insert additional knowledge into the machine interlingual rendition system. Apart from using different kinds of features , we study the effect of different architectural conformation. Specifically , we analyze the performance of combining words and features at the embedding point or at the encoder point , and we experiment with two different combination strategies. With the best-found configuration , we usher improvements of 0. 8 BLEU over the baseline Transformer in the IWSLT German-to-English undertaking. Moreover , we experiment with the more challenging FLoRes English-to-Nepali benchmark , which includes both extremely low-resourced and very aloof languages , and obtain an improvement of 1. 2 bleu. These melioration are achieved with linguistic and not with semantic information. ", "label": 1}
{"original_text": "We introduce novel dynamic oracles for training two of the most accurate known shift-reduce algorithms for constituent parsing: the top-down and in-order transition-based parsers. In both cases, the dynamic oracles manage to notably increase their accuracy, in comparison to that obtained by performing classic static training. In addition, by improving the performance of the state-of-the-art in-order shift-reduce parser, we achieve the best accuracy to date (92.0 F1) obtained by a fully-supervised single-model greedy shift-reduce constituent parser on the WSJ benchmark.", "text_perturb": "We introduce fresh dynamic oracles for training two of the most accurate known shift-reduce algorithms for constituent parsing : the top-down and in-order transition-based parsers. In both cases , the dynamical oracles manage to notably increase their accuracy , in comparison to that obtained by performing classic static training. In addition , by improving the performance of the state-of-the-art in-order shift-reduce parser , we achieve the best accuracy to day of the month ( 92. 0 F1 ) obtain by a fully-supervised single-model greedy shift-reduce constituent parser on the WSJ benchmark. ", "label": 1}
{"original_text": "We study the relationship between performance and practice by analyzing the activity of many players of a casual online game. We find significant heterogeneity in the improvement of player performance, given by score, and address this by dividing players into similar skill levels and segmenting each player's activity into sessions, i.e., sequence of game rounds without an extended break. After disaggregating data, we find that performance improves with practice across all skill levels. More interestingly, players are more likely to end their session after an especially large improvement, leading to a peak score in their very last game of a session. In addition, success is strongly correlated with a lower quitting rate when the score drops, and only weakly correlated with skill, in line with psychological findings about the value of persistence and \"grit\": successful players are those who persist in their practice despite lower scores. Finally, we train an -machine, a type of hidden Markov model, and find a plausible mechanism of game play that can predict player performance and quitting the game. Our work raises the possibility of real-time assessment and behavior prediction that can be used to optimize human performance.", "text_perturb": "We examine the relationship between performance and practice by analyzing the activity of many players of a casual online game. We find significant heterogeneity in the improvement of player performance , hand by score , and address this by dividing players into similar skill levels and segmenting each player 's activity into sessions , i. einsteinium. , sequence of game rounds without an prolonged break. After disaggregating data , we find that performance improves with practice across all accomplishment levels. More interestingly , players make up more likely to end their session after an especially large improvement , leading to a peak score in their very last game of a session. In addition , success is strongly correlated with a lower quitting rate when the score drops , and only weakly correlated with skill , in line with psychological determination about the value of persistence and `` grit '' : successful players are those who persist in their practice despite lower scores. Finally , we condition an -machine , a type of hidden Markov model , and find a plausible mechanism of game play that can predict player performance and quitting the game. Our work raises the possibility of real-time assessment and behavior foretelling that can be used to optimize human performance. ", "label": 1}
{"original_text": "Characterizing large online social networks (OSNs) through node querying is a challenging task. OSNs often impose severe constraints on the query rate, hence limiting the sample size to a small fraction of the total network. Various ad-hoc subgraph sampling methods have been proposed, but many of them give biased estimates and no theoretical basis on the accuracy. In this work, we focus on developing sampling methods for OSNs where querying a node also reveals partial structural information about its neighbors. Our methods are optimized for NoSQL graph databases (if the database can be accessed directly), or utilize Web API available on most major OSNs for graph sampling. We show that our sampling method has provable convergence guarantees on being an unbiased estimator, and it is more accurate than current state-of-the-art methods. We characterize metrics such as node label density estimation and edge label density estimation, two of the most fundamental network characteristics from which other network characteristics can be derived. We evaluate our methods on-the-fly over several live networks using their native APIs. Our simulation studies over a variety of offline datasets show that by including neighborhood information, our method drastically (4-fold) reduces the number of samples required to achieve the same estimation accuracy of state-of-the-art methods.", "text_perturb": "Characterizing big online social networks ( OSNs ) through node querying is a challenging task. OSNs often impose severe constraints on the enquiry rate , hence limiting the sample size to a small fraction of the total network. Various ad-hoc subgraph sampling methods have been proposed , but many of them give predetermine estimates and no theoretical basis on the accuracy. In this work , we focus on developing sampling methods for OSNs where query a node also reveals partial structural information about its neighbors. Our methods be optimized for NoSQL graph databases ( if the database can be accessed directly ) , or utilize Web API available on most major OSNs for graph sampling. We show that our sampling method ingest provable convergence guarantees on being an unbiased estimator , and it is more accurate than current state-of-the-art methods. We characterize prosody such as node label density estimation and edge label density estimation , two of the most fundamental network characteristics from which other network characteristics can be derived. We judge our methods on-the-fly over several live networks using their native APIs. Our simulation studies over a variety of offline datasets show that by including neighborhood info , our method drastically ( 4-fold ) reduces the number of samples required to achieve the same estimation accuracy of state-of-the-art methods. ", "label": 1}
{"original_text": "lettrine Lesion segmentation from the surrounding skin is the first task for developing automatic Computer-Aided Diagnosis of skin cancer. Variant features of lesion like uneven distribution of color, irregular shape, border and texture make this task challenging. The contribution of this paper is to present and compare two different approaches to skin lesion segmentation. The first approach uses watershed, while the second approach uses mean-shift. Pre-processing steps were performed in both approaches for removing hair and dark borders of microscopic images. The Evaluation of the proposed approaches was performed using Jaccard Index (Intersection over Union or IoU). An additional contribution of this paper is to present pipelines for performing pre-processing and segmentation applying existing segmentation and morphological algorithms which led to promising results. On average, the first approach showed better performance than the second one with average Jaccard Index over 200 ISIC-2017 challenge images are 89.16 and 76.94 respectively.", "text_perturb": "lettrine Lesion segmentation from the surrounding skin is the first task for developing automatonlike Computer-Aided Diagnosis of skin cancer. Variant features of lesion like uneven dispersion of color , irregular shape , border and texture make this task challenging. The contribution of this paper is to present and compare two different approaches to skin lesion partitioning. The first approach utilize watershed , while the second approach utilize mean-shift. Pre-processing steps were performed in both approaches for bump off hair and dark borders of microscopic images. The Evaluation of the proposed approaches make up performed using Jaccard Index ( Intersection over Union or IoU ). An additional contribution of this paper is to present pipelines for performing pre-processing and sectionalisation applying existing sectionalisation and morphological algorithms which led to promising results. On average , the first approach showed better carrying out than the second one with average Jaccard Index over 200 ISIC-2017 challenge images are 89. 16 and 76. 94 severally. ", "label": 1}
{"original_text": "What can we learn from a connectome? We constructed a simplified model of the first two stages of the fly visual system, the lamina and medulla. The resulting hexagonal lattice convolutional network was trained using backpropagation through time to perform object tracking in natural scene videos. Networks initialized with weights from connectome reconstructions automatically discovered well-known orientation and direction selectivity properties in T4 neurons and their inputs, while networks initialized at random did not. Our work is the first demonstration, that knowledge of the connectome can enable in silico predictions of the functional properties of individual neurons in a circuit, leading to an understanding of circuit function from structure alone.", "text_perturb": "What fire we learn from a connectome ? We constructed a simplified model of the first two stages of the fly visual system , the lamina and medulla. The resulting hexagonal lattice convolutional network was trained using backpropagation through time to perform object tracking in natural prospect videos. mesh initialized with weights from connectome reconstructions automatically discovered well-known orientation and direction selectivity properties in T4 neurons and their inputs , while networks initialized at random did not. Our work is the first demonstration , that knowledge of the connectome can enable in silico predictions of the functional properties of individual neurons in a tour , leading to an understanding of tour function from structure alone. ", "label": 1}
{"original_text": "Much of recent success in multiagent reinforcement learning has been in two-player zero-sum games. In these games, algorithms such as fictitious self-play and minimax tree search can converge to an approximate Nash equilibrium. While playing a Nash equilibrium strategy in a two-player zero-sum game is optimal, in an n -player general sum game, it becomes a much less informative solution concept. Despite the lack of a satisfying solution concept, n -player games form the vast majority of real-world multiagent situations. In this paper we present a new framework for research in reinforcement learning in n -player games. We hope that by analyzing behavior learned by agents in these environments the community can better understand this important research area and move toward meaningful solution concepts and research directions. The implementation and additional information about this framework can be found at .", "text_perturb": "Much of recent success in multiagent reenforcement learning has been in two-player zero-sum games. In these games , algorithms such as fictitious self-play and minimax tree search can converge to an approximate ogden nash equilibrium. While playing a Nash equilibrium strategy in a two-player zero-sum game is optimal , in an n -player general marrow game , it becomes a much less informative solution concept. Despite the lack of a satisfying solution concept , n -player games form the brobdingnagian majority of real-world multiagent situations. In this paper we pose a new framework for research in reinforcement learning in n -player games. We hope that by analyzing behavior learned by broker in these environments the community can better understand this important research area and move toward meaningful solution concepts and research directions. The effectuation and additional information about this framework can be found at. ", "label": 1}
{"original_text": "We developed a Statistical Automatic Post-Editing (SAPE) system that works on Machine Translation (MT) output. A hybrid word alignment model was employed into the SAPE system. The proposed hybrid approach combines different word alignment tables and provides the well estimated alignment links to the SAPE system. This also allows the proposed system to correct lexical errors, erroneous words using insertion and deletion, as well as word ordering. We carried out the experiments on parallel dataset consisting of English text, Spanish MT output and corresponding post-edited output. In this paper, we have also applied the Hierarchical Phrase Based SMT (HPBSMT) to the SAPE system. It has to be mentioned that the output of our SAPE system not only provides better translations than the standard MT output, but also reduces the post-editing efforts as per the evaluation done with respect to different MT evaluation metrics (BLEU, TER and METEOR).", "text_perturb": "We developed a Statistical Automatic Post-Editing ( SAPE ) system that works on automobile Translation ( MT ) output. A hybrid word alignment model personify employed into the SAPE system. The proposed hybrid approach combines different word alliance tables and provides the well estimated alignment links to the SAPE system. This also allows the proposed system to correct lexical errors , erroneous words using insertion and deletion , as well as word order. We carried out the experiments on parallel dataset consisting of english language text , Spanish MT output and corresponding post-edited output. In this paper , we have also applied the Hierarchical Phrase Based SMT ( HPBSMT ) to the SAPE scheme. It has to be mentioned that the output of our SAPE system not only provides better translations than the standard MT output , but also reduces the post-editing efforts as per the evaluation done with respect to different MT evaluation metric unit ( BLEU , TER and METEOR ). ", "label": 1}
{"original_text": "Object detection has been vigorously investigated for years but fast accurate detection for real-world scenes remains a very challenging problem. Overcoming drawbacks of single-stage detectors, we take aim at precisely detecting objects for static and temporal scenes in real time. Firstly, as a dual refinement mechanism, a novel anchor-offset detection is designed, which includes an anchor refinement, a feature location refinement, and a deformable detection head. This new detection mode is able to simultaneously perform two-step regression and capture accurate object features. Based on the anchor-offset detection, a dual refinement network (DRNet) is developed for high-performance static detection, where a multi-deformable head is further designed to leverage contextual information for describing objects. As for temporal detection in videos, temporal refinement networks (TRNet) and temporal dual refinement networks (TDRNet) are developed by propagating the refinement information across time. We also propose a soft refinement strategy to temporally match object motion with the previous refinement. Our proposed methods are evaluated on PASCAL VOC, COCO, and ImageNet VID datasets. Extensive comparisons on static and temporal detection verify the superiority of DRNet, TRNet, and TDRNet. Consequently, our developed approaches run in a fairly fast speed, and in the meantime achieve a significantly enhanced detection accuracy, i.e., 84.4 mAP on VOC 2007, 83.6 mAP on VOC 2012, 69.4 mAP on VID 2017, and 42.4 AP on COCO. Ultimately, producing encouraging results, our methods are applied to online underwater object detection and grasping with an autonomous system. Codes are publicly available at", "text_perturb": "Object signal detection has been vigorously investigated for years but fast accurate signal detection for real-world scenes remains a very challenging problem. Overcoming drawback of single-stage detectors , we take aim at precisely detecting objects for static and temporal scenes in real time. Firstly , as a dual refinement mechanism , a novel anchor-offset detection is designed , which includes an anchor refinement , a feature location refinement , and a deformable detection headway. This new detection modality is able to simultaneously perform two-step regression and capture accurate object features. Based on the anchor-offset sensing , a dual refinement network ( DRNet ) is developed for high-performance static sensing , where a multi-deformable head is further designed to leverage contextual information for describing objects. As for worldly detection in videos , worldly refinement networks ( TRNet ) and worldly dual refinement networks ( TDRNet ) are developed by propagating the refinement information across time. We also propose a soft cultivation strategy to temporally match object motion with the previous cultivation. Our proposed methods are evaluated on PASCAL VOC , cocos nucifera , and ImageNet VID datasets. Extensive compare on static and temporal detection verify the superiority of DRNet , TRNet , and TDRNet. Consequently , our developed approaches run in a fairly fast speed , and in the meantime achieve a importantly enhanced detection accuracy , i. due east. , 84. 4 map on VOC 2007 , 83. 6 mAP on VOC 2012 , 69. 4 mapping on VID 2017 , and 42. 4 AP on coconut. Ultimately , producing encouraging results , our methods are applied to online underwater object detecting and grasping with an autonomous system. Codes are publicly useable at", "label": 1}
{"original_text": "In partially observable (PO) environments, deep reinforcement learning (RL) agents often suffer from unsatisfactory performance, since two problems need to be tackled together: how to extract information from the raw observations to solve the task, and how to improve the policy. In this study, we propose an RL algorithm for solving PO tasks. Our method comprises two parts: a variational recurrent model (VRM) for modeling the environment, and an RL controller that has access to both the environment and the VRM. The proposed algorithm was tested in two types of PO robotic control tasks, those in which either coordinates or velocities were not observable and those that require long-term memorization. Our experiments show that the proposed algorithm achieved better data efficiency andor learned more optimal policy than other alternative approaches in tasks in which unobserved states cannot be inferred from raw observations in a simple manner 1 footnote 1 1 footnote 1 Codes are available at", "text_perturb": "In partially observable ( PO ) environments , deep reinforcement learning ( RL ) agents often suffer from unsatisfactory performance , since two problems need to be tackled together : how to extract data from the raw observations to solve the task , and how to improve the policy. In this study , we propose an RL algorithm for solving PO job. Our method comprises two parts : a variational recurrent model ( VRM ) for modeling the environs , and an RL controller that has access to both the environs and the VRM. The proposed algorithm was tested in two types of PO robotic control tasks , those in which either coordinates or velocities personify not observable and those that require long-term memorization. Our experiment show that the proposed algorithm achieved better data efficiency andor learned more optimal policy than other alternative approaches in tasks in which unobserved states can not be inferred from raw observations in a simple manner 1 footnote 1 1 footnote 1 Codes are available at", "label": 1}
{"original_text": "We evaluate chemical patent word embeddings against known biomedical embeddings and show that they outperform the latter extrinsically and intrinsically. We also show that using contextualized embeddings can induce predictive models of reasonable performance for this domain over a relatively small gold standard.", "text_perturb": "We evaluate chemical patent word embeddings against known biomedical embeddings and show that they surmount the latter extrinsically and intrinsically. We also show that using contextualized embeddings can bring on predictive models of reasonable performance for this domain over a relatively small gold standard. ", "label": 1}
{"original_text": "A fundamental part of data visualization is transforming data to map abstract information onto visual attributes. While this abstraction is a powerful basis for data visualization, the connection between the representation and the original underlying data (i.e., what the quantities and measurements actually correspond with in reality) can be lost. On the other hand, virtual reality (VR) is being increasingly used to represent real and abstract models as natural experiences to users. In this work, we explore the potential of using VR to help restore the basic understanding of units and measures that are often abstracted away in data visualization in an approach we call data visceralization. By building VR prototypes as design probes, we identify key themes and factors for data visceralization. We do this first through a critical reflection by the authors, then by involving external participants. We find that data visceralization is an engaging way of understanding the qualitative aspects of physical measures and their real-life form, which complements analytical and quantitative understanding commonly gained from data visualization. However, data visceralization is most effective when there is a one-to-one mapping between data and representation, with transformations such as scaling affecting this understanding. We conclude with a discussion of future directions for data visceralization.", "text_perturb": "A fundamental part of data visualization is transforming data to map abstract information onto ocular attributes. While this abstract entity is a powerful basis for data visualization , the connection between the representation and the original underlying data ( i. einsteinium. , what the quantities and measurements in reality correspond with in reality ) can be lost. On the other hand , virtual reality ( VR ) is being increasingly used to represent real and abstract mannequin as natural experiences to users. In this work , we explore the potential of using VR to assist restore the basic understanding of units and measures that are often abstracted away in data visualization in an approach we call data visceralization. By building VR prototypes as design probes , we identify key themes and ingredient for data visceralization. We do this first through a critical reflection by the generator , then by involving external participants. We find that data visceralization is an engaging means of understanding the qualitative aspects of physical measures and their real-life form , which complements analytical and quantitative understanding commonly gained from data visualization. However , data visceralization is most in force when there is a one-to-one mapping between data and representation , with transformations such as scaling affecting this understanding. We conclude with a discussion of future focusing for data visceralization. ", "label": 1}
{"original_text": "Automotive companies increasingly adopt scaled agile methods to allow them to deal with their organisational and product complexity. Suitable methods are needed to ensure safety when developing automotive systems. On a small scale, R-Scrum and SafeScrum are two concrete suggestions for how to develop safety-critical systems using agile methods. However, for large-scale environments, existing frameworks like SAFe or LeSS do not support the development of safety-critical systems out of the box. We, therefore, aim to understand which challenges exist when developing safety-critical systems within large-scale agile industrial settings, in particular in the automotive domain. Based on an analysis of R-Scrum and SafeScrum , we conducted a focus group with three experts from industry to collect challenges in their daily work. We found challenges in the areas of living traceability, continuous compliance, and organisational flexibility. Among others, organisations struggle with defining a suitable traceability strategy, performing incremental safety analysis, and with integrating safety practices into their scaled way of working. Our results indicate a need to provide practical approaches to integrate safety work into large-scale agile development and point towards possible solutions, e.g., modular safety cases.", "text_perturb": "Automotive companies increasingly acquire scaled agile methods to allow them to deal with their organisational and product complexity. suited methods are needed to ensure safety when developing automotive systems. On a small scale , R-Scrum and SafeScrum are two concrete suggestions for how to develop safety-critical systems using spry methods. However , for large-scale environment , existing frameworks like SAFe or LeSS do not support the development of safety-critical systems out of the box. We , therefore , aim to understand which challenges exist when developing safety-critical systems within large-scale agile industrial settings , in particular in the self propelling domain. Based on an analysis of R-Scrum and SafeScrum , we conducted a focus group with three expert from industry to collect challenges in their daily work. We found challenges in the areas of support traceability , continuous compliance , and organisational flexibility. Among others , organisations struggle with defining a suitable traceability strategy , perform incremental safety analysis , and with integrating safety practices into their scaled way of working. Our results indicate a need to provide practical glide slope to integrate safety work into large-scale agile development and point towards possible solutions , e. m. , modular safety cases. ", "label": 1}
{"original_text": "This paper presents a new method for dynamic texture recognition based on spatiotemporal Gabor filters. Dynamic textures have emerged as a new field of investigation that extends the concept of self-similarity of texture image to the spatiotemporal domain. To model a dynamic texture, we convolve the sequence of images to a bank of spatiotemporal Gabor filters. For each response, a feature vector is built by calculating the energy statistic. As far as the authors know, this paper is the first to report an effective method for dynamic texture recognition using spatiotemporal Gabor filters. We evaluate the proposed method on two challenging databases and the experimental results indicate that the proposed method is a robust approach for dynamic texture recognition.", "text_perturb": "This paper presents a newfangled method for dynamic texture recognition based on spatiotemporal Gabor filters. Dynamic textures have emerged as a new field of investigation that extends the concept of self-similarity of texture range to the spatiotemporal domain. To model a dynamic texture , we convolve the sequence of figure of speech to a bank of spatiotemporal Gabor filters. For each response , a feature transmitter is built by calculating the energy statistic. As far as the authors recognize , this paper is the first to report an effective method for dynamic texture recognition using spatiotemporal Gabor filters. We evaluate the proposed method on two challenging databases and the observational results indicate that the proposed method is a robust approach for dynamic texture recognition. ", "label": 1}
{"original_text": "We propose a way to learn visual features that are compatible with previously computed ones even when they have different dimensions and are learned via different neural network architectures and loss functions. Compatible means that, if such features are used to compare images, then \"new\" features can be compared directly to \"old\" features, so they can be used interchangeably. This enables visual search systems to bypass computing new features for all previously seen images when updating the embedding models, a process known as backfilling. Backward compatibility is critical to quickly deploy new embedding models that leverage ever-growing large-scale training datasets and improvements in deep learning architectures and training methods. We propose a framework to train embedding models, called backward-compatible training (BCT), as a first step towards backward compatible representation learning. In experiments on learning embeddings for face recognition, models trained with BCT successfully achieve backward compatibility without sacrificing accuracy, thus enabling backfill-free model updates of visual embeddings.", "text_perturb": "We propose a way to learn visual features that are compatible with previously computed unity even when they have different dimensions and are learned via different neural network architectures and loss functions. Compatible means that , if such features are used to equate images , then `` new '' features can be compared directly to `` old '' features , so they can be used interchangeably. This enables visual search systems to bypass computing new features for all previously seen images when updating the embedding mannikin , a process known as backfilling. Backward compatibility is critical to quickly deploy new embedding models that leverage ever-growing large-scale grooming datasets and improvements in deep learning architectures and grooming methods. We propose a framework to train embedding models , called backward-compatible training ( BCT ) , as a first step towards rearward compatible representation learning. In experiments on memorise embeddings for face recognition , models trained with BCT successfully achieve backward compatibility without sacrificing accuracy , thus enabling backfill-free model updates of visual embeddings. ", "label": 1}
{"original_text": "Complex phenomena are generally modeled with sophisticated simulators that, depending on their accuracy, can be very demanding in terms of computational resources and simulation time. Their time-consuming nature, together with a typically vast parameter space to be explored, make simulation-based optimization often infeasible. In this work, we present a method that enables the optimization of complex systems through Machine Learning (ML) techniques. We show how well-known learning algorithms are able to reliably emulate a complex simulator with a modest dataset obtained from it. The trained emulator is then able to yield values close to the simulated ones in virtually no time. Therefore, it is possible to perform a global numerical optimization over the vast multi-dimensional parameter space, in a fraction of the time that would be required by a simple brute-force search. As a testbed for the proposed methodology, we used a network simulator for next-generation mmWave cellular systems. After simulating several antenna configurations and collecting the resulting network-level statistics, we feed it into our framework. Results show that, even with few data points, extrapolating a continuous model makes it possible to estimate the global optimum configuration almost instantaneously. The very same tool can then be used to achieve any further optimization goal on the same input parameters in negligible time.", "text_perturb": "Complex phenomenon are generally modeled with sophisticated simulators that , depending on their accuracy , can be very demanding in terms of computational resources and simulation time. Their time-consuming nature , together with a typically vast parameter space to be explored , micturate simulation-based optimization often infeasible. In this work , we present a method that enables the optimization of complex organisation through Machine Learning ( ML ) techniques. We record how well-known learning algorithms are able to reliably emulate a complex simulator with a modest dataset obtained from it. The trained emulator is then able to yield values close to the false ones in virtually no time. thus , it is possible to perform a global numerical optimization over the vast multi-dimensional parameter space , in a fraction of the time that would be required by a simple brute-force search. As a testbed for the proposed methodology , we use a network simulator for next-generation mmWave cellular systems. After copy several antenna configurations and collecting the resulting network-level statistics , we feed it into our framework. final result show that , even with few data points , extrapolating a continuous model makes it possible to estimate the global optimum configuration almost instantaneously. The very same tool can then be used to achieve any further optimization destination on the same input parameters in negligible time. ", "label": 1}
{"original_text": "In this paper, we propose a relaxation to the stochastic ruler method originally described by Yan and Mukai in 1992 for asymptotically determining the global optima of discrete simulation optimization problems. We show that our proposed variant of the stochastic ruler method provides accelerated convergence to the optimal solution by providing computational results for two example problems, each of which support the better performance of the variant of the stochastic ruler over the original. We then provide the theoretical grounding for the asymptotic convergence in probability of the variant to the global optimal solution under the same set of assumptions as those underlying the original stochastic ruler method.", "text_perturb": "In this paper , we propose a relaxation to the stochastic ruler method in the first place described by Yan and Mukai in 1992 for asymptotically determining the global optima of discrete simulation optimization problems. We show that our proposed variant of the stochastic ruler method provides accelerated intersection to the optimal solution by providing computational results for two example problems , each of which support the better performance of the variant of the stochastic ruler over the original. We then provide the theoretical grounding for the asymptotic convergence in probability of the variant to the global optimal solution under the same set of laying claim as those underlying the original stochastic ruler method. ", "label": 1}
{"original_text": "We consider a wide range of regularized stochastic minimization problems with two regularization terms, one of which is composed with a linear function. This optimization model abstracts a number of important applications in artificial intelligence and machine learning, such as fused Lasso, fused logistic regression, and a class of graph-guided regularized minimization. The computational challenges of this model are in two folds. On one hand, the closed-form solution of the proximal mapping associated with the composed regularization term or the expected objective function is not available. On the other hand, the calculation of the full gradient of the expectation in the objective is very expensive when the number of input data samples is considerably large. To address these issues, we propose a stochastic variant of extra-gradient type methods, namely Stochastic Primal-Dual Proximal ExtraGradient descent (SPDPEG), and analyze its convergence property for both convex and strongly convex objectives. For general convex objectives, the uniformly average iterates generated by SPDPEG converge in expectation with O (1 t) rate. While for strongly convex objectives, the uniformly and non-uniformly average iterates generated by SPDPEG converge with O (log (t) t) and O (1 t) rates, respectively. The order of the rate of the proposed algorithm is known to match the best convergence rate for first-order stochastic algorithms. Experiments on fused logistic regression and graph-guided regularized logistic regression problems show that the proposed algorithm performs very efficiently and consistently outperforms other competing algorithms.", "text_perturb": "We consider a extensive range of regularized stochastic minimization problems with two regularization terms , one of which is composed with a linear function. This optimization model abstracts a number of important applications in artificial intelligence and machine learning , such as fused Lasso , fused logistic regression , and a class of graph-guided regularized minimisation. The computational challenge of this model are in two folds. On one hand , the closed-form solution of the proximal mapping associated with the composed regularization term or the expected objective subprogram is not available. On the other hand , the calculation of the full gradient of the expectation in the objective make up very expensive when the number of input data samples make up considerably large. To address these issues , we suggest a stochastic variant of extra-gradient type methods , namely Stochastic Primal-Dual Proximal ExtraGradient descent ( SPDPEG ) , and analyze its convergence property for both convex and strongly convex objectives. For general convex objectives , the uniformly ordinary iterates generated by SPDPEG converge in expectation with O ( 1 t ) rate. While for strongly convex objectives , the uniformly and non-uniformly average iterates generated by SPDPEG converge with O ( log ( tonne ) tonne ) and O ( 1 tonne ) rates , respectively. The order of the rate of the proposed algorithm be known to match the best convergence rate for first-order stochastic algorithms. experiment on fused logistic regression and graph-guided regularized logistic regression problems show that the proposed algorithm performs very efficiently and consistently outperforms other competing algorithms. ", "label": 1}
{"original_text": "We study detection of random signals corrupted by noise that over time switchtheir values (states) from a finite set of possible values, where theswitchings occur at unknown points in time. We model such signals by means of arandom duration model that to each possible state assigns a probability massfunction which controls the statistics of durations of that state occurrences.Assuming two possible signal states and Gaussian noise, we derive optimallikelihood ratio test and show that it has a computationally tractable form ofa matrix product, with the number of matrices involved in the product being thenumber of process observations. Each matrix involved in the product is ofdimension equal to the sum of durations spreads of the two states, and it canbe decomposed as a product of a diagonal random matrix controlled by theprocess observations and a sparse constant matrix which governs transitions inthe sequence of states. Using this result, we show that the Neyman-Pearsonerror exponent is equal to the top Lyapunov exponent for the correspondingrandom matrices. Using theory of large deviations, we derive a lower bound onthe error exponent. Finally, we show that this bound is tight by means ofnumerical simulations.", "text_perturb": "We study detection of random signals deprave by noise that over time switchtheir values ( states ) from a finite set of possible values , where theswitchings occur at unknown points in time. We model such signals by means of arandom length model that to each possible state assigns a probability massfunction which controls the statistics of durations of that state occurrences. Assuming two possible signal states and Gaussian noise , we derive optimallikelihood ratio mental testing and show that it has a computationally tractable form ofa matrix product , with the number of matrices involved in the product being thenumber of process observations. Each matrix involved in the product is ofdimension equal to the sum of durations spreads of the two states , and it canbe decomposed as a product of a diagonal random matrix controlled by theprocess watching and a sparse constant matrix which governs transitions inthe sequence of states. Using this result , we show that the Neyman-Pearsonerror exponent live equal to the top Lyapunov exponent for the correspondingrandom matrices. Using theory of large deviations , we derive a lower bound onthe erroneousness exponent. ultimately , we show that this bound is tight by means ofnumerical simulations. ", "label": 1}
{"original_text": "Despite continuously improving performance, contemporary image captioning models are prone to \"hallucinating\" objects that are not actually in a scene. One problem is that standard metrics only measure similarity to ground truth captions and may not fully capture image relevance. In this work, we propose a new image relevance metric to evaluate current models with veridical visual labels and assess their rate of object hallucination. We analyze how captioning model architectures and learning objectives contribute to object hallucination, explore when hallucination is likely due to image misclassification or language priors, and assess how well current sentence metrics capture object hallucination. We investigate these questions on the standard image captioning benchmark, MSCOCO, using a diverse set of models. Our analysis yields several interesting findings, including that models which score best on standard sentence metrics do not always have lower hallucination and that models which hallucinate more tend to make errors driven by language priors.", "text_perturb": "Despite continuously improving performance , contemporary image captioning models constitute prone to `` hallucinating '' objects that constitute not actually in a scene. One problem is that standard metrics only measure similarity to ground truth captions and may not fully capture figure of speech relevance. In this work , we propose a new image relevancy metric to evaluate current models with veridical visual labels and assess their rate of object hallucination. We analyze how captioning model architectures and learning objectives contribute to object hallucination , explore when hallucination is likely due to image misclassification or language priors , and assess how well current condemnation metrics capture object hallucination. We investigate these questions on the standard look alike captioning benchmark , MSCOCO , using a diverse set of models. Our analysis yields several interesting findings , including that modelling which score best on standard sentence metrics do not always have lower hallucination and that modelling which hallucinate more tend to make errors driven by language priors. ", "label": 1}
{"original_text": "In a multi-agent pathfinding (MAPF) problem, agents need to navigate from their start to their goal locations without colliding into each other. There are various MAPF algorithms, including Windowed Hierarchical Cooperative A, Flow Annotated Replanning, and Bounded Multi-Agent A. It is often the case that there is no single algorithm that dominates all MAPF instances. Therefore, in this paper, we investigate the use of deep learning to automatically select the best MAPF algorithm from a portfolio of algorithms for a given MAPF problem instance. Empirical results show that our automatic algorithm selection approach, which uses an off-the-shelf convolutional neural network, is able to outperform any individual MAPF algorithm in our portfolio.", "text_perturb": "In a multi-agent pathfinding ( MAPF ) problem , agents call for to navigate from their start to their goal locations without colliding into each other. There are various MAPF algorithms , let in Windowed Hierarchical Cooperative A , Flow Annotated Replanning , and Bounded Multi-Agent A. It make up often the case that there make up no single algorithm that dominates all MAPF instances. Therefore , in this paper , we investigate the use of deep learning to automatically select the best MAPF algorithm from a portfolio of algorithmic rule for a given MAPF problem instance. Empirical results show that our automatic algorithm selection approach , which uses an off the peg convolutional neural network , is able to outperform any individual MAPF algorithm in our portfolio. ", "label": 1}
{"original_text": "The matrix version of the entropy-power inequality for real or complex coefficients and variables is proved using a transportation argument that easily settles the equality case. An application to blind source extraction is given.", "text_perturb": "The matrix version of the entropy-power inequality for real or complex coefficients and variables is proved using a transportation argument that easily settles the par case. An application to blind source origin is given. ", "label": 1}
{"original_text": "The effects of adding pitch and voice quality features such as jitter and shimmer to a state-of-the-art CNN model for Automatic Speech Recognition are studied in this work. Pitch features have been previously used for improving classical HMM and DNN baselines, while jitter and shimmer parameters have proven to be useful for tasks like speaker or emotion recognition. Up to our knowledge, this is the first work combining such pitch and voice quality features with modern convolutional architectures, showing improvements up to 7 and 3 relative WER points, for the publicly available Spanish Common Voice and LibriSpeech 100h datasets, respectively. Particularly, our work combines these features with mel-frequency spectral coefficients (MFSCs) to train a convolutional architecture with Gated Linear Units (Conv GLUs). Such models have shown to yield small word error rates, while being very suitable for parallel processing for online streaming recognition use cases. We have added pitch and voice quality functionality to Facebook's wav2letter speech recognition framework, and we provide with such code and recipes to the community, to carry on with further experiments. Besides, to the best of our knowledge, our Spanish Common Voice recipe is the first public Spanish recipe for wav2letter.", "text_perturb": "The effects of adding pitch and articulation quality features such as jitter and shimmer to a state-of-the-art CNN model for Automatic Speech Recognition are studied in this work. Pitch features have been previously used for improving classical HMM and DNN baselines , while jitter and shimmer parameters have proven to be utilitarian for tasks like speaker or emotion recognition. Up to our knowledge , this is the first work combining such pitch and voice quality features with modern convolutional architectures , designate improvements up to 7 and 3 relative WER points , for the publicly available Spanish Common Voice and LibriSpeech 100h datasets , respectively. Particularly , our work combines these feature of speech with mel-frequency spectral coefficients ( MFSCs ) to train a convolutional architecture with Gated Linear Units ( Conv GLUs ). Such models have shown to yield small intelligence error rates , while being very suitable for parallel processing for online streaming recognition use cases. We have added pitch and voice quality functionality to Facebook 's wav2letter speech recognition framework , and we provide with such code and recipes to the community of interests , to carry on with further experiments. Besides , to the best of our knowledge , our Spanish green Voice recipe is the first public Spanish recipe for wav2letter. ", "label": 1}
{"original_text": "In the authors present a set of integer programs (IPs) for the Steiner tree problem, which can be used for both, the directed and the undirected setting of the problem. Each IP finds an optimal Steiner tree with a specific structure. A solution with the lowest cost, corresponds to an optimal solution to the entire problem. The authors show that the linear programming relaxation of each IP is integral and, also, that each IP is polynomial in the size of the instance, consequently, they can be solved in polynomial time. The main issue is that the number of IPs to solve grows exponentially with the number of terminal nodes, which makes this approach impractical for large instances. In this paper, we propose a local search procedure to solve the directed Steiner tree problem using the approach presented in. In order to do this, we present a dynamic programming algorithm to solve each IP efficiently. Then we provide a characterization of the neighborhood of each tree structure. Finally, we use the proposed algorithm and the neighborhood characterization to solve the problem using a simulated annealing framework. Computational experiments show that the quality of the solutions delivered by our approach is better than the ones presented in the literature for the directed Steiner tree problem.", "text_perturb": "In the authors present a set of integer programs ( informatics ) for the Steiner tree problem , which can be used for both , the directed and the undirected setting of the problem. Each IP finds an optimal Steiner tree with a specific social organization. A solution with the last cost , corresponds to an optimal solution to the entire problem. The authors show that the analogue programming relaxation of each IP is integral and , also , that each IP is polynomial in the size of the instance , consequently , they can be solved in polynomial time. The main issue is that the routine of IPs to solve grows exponentially with the routine of terminal nodes , which makes this approach impractical for large instances. In this paper , we nominate a local search procedure to solve the directed Steiner tree problem using the approach presented in. In order to behave this , we present a dynamic programming algorithm to solve each IP efficiently. Then we provide a characterization of the neighborhood of each tree diagram structure. Finally , we use the proposed algorithm and the neighborhood characterization to solve the problem using a faux annealing framework. Computational experiments show that the quality of the solutions delivered by our approach is better than the ones presented in the lit for the directed Steiner tree problem. ", "label": 1}
{"original_text": "The Turing Machine is the paradigmatic case of computing machines, but there are others, such as Artificial Neural Networks, Table Computing, Relational-Indeterminate Computing and diverse forms of analogical computing, each of which based on a particular underlying intuition of the phenomenon of computing. This variety can be captured in terms of system levels, re-interpreting and generalizing Newell's hierarchy, which includes the knowledge level at the top and the symbol level immediately below it. In this re-interpretation the knowledge level consists of human knowledge and the symbol level is generalized into a new level that here is called The Mode of Computing. Natural computing performed by the brains of humans and non-human animals with a developed enough neural system should be understood in terms of a hierarchy of system levels too. By analogy from standard computing machinery there must be a system level above the neural circuitry levels and directly below the knowledge level that is named here The mode of Natural Computing. A central question for Cognition is the characterization of this mode. The Mode of Computing provides a novel perspective on the phenomena of computing, interpreting, the representational and non-representational views of cognition, and consciousness.", "text_perturb": "The Turing Machine is the paradigmatic case of computing machines , but there are others , such as Artificial Neural Networks , Table Computing , Relational-Indeterminate Computing and various forms of analogical computing , each of which based on a particular underlying intuition of the phenomenon of computing. This variety can be captured in terms of system levels , re-interpreting and generalizing Newell 's hierarchy , which includes the knowledge storey at the top and the symbol storey immediately below it. In this re-interpretation the knowledge level consists of human knowledge and the symbol level is generalize into a new level that here is called The Mode of Computing. Natural computing performed by the brains of humans and non-human animals with a developed plenty neural system should be understood in terms of a hierarchy of system levels too. By analogy from standard computing machinery there must be a system level above the neural circuitry levels and directly below the knowledge level that is named hither The mode of Natural Computing. A fundamental question for Cognition is the characterization of this mode. The Mode of Computing provides a novel perspective on the phenomena of reckon , interpreting , the representational and non-representational views of cognition , and consciousness. ", "label": 1}
{"original_text": "Bring Your Own Device (BYOD) has become the new norm in enterprise networks, but BYOD security remains a top concern. Context-aware security, which enforces access control based on dynamic runtime context, holds much promise. Recent work has developed SDN solutions to collect device context for network-wide access control in a central controller. However, the central controller poses a bottleneck that can become an attack target, and processing context changes at remote software has low agility. We present a new paradigm, programmable in-network security (Poise), which is enabled by the emergence of programmable switches. At the heart of Poise is a novel switch primitive, which can be programmed to support a wide range of context-aware policies in hardware. Users of Poise specify concise policies, and Poise compiles them into different instantiations of the security primitive in P4. Compared to centralized SDN defenses, Poise is resilient to control plane saturation attacks, and it dramatically increases defense agility.", "text_perturb": "Bring Your Own Device ( BYOD ) has become the new norm in enterprise networks , but BYOD protection remains a top concern. Context-aware security , which enforces access control based on dynamic runtime context , holds much hope. Recent work has developed SDN solutions to collect device context for network-wide access ascendence in a central controller. However , the central controller poses a bottleneck that can become an attack target , and treat context changes at remote software has low agility. We present a new paradigm , programmable in-network security ( Poise ) , which is enabled by the growth of programmable switches. At the heart of Poise cost a novel switch primitive , which can be programmed to support a wide range of context-aware policies in hardware. Users of Poise specify concise policies , and Poise compiles them into different instantiations of the security measure primitive in P4. equate to centralized SDN defenses , Poise is resilient to control plane saturation attacks , and it dramatically increases defense agility. ", "label": 1}
{"original_text": "Deep neuroevolution, that is evolutionary policy search methods based on deep neural networks, have recently emerged as a competitor to deep reinforcement learning algorithms due to their better parallelization capabilities. However, these methods still suffer from a far worse sample efficiency. In this paper we investigate whether a mechanism known as \"importance mixing\" can significantly improve their sample efficiency. We provide a didactic presentation of importance mixing and we explain how it can be extended to reuse more samples. Then, from an empirical comparison based on a simple benchmark, we show that, though it actually provides better sample efficiency, it is still far from the sample efficiency of deep reinforcement learning, though it is more stable.", "text_perturb": "Deep neuroevolution , that is evolutionary policy search methods based on deep neural electronic network , have recently emerged as a competitor to deep reinforcement learning algorithms due to their better parallelization capabilities. However , these methods still suffer from a far forged sample efficiency. In this paper we investigate whether a mechanism known as `` importance mixing '' can importantly improve their sample efficiency. We provide a didactic presentation of grandness mixing and we explain how it can be extended to reuse more samples. Then , from an empirical comparison based on a simple benchmark , we show that , though it actually provides better sample efficiency , it is still far from the sample efficiency of recondite reinforcement learning , though it is more stable. ", "label": 1}
{"original_text": "Design patterns are distilled from many real systems to catalog common programming practice. However, some object-oriented design patterns are distorted or overly complicated because of the lack of supporting programming language constructs or mechanisms. For this paper, we have analyzed several published design patterns looking for idiomatic ways of working around constraints of the implementation language. From this analysis, we lay a groundwork of general-purpose language constructs and mechanisms that, if provided by a statically typed, object-oriented language, would better support the implementation of design patterns and, transitively, benefit the construction of many real systems. In particular, our catalog of language constructs includes subtyping separate from inheritance, lexically scoped closure objects independent of classes, and multimethod dispatch. The proposed constructs and mechanisms are not radically new, but rather are adopted from a variety of languages and programming language research and combined in a new, orthogonal manner. We argue that by describing design patterns in terms of the proposed constructs and mechanisms, pattern descriptions become simpler and, therefore, accessible to a larger number of language communities. Constructs and mechanisms lacking in a particular language can be implemented using paradigmatic idioms.", "text_perturb": "Design patterns are distilled from many real systems to catalogue common programming practice. However , some object-oriented design patterns are distorted or overly complicated because of the lack of supporting programming linguistic process constructs or mechanisms. For this paper , we birth analyzed several published design patterns looking for idiomatic ways of working around constraints of the implementation language. From this analysis , we lay a groundwork of general-purpose speech constructs and mechanisms that , if provided by a statically typed , object-oriented speech , would better support the implementation of design patterns and , transitively , benefit the construction of many real systems. In particular , our catalog of language constructs includes subtyping separate from inheritance , lexically scoped closure objects independent of classes , and multimethod shipment. The proposed constructs and mechanisms are not radically fresh , but rather are adopted from a variety of languages and programming language research and combined in a fresh , orthogonal manner. We indicate that by describing design patterns in terms of the proposed constructs and mechanisms , pattern descriptions become simpler and , therefore , accessible to a larger number of language communities. Constructs and mechanisms lacking in a particular language can personify implemented using paradigmatic idioms. ", "label": 1}
{"original_text": "The reconstruction of the unknown acoustic source is studied using the noisy multiple frequency data on a remote closed surface. Assume that the unknown source is coded in a spatial dependent piecewise constant function, whose support set is the target to be determined. In this setting, the unknown source can be formalized by a level set function. The function is explored with Bayesian level set approach. To reduce the infinite dimensional problem to finite dimension, we parameterize the level set function by the radial basis expansion. The well-posedness of the posterior distribution is proven. The posterior samples are generated according to the Metropolis-Hastings algorithm and the sample mean is used to approximate the unknown. Several shapes are tested to verify the effectiveness of the proposed algorithm. These numerical results show that the proposed algorithm is feasible and competitive with the Matern random field for the acoustic source problem. Key words: Level set; Bayesian inversion; Acoustic source; Radial basis; Matern random field prior MSC 2010: 35R20, 65R20", "text_perturb": "The reconstruction of the unknown acoustic source equal studied using the noisy multiple frequency data on a remote closed surface. Assume that the unknown source represent coded in a spatial dependent piecewise constant function , whose support set represent the target to be determined. In this setting , the unknown source can be formalized by a level set purpose. The subprogram is explored with Bayesian level set approach. To reduce the infinite dimensional problem to finite dimension , we parameterize the level set function by the stellate basis expansion. The well-posedness of the posterior distribution constitute proven. The posterior samples comprise generated according to the Metropolis-Hastings algorithm and the sample mean is used to approximate the unknown. Several shapes are tested to verify the effectiveness of the proposed algorithmic program. These numerical results show that the proposed algorithm is feasible and competitive with the Matern random field for the acoustical source problem. Key words : Level set ; Bayesian inversion ; Acoustic rootage ; Radial basis ; Matern random field prior MSC 2010 : 35R20 , 65R20", "label": 1}
{"original_text": "Partial label learning (PLL) is a class of weakly supervised learning where each training instance consists of a data and a set of candidate labels containing a unique ground truth label. To tackle this problem, a majority of current state-of-the-art methods employs either label disambiguation or averaging strategies. So far, PLL methods without such techniques have been considered impractical. In this paper, we challenge this view by revealing the hidden power of the oldest and naivest PLL method when it is instantiated with deep neural networks. Specifically, we show that, with deep neural networks, the naive model can achieve competitive performances against the other state-of-the-art methods, suggesting it as a strong baseline for PLL. We also address the question of how and why such a naive model works well with deep neural networks. Our empirical results indicate that deep neural networks trained on partially labeled examples generalize very well even in the over-parametrized regime and without label disambiguations or regularizations. We point out that existing learning theories on PLL are vacuous in the over-parametrized regime. Hence they cannot explain why the deep naive method works. We propose an alternative theory on how deep learning generalize in PLL problems.", "text_perturb": "Partial label learning ( PLL ) is a class of weakly supervised learning where each training instance consists of a data and a set of candidate recording label containing a unique ground truth label. To tackle this problem , a majority of current state-of-the-art method acting employs either label disambiguation or averaging strategies. So far , PLL methods without such techniques have been considered laputan. In this paper , we take exception this view by revealing the hidden power of the oldest and naivest PLL method when it is instantiated with deep neural networks. Specifically , we show that , with deep neural networks , the naive model can achieve competitive performances against the other state-of-the-art method , suggesting it as a strong baseline for PLL. We also address the question of how and why such a naive model works well with deep nervous networks. Our empirical results indicate that deep neural networks trained on partially labeled examples generalize very well still in the over-parametrized regime and without label disambiguations or regularizations. We point out that existing learning theories on PLL equal vacuous in the over-parametrized regime. Hence they can not explain why the deep naive method plant. We propose an alternate theory on how deep learning generalize in PLL problems. ", "label": 1}
{"original_text": "Approximations of loopy belief propagation, including expectation propagation and approximate message passing, have attracted considerable attention for probabilistic inference problems. This paper proposes and analyzes a generalization of Opper and Winther's expectation consistent (EC) approximate inference method. The proposed method, called Generalized Expectation Consistency (GEC), can be applied to both maximum a posteriori (MAP) and minimum mean squared error (MMSE) estimation. Here we characterize its fixed points, convergence, and performance relative to the replica prediction of optimality.", "text_perturb": "Approximations of loopy belief propagation , including anticipation propagation and approximate message passing , have attracted considerable attention for probabilistic inference problems. This paper proposes and examine a generalization of Opper and Winther 's expectation consistent ( EC ) approximate inference method. The proposed method , called Generalized Expectation Consistency ( GEC ) , fire be applied to both maximum a posteriori ( MAP ) and minimum mean squared error ( MMSE ) estimation. Here we characterize its fixed points , overlap , and performance relative to the replica prediction of optimality. ", "label": 1}
{"original_text": "Reinforcement learning requires manual specification of a reward function to learn a task. While in principle this reward function only needs to specify the task goal, in practice reinforcement learning can be very time-consuming or even infeasible unless the reward function is shaped so as to provide a smooth gradient towards a successful outcome. This shaping is difficult to specify by hand, particularly when the task is learned from raw observations, such as images. In this paper, we study how we can automatically learn dynamical distances: a measure of the expected number of time steps to reach a given goal state from any other state. These dynamical distances can be used to provide well-shaped reward functions for reaching new goals, making it possible to learn complex tasks efficiently. We show that dynamical distances can be used in a semi-supervised regime, where unsupervised interaction with the environment is used to learn the dynamical distances, while a small amount of preference supervision is used to determine the task goal, without any manually engineered reward function or goal examples. We evaluate our method both on a real-world robot and in simulation. We show that our method can learn to turn a valve with a real-world 9-DoF hand, using raw image observations and just ten preference labels, without any other supervision. Videos of the learned skills can be found on the project website:", "text_perturb": "Reinforcement learning requires manual spec of a reward function to learn a task. While in principle this reward function only needs to specify the task goal , in practice reinforcement learning can make up very time-consuming or even infeasible unless the reward function is shaped so as to provide a smooth gradient towards a successful outcome. This shaping is difficult to specify by hand , particularly when the task is learned from raw observations , such as range. In this paper , we study how we can mechanically learn dynamical distances : a measure of the expected number of time steps to reach a given goal state from any other state. These dynamical distances can be used to provide well-shaped reward functions for reaching new goals , making it possible to discover complex tasks efficiently. We show that dynamical distances can be used in a semi-supervised regime , where unsupervised interaction with the environment is used to learn the dynamical distances , while a small amount of preference supervision is used to determine the task end , without any manually engineered reward function or end examples. We evaluate our method acting both on a real-world robot and in simulation. We show that our method can learn to turn a valve with a real-world 9-DoF helping hand , using raw image observations and just ten preference labels , without any other supervision. Videos of the learned skills can be institute on the project website :", "label": 1}
{"original_text": "Despite being the standard loss function to train multi-class neural networks, the log-softmax has two potential limitations. First, it involves computations that scale linearly with the number of output classes, which can restrict the size of problems that we are able to tackle with current hardware. Second, it remains unclear how close it matches the task loss such as the top-k error rate or other non-differentiable evaluation metrics which we aim to optimize ultimately. In this paper, we introduce an alternative classification loss function, the Z-loss, which is designed to address these two issues. Unlike the log-softmax, it has the desirable property of belonging to the spherical loss family (,), a class of loss functions for which training can be performed very efficiently with a complexity independent of the number of output classes. We show experimentally that it significantly outperforms the other spherical loss functions previously published and investigated. Furthermore, we show on a word language modeling task that it also outperforms the log-softmax with respect to certain ranking scores, such as top-k scores, suggesting that the Z-loss has the flexibility to better match the task loss. These qualities thus makes the Z-loss an appealing candidate to train very efficiently large output networks such as word-language models or other extreme classification problems. On the One Billion Word (,) dataset, we are able to train a model with the Z-loss 40 times faster than the log-softmax and more than 4 times faster than the hierarchical softmax.", "text_perturb": "Despite being the standard loss function to rail multi-class neural networks , the log-softmax has two potential limitations. First , it involves computations that scale linearly with the number of output classes , which can restrict the size of problems that we are able to tackle with current ironware. Second , it remains unclear how close it matches the task loss such as the top-k error rate or other non-differentiable rating metrics which we aim to optimize ultimately. In this paper , we introduce an alternative classification loss function , the Z-loss , which equal designed to address these two issues. Unlike the log-softmax , it has the desirable property of belonging to the spherical loss family ( , ) , a class of loss functions for which training can be performed real efficiently with a complexity independent of the number of output classes. We show experimentally that it significantly outperforms the other spherical loss functions previously bring out and investigated. Furthermore , we show on a word language modeling task that it also outperforms the log-softmax with respect to certain ranking oodles , such as top-k oodles , suggesting that the Z-loss has the flexibility to better match the task loss. These qualities thus makes the Z-loss an appealing prospect to train very efficiently large output networks such as word-language models or other extreme classification problems. On the One Billion Word ( , ) dataset , we are able to train a model with the Z-loss 40 times quicker than the log-softmax and more than 4 times quicker than the hierarchical softmax. ", "label": 1}
{"original_text": "In bipartite matching problems, vertices on one side of a bipartite graph are paired with those on the other. In its online variant, one side of the graph is available offline, while the vertices on the other side arrive online. When a vertex arrives, an irrevocable and immediate decision should be made by the algorithm; either match it to an available vertex or drop it. Examples of such problems include matching workers to firms, advertisers to keywords, organs to patients, and so on. Much of the literature focuses on maximizing the total relevance - modeled via total weight - of the matching. However, in many real-world problems, it is also important to consider contributions of diversity: hiring a diverse pool of candidates, displaying a relevant but diverse set of ads, and so on. In this paper, we propose the Online Submodular Bipartite Matching (OSBM) problem, where the goal is to maximize a submodular function f over the set of matched edges. This objective is general enough to capture the notion of both diversity (e.g., a weighted coverage function) and relevance (e.g., the traditional linear function) - as well as many other natural objective functions occurring in practice (e.g., limited total budget in advertising settings). We propose novel algorithms that have provable guarantees and are essentially optimal when restricted to various special cases. We also run experiments on real-world and synthetic datasets to validate our algorithms.", "text_perturb": "In bipartite matching problems , vertices on one side of a bipartite graphical record are paired with those on the other. In its online variant , one side of the graph is available offline , while the acme on the other side arrive online. When a vertex arrives , an irrevocable and immediate decision should be name by the algorithm ; either match it to an available vertex or drop it. Examples of such problems include matching workers to firms , advertisers to keywords , organs to patients , and then on. Much of the literature focuses on maximizing the total relevance - sit via total weight - of the matching. However , in many real-world problems , it is also important to consider contributions of diversity : hiring a diverse pool of candidate , displaying a relevant but diverse set of ads , and so on. In this paper , we propose the Online Submodular Bipartite Matching ( OSBM ) problem , where the goal embody to maximize a submodular function f over the set of matched edges. This objective is universal enough to capture the notion of both diversity ( e. gibibyte. , a weighted coverage function ) and relevancy ( e. gb. , the traditional linear occasion ) - as well as many other natural objective functions occurring in practice ( e. thou. , limited total budget in advertizing settings ). We propose novel algorithms that have provable guaranty and are essentially optimal when restricted to various special cases. We too run experiments on real-world and synthetic datasets to validate our algorithms. ", "label": 1}
{"original_text": "Complex models are commonly used in predictive modeling. In this paper we present R packages that can be used for explaining predictions from complex black box models and attributing parts of these predictions to input features. We introduce two new approaches and corresponding packages for such attribution, namely pkg live and pkg breakDown. We also compare their results with existing implementations of state-of-the-art solutions, namely pkg lime that implements Locally Interpretable Model-agnostic Explanations and pkg ShapleyR that implements Shapley values.", "text_perturb": "Complex models are normally used in predictive modeling. In this paper we present R packages that can be used for explaining prevision from complex black box models and attributing parts of these prevision to input features. We introduce two new approaches and equate packages for such attribution , namely pkg live and pkg breakDown. We also compare their result with existing implementations of state-of-the-art solutions , namely pkg lime that implements Locally Interpretable Model-agnostic Explanations and pkg ShapleyR that implements Shapley values. ", "label": 1}
{"original_text": "We aim to optimize a black-box function: f - X R under the assumption that f is Holder smooth and has bounded norm in the Reproducing Kernel Hilbert Space (RKHS) associated with a given kernel K. This problem is known to have an agnostic Gaussian Process (GP) bandit interpretation in which an appropriately constructed GP surrogate model with kernel K is used to obtain an upper confidence bound (UCB) algorithm. In this paper, we propose a new algorithm (LP-GP-UCB) where the usual GP surrogate model is augmented with Local Polynomial (LP) estimators of the Holder smooth function f to construct a multi-scale upper confidence bound guiding the search for the optimizer. We analyze this algorithm and derive high probability bounds on its simple and cumulative regret. We then prove that the elements of many common reproducing kernel Hilbert spaces are Holder smooth and obtain the corresponding Holder smoothness parameters, and hence, specialize our regret bounds for several commonly used and practically relevant kernels. When specialized to the Squared Exponential (SE) kernel, LP-GP-UCB matches the optimal performance, while for the case of Matern kernels (K n) n 0, it results in uniformly tighter regret bounds for all values of the smoothness parameter n 0. Most notably, for certain ranges of n, the algorithm achieves near-optimal bounds on simple and cumulative regrets, matching the algorithm-independent lower bounds up to poly-logarithmic factors, and thus closing the large gap between the existing upper and lower bounds for these values of n. Additionally, our analysis provides the first explicit regret bounds, in terms of the budget n, for the Rational-Quadratic (RQ) and Gamma-Exponential (GE). Finally, experiments with synthetic functions as well as a Convolutional Neural Network hyperparameter tuning task demonstrate the practical benefits of our multi-scale partitioning approach over some existing algorithms numerically.", "text_perturb": "We aim to optimize a black-box function : f - X R under the assumption that f is Holder smooth and has bounded norm in the Reproducing inwardness Hilbert Space ( RKHS ) associated with a given kernel K. This problem equal known to have an agnostic Gaussian Process ( GP ) bandit interpretation in which an appropriately constructed GP surrogate model with kernel K equal used to obtain an upper confidence bound ( UCB ) algorithm. In this paper , we propose a new algorithm ( LP-GP-UCB ) where the common GP surrogate model is augmented with Local Polynomial ( LP ) estimators of the Holder smooth function f to construct a multi-scale upper confidence bound guiding the search for the optimizer. We analyze this algorithmic program and derive high probability bounds on its simple and cumulative regret. We then prove that the elements of many common reproducing substance Hilbert spaces are Holder smooth and obtain the corresponding Holder smoothness parameters , and hence , specialize our regret bounds for several commonly used and practically relevant kernels. When specialized to the Squared Exponential ( SE ) kernel , LP-GP-UCB matches the optimal performance , while for the case of Matern kernels ( K n ) n 0 , it results in uniformly tighter regret bounds for all note value of the smoothness parameter n 0. Most notably , for certain ranges of n , the algorithm achieves near-optimal bounds on simple and accumulative regrets , matching the algorithm-independent lower bounds up to poly-logarithmic factors , and thus closing the large gap between the existing upper and lower bounds for these values of n. Additionally , our analysis provides the first explicit rue bounds , in terms of the budget n , for the Rational-Quadratic ( RQ ) and Gamma-Exponential ( GE ). Finally , experiments with synthetic functions as well as a Convolutional Neural Network hyperparameter tuning task demonstrate the practical benefit of our multi-scale partitioning approach over some existing algorithms numerically. ", "label": 1}
{"original_text": "This paper develops a Hoeffding inequality for the partial sums k 1 n f (X k), where {X k } k Z 0 is an irreducible Markov chain on a finite state space S, and: f - S [ a, b ] is a real-valued function. Our bound is simple, general, since it only assumes irreducibility and finiteness of the state space, and powerful. In order to demonstrate its usefulness we provide two applications in multi-armed bandit problems. The first is about identifying an approximately best Markovian arm, while the second is concerned with regret minimization in the context of Markovian bandits.", "text_perturb": "This paper develops a Hoeffding inequality for the partial sums k 1 n f ( X k ) , where { X k } k Z 0 is an irreducible Markov chain on a finite state blank S , and : f - S [ a , b ] is a real-valued function. Our bound is simple , general , since it only feign irreducibility and finiteness of the state space , and powerful. In order to demo its usefulness we provide two applications in multi-armed bandit problems. The st is about identifying an approximately best Markovian arm , while the second is concerned with regret minimization in the context of Markovian bandits. ", "label": 1}
{"original_text": "Most of the current action recognition algorithms are based on deep networks which stack multiple convolutional, pooling and fully connected layers. While convolutional and fully connected operations have been widely studied in the literature, the design of pooling operations that handle action recognition, with different sources of temporal granularity in action categories, has comparatively received less attention, and existing solutions rely mainly on max or averaging operations. The latter are clearly powerless to fully exhibit the actual temporal granularity of action categories and thereby constitute a bottleneck in classification performances. In this paper, we introduce a novel hierarchical pooling design that captures different levels of temporal granularity in action recognition. Our design principle is coarse-to-fine and achieved using a tree-structured network; as we traverse this network top-down, pooling operations are getting less invariant but timely more resolute and well localized. Learning the combination of operations in this network - which best fits a given ground-truth - is obtained by solving a constrained minimization problem whose solution corresponds to the distribution of weights that capture the contribution of each level (and thereby temporal granularity) in the global hierarchical pooling process. Besides being principled and well grounded, the proposed hierarchical pooling is also video-length and resolution agnostic. Extensive experiments conducted on the challenging UCF-101, HMDB-51 and JHMDB-21 databases corroborate all these statements.", "text_perturb": "Most of the current action recognition algorithmic rule are based on deep networks which stack multiple convolutional , pooling and fully connected layers. While convolutional and fully connected operations have been widely studied in the literature , the design of pooling operations that handle action mechanism recognition , with different sources of temporal granularity in action mechanism categories , has comparatively received less attention , and existing solutions rely mainly on max or averaging operations. The latter equal clearly powerless to fully exhibit the actual temporal granularity of action categories and thereby constitute a bottleneck in classification performances. In this paper , we introduce a novel hierarchical pooling design that captures different levels of worldly granularity in action recognition. Our design principle is coarse-to-fine and achieved using a tree-structured network ; as we traverse this network top-down , pooling operations personify getting less invariant but timely more resolute and well localized. Learning the combination of operations in this network - which best fits a given ground-truth - is obtained by solving a constrained minimization problem whose solution corresponds to the distribution of weights that capture the contribution of each level ( and thereby worldly granularity ) in the global hierarchical pooling process. Besides being principled and well grounded , the proposed hierarchical pooling is also video-length and closure agnostic. Extensive experiments conducted on the challenging UCF-101 , HMDB-51 and JHMDB-21 databases corroborate all these instruction. ", "label": 1}
{"original_text": "We show that for every l 1, there is a counterexample to the l -modular secrecy function conjecture by Oggier, Sole and Belfiore. These counterexamples all satisfy the modified conjecture by Ernvall-Hytonen and Sethuraman. Furthermore, we provide a method to prove or disprove the modified conjecture for any given l -modular lattice rationally equivalent to a suitable amount of copies of Z l Z with l {3, 5, 7, 11, 23 }. We also provide a variant of the method for strongly l -modular lattices when l {6, 14, 15 }.", "text_perturb": "We show that for every l 1 , there is a counterexample to the l -modular secrecy function guess by Oggier , Sole and Belfiore. These counterexample all satisfy the modified conjecture by Ernvall-Hytonen and Sethuraman. Furthermore , we provide a method to prove or disprove the modified conjecture for any given l -modular lattice rationally equivalent to a suitable measure of copies of Z l Z with l { 3 , 5 , 7 , 11 , 23 }. We also provide a variant of the method for strongly l -modular lattice when l { 6 , 14 , 15 }. ", "label": 1}
{"original_text": "We propose to classify the power of algorithms by the complexity of the problems that they can be used to solve. Instead of restricting to the problem a particular algorithm was designed to solve explicitly, however, we include problems that, with polynomial overhead, can be solved ' implicitly'during the algorithm's execution. For example, we allow to solve a decision problem by suitably transforming the input, executing the algorithm, and observing whether a specific bit in its internal configuration ever switches during the execution. We show that the Simplex Method, the Network Simplex Method (both with Dantzig's original pivot rule), and the Successive Shortest Path Algorithm are NP-mighty, that is, each of these algorithms can be used to solve any problem in NP. This result casts a more favorable light on these algorithms' exponential worst-case running times. Furthermore, as a consequence of our approach, we obtain several novel hardness results. For example, for a given input to the Simplex Algorithm, deciding whether a given variable ever enters the basis during the algorithm's execution and determining the number of iterations needed are both NP-hard problems. Finally, we close a long-standing open problem in the area of network flows over time by showing that earliest arrival flows are NP-hard to obtain.", "text_perturb": "We propose to classify the index of algorithms by the complexity of the problems that they can be used to solve. Instead of restricting to the problem a particular algorithm was designed to clear explicitly , however , we include problems that , with polynomial overhead , can be solved ' implicitly'during the algorithm 's execution. For example , we allow to solve a decision problem by suitably transforming the input , executing the algorithm , and keep whether a specific bit in its internal configuration ever switches during the execution. We designate that the Simplex Method , the Network Simplex Method ( both with Dantzig 's original pivot rule ) , and the Successive Shortest Path Algorithm are NP-mighty , that is , each of these algorithms can be used to solve any problem in NP. This result casts a more favorable brightness on these algorithms ' exponential worst-case running times. Furthermore , as a consequence of our approach , we get several novel hardness results. For example , for a given input to the Simplex Algorithm , deciding whether a given variable ever enters the basis during the algorithmic program 's execution and determining the number of iterations needed are both NP-hard problems. Finally , we shut down a long-standing open problem in the area of network flows over time by showing that earliest arrival flows are NP-hard to obtain. ", "label": 1}
{"original_text": "Predicting the structure of a protein from its sequence is a cornerstone task of molecular biology. Established methods in the field, such as homology modeling and fragment assembly, appeared to have reached their limit. However, this year saw the emergence of promising new approaches: end-to-end protein structure and dynamics models, as well as reinforcement learning applied to protein folding. For these approaches to be investigated on a larger scale, an efficient implementation of their key computational primitives is required. In this paper we present a library of differentiable mappings from two standard dihedral-angle representations of protein structure (full-atom representation \" ph, ps, o, kh \" and backbone-only representation \" ph, ps, o to atomic Cartesian coordinates. The source code and documentation can be found at", "text_perturb": "Predicting the structure of a protein from its sequence make up a cornerstone task of molecular biology. Established methods in the field , such as homology modeling and fragment assembly , appeared to have reached their terminus ad quem. However , this year saw the emergence of promising new approaches : end-to-end protein structure and dynamics models , as well as strengthener learning applied to protein folding. For these approaches to be investigated on a larger scale , an efficient implementation of their key computational primitives is take. In this paper we present a library of differentiable mappings from two standard dihedral-angle representations of protein structure ( full-atom representation `` ph , postscript , o , kh `` and backbone-only representation `` ph , postscript , o to atomic Cartesian coordinates. The source code and documentation can comprise found at", "label": 1}
{"original_text": "This work examines the possibility, performance limits, and associated costs for a self-sustained relay to transmit its own covert information to a destination on top of forwarding the source's information. Since the source provides energy to the relay for forwarding its information, the source does not allow the relay's covert transmission and is to detect it. Considering the time switching (TS) and power splitting (PS) schemes for energy harvesting, where all the harvested energy is used for transmission at the self-sustained relay, we derive the minimum detection error probability x at the source, based on which we determine the maximum effective covert rate Ps subject to a given covertness constraint on x . Our analysis shows that x is the same for the TS and PS schemes, which leads to the fact that the cost of achieving Ps in both the two schemes in terms of the required increase in the energy conversion efficiency at the relay is the same, although the values of Ps in these two schemes can be different in specific scenarios. For example, the TS scheme outperforms the PS scheme in terms of achieving a higher Ps when the transmit power at the source is relatively low. If the covertness constraint is tighter than a specific value, it is the covertness constraint that limits Ps , and otherwise it is upper bound on the energy conversion efficiency that limits Ps .", "text_perturb": "This work examines the possibility , performance limits , and associated costs for a self-sustained relay to transmit its ain covert information to a destination on top of forwarding the source 's information. Since the generator provides energy to the relay for forwarding its information , the generator does not allow the relay 's covert transmission and is to detect it. Considering the time switching ( TS ) and power splitting ( PS ) schemes for energy harvesting , where all the harvested energy is used for transmission at the self sustained relay , we derive the minimum detection error probability x at the source , based on which we determine the maximum effective covert rate Ps subject to a given covertness constraint on x. Our analysis shows that x is the same for the TS and PS schemes , which leads to the fact that the cost of achieving phosphorus in both the two schemes in terms of the required increase in the energy conversion efficiency at the relay is the same , although the values of phosphorus in these two schemes can be different in specific scenarios. For example , the TS scheme outperforms the PS scheme in terms of achieving a higher Ps when the transmit power at the root is relatively low. If the covertness constraint is tighter than a specific value , it is the covertness constraint that limits Ps , and otherwise it is upper leaping on the energy conversion efficiency that limits Ps. ", "label": 1}
{"original_text": "Large-scale machine learning training suffers from two prior challenges, specifically for nuclear-norm constrained problems with distributed systems: the synchronization slowdown due to the straggling workers, and high communication costs. In this work, we propose an asynchronous Stochastic Frank Wolfe (SFW-asyn) method, which, for the first time, solves the two problems simultaneously, while successfully maintaining the same convergence rate as the vanilla SFW. We implement our algorithm in python (with MPI) to run on Amazon EC2, and demonstrate that SFW-asyn yields speed-ups almost linear to the number of machines compared to the vanilla SFW.", "text_perturb": "Large-scale machine learning training suffers from two prior challenges , specifically for nuclear-norm constrained problems with distributed systems : the synchronization slowdown due to the straggling proletarian , and high communication costs. In this body of work , we propose an asynchronous Stochastic Frank Wolfe ( SFW-asyn ) method , which , for the first time , solves the two problems simultaneously , while successfully maintaining the same convergence rate as the vanilla SFW. We implement our algorithmic program in python ( with MPI ) to run on Amazon EC2 , and demonstrate that SFW-asyn yields speed-ups almost linear to the number of machines compared to the vanilla SFW. ", "label": 1}
{"original_text": "Audio-based cover song detection has received much attention in the MIR community in the recent years. To date, the most popular formulation of the problem has been to compare the audio signals of two tracks and to make a binary decision based on this information only. However, leveraging additional signals might be key if one wants to solve the problem at an industrial scale. In this paper, we introduce an ensemble-based method that approaches the problem from a many-to-many perspective. Instead of considering pairs of tracks in isolation, we consider larger sets of potential versions for a given composition, and create and exploit the graph of relationships between these tracks. We show that this can result in a significant improvement in performance, in particular when the number of existing versions of a given composition is large.", "text_perturb": "Audio-based cover song dynasty detection has received much attention in the MIR community in the recent years. To date , the almost popular formulation of the problem has been to compare the audio signals of two tracks and to make a binary decision based on this information only. However , leveraging additional signals might be key if one want to solve the problem at an industrial scale. In this paper , we introduce an ensemble-based method that near the problem from a many-to-many perspective. Instead of considering pairs of tracks in isolation , we consider larger sets of potential versions for a kick in composition , and create and exploit the graph of relationships between these tracks. We show that this can result in a significant improvement in performance , in particular when the number of existing versions of a throw composition is large. ", "label": 1}
{"original_text": "Principal components analysis (PCA) is the optimal linear auto-encoder of data, and it is often used to construct features. Enforcing sparsity on the principal components can promote better generalization, while improving the interpretability of the features. We study the problem of constructing optimal sparse linear auto-encoders. Two natural questions in such a setting are: (i) I item I Given a level of sparsity, what is the best approximation to PCA that can be achieved? (ii) ii item ii Are there low-order polynomial-time algorithms which can asymptotically achieve this optimal tradeoff between the sparsity and the approximation quality? In this work, we answer both questions by giving efficient low-order polynomial-time algorithms for constructing asymptotically optimal linear auto-encoders (in particular, sparse features with near-PCA reconstruction error) and demonstrate the performance of our algorithms on real data.", "text_perturb": "Principal components analysis ( PCA ) is the optimal linear auto-encoder of data point , and it is often used to construct features. Enforcing spareness on the principal components can promote better generalization , while improving the interpretability of the features. We study the problem of constructing optimal thin linear auto-encoders. Two natural questions in such a setting are : ( i ) I item I Given a level of sparsity , what is the best approximation to PCA that send away be achieved ? ( ii ) ii item ii Are there low-order polynomial-time algorithms which send away asymptotically achieve this optimal tradeoff between the sparsity and the approximation quality ? In this work , we answer both questions by giving efficient low-order polynomial-time algorithms for constructing asymptotically optimal linear auto-encoders ( in particular , sparse features with near-PCA reconstruction error ) and demonstrate the performance of our algorithms on real data. ", "label": 1}
{"original_text": "Filtered Smith predictors are well established for controlling linear plants with constant time delays. Apart from this classical application scenario, they are also employed within networked control loops, where the measurements are sent in separate packets over a transmission channel that is subject to time-varying delays. However, no stability guarantees can be given in this case. The present paper illustrates that the time-varying delays as well as the packetized character of the transmissions have to be taken into account for stability analysis. Hence, three network protocols, which use different packet selection and hold mechanisms, are considered. Criteria for robust stability of the networked feedback loop are given. They are based on the small gain theorem and allow a computationally inexpensive way to check stability for the case with bounded packet delays. Simulation examples provide insight into the presented approach and show why the inclusion of the time-varying packetized character of the network transmissions is vital for stability analysis.", "text_perturb": "filtrate Smith predictors are well established for controlling linear plants with constant time delays. Apart from this classical application scenario , they are also employed within networked control loops , where the measurements are sent in separate packets over a transmission channel that embody subject to time-varying delays. However , no stableness guarantees can be given in this case. The present paper illustrates that the time-varying delays as well as the packetized character of the transmissions have to be taken into account for stability analytic thinking. Hence , three network protocols , which use different packet selection and hold mechanisms , are study. Criteria for robust stability of the networked feedback loop live given. They are based on the small gain theorem and allow a computationally inexpensive way to check stability for the case with bounded packet postponement. Simulation examples provide insight into the presented approach and show why the inclusion of the time-varying packetized character of the network transmissions is vital for stability depth psychology. ", "label": 1}
{"original_text": "One of the long term goals of any college or university is increasing the student retention. The negative impact of student dropout are clear to students, parents, universities and society. The positive effect of decreasing studentattrition is also self-evident including higher chance of having a better career and higher standard of life for college graduate. In view of these reasons, directors in higher education feel increasingly pressurized to outline and implement strategies to increase student retention. In this paper, we provide a detailed analysis of the student attrition problem and use statistical methods to predict when students are going to dropout from school using real case data. Our work has a number of advantages with the potential of being employed by higher education administrator of universities. We take advantage of multiple kinds of information about different aspects of student's characteristic and efficiently utilize them to make a personalized decision about the risk of dropout for a particular student.", "text_perturb": "One of the recollective term goals of any college or university is increasing the student retention. The disconfirming impact of student dropout are clear to students , parents , universities and society. The positive effect of decreasing studentattrition is also self-evident including eminent chance of having a better career and eminent standard of life for college graduate. In persuasion of these reasons , directors in higher education feel increasingly pressurized to outline and implement strategies to increase student retention. In this paper , we provide a detailed analysis of the student attrition problem and use statistical methods to predict when students are operate to dropout from school using real case data. Our work has a number of advantages with the electric potential of being employed by higher education administrator of universities. We take advantage of multiple kinds of information about different aspects of student 's characteristic and expeditiously utilize them to make a personalized decision about the risk of dropout for a particular student. ", "label": 1}
{"original_text": "The rapid growth of multimedia consumption has triggered technical, economic, and business innovations that improve the quality and accessibility of content. It has also opened new markets, promising large revenues for industry players. However, new technologies also pose new questions regarding the legal aspects of content delivery, which are often resolved through litigation between copyright owners and content distributors. The precedents set by these cases will act as a game changer in the content delivery industry and will shape the existing offerings in the market in terms of how new technologies can be deployed and what kind of pricing strategies can be associated with them. In this paper, we offer a tutorial on key copyright and communications laws and decisions related to storage and transmission of video content over the Internet. We summarize legal limitations on the deployment of new technologies and pricing mechanisms, and explain the implications of recent lawsuits. Understanding these concerns is essential for engineers engaged in designing the technical and economic aspects of video delivery systems.", "text_perturb": "The rapid growing of multimedia consumption has triggered technical , economic , and business innovations that improve the quality and accessibility of content. It has also opened unexampled markets , promising large revenues for industry players. However , new technologies also pose new questions regarding the legal aspects of content delivery , which are often resolved through litigation between copyright owners and content distributer. The precedents set by these cases bequeath act as a game changer in the content delivery industry and bequeath shape the existing offerings in the market in terms of how new technologies can be deployed and what kind of pricing strategies can be associated with them. In this paper , we offer a tutorial on key copyright and communications natural law and decisions related to storage and transmission of video content over the Internet. We summarize legal limitations on the deployment of new technologies and pricing mechanisms , and explain the implications of recent cause. Understanding these concerns is essential for engineers engaged in plan the technical and economic aspects of video delivery systems. ", "label": 1}
{"original_text": "In this work, we study the problem of band allocation of M s buffered secondary users (SUs) to M p primary bands licensed to (owned by) M p buffered primary users (PUs). The bands are assigned to SUs in an orthogonal (one-to-one) fashion such that neither band sharing nor multi-band allocations are permitted. In order to study the stability region of the secondary network, the optimization problem used to obtain the stability region's envelope (closure) is established and is shown to be a linear program which can be solved efficiently and reliably. We compare our orthogonal allocation system with two typical low-complexity and intuitive band allocation systems. In one system, each cognitive user chooses a band randomly in each time slot with some assignment probability designed such that the system maintained stable, while in the other system fixed (deterministic) band assignment is adopted throughout the lifetime of the network. We derive the stability regions of these two systems. We prove mathematically, as well as through numerical results, the advantages of our proposed orthogonal system over the other two systems.", "text_perturb": "In this work , we study the problem of band allocation of M s buffered secondary users ( SUs ) to M phosphorus primary bands licensed to ( owned by ) M phosphorus buffered primary users ( PUs ). The ring are assigned to SUs in an orthogonal ( one-to-one ) fashion such that neither band sharing nor multi-band allocations are permitted. In order to study the stability region of the secondary network , the optimization problem used to obtain the stability region 's envelope ( closure ) is established and is shown to be a analog program which can be solved efficiently and reliably. We compare our orthogonal allocation system with two typical low-complexity and intuitive ring allocation systems. In one system , each cognitive user chooses a band randomly in each time slot with some assignment probability designed such that the system maintained stable , while in the early system fixed ( deterministic ) band assignment is adopted throughout the lifetime of the network. We descend the stability regions of these two systems. We prove mathematically , as well as through numerical results , the advantages of our proposed orthogonal system over the former two systems. ", "label": 1}
{"original_text": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.", "text_perturb": "We present an integrated framework for using Convolutional Networks for classification , localization and detecting. We show how a multiscale and skid window approach can be efficiently implemented within a ConvNet. We also premise a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated sooner than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single apportion network. This integrated framework is the winner of the localization task of the ImageNet Large ordered series Visual Recognition Challenge 2013 ( ILSVRC2013 ) and obtained very competitive results for the detection and classifications tasks. In post-competition work , we establish a new state of the art for the detection chore. Finally , we release a feature extractor from our skilful model called OverFeat. ", "label": 1}
{"original_text": "How can we approximate sparse graphs and sequences of sparse graphs (with average degree unbounded and o (n? We consider convergence in the first k moments of the graph spectrum (equivalent to the numbers of closed k -walks) appropriately normalized. We introduce a simple, easy to sample, random graph model that captures the limiting spectra of many sequences of interest, including the sequence of hypercube graphs. The Random Overlapping Communities (ROC) model is specified by a distribution on pairs (s, q), s Z , q (0, 1 ]. A graph on n vertices with average degree d is generated by repeatedly picking pairs (s, q) from the distribution, adding an Erdos-Renyi random graph of edge density q on a subset of vertices chosen by including each vertex with probability s n, and repeating this process so that the expected degree is d. Our proof of convergence to a ROC random graph is based on the Stieltjes moment condition. We also show that the model is an effective approximation for individual graphs. For almost all possible triangle-to-edge and four-cycle-to-edge ratios, there exists a pair (s, q) such that the ROC model with this single community type produces graphs with both desired ratios, a property that cannot be achieved by stochastic block models of bounded description size. Moreover, ROC graphs exhibit an inverse relationship between degree and clustering coefficient, a characteristic of many real-world networks.", "text_perturb": "How can we approximate sparse graphs and sequences of sparse graphs ( with average degree unbounded and o ( n ? We consider convergence in the first m moments of the graph spectrum ( equivalent to the numbers of closed m -walks ) appropriately normalized. We introduce a simple , easy to sample , random graph model that captures the limiting spectra of many chronological sequence of interest , including the sequence of hypercube graphs. The Random Overlapping Communities ( roc ) model is specified by a distribution on pairs ( s , q ) , s Z , q ( 0 , 1 ]. A graph on n vertices with average degree d be generated by repeatedly picking pairs ( s , q ) from the distribution , adding an Erdos-Renyi random graph of edge density q on a subset of vertices chosen by including each vertex with probability s n , and repeating this process so that the expected degree be d. Our proof of converging to a ROC random graph is based on the Stieltjes moment condition. We also show that the model is an effective approximation for individual graphical record. For almost all possible triangle-to-edge and four-cycle-to-edge ratios , there exists a pair ( s , q ) such that the ROC mannequin with this single community type produces graphs with both desired ratios , a property that can not be achieved by stochastic block models of bounded description size. Moreover , ROC graphs showing an inverse relationship between degree and clustering coefficient , a characteristic of many real-world networks. ", "label": 1}
{"original_text": "Normalizing flows transform a simple base distribution into a complex target distribution and have proved to be powerful models for data generation and density estimation. In this work, we propose a novel type of normalizing flow driven by a differential deformation of the continuous-time Wiener process. As a result, we obtain a rich time series model whose observable process inherits many of the appealing properties of its base process, such as efficient computation of likelihoods and marginals. Furthermore, our continuous treatment provides a natural framework for irregular time series with an independent arrival process, including straightforward interpolation. We illustrate the desirable properties of the proposed model on popular stochastic processes and demonstrate its superior flexibility to variational RNN and latent ODE baselines in a series of experiments on synthetic and real-world data.", "text_perturb": "Normalizing flows metamorphose a simple base distribution into a complex target distribution and have proved to be powerful models for data generation and density estimation. In this work , we propose a novel type of normalizing flow driven by a differential deformation of the continuous-time Wiener unconscious process. As a result , we obtain a rich meter series model whose observable process inherits many of the appealing properties of its base process , such as efficient computation of likelihoods and marginals. Furthermore , our uninterrupted treatment provides a natural framework for irregular time series with an independent arrival process , including straightforward interpolation. We illustrate the desirable properties of the proposed model on democratic stochastic processes and demonstrate its superior flexibility to variational RNN and latent ODE baselines in a series of experiments on synthetic and real-world data. ", "label": 1}
{"original_text": "Data-driven decision-making consequential to individuals raises important questions of accountability and justice. Indeed, European law provides individuals limited rights to 'meaningful information about the logic' behind significant, autonomous decisions such as loan approvals, insurance quotes, and CV filtering. We undertake three experimental studies examining people's perceptions of justice in algorithmic decision-making under different scenarios and explanation styles. Dimensions of justice previously observed in response to human decision-making appear similarly engaged in response to algorithmic decisions. Qualitative analysis identified several concerns and heuristics involved in justice perceptions including arbitrariness, generalisation, and (in) dignity. Quantitative analysis indicates that explanation styles primarily matter to justice perceptions only when subjects are exposed to multiple different styles - under repeated exposure of one style, scenario effects obscure any explanation effects. Our results suggests there may be no 'best' approach to explaining algorithmic decisions, and that reflection on their automated nature both implicates and mitigates justice dimensions.", "text_perturb": "Data-driven decision-making consequential to individuals raises important questions of accountability and judge. Indeed , European law provides individuals limited rights to 'meaningful information about the logic ' behind meaning , autonomous decisions such as loan approvals , insurance quotes , and CV filtering. We undertake three experimental studies examining multitude 's perceptions of justice in algorithmic decision-making under different scenarios and explanation styles. Dimensions of justice previously observed in response to human decision-making appear similarly lease in response to algorithmic decisions. Qualitative analysis identified several worry and heuristics involved in justice perceptions including arbitrariness , generalisation , and ( in ) dignity. Quantitative analysis indicates that explanation styles primarily matter to justice perceptions only when subjects are break to multiple different styles - under repeated exposure of one style , scenario effects obscure any explanation effects. Our results suggests there may be no 'best ' approach to explaining algorithmic decisions , and that reflection on their automated nature both implicates and mitigates justice proportion. ", "label": 1}
{"original_text": "Motivation: In the absence of horizontal gene transfer it is possible to reconstruct the history of gene families from empirically determined orthology relations, which are equivalent to event-labeled gene trees. Knowledge of the event labels considerably simplifies the problem of reconciling a gene tree T with a species trees S, relative to the reconciliation problem without prior knowledge of the event types. It is well-known that optimal reconciliations in the unlabeled case may violate time-consistency and thus are not biologically feasible. Here we investigate the mathematical structure of the event labeled reconciliation problem with horizontal transfer. Results: We investigate the issue of time-consistency for the event-labeled version of the reconciliation problem, provide a convenient axiomatic framework, and derive a complete characterization of time-consistent reconciliations. This characterization depends on certain weak conditions on the event-labeled gene trees that reflect conditions under which evolutionary events are observable at least in principle. We give an O (V (T) log (V (S) -time algorithm to decide whether a time-consistent reconciliation map exists. It does not require the construction of explicit timing maps, but relies entirely on the comparably easy task of checking whether a small auxiliary graph is acyclic. Significance: The combinatorial characterization of time consistency and thus biologically feasible reconciliation is an important step towards the inference of gene family histories with horizontal transfer from orthology data, i.e., without presupposed gene and species trees. The fast algorithm to decide time consistency is useful in a broader context because it constitutes an attractive component for all tools that address tree reconciliation problems.", "text_perturb": "Motivation : In the absence of horizontal gene transfer it is possible to reconstruct the chronicle of gene families from empirically determined orthology relations , which are equivalent to event-labeled gene trees. noesis of the event labels considerably simplifies the problem of reconciling a gene tree T with a species trees S , relative to the reconciliation problem without prior knowledge of the event types. It is well-known that optimal reconciliations in the unlabeled case may assault time-consistency and thus are not biologically feasible. Here we investigate the mathematical structure of the event labeled reconciliation job with horizontal transfer. Results : We investigate the issue of time-consistency for the event-labeled version of the balancing problem , provide a convenient axiomatic framework , and derive a complete characterization of time-consistent reconciliations. This characterization depends on certain weak conditions on the event-labeled cistron trees that reflect conditions under which evolutionary events are observable at least in principle. We give an O ( V ( thymine ) log ( V ( S ) -time algorithm to decide whether a time-consistent reconciliation map exists. It coif not require the construction of explicit timing maps , but relies entirely on the comparably easy task of checking whether a small auxiliary graph is acyclic. Significance : The combinative characterization of time consistency and thus biologically feasible reconciliation is an important step towards the inference of gene family histories with horizontal transfer from orthology data , i. eastward. , without presupposed cistron and species trees. The fast algorithm to decide time consistency is useful in a broader context because it constitutes an attractive component for all putz that address tree reconciliation problems. ", "label": 1}
{"original_text": "Most users of online services have unique behavioral or usage patterns. These behavioral patterns can be exploited to identify and track users by using only the observed patterns in the behavior. We study the task of identifying users from statistics of their behavioral patterns. Specifically, we focus on the setting in which we are given histograms of users' data collected during two different experiments. We assume that, in the first dataset, the users' identities are anonymized or hidden and that, in the second dataset, their identities are known. We study the task of identifying the users by matching the histograms of their data in the first dataset with the histograms from the second dataset. In recent works the optimal algorithm for this user identification task is introduced. In this paper, we evaluate the effectiveness of this method on three different types of datasets with up to 50, 000 users, and in multiple scenarios. Using datasets such as call data records, web browsing histories, and GPS trajectories, we demonstrate that a large fraction of users can be easily identified given only histograms of their data; hence these histograms can act as users' fingerprints. We also verify that simultaneous identification of users achieves better performance compared to one-by-one user identification. Furthermore, we show that using the optimal method for identification indeed gives higher identification accuracy than heuristics-based approaches in practical scenarios. The accuracy obtained under this optimal method can thus be used to quantify the maximum level of user identification that is possible in such settings. We show that the key factors affecting the accuracy of the optimal identification algorithm are the duration of the data collection, the number of users in the anonymized dataset, and the resolution of the dataset. We also analyze the effectiveness of k -anonymization in resisting user identification attacks on these datasets. 1 footnote 1 1 footnote 1 Following the principle of reproducible research, the code for performing user matching and for generating the figures related to the publicly available datasets are made available for download at rr.epfl.ch.", "text_perturb": "Most users of online services have unique behavioral or usage form. These behavioral patterns can be exploited to identify and track exploiter by using only the observed patterns in the behavior. We study the task of identifying exploiter from statistics of their behavioral patterns. Specifically , we focus on the setting in which we are given histograms of users ' data collected during two different experiment. We assume that , in the first dataset , the users ' identity element are anonymized or hidden and that , in the second dataset , their identity element are known. We study the task of identifying the users by matching the histograms of their information in the first dataset with the histograms from the second dataset. In late works the optimal algorithm for this user identification task is introduced. In this paper , we evaluate the effectiveness of this method on three unlike types of datasets with up to 50 , 000 users , and in multiple scenarios. Using datasets such as call data records , web browsing histories , and GPS trajectories , we demonstrate that a tumid fraction of users can be easily identified given only histograms of their data ; hence these histograms can act as users ' fingerprints. We also verify that simultaneous recognition of users achieves better performance compared to one-by-one user recognition. Furthermore , we show that using the optimal method for identification indeed gives higher identification accuracy than heuristics-based approaches in hard nosed scenarios. The accuracy obtained under this optimal method can thus be used to quantify the maximal level of user identification that is possible in such settings. We show that the key factors affecting the accuracy of the optimal identification algorithm are the duration of the data collecting , the number of users in the anonymized dataset , and the resolution of the dataset. We also analyze the effectiveness of k -anonymization in resisting user recognition attacks on these datasets. 1 footnote 1 1 footnote 1 Following the principle of reproducible research , the code for performing user matching and for generating the figures come to to the publicly available datasets are made available for download at rr. epfl. ch. ", "label": 1}
{"original_text": "We study alternating automata with qualitative semantics over infinite binary trees: alternation means that two opposing players construct a decoration of the input tree called a run, and the qualitative semantics says that a run of the automaton is accepting if almost all branches of the run are accepting. In this paper we prove a positive and a negative result for the emptiness problem of alternating automata with qualitative semantics. The positive result is the decidability of the emptiness problem for the case of Buchi acceptance condition. An interesting aspect of our approach is that we do not extend the classical solution for solving the emptiness problem of alternating automata, which first constructs an equivalent non-deterministic automaton. Instead, we directly construct an emptiness game making use of imperfect information. The negative result is the undecidability of the emptiness problem for the case of co-Buchi acceptance condition. This result has two direct consequences: the undecidability of monadic second-order logic extended with the qualitative path-measure quantifier, and the undecidability of the emptiness problem for alternating tree automata with non-zero semantics, a recently introduced probabilistic model of alternating tree automata.", "text_perturb": "We study alternating automata with qualitative semantics over infinite binary trees : alternation means that two opposing players construct a decoration of the input tree called a run , and the qualitative semantics says that a run of the automaton is swallow if almost all branches of the run are swallow. In this theme we prove a positive and a negative result for the emptiness problem of alternating automata with qualitative semantics. The positive result is the decidability of the vanity problem for the case of Buchi acceptance condition. An interesting aspect of our approach is that we do not extend the classical solution for solving the emptiness trouble of alternating automata , which first constructs an equivalent non-deterministic automaton. rather , we directly construct an emptiness game making use of imperfect information. The negative result is the undecidability of the emptiness problem for the case of co-Buchi espousal condition. This result has two direct consequence : the undecidability of monadic second-order logic extended with the qualitative path-measure quantifier , and the undecidability of the emptiness problem for alternating tree automata with non-zero semantics , a recently introduced probabilistic model of alternating tree automata. ", "label": 1}
{"original_text": "GPU accelerators have had a notable impact on high-performance computing across many disciplines. They provide high performance with low costpower, and therefore have become a primary compute resource on many of the largest supercomputers. Here, we implement multi-GPU acceleration into our Solar MHD code (MAS) using OpenACC in a fully portable, single-source manner. Our preliminary implementation is focused on MAS running in a reduced physics \"zero-beta\" mode. While valuable on its own, our main goal is to pave the way for a full physics, thermodynamic MHD implementation. We describe the OpenACC implementation methodology and challenges. \"Time-to-solution\" performance results of a production-level flux rope eruption simulation on multi-CPU and multi-GPU systems are shown. We find that the GPU-accelerated MAS code has the ability to run \"zero-beta\" simulations on a single multi-GPU server at speeds previously requiring multiple CPU server-nodes of a supercomputer.", "text_perturb": "GPU accelerators have had a famous impact on high-performance computing across many disciplines. They provide high performance with low costpower , and therefore have become a primary compute resource on many of the largest supercomputer. Here , we implement multi-GPU acceleration into our Solar MHD code ( mummy ) using OpenACC in a fully portable , single-source manner. Our preliminary implementation is focused on MAS running in a reduced aperient `` zero-beta '' mode. While valuable on its ain , our main goal is to pave the way for a full physics , thermodynamic MHD implementation. We describe the OpenACC implementation methodological analysis and challenges. `` Time-to-solution '' functioning results of a production-level flux rope eruption simulation on multi-CPU and multi-GPU systems are shown. We find that the GPU-accelerated MAS code has the ability to course `` zero-beta '' simulations on a single multi-GPU server at speeds previously requiring multiple CPU server-nodes of a supercomputer. ", "label": 1}
{"original_text": "Many NLP applications, such as biomedical data and technical support, have 10-100 million tokens of in-domain data and limited computational resources for learning from it. How should we train a language model in this scenario? Most language modeling research considers either a small dataset with a closed vocabulary (like the standard 1 million token Penn Treebank), or the whole web with byte-pair encoding. We show that for our target setting in English, initialising and freezing input embeddings using in-domain data can improve language model performance by providing a useful representation of rare words, and this pattern holds across several different domains. In the process, we show that the standard convention of tying input and output embeddings does not improve perplexity when initializing with embeddings trained on in-domain data.", "text_perturb": "Many NLP applications , such as biomedical data and technical support , consume 10-100 million tokens of in-domain data and limited computational resources for learning from it. How should we train a language model in this scenario ? Most language modeling research considers either a humble dataset with a closed vocabulary ( like the standard 1 million token Penn Treebank ) , or the whole web with byte-pair encoding. We show that for our target setting in English , initialising and freezing input embeddings using in-domain datum can improve language model performance by providing a useful representation of rare words , and this pattern holds across several different domains. In the process , we show that the standard convention of tying input and production embeddings does not improve perplexity when initializing with embeddings trained on in-domain data. ", "label": 1}
{"original_text": "Consensus protocols are currently the bottlenecks that prevent blockchain systems from scaling. However, we argue that transaction execution is also important to the performance and security of blockchains. In other words, there are ample opportunities to speed up and further secure blockchains by reducing the cost of transaction execution. Our goal is to understand how much we can speed up blockchains by exploiting transaction concurrency available in blockchain workloads. To this end, we first analyze historical data of seven major public blockchains, namely Bitcoin, Bitcoin Cash, Litecoin, Dogecoin, Ethereum, Ethereum Classic, and Zilliqa. We consider two metrics for concurrency, namely the single-transaction conflict rate per block, and the group conflict rate per block. We find that there is more concurrency in UTXO-based blockchains than in account-based ones, although the amount of concurrency in the former is lower than expected. Another interesting finding is that some blockchains with larger blocks have more concurrency than blockchains with smaller blocks. Next, we propose an analytical model for estimating the transaction execution speed-up given an amount of concurrency. Using results from our empirical analysis, the model estimates that 6 x speed-ups in Ethereum can be achieved if all available concurrency is exploited.", "text_perturb": "Consensus protocols are currently the bottlenecks that preclude blockchain systems from scaling. However , we argue that transaction execution is also important to the public presentation and security of blockchains. In other words , there are sizable opportunities to speed up and further secure blockchains by reducing the cost of transaction execution. Our goal is to understand how much we can zip up blockchains by exploiting transaction concurrency available in blockchain workloads. To this end , we firstly analyze historical data of seven major public blockchains , namely Bitcoin , Bitcoin Cash , Litecoin , Dogecoin , Ethereum , Ethereum Classic , and Zilliqa. We consider two metrics for concurrence , namely the single-transaction conflict rate per block , and the group conflict rate per block. We find that there is more concurrency in UTXO-based blockchains than in account-based ones , although the amount of concurrency in the former is lower than look. Another interesting determination is that some blockchains with larger blocks have more concurrency than blockchains with smaller blocks. Next , we advise an analytical model for estimating the transaction execution speed-up given an amount of concurrency. Using resultant from our empirical analysis , the model estimates that 6 x speed-ups in Ethereum can be achieved if all available concurrency is exploited. ", "label": 1}
{"original_text": "A major difficulty of solving continuous POMDPs is to infer the multi-modal distribution of the unobserved true states and to make the planning algorithm dependent on the perceived uncertainty. We cast POMDP filtering and planning problems as two closely related Sequential Monte Carlo (SMC) processes, one over the real states and the other over the future optimal trajectories, and combine the merits of these two parts in a new model named the DualSMC network. In particular, we first introduce an adversarial particle filter that leverages the adversarial relationship between its internal components. Based on the filtering results, we then propose a planning algorithm that extends the previous SMC planning approach to continuous POMDPs with an uncertainty-dependent policy. Crucially, not only can DualSMC handle complex observations such as image input but also it remains highly interpretable. It is shown to be effective in three continuous POMDP domains: the floor positioning domain, the 3D light-dark navigation domain, and a modified Reacher domain 2 footnote 2 2 footnote 2 Code available at", "text_perturb": "A major difficulty of solving continuous POMDPs is to infer the multi-modal distribution of the unobserved true states and to take in the planning algorithm dependent on the perceived uncertainty. We cast POMDP filtering and planning problems as two closely related Sequential Monte Carlo ( SMC ) processes , one over the real states and the other over the future optimum trajectories , and combine the merits of these two parts in a new model named the DualSMC network. In particular , we foremost introduce an adversarial particle filter that leverages the adversarial relationship between its internal components. Based on the filtering results , we then propose a preparation algorithm that extends the previous SMC preparation approach to continuous POMDPs with an uncertainty-dependent policy. Crucially , not merely can DualSMC handle complex observations such as image input but also it remains highly interpretable. It is shown to be efficient in three continuous POMDP domains : the floor positioning domain , the 3D light-dark navigation domain , and a modified Reacher domain 2 footnote 2 2 footnote 2 Code available at", "label": 1}
{"original_text": "Question-answering (QA) is certainly the best known and probably also one of the most complex problem within Natural Language Processing (NLP) and artificial intelligence (AI). Since the complete solution to the problem of finding a generic answer still seems far away, the wisest thing to do is to break down the problem by solving single simpler parts. Assuming a modular approach to the problem, we confine our research to intent classification for an answer, given a question. Through the use of an LSTM network, we show how this type of classification can be approached effectively and efficiently, and how it can be properly used within a basic prototype responder.", "text_perturb": "Question-answering ( QA ) is certainly the best known and probably also one of the near complex problem within Natural Language Processing ( NLP ) and artificial intelligence ( AI ). Since the complete solution to the problem of finding a generic answer still seem far away , the wisest thing to do is to break down the problem by solving single simpler parts. Assuming a modular approach path to the problem , we confine our research to intent classification for an answer , given a question. Through the use of an LSTM network , we usher how this type of classification can be approached effectively and efficiently , and how it can be properly used within a basic prototype responder. ", "label": 1}
{"original_text": "As a programming paradigm, answer set programming (ASP) brings about the usual issue of the human error. Hence, it is desirable to provide automated techniques that could help the programmer to find the error. This paper addresses the question of computing a subset-minimal correction of a contradictory ASP program. A contradictory ASP program is often undesirable and we wish to provide an automated way of fixing it. We consider a minimal correction set of a contradictory program to be an irreducible set of rules whose removal makes the program consistent. In contrast to propositional logic, corrections of ASP programs behave non-monotonically. Nevertheless, we show that a variety of algorithms for correction set computation in propositional logic can be ported to ASP. An experimental evaluation was carried showing that having a portfolio of such algorithms is indeed of benefit.", "text_perturb": "As a programming epitome , answer set programming ( ASP ) brings about the usual issue of the human error. Hence , it is desirable to provide automated techniques that could help the programmer to line up the error. This paper addresses the question of computing a subset-minimal correction of a contradictory ASP political platform. A contradictory ASP program is often unwanted and we wish to provide an automated way of fixing it. We consider a minimal correction set of a contradictory program to make up an irreducible set of rules whose removal makes the program consistent. In contrast to propositional logic , corrections of ASP programs bear non-monotonically. Nevertheless , we bear witness that a variety of algorithms for correction set computation in propositional logic can be ported to ASP. An experimental evaluation was carried demo that having a portfolio of such algorithms is indeed of benefit. ", "label": 1}
{"original_text": "We develop novel data dissemination and collection algorithms for Wireless Sensor Networks (WSNs) in which we consider n sensor nodes distributed randomly in a certain field to measure a physical phenomena. Such sensors have limited energy, shortage coverage range, bandwidth and memory constraints. We desire to disseminate nodes' data throughout the network such that a base station will be able to collect the sensed data by querying a small number of nodes. We propose two data dissemination and collection algorithms (DCA's) to solve this problem. Data dissemination is achieved through dynamical selection of some nodes. The selected nodes will be changed after a time slot t and may be repeated after a period T . 1 1 footnote 1 Thanks to HajjCoRE, Center of Research Excellence in Hajj and Umrah at UQU, and NPSTI at KACST in KSA, agencies for funding this work.", "text_perturb": "We develop novel data dissemination and collection algorithms for Wireless Sensor Networks ( WSNs ) in which we consider n sensor nodes distributed arbitrarily in a certain field to measure a physical phenomena. Such sensors have limited energy , shortage coverage kitchen range , bandwidth and memory constraints. We desire to disseminate nodes ' data throughout the network such that a base station will be capable to collect the sensed data by querying a small number of nodes. We propose two data dispersion and collection algorithms ( DCA 's ) to solve this problem. Data dissemination exist achieved through dynamical selection of some nodes. The selected nodes will be changed after a time slot t and may be take over after a period T. 1 1 footnote 1 Thanks to HajjCoRE , Center of Research Excellence in Hajj and Umrah at UQU , and NPSTI at KACST in KSA , agencies for funding this workplace. ", "label": 1}
{"original_text": "Modern intelligent transportation systems provide data that allow real-time demand prediction, which is essential for planning and operations. The main challenge of prediction of Origin-Destination (O-D) flow matrices is that demands cannot be directly measured by traffic sensors; instead, they have to be inferred from aggregate traffic flow data on traffic links. Specifically, spatial correlation, congestion and time dependent factors need to be considered in general transportation networks. In this paper we propose a novel O-D prediction framework based on Fusion Line Graph Convolutional Networks (FL-GCNs). We use FL-GCN to recognize spatial and temporal patterns simultaneously. The underlying road network topology is transformed into a corresponding line graph. This structure provides a general framework for predicting spatial-temporal O-D information from link traffic flows. Data from a New Jersey Turnpike network is used to evaluate the proposed model. The results show that FL-GCN can recognize spatial and temporal patterns. We also compare FL-GCN with Kalman filter; the results show that our model can outperform Kalman filter by 17.87 in predicting the whole O-D pairs.", "text_perturb": "Modern intelligent transfer systems provide data that allow real-time demand prediction , which is essential for planning and operations. The main challenge of prediction of Origin-Destination ( O-D ) flow matrices is that demands can not be directly measured by traffic sensors ; instead , they have to be inferred from aggregate traffic flow data on traffic data link. Specifically , spatial correlation , over crowding and time dependent factors need to be considered in general transportation networks. In this paper we propose a novel O-D prediction fabric based on Fusion Line Graph Convolutional Networks ( FL-GCNs ). We utilize FL-GCN to recognize spatial and temporal patterns simultaneously. The underlying route network topology is transformed into a corresponding line graph. This structure provides a general framework for predicting spatial-temporal O-D data from link traffic flows. Data from a New Jersey Turnpike network follow used to evaluate the proposed model. The effect show that FL-GCN can recognize spatial and temporal patterns. We also compare FL-GCN with Kalman filter ; the upshot show that our model can outperform Kalman filter by 17. 87 in omen the whole O-D pairs. ", "label": 1}
{"original_text": "We propose RSFT, which is an extension of the one dimensional Sparse Fourier Transform algorithm to higher dimensions in a way that it can be applied to real, noisy data. The RSFT allows for off-grid frequencies. Furthermore, by incorporating Neyman-Pearson detection, the frequency detection stages in RSFT do not require knowledge of the exact sparsity of the signal and are more robust to noise. We analyze the asymptotic performance of RSFT, and study the computational complexity versus the worst case signal SNR tradeoff. We show that by choosing the proper parameters, the optimal tradeoff can be achieved. We discuss the application of RSFT on short range ubiquitous radar signal processing, and demonstrate its feasibility via simulations.", "text_perturb": "We propose RSFT , which is an extension of the one dimensional Sparse Fourier Transform algorithm to higher dimensions in a means that it can be applied to real , noisy data. The RSFT tolerate for off-grid frequencies. Furthermore , by incorporating Neyman-Pearson espial , the frequency espial stages in RSFT do not require knowledge of the exact sparsity of the signal and are more robust to noise. We analyze the asymptotic performance of RSFT , and study the computational complexity versus the worst case signal SNR trade off. We show that by choosing the right parameters , the optimal tradeoff can be achieved. We discuss the covering of RSFT on short range ubiquitous radar signal processing , and demonstrate its feasibility via simulations. ", "label": 1}
{"original_text": "The Intensive Care Unit (ICU) is a hospital department where machine learning has the potential to provide valuable assistance in clinical decision making. Classical machine learning models usually only provide point-estimates and no uncertainty of predictions. In practice, uncertain predictions should be presented to doctors with extra care in order to prevent potentially catastrophic treatment decisions. In this work we show how Bayesian modelling and the predictive uncertainty that it provides can be used to mitigate risk of misguided prediction and to detect out-of-domain examples in a medical setting. We derive analytically a bound on the prediction loss with respect to predictive uncertainty. The bound shows that uncertainty can mitigate loss. Furthermore, we apply a Bayesian Neural Network to the MIMIC-III dataset, predicting risk of mortality of ICU patients. Our empirical results show that uncertainty can indeed prevent potential errors and reliably identifies out-of-domain patients. These results suggest that Bayesian predictive uncertainty can greatly improve trustworthiness of machine learning models in high-risk settings such as the ICU.", "text_perturb": "The Intensive Care Unit ( ICU ) be a hospital department where machine learning has the potential to provide valuable assistance in clinical decision making. Classical machine learning models usually only bring home the bacon point-estimates and no uncertainty of predictions. In practice , uncertain predictions should be presented to doctor of the church with extra care in order to prevent potentially catastrophic treatment decisions. In this piece of work we show how Bayesian modelling and the predictive uncertainty that it provides can be used to mitigate risk of misguided prediction and to detect out-of-domain examples in a medical setting. We derive analytically a bound on the prediction red ink with respect to predictive uncertainty. The bound shows that uncertainty give the axe mitigate loss. Furthermore , we practice a Bayesian Neural Network to the MIMIC-III dataset , predicting risk of mortality of ICU patients. Our empirical results show that uncertainty can indeed prevent potential wrongdoing and reliably identifies out-of-domain patients. These results suggest that Bayesian predictive uncertainty can greatly improve trustworthiness of machine learning models in high-risk circumstance such as the ICU. ", "label": 1}
{"original_text": "We describe the first nearly linear-time approximation algorithms for explicitly given mixed packingcovering linear programs, and for (non-metric) fractional facility location. We also describe the first parallel algorithms requiring only near-linear total work and finishing in polylog time. The algorithms compute (1) -approximate solutions in time (and work) O (N 2), where N is the number of non-zeros in the constraint matrix. For facility location, N is the number of eligible clientfacility pairs.", "text_perturb": "We describe the first nearly linear-time approximation algorithms for explicitly given mixed packingcovering linear programs , and for ( non-metric ) fractional facility locating. We also describe the first parallel algorithmic rule requiring only near-linear total work and finishing in polylog time. The algorithms compute ( 1 ) -approximate solutions in time ( and work ) O ( due north 2 ) , where due north is the number of non-zeros in the constraint matrix. For facility location , north is the number of eligible clientfacility pairs. ", "label": 1}
{"original_text": "Parkinson's disease (PD) is a progressive neurological disorder primarily affecting motor function resulting in tremor at rest, rigidity, bradykinesia, and postural instability. The physical severity of PD impairments can be quantified through the Movement Disorder Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS), a widely used clinical rating scale. Accurate and quantitative assessment of disease progression is critical to developing a treatment that slows or stops further advancement of the disease. Prior work has mainly focused on dopamine transport neuroimaging for diagnosis or costly and intrusive wearables evaluating motor impairments. For the first time, we propose a computer vision-based model that observes non-intrusive video recordings of individuals, extracts their 3D body skeletons, tracks them through time, and classifies the movements according to the MDS-UPDRS gait scores. Experimental results show that our proposed method performs significantly better than chance and competing methods with an F 1 -score of 0.83 and a balanced accuracy of 81. This is the first benchmark for classifying PD patients based on MDS-UPDRS gait severity and could be an objective biomarker for disease severity. Our work demonstrates how computer-assisted technologies can be used to non-intrusively monitor patients and their motor impairments. The code is available at", "text_perturb": "Parkinson 's disease ( PD ) is a progressive neurological disorder primarily affecting motor function lead in tremor at rest , rigidity , bradykinesia , and postural instability. The physical severity of PD impairments can be quantified through the Movement Disorder lodge Unified Parkinson 's Disease Rating Scale ( MDS-UPDRS ) , a widely used clinical rating scale. Accurate and quantitative assessment of disease progression is vital to developing a treatment that slows or stops further advancement of the disease. Prior work has mainly focused on dopamine transport neuroimaging for diagnosis or costly and intrusive habiliment evaluating motor impairments. For the first fourth dimension , we propose a computer vision-based model that observes non-intrusive video recordings of individuals , extracts their 3D body skeletons , tracks them through fourth dimension , and classifies the movements according to the MDS-UPDRS gait scores. Experimental results show that our proposed method acting performs significantly better than chance and competing methods with an F 1 -score of 0. 83 and a balanced truth of 81. This is the first bench mark for classifying PD patients based on MDS-UPDRS gait severity and could be an objective biomarker for disease severity. Our work demonstrates how computer-assisted technologies give the sack be used to non-intrusively monitor patients and their motor impairments. The code equal available at", "label": 1}
{"original_text": "We present a random access method inspired on Bloom filters that is suited for Machine-Type Communications (MTC). Each accessing device sends a signature during the contention process. A signature is constructed using the Bloom filtering method and contains information on the device identity and the connection establishment cause. We instantiate the proposed method over the current LTE-A access protocol. However, the method is applicable to a more general class of random access protocols that use preambles or other reservation sequences, as expected to be the case in 5G systems. We show that our method utilizes the system resources more efficiently and achieves significantly lower connection establishment latency in case of synchronous arrivals, compared to the variant of the LTE-A access protocol that is optimized for MTC traffic. A dividend of the proposed method is that it allows the base station (BS) to acquire the device identity and the connection establishment cause already in the initial phase of the connection establishment, thereby enabling their differentiated treatment by the BS.", "text_perturb": "We present a random access method exalt on Bloom filters that is suited for Machine-Type Communications ( MTC ). Each accessing device sends a signature tune during the contention process. A signature is reconstruct using the Bloom filtering method and contains information on the device identity and the connection establishment cause. We instantiate the nominate method over the current LTE-A access protocol. However , the method is applicable to a more general class of random access protocols that apply preambles or other reservation sequences , as expected to be the case in 5G systems. We show that our method utilizes the system resources more efficiently and achieves significantly lower connectedness establishment latency in case of synchronous arrivals , compared to the variant of the LTE-A access protocol that is optimized for MTC traffic. A dividend of the proposed method is that it allows the base station ( BS ) to acquire the device identity and the connective establishment cause already in the initial phase of the connective establishment , thereby enabling their differentiated treatment by the BS. ", "label": 1}
{"original_text": "We consider a contextual version of multi-armed bandit problem with global knapsack constraints. In each round, the outcome of pulling an arm is a scalar reward and a resource consumption vector, both dependent on the context, and the global knapsack constraints require the total consumption for each resource to be below some pre-fixed budget. The learning agent competes with an arbitrary set of context-dependent policies. This problem was introduced by , who gave a computationally inefficient algorithm with near-optimal regret bounds for it. We give a computationally efficient algorithm for this problem with slightly better regret bounds, by generalizing the approach of for the non-constrained version of the problem. The computational time of our algorithm scales logarithmically in the size of the policy space. This answers the main open question of . We also extend our results to a variant where there are no knapsack constraints but the objective is an arbitrary Lipschitz concave function of the sum of outcome vectors.", "text_perturb": "We look at a contextual version of multi-armed bandit problem with global knapsack constraints. In each round , the outcome of pulling an arm is a scalar reward and a resource consumption vector , both dependent on the context , and the global knapsack constraint require the total consumption for each resource to be below some pre-fixed budget. The learning federal agent competes with an arbitrary set of context-dependent policies. This problem was introduced by , who gave a computationally ineffective algorithm with near-optimal regret bounds for it. We give a computationally effective algorithm for this problem with slightly better regret bounds , by generalizing the approach of for the non-constrained version of the problem. The computational time of our algorithm scurf logarithmically in the size of the policy space. This answers the main subject question of. We also extend our results to a variant where there exist no knapsack constraints but the objective is an arbitrary Lipschitz concave function of the sum of outcome vectors. ", "label": 1}
{"original_text": "The emergence of smartphones has given mobile computing access to everydayreality. More specifically, the context modeling offers users an effective wayto customize search results and even the recommended elements by limiting thedata space. Moreover, in recent years, many social sites have embraced thenotion of context in their recommendations. Indeed, with the availability ofmobile devices, these new mobile sites have the advantage of providing userswith more relevant elements based on their current situations. Thus, weintroduce a new approach of contextual IR in a mobile environment. We offer ahand, an approach called SA-IRI based on the prediction of users' interests,from DBpedia, given their current situations. This approach applies thetechnique of associative classification in order to enrich the users' queries.Secondly, we introduce an approach of communities discovering, calledFoaf-A-Walk, combining the random walk technique and the Foaf modeling, forfriend recommendation.", "text_perturb": "The emergence of smartphones has given fluid computing access to everydayreality. More specifically , the context modeling offers users an effective wayto customize search results and even the recommended factor by limiting thedata space. Moreover , in recent years , many social sites sustain embraced thenotion of context in their recommendations. Indeed , with the availability ofmobile devices , these new mobile river sites have the advantage of providing userswith more relevant elements based on their current situations. Thus , weintroduce a new approach of contextual IR in a mobile environs. We propose ahand , an approach called SA-IRI based on the prediction of users ' interests , from DBpedia , given their current situations. This approach applies thetechnique of associative classification in order to enrich the users ' enquiry. Secondly , we introduce an approach of communities discovering , calledFoaf-A-Walk , combining the random walking technique and the Foaf modeling , forfriend recommendation. ", "label": 1}
{"original_text": "footnote footnote 1) These authors contributed equally Throughout this paper, we focus on the improvement of the direct feedback alignment (DFA) algorithm and extend the usage of the DFA to convolutional and recurrent neural networks (CNNs and RNNs). Even though the DFA algorithm is biologically plausible and has a potential of high-speed training, it has not been considered as the substitute for back-propagation (BP) due to the low accuracy in the CNN and RNN training. In this work, we propose a new DFA algorithm for BP-level accurate CNN and RNN training. Firstly, we divide the network into several modules and apply the DFA algorithm within the module. Second, the DFA with the sparse backward weight is applied. It comes with a form of dilated convolution in the CNN case, and in a form of sparse matrix multiplication in the RNN case. Additionally, the error propagation method of CNN becomes simpler through the group convolution. Finally, hybrid DFA increases the accuracy of the CNN and RNN training to the BP-level while taking advantage of the parallelism and hardware efficiency of the DFA algorithm. keywords Direct Feedback Alignment Back-propagation Deep Neural Network Convolutional Neural network Recurrent Neural Network Backward Locking Biologically Plausible", "text_perturb": "footnote footnote 1 ) These authors contributed as Throughout this paper , we focus on the improvement of the direct feedback alignment ( DFA ) algorithm and extend the usage of the DFA to convolutional and recurrent neural networks ( CNNs and RNNs ). Even though the DFA algorithm is biologically plausible and has a potential of high-speed training , it has not been considered as the substitute for back-propagation ( BP ) due to the low truth in the CNN and RNN training. In this work , we propose a new DFA algorithmic program for BP-level accurate CNN and RNN training. Firstly , we divide the network into several module and apply the DFA algorithm within the module. Second , the DFA with the sparse backward weight represent applied. It comes with a form of dilated convolution in the CNN display case , and in a form of sparse matrix multiplication in the RNN display case. Additionally , the error propagation method of CNN becomes simpler through the group gyrus. Finally , hybrid DFA increases the accuracy of the CNN and RNN training to the BP-level while taking advantage of the parallelism and hardware efficiency of the DFA algorithmic rule. keywords Direct Feedback Alignment Back-propagation Deep Neural meshing Convolutional Neural network Recurrent Neural meshing Backward Locking Biologically Plausible", "label": 1}
{"original_text": "A new method for estimating the relative positions of location-unaware nodes from the location-aware nodes and the received signal strength (RSS) between the nodes, in a wireless sensor network (WSN), is proposed. In the method, a regularization term is incorporated in the optimization problem leading to significant improvement in the estimation accuracy even in the presence of position errors of the location-aware nodes and distance errors between the nodes. The regularization term is appropriated weighted on the basis of the degree of connectivity between the nodes in the network. The method is formulated as a convex optimization problem using the semidefinite relaxation approach. Experimental comparisons with state-of-the-art competing methods show that the proposed method yields node positions that are much more accurate even in the presence of measurement errors.", "text_perturb": "A new method for estimating the relative positions of location-unaware thickening from the location-aware thickening and the received signal strength ( RSS ) between the thickening , in a wireless sensor network ( WSN ) , is proposed. In the method , a regularization term is incorporated in the optimization trouble leading to significant improvement in the estimation accuracy even in the presence of position errors of the location-aware nodes and distance errors between the nodes. The regularization term is appropriated weighted on the basis of the degree of connectivity between the thickening in the network. The method is formulated as a convex optimization problem using the semidefinite liberalization approach. Experimental comparisons with state-of-the-art competing methods show that the proposed method yields node positions that are much more accurate yet in the presence of measurement errors. ", "label": 1}
{"original_text": "Emergent narratives provide a unique and compelling approach to interactive storytelling through simulation, and have applications in games, narrative generation, and virtual agents. However the inherent complexity of simulation makes understanding the expressive potential of emergent narratives difficult, particularly at the design phase of development. In this paper, we present a novel approach to emergent narrative using the narratological theory of possible worlds and demonstrate how the design of works in such a system can be understood through a formal means of analysis inspired by expressive range analysis. Lastly, we propose a novel way through which content may be authored for the emergent narrative system using a sketch-based interface.", "text_perturb": "Emergent narratives allow for a unique and compelling approach to interactive storytelling through simulation , and have applications in games , narrative generation , and virtual agents. However the inherent complexity of simulation makes understanding the expressive potential of emergent narratives difficult , particularly at the invention phase of development. In this paper , we present a novel approach to emergent narrative using the narratological theory of possible worlds and demonstrate how the purpose of works in such a system can be understood through a formal means of analysis inspired by expressive range analysis. Lastly , we purport a novel way through which content may be authored for the emergent narrative system using a sketch-based interface. ", "label": 1}
{"original_text": "The theme of this paper is three-phase distribution system modeling suitable for the Z-Bus load-flow. Detailed models of wye and delta constant-power, constant-current, and constant-impedance loads are presented. Models of transmission lines, step-voltage regulators, and transformers that build the bus admittance matrix (Y-Bus) are laid out. The Z-Bus load-flow is then reviewed and the singularity of the Y-Bus in case of certain transformer connections is rigorously discussed. Based on realistic assumptions and conventional modifications, the invertibility of the Y-Bus is proved. Last but not least, MATLAB scripts that model the components of the IEEE 37-bus, the IEEE 123-bus, the 8500-node feeders, and the European 906-bus low-voltage feeder are provided.", "text_perturb": "The theme of this paper is three-phase dispersion system modeling suitable for the Z-Bus load-flow. Detailed modeling of wye and delta constant-power , constant-current , and constant-impedance loads are presented. Models of transmission lines , step-voltage regulators , and transformers that build the bus admittance ground substance ( Y-Bus ) are laid out. The Z-Bus load-flow is then reviewed and the singularity of the Y-Bus in case of certain transformer connections is strictly discussed. Based on realistic assumptions and conventional modifications , the invertibility of the Y-Bus is evidence. last but not least , MATLAB scripts that model the components of the IEEE 37-bus , the IEEE 123-bus , the 8500-node feeders , and the European 906-bus low-voltage feeder are provided. ", "label": 1}
{"original_text": "Orthogonal Time Frequency Space (OTFS) modulation has been recently proposed to be robust to channel induced Doppler shift in high mobility wireless communication systems. However, to the best of our knowledge, none of the prior works on OTFS have derived it from first principles. In this paper, using the ZAK representation of time-domain (TD) signals, we rigorously derive an orthonormal basis of approximately time and bandwidth limited signals which are also localized in the delay-Doppler (DD) domain. We then consider DD domain modulation based on this orthonormal basis, and derive OTFS modulation. To the best of our knowledge, this is the first paper to rigorously derive OTFS modulation from first principles. We show that irrespective of the amount of Doppler shift, the received DD domain basis signals are localized in a small interval of size roughly equal to the inverse time duration along the Doppler domain and of size roughly equal to the inverse bandwidth along the delay domain (time duration refers to the length of the time-interval where the TD transmit signal has been limited). With sufficiently large time duration and bandwidth, there is little interference between information symbols modulated on different basis signals, which allows for joint DD domain equalization of all information symbols. This explains the inherent robustness of DD domain modulation to channel induced Doppler shift when compared with Orthogonal Frequency Division Multiplexing (OFDM). The degree of localization of the DD domain basis signals is inversely related to the time duration of the transmit signal, which explains the trade-off between robustness to Doppler shift and latency.", "text_perturb": "Orthogonal Time Frequency Space ( OTFS ) modulation hold been recently proposed to be robust to channel induced Doppler shift in high mobility wireless communication systems. However , to the best of our knowledge , none of the prior industrial plant on OTFS have derived it from first principles. In this paper , using the ZAK representation of time-domain ( TD ) sign , we rigorously derive an orthonormal basis of approximately time and bandwidth limited sign which are also localized in the delay-Doppler ( DD ) domain. We then consider DD domain modulation free base on this orthonormal basis , and derive OTFS modulation. To the best of our knowledge , this is the first theme to rigorously derive OTFS modulation from first principles. We show that irrespective of the amount of Doppler shift key , the received DD domain basis signals are localized in a small interval of size roughly equal to the inverse time duration along the Doppler domain and of size roughly equal to the inverse bandwidth along the delay domain ( time duration refers to the length of the time-interval where the TD transmit signal has been limited ). With sufficiently prominent time duration and bandwidth , there is little interference between information symbols modulated on different basis signals , which allows for joint DD domain equalization of all information symbols. This explains the implicit in robustness of DD domain modulation to channel induced Doppler shift when compared with Orthogonal Frequency Division Multiplexing ( OFDM ). The degree of localization of the DD domain basis signals follow inversely related to the time duration of the transmit signal , which explains the trade-off between robustness to Doppler shift and latency. ", "label": 1}
{"original_text": "ML-based predictive systems are increasingly used to support decisions with a critical impact on individuals' lives such as college admission, job hiring, child custody, criminal risk assessment, etc. As a result, fairness emerged as an important requirement to guarantee that predictive systems do not discriminate against specific individuals or entire sub-populations, in particular, minorities. Given the inherent subjectivity of viewing the concept of fairness, several notions of fairness have been introduced in the literature. This paper is a survey of fairness notions that, unlike other surveys in the literature, addresses the question of \"which notion of fairness is most suited to a given real-world scenario and why?.\" Our attempt to answer this question consists in (1) identifying the set of fairness-related characteristics of the real-world scenario at hand, (2) analyzing the behavior of each fairness notion, and then (3) fitting these two elements to recommend the most suitable fairness notion in every specific setup. The results are summarized in a decision diagram that can be used by practitioners and policy makers to navigate the relatively large catalogue of fairness notions. keywords Fairness Machine learning Discrimination.", "text_perturb": "ML-based predictive systems are increasingly used to support decisions with a critical impact on individuals ' lives such as college admission , occupation hiring , child custody , criminal risk assessment , etc. As a result , fairness emerged as an important requirement to guarantee that predictive systems do not discriminate against specific individuals or intact sub-populations , in particular , minorities. Given the inherent subjectivity of viewing the concept of fairness , several notions of fairness have comprise introduced in the literature. This paper is a survey of fairness notions that , unlike other surveys in the literature , addresses the question of `` which notion of fairness is most suitable to a given real-world scenario and why ?. `` Our attempt to answer this question consists in ( 1 ) identifying the set of fairness-related characteristics of the real-world scenario at hand , ( 2 ) analyzing the behavior of each fairness notion , and then ( 3 ) fitting these two elements to recommend the most desirable fairness notion in every specific setup. The results make up summarized in a decision diagram that can be used by practitioners and policy makers to navigate the relatively large catalogue of fairness notions. keywords Fairness political machine learning Discrimination. ", "label": 1}
{"original_text": "The field of automatic image inpainting has progressed rapidly in recent years, but no one has yet proposed a standard method of evaluating algorithms. This absence is due to the problem's challenging nature: image-inpainting algorithms strive for realism in the resulting images, but realism is a subjective concept intrinsic to human perception. Existing objective image-quality metrics provide a poor approximation of what humans consider more or less realistic. To improve the situation and to better organize both prior and future research in this field, we conducted a subjective comparison of nine state-of-the-art inpainting algorithms and propose objective quality metrics that exhibit high correlation with the results of our comparison.", "text_perturb": "The playing area of automatic image inpainting has progressed rapidly in recent years , but no one has yet proposed a standard method of evaluating algorithms. This absence is due to the problem 's challenging nature : image-inpainting algorithms strive for realism in the resulting icon , but realism is a subjective concept intrinsic to human perception. Existing objective image-quality system of measurement provide a poor approximation of what humans consider more or less realistic. To ameliorate the situation and to better organize both prior and future research in this field , we conducted a subjective comparison of nine state-of-the-art inpainting algorithms and propose objective quality metrics that exhibit high correlation with the results of our comparison. ", "label": 1}
{"original_text": "We study the transmission of a set of correlated sources (U 1, , U K) over a Gaussian multiple access relay channel with time asynchronism between the encoders. We assume that the maximum possible offset d max (n) between the transmitters grows without bound as the block length - n while the relative ratio d max (n) n of the maximum possible offset to the block length asymptotically vanishes. For such a joint source-channel coding problem, and under specific gain conditions, we derive necessary and sufficient conditions for reliable communications and show that separate source and channel coding achieves optimal performance. In particular, we first derive a general outer bound on the source entropy content for all channel gains as our main result. Then, using Slepian-Wolf source coding combined with the channel coding scheme introduced in on top of block Markov coding, we show that the thus achieved inner bound matches the outer bound. Consequently, as a corollary, we also address the problem of sending a pair of correlated sources over a two user interference channel in the same context.", "text_perturb": "We study the transmission of a set of correlated generator ( U 1 , , U K ) over a Gaussian multiple access relay channel with time asynchronism between the encoders. We assume that the maximum possible offset d georgia home boy ( n ) between the transmitters grows without bound as the block length - n while the relative ratio d georgia home boy ( n ) n of the maximum possible offset to the block length asymptotically vanishes. For such a joint source-channel coding problem , and under specific gain conditions , we descend necessary and sufficient conditions for reliable communications and show that separate source and channel coding achieves optimal performance. In particular , we first of all derive a general outer bound on the source entropy content for all channel gains as our main result. Then , using Slepian-Wolf source coding combined with the channel coding scheme introduced in on top of block Markov coding , we show that the thus achieved inner bound cope with the outer bound. accordingly , as a corollary , we also address the problem of sending a pair of correlated sources over a two user interference channel in the same context. ", "label": 1}
{"original_text": "We consider the problem of learning a non-deterministic probabilistic system consistent with a given finite set of positive and negative tree samples. Consistency is defined with respect to strong simulation conformance. We propose learning algorithms that use traditional and a new stochastic state-space partitioning, the latter resulting in the minimum number of states. We then use them to solve the problem of active learning, that uses a knowledgeable teacher to generate samples as counterexamples to simulation equivalence queries. We show that the problem is undecidable in general, but that it becomes decidable under a suitable condition on the teacher which comes naturally from the way samples are generated from failed simulation checks. The latter problem is shown to be undecidable if we impose an additional condition on the learner to always conjecture a minimum state hypothesis. We therefore propose a semi-algorithm using stochastic partitions. Finally, we apply the proposed (semi algorithms to infer intermediate assumptions in an automated assume-guarantee verification framework for probabilistic systems.", "text_perturb": "We consider the problem of learning a non-deterministic probabilistic system consistent with a present finite set of positive and negative tree samples. Consistency is defined with respect to strong simulation conformity. We propose learning algorithms that use traditional and a young stochastic state-space partitioning , the latter resulting in the minimum number of states. We then use them to puzzle out the problem of active learning , that uses a knowledgeable teacher to generate samples as counterexamples to simulation equivalence queries. We show that the problem is undecidable in general , but that it becomes decidable under a suitable condition on the teacher which comes naturally from the way samples are generated from failed pretense checks. The latter trouble is shown to be undecidable if we impose an additional condition on the learner to always conjecture a minimum state hypothesis. We therefore propose a semi-algorithm using stochastic partition. Finally , we apply the proposed ( semi algorithms to infer intermediate assumptions in an automated assume-guarantee verification framework for probabilistic scheme. ", "label": 1}
{"original_text": "While first-order optimization methods such as stochastic gradient descent (SGD) are popular in machine learning (ML), they come with well-known deficiencies, including relatively-slow convergence, sensitivity to the settings of hyper-parameters such as learning rate, stagnation at high training errors, and difficulty in escaping flat regions and saddle points. These issues are particularly acute in highly non-convex settings such as those arising in neural networks. Motivated by this, there has been recent interest in second-order methods that aim to alleviate these shortcomings by capturing curvature information. In this paper, we report detailed empirical evaluations of a class of Newton-type methods, namely sub-sampled variants of trust region (TR) and adaptive regularization with cubics (ARC) algorithms, for non-convex ML problems. In doing so, we demonstrate that these methods not only can be computationally competitive with hand-tuned SGD with momentum, obtaining comparable or better generalization performance, but also they are highly robust to hyper-parameter settings. Further, in contrast to SGD with momentum, we show that the manner in which these Newton-type methods employ curvature information allows them to seamlessly escape flat regions and saddle points.", "text_perturb": "While first-order optimization methods such as stochastic gradient descent ( SGD ) are popular in machine learning ( ML ) , they come with well-known deficiencies , including relatively-slow convergence , sensibility to the settings of hyper-parameters such as learning rate , stagnation at high training errors , and difficulty in escaping flat regions and saddle points. These issues are particularly discriminating in highly non-convex settings such as those arising in neural networks. Motivated by this , there has been recent interest in second-order methods that shoot for to alleviate these shortcomings by capturing curvature information. In this paper , we report detailed empirical evaluations of a socio economic class of Newton-type methods , namely sub-sampled variants of trust region ( TR ) and adaptive regularization with cubics ( ARC ) algorithms , for non-convex ML problems. In doing so , we demonstrate that these methods not only can be computationally competitive with hand-tuned SGD with momentum , obtaining comparable or just generalization performance , but also they are highly robust to hyper-parameter settings. Further , in direct contrast to SGD with momentum , we show that the manner in which these Newton-type methods employ curvature information allows them to seamlessly escape flat regions and saddle points. ", "label": 1}
{"original_text": "In a sponsored search auction, decisions about how to rank ads impose tradeoffs between objectives such as revenue and welfare. In this paper, we examine how these tradeoffs should be made. We begin by arguing that the most natural solution concept to evaluate these tradeoffs is the lowest symmetric Nash equilibrium (SNE). As part of this argument, we generalise the well known connection between the lowest SNE and the VCG outcome. We then propose a new ranking algorithm, loosely based on the revenue-optimal auction, that uses a reserve price to order the ads (not just to filter them) and give conditions under which it raises more revenue than simply applying that reserve price. Finally, we conduct extensive simulations examining the tradeoffs enabled by different ranking algorithms and show that our proposed algorithm enables superior operating points by a variety of metrics.", "text_perturb": "In a sponsored search auction , decisions about how to rank ads impose tradeoffs between aim such as revenue and welfare. In this newspaper , we examine how these tradeoffs should be made. We begin by arguing that the most natural solution concept to judge these tradeoffs is the lowest symmetric Nash equilibrium ( SNE ). As part of this argument , we generalise the well known connection between the broken SNE and the VCG outcome. We then propose a new ranking algorithm , loosely free base on the revenue-optimal auction , that uses a reserve price to order the ads ( not just to filter them ) and give conditions under which it raises more revenue than simply applying that reserve price. Finally , we conduct extensive simulations examining the trade off enabled by different ranking algorithms and show that our proposed algorithm enables superior operating points by a variety of metrics. ", "label": 1}
{"original_text": "The data revolution continues to transform every sector of science, industry and government. Due to the incredible impact of data-driven technology on society, we are becoming increasingly aware of the imperative to use data and algorithms responsibly - in accordance with laws and ethical norms. In this article we discuss three recent regulatory frameworks: the European Union's General Data Protection Regulation (GDPR), the New York City Automated Decisions Systems (ADS) Law, and the Net Neutrality principle, that aim to protect the rights of individuals who are impacted by data collection and analysis. These frameworks are prominent examples of a global trend: Governments are starting to recognize the need to regulate data-driven algorithmic technology. Our goal in this paper is to bring these regulatory frameworks to the attention of the data management community, and to underscore the technical challenges they raise and which we, as a community, are well-equipped to address. The main take-away of this article is that legal and ethical norms cannot be incorporated into data-driven systems as an afterthought. Rather, we must think in terms of responsibility by design, viewing it as a systems requirement.", "text_perturb": "The data rotation continues to transform every sector of science , industry and government. Due to the incredible wallop of data-driven technology on society , we are becoming increasingly aware of the imperative to use data and algorithms responsibly - in accordance with laws and ethical norms. In this article we discuss three recent regulatory framework : the European Union 's General Data Protection Regulation ( GDPR ) , the New York City Automated Decisions Systems ( ADS ) Law , and the Net Neutrality principle , that aim to protect the rights of individuals who are impacted by data collection and analysis. These frameworks equal prominent examples of a global trend : Governments equal starting to recognize the need to regulate data-driven algorithmic technology. Our goal in this paper is to bring these regulatory frameworks to the attention of the data point management community , and to underscore the technical challenges they raise and which we , as a community , are well-equipped to address. The main take-away of this article is that legal and ethical norms can non be incorporated into data-driven systems as an afterthought. Rather , we must guess in terms of responsibility by design , viewing it as a systems requirement. ", "label": 1}
{"original_text": "We consider a broad class of Approximate Message Passing (AMP) algorithms defined as a Lipschitzian functional iteration in terms of an x n n random symmetric matrix A. We establish universality in noise for this AMP in the n -limit and validate this behavior in a number of AMPs popularly adapted in compressed sensing, statistical inferences, and optimizations in spin glasses.", "text_perturb": "We consider a broad class of Approximate Message Passing ( AMP ) algorithmic program defined as a Lipschitzian functional iteration in terms of an x n n random symmetric matrix A. We establish universality in noise for this ampere in the n -limit and validate this behavior in a number of AMPs popularly adapted in compressed sensing , statistical inferences , and optimizations in spin glasses. ", "label": 1}
{"original_text": "An adaptive distributed space-time coding (DSTC) scheme is proposed for two-hop cooperative MIMO networks. Linear minimum mean square error (MMSE) receive filters and adjustable code matrices are considered subject to a power constraint with an amplify-and-forward (AF) cooperation strategy. In the proposed adaptive DSTC scheme, an adjustable code matrix obtained by a feedback channel is employed to transform the space-time coded matrix at the relay node. The effects of the limited feedback and the feedback errors are assessed. Linear MMSE expressions are devised to compute the parameters of the adjustable code matrix and the linear receive filters. Stochastic gradient (SG) and least-squares (LS) algorithms are also developed with reduced computational complexity. An upper bound on the pairwise error probability analysis is derived and indicates the advantage of employing the adjustable code matrices at the relay nodes. An alternative optimization algorithm for the adaptive DSTC scheme is also derived in order to eliminate the need for the feedback. The algorithm provides a fully distributed scheme for the adaptive DSTC at the relay node based on the minimization of the error probability. Simulation results show that the proposed algorithms obtain significant performance gains as compared to existing DSTC schemes.", "text_perturb": "An adaptative distributed space-time coding ( DSTC ) scheme is proposed for two-hop cooperative MIMO networks. Linear minimum mean value square error ( MMSE ) receive filters and adjustable code matrices are considered subject to a power constraint with an amplify-and-forward ( AF ) cooperation strategy. In the proposed adaptive DSTC scheme , an adjustable code ground substance obtained by a feedback channel is employed to transform the space-time coded ground substance at the relay node. The effects of the limited feedback and the feedback errors equal assessed. Linear MMSE expressions are devised to compute the parameters of the adjustable computer code matrix and the linear receive filters. stochastic gradient ( SG ) and least-squares ( LS ) algorithms are also developed with reduced computational complexity. An upper bound on the pairwise error probability analysis is derived and show the advantage of employing the adjustable code matrices at the relay nodes. An alternative optimisation algorithm for the adaptive DSTC scheme is also derived in order to eliminate the need for the feedback. The algorithm provides a fully distributed scheme for the adaptive DSTC at the relay lymph node based on the minimization of the error probability. Simulation results show that the proposed algorithms obtain significant functioning gains as compared to existing DSTC schemes. ", "label": 1}
{"original_text": "Sharding has emerged as one of the common techniques to address the scalability problems of blockchain systems. To this end, various sharding techniques for blockchain systems have been proposed in the literature. When sharded blockchains process personal data, the data controllers and the data processors associated with the sharded blockchains need to be compliant with the General Data Protection Regulation (GDPR). To this end, this article makes the first attempt to address the following key question: to what extent the existing techniques developed by different communities such as the distributed computing community, the distributed systems community, the database community, identity and access control community and the dependability community can be used by the data controllers and data processors for complying with the GDPR requirements of data subject rights in sharded blockchains? As part of answering this question, this article argues that there is a need for cross-disciplinary research towards finding optimal solutions for implementing the data subject rights in sharded blockchains.", "text_perturb": "Sharding has emerged as one of the common techniques to turn to the scalability problems of blockchain systems. To this goal , various sharding techniques for blockchain systems have been proposed in the literature. When sharded blockchains process personal datum , the datum controllers and the datum processors associated with the sharded blockchains need to be compliant with the General Data Protection Regulation ( GDPR ). To this end , this article makes the first attempt to address the following key question : to what extent the existing techniques developed by different communities such as the distributed computing community , the distributed systems community , the database community , identity and access control community and the dependability community can be used by the data controllers and data processors for complying with the GDPR requirements of data subject right hand in sharded blockchains ? As part of answering this question , this article argues that there is a need for cross-disciplinary research towards finding optimal solutions for implementing the data subject right hand in sharded blockchains. ", "label": 1}
{"original_text": "For over twenty years, the term 'cosmic web' has guided our understanding of the large-scale arrangement of matter in the cosmos, accurately evoking the concept of a network of galaxies linked by filaments. But the physical correspondence between the cosmic web and structural-engineering or textile 'spiderwebs' is even deeper than previously known, and extends to origami tessellations as well. Here we explain that in a good structure-formation approximation known as the adhesion model, threads of the cosmic web form a spiderweb, i.e. can be strung up to be entirely in tension. The correspondence is exact if nodes sampling voids are included, and if structure is excluded within collapsed regions (walls, filaments and haloes), where dark-matter multistreaming and baryonic physics affect the structure. We also suggest how concepts arising from this link might be used to test cosmological models: for example, to test for large-scale anisotropy and rotational flows in the cosmos.", "text_perturb": "For over twenty years , the term 'cosmic web ' has guided our understanding of the large-scale system of matter in the cosmos , accurately evoking the concept of a network of galaxies linked by filaments. But the strong arm correspondence between the cosmic web and structural-engineering or textile 'spiderwebs ' is even deeper than previously known , and extends to origami tessellations as well. Here we explain that in a good structure-formation approximation known as the attachment model , threads of the cosmic web form a spiderweb , i. vitamin e. can follow strung up to follow entirely in tension. The correspondence is exact if nodes sampling voids are included , and if structure is excluded within collapsed regions ( walls , filament and haloes ) , where dark-matter multistreaming and baryonic physics affect the structure. We also suggest how concepts arising from this link might be used to test cosmological models : for example , to test for large scale anisotropy and rotational flows in the cosmos. ", "label": 1}
{"original_text": "We defined in a new multiplicative c -differential, and the corresponding c -differential uniformity and we characterized the known perfect nonlinear functions with respect to this new concept, as well as the inverse in any characteristic. The work was continued in, investigating the c -differential uniformity for some further APN functions. Here, we extend the concept to the boomerang uniformity, introduced at Eurocrypt '18 by Cid et al., to evaluate S-boxes of block ciphers, and investigate it in the context of perfect nonlinearity and related functions.", "text_perturb": "We defined in a new multiplicative c -differential , and the corresponding c -differential uniformness and we characterized the known perfect nonlinear functions with respect to this new concept , as well as the inverse in any characteristic. The work was continued in , investigating the  -differential uniformity for some further APN functions. Here , we unfold the concept to the boomerang uniformity , introduced at Eurocrypt '18 by Cid et al. , to evaluate S-boxes of block ciphers , and enquire it in the context of perfect nonlinearity and related functions. ", "label": 1}
{"original_text": "In this paper we offer a method and algorithm, which make possible fully autonomous (unsupervised) detection of new classes, and learning following a very parsimonious training priming (few labeled data samples only). Moreover, new unknown classes may appear at a later stage and the proposed xClass method and algorithm are able to successfully discover this and learn from the data autonomously. Furthermore, the features (inputs to the classifier) are automatically sub-selected by the algorithm based on the accumulated data density per feature per class. As a result, a highly efficient, lean, human-understandable, autonomously self-learning model (which only needs an extremely parsimonious priming) emerges from the data. To validate our proposal we tested it on two challenging problems, including imbalanced Caltech-101 data set and iRoads dataset. Not only we achieved higher precision, but, more significantly, we only used a single class beforehand, while other methods used all the available classes) and we generated interpretable models with smaller number of features used, through extremely weak and weak supervision.", "text_perturb": "In this paper we offer a method and algorithm , which make possible fully self directed ( unsupervised ) detection of new classes , and learning following a very parsimonious training priming ( few labeled data samples only ). Moreover , new strange classes may appear at a later stage and the proposed xClass method and algorithm are able to successfully discover this and learn from the data autonomously. Furthermore , the feature of speech ( inputs to the classifier ) are automatically sub-selected by the algorithm based on the accumulated data density per feature per class. As a event , a highly efficient , lean , human-understandable , autonomously self-learning model ( which only needs an extremely parsimonious priming ) emerges from the data. To validate our proposal we tested it on two challenging problems , including unbalanced Caltech-101 data set and iRoads dataset. Not only we achieved higher precision , but , more significantly , we only utilise a single class beforehand , while other methods utilise all the available classes ) and we generated interpretable models with smaller number of features utilise , through extremely weak and weak supervision. ", "label": 1}
{"original_text": "Modern applications significantly enhance user experience by adapting to each user's individual condition andor preferences. While this adaptation can greatly improve utility or be essential for the application to work (e.g., for ride-sharing applications), the exposure of user data to the application presents a significant privacy threat to the users, even when the traces are anonymized, since the statistical matching of an anonymized trace to prior user behavior can identify a user and their habits. Because of the current and growing algorithmic and computational capabilities of adversaries, provable privacy guarantees as a function of the degree of anonymization and obfuscation of the traces are necessary. Our previous work has established the requirements on anonymization and obfuscation in the case that data traces are independent between users. However, the data traces of different users will be dependent in many applications, and an adversary can potentially exploit such. In this paper, we consider the impact of correlation between user traces on their privacy. First, we demonstrate that the adversary can readily identify the association graph, revealing which user data traces are correlated. Next, we demonstrate that the adversary can use this association graph to break user privacy with significantly shorter traces than in the case when traces are independent between users, and that independent obfuscation of the data traces is often insufficient to remedy such. Finally, we discuss how the users can employ dependency in their obfuscation to improve their privacy.", "text_perturb": "Modern applications significantly enhance user experience by adjust to each user 's individual condition andor preferences. While this adaptation can greatly improve utility or be essential for the covering to work ( e. gramme. , for ride-sharing applications ) , the exposure of user data to the application presents a significant privacy threat to the users , even when the traces are anonymized , since the statistical matching of an anonymized trace to prior user behavior can identify a user and their use. Because of the current and growing algorithmic and computational capabilities of adversaries , provable privacy guarantees as a function of the degree of anonymization and bemusement of the traces are necessary. Our previous work has established the requirements on anonymization and obfuscation in the compositors case that data traces are independent between users. still , the data traces of different users will be dependent in many applications , and an adversary can potentially exploit such. In this report , we consider the impact of correlation between user traces on their privacy. First , we demonstrate that the adversary can readily identify the association graph , break which user data traces are correlated. Next , we demonstrate that the adversary can use this tie up graph to break user privacy with significantly shorter traces than in the case when traces are independent between users , and that independent obfuscation of the data traces is often insufficient to remedy such. Finally , we discuss how the users can employ dependency in their obfuscation to improve their secrecy. ", "label": 1}
{"original_text": "The identification and quantification of markers in medical images is critical for diagnosis, prognosis, and disease management. Supervised machine learning enables the detection and exploitation of findings that are known a priori after annotation of training examples by experts. However, supervision does not scale well, due to the amount of necessary training examples, and the limitation of the marker vocabulary to known entities. In this proof-of-concept study, we propose unsupervised identification of anomalies as candidates for markers in retinal Optical Coherence Tomography (OCT) imaging data without a constraint to a priori definitions. We identify and categorize marker candidates occurring frequently in the data, and demonstrate that these markers show predictive value in the task of detecting disease. A careful qualitative analysis of the identified data driven markers reveals how their quantifiable occurrence aligns with our current understanding of disease course, in early- and late age-related macular degeneration (AMD) patients. A multi-scale deep denoising autoencoder is trained on healthy images, and a one-class support vector machine identifies anomalies in new data. Clustering in the anomalies identifies stable categories. Using these markers to classify healthy-, early AMD- and late AMD cases yields an accuracy of 81.40. In a second binary classification experiment on a publicly available data set (healthy vs. intermediate AMD) the model achieves an AUC of 0.944.", "text_perturb": "The identification and quantification of markers in aesculapian images is critical for diagnosis , prognosis , and disease management. Supervised machine learning enables the detective work and exploitation of findings that are known a priori after annotation of training examples by experts. However , supervision does not scale good , due to the amount of necessary training examples , and the limitation of the marker vocabulary to known entities. In this proof-of-concept study , we propose unsupervised identification of anomalies as candidates for markers in retinal Optical Coherence Tomography ( OCT ) imaging information without a constraint to a priori definitions. We identify and categorize marker candidates occurring frequently in the data , and demonstrate that these markers show predictive note value in the task of detecting disease. A careful qualitative analysis of the identified data driven markers reveals how their quantifiable occurrence aligns with our current understanding of disease course , in early- and late age-related macular degeneration ( AMD ) patient role. A multi-scale deep denoising autoencoder is trained on healthy images , and a one-class support vector machine identifies anomalies in fresh data. bunch in the anomalies identifies stable categories. Using these markers to classify healthy- , early AMD- and late AMD showcase yields an accuracy of 81. 40. In a second binary classification experiment on a publicly available data set ( healthy . medium AMD ) the model achieves an AUC of 0. 944. ", "label": 1}
{"original_text": "With the increasing popularity of PET-MR scanners in clinical applications, synthesis of CT images from MR has been an important research topic. Accurate PET image reconstruction requires attenuation correction, which is based on the electron density of tissues and can be obtained from CT images. While CT measures electron density information for x-ray photons, MR images convery information about the magnetic properties of tissues. Therefore, with the advent of PET-MR systems, the attenuation coefficients need to be indirectly estimated from MR images. In this paper, we propose a fully convolutional neural network (CNN) based method to synthesize head CT from ultra-short echo-time (UTE) dual-echo MR images. Unlike traditional T 1 -w images which do not have any bone signal, UTE images show some signal for bone, which makes it a good candidate for MR to CT synthesis. A notable advantage of our approach is that accurate results were achieved with a small training data set. Using an atlas of a single CT and dual-echo UTE pair, we train a deep neural network model to learn the transform of MR intensities to CT using patches. We compared our CNN based model with a state-of-the-art registration based as well as a Bayesian model based CT synthesis method, and showed that the proposed CNN model outperforms both of them. We also compared the proposed model when only T 1 -w images are available instead of UTE, and show that UTE images produce better synthesis than using just T 1 -w images.", "text_perturb": "With the increasing popularity of PET-MR scanners in clinical applications , synthesis of CT look alike from MR has been an important research topic. Accurate PET image reconstruction requires attenuation correction , which represent based on the electron density of tissues and can be obtained from CT images. While CT measures electron density information for x-ray photons , MR images convery information about the magnetic place of tissues. Therefore , with the advent of PET-MR systems , the attenuation coefficients need to be indirectly gauge from MR images. In this paper , we propose a fully convolutional neural network ( CNN ) based method acting to synthesize head CT from ultra-short echo-time ( UTE ) dual-echo MR images. Unlike traditional T 1 -w images which do not sustain any bone signal , UTE images show some signal for bone , which makes it a good candidate for MR to CT synthesis. A notable reward of our approach is that accurate results were achieved with a small training data set. Using an atlas of a single CT and dual-echo UTE pair , we train a deep neural network model to learn the transform of mister intensities to CT using patches. We compare our CNN based model with a state-of-the-art registration based as well as a Bayesian model based CT synthesis method , and showed that the proposed CNN model outperforms both of them. We also compared the proposed model when only T 1 -w images are available instead of ute , and show that ute images produce better synthesis than using just T 1 -w images. ", "label": 1}
{"original_text": "Typical retrieval systems have three requirements: a) Accurate retrieval i.e., the method should have high precision, b) Diverse retrieval, i.e., the obtained set of points should be diverse, c) Retrieval time should be small. However, most of the existing methods address only one or two of the above mentioned requirements. In this work, we present a method based on randomized locality sensitive hashing which tries to address all of the above requirements simultaneously. While earlier hashing approaches considered approximate retrieval to be acceptable only for the sake of efficiency, we argue that one can further exploit approximate retrieval to provide impressive trade-offs between accuracy and diversity. We extend our method to the problem of multi-label prediction, where the goal is to output a diverse and accurate set of labels for a given document in real-time. Moreover, we introduce a new notion to simultaneously evaluate a method's performance for both the precision and diversity measures. Finally, we present empirical results on several different retrieval tasks and show that our method retrieves diverse and accurate imageslabels while ensuring 100 x -speed-up over the existing diverse retrieval approaches.", "text_perturb": "Typical retrieval systems give three requirements : a ) Accurate retrieval i. tocopherol. , the method should have high precision , bacillus ) Diverse retrieval , i. east. , the obtained set of points should be diverse , c ) Retrieval meter should be small. However , most of the existing method acting address only one or two of the above mentioned requirements. In this work , we stage a method based on randomized locality sensitive hashing which tries to address all of the above requirements simultaneously. While earlier hashing approaches considered approximate retrieval to be acceptable only for the sake of efficiency , we argue that one can further overwork approximate retrieval to provide impressive trade-offs between accuracy and diversity. We extend our method to the trouble of multi-label prediction , where the goal is to output a diverse and accurate set of labels for a given document in real-time. Moreover , we introduce a new notion to simultaneously evaluate a method acting 's performance for both the precision and diversity measures. Finally , we present empirical results on several different retrieval tasks and show that our method retrieves diverse and accurate imageslabels while ensuring 100 x -speed-up over the existing diverse retrieval glide path. ", "label": 1}
{"original_text": "We transform reinforcement learning (RL) into a form of supervised learning (SL) by turning traditional RL on its head, calling this RL or Upside Down RL (UDRL). Standard RL predicts rewards, while RL instead uses rewards as task-defining inputs, together with representations of time horizons and other computable functions of historic and desired future data. RL learns to interpret these input observations as commands, mapping them to actions (or action probabilities) through SL on past (possibly accidental) experience. RL generalizes to achieve high rewards or other goals, through input commands such as: get lots of reward within at most so much time! RL can also learn to improve its exploration strategy. A separate paper on first experiments with RL shows that even a pilot version of RL can outperform traditional baseline algorithms on certain challenging RL problems. We also conceptually simplify an approach for teaching a robot to imitate humans. First videotape humans imitating the robot's current behaviors, then let the robot learn through SL to map the videos (as input commands) to these behaviors, then let it generalize and imitate videos of humans executing previously unknown behavior. This Imitate-Imitator concept may actually explain why biological evolution has resulted in parents who imitate the babbling of their babies.", "text_perturb": "We transform reinforcement learning ( RL ) into a form of supervised learning ( SL ) by turning traditional RL on its drumhead , calling this RL or Upside Down RL ( UDRL ). Standard RL predicts rewards , while RL instead uses rewards as task-defining inputs , together with representations of time horizons and other computable functions of historical and desired future data. RL learns to interpret these input observations as mastery , mapping them to actions ( or action probabilities ) through SL on past ( possibly accidental ) experience. RL generalizes to achieve high rewards or other goals , through input commands such as : induce lots of reward within at most so much time ! RL can also learn to improve its exploration strategy. A separate paper on first experiments with RL shows that even a pilot version of RL can outperform traditional baseline algorithms on certain challenging RL trouble. We too conceptually simplify an approach for teaching a robot to imitate humans. First videotape humans imitating the golem 's current behaviors , then let the golem learn through SL to map the videos ( as input commands ) to these behaviors , then let it generalize and imitate videos of humans executing previously unknown behavior. This Imitate-Imitator concept may actually explain why biological evolution ingest resulted in parents who imitate the babbling of their babies. ", "label": 1}
{"original_text": "We propose a model order reduction approach for balanced truncation of linear switched systems. Such systems switch among a finite number of linear subsystems or modes. We compute pairs of controllability and observability Gramians corresponding to each active discrete mode by solving systems of coupled Lyapunov equations. Depending on the type, each such Gramian corresponds to the energy associated to all possible switching scenarios that start or, respectively end, in a particular operational mode. In order to guarantee that hard to control and hard to observe states are simultaneously eliminated, we construct a transformed system, whose Gramians are equal and diagonal. Then, by truncation, directly construct reduced order models. One can show that these models preserve some properties of the original model, such as stability and that it is possible to obtain error bounds relating the observed output, the control input and the entries of the diagonal Gramians.", "text_perturb": "We propose a model order reduction approach for balanced truncation of additive switched systems. Such system switch among a finite number of linear subsystems or modes. We compute pairs of controllability and observability Gramians gibe to each active discrete mode by solving systems of coupled Lyapunov equations. Depending on the type , each such Gramian corresponds to the energy associated to all possible switching scenarios that start or , severally end , in a particular operational mode. In order to guarantee that hard to control and hard to observe states are simultaneously eliminated , we construct a transformed system , whose Gramians are equal and slanted. Then , by truncation , directly construct reduced society models. One can show that these models preserve some properties of the original model , such as stability and that it is possible to get error bounds relating the observed output , the control input and the entries of the diagonal Gramians. ", "label": 1}
{"original_text": "The offline problem of transmission completion time minimization for an energy harvesting transmitter under fading is extended to allow packet arrivals during transmission. A method for computing an optimal power and rate allocation (i.e., an optimal offline schedule) is developed and studied.", "text_perturb": "The offline problem of transmission completion prison term minimization for an energy harvesting transmitter under fading is extended to allow packet arrivals during transmission. A method for computing an optimal power and rate allocation ( ace. vitamin e. , an optimal offline schedule ) is build up and studied. ", "label": 1}
{"original_text": "Summary: Genome-to-genome comparisons require designating anchor points, which are given by Maximum Exact Matches (MEMs) between their sequences. For large genomes this is a challenging problem and the performance of existing solutions, even in parallel regimes, is not quite satisfactory. We present a new algorithm, copMEM, that allows to sparsely sample both input genomes, with sampling steps being coprime. Despite being a single-threaded implementation, copMEM computes all MEMs of minimum length 100 between the human and mouse genomes in less than 2 minutes, using less than 10 GB of RAM memory. Availability: The source code of copMEM is freely available at Contact: href", "text_perturb": "Summary : Genome-to-genome comparisons require designating anchor points , which are leave by Maximum Exact Matches ( MEMs ) between their sequences. For large genomes this represent a challenging problem and the performance of existing solutions , even in parallel regimes , represent not quite satisfactory. We present a new algorithm , copMEM , that allows to sparsely sample both input genomes , with sampling steps be coprime. Despite being a single-threaded implementation , copMEM computes all MEMs of minimum length 100 between the human and mouse genomes in less than 2 minutes , utilise less than 10 GB of RAM memory. Availability : The source code of copMEM is freely available at link : href", "label": 1}
{"original_text": "Most theoretical frameworks that focus on data errors and inconsistencies follow logic-based reasoning. Yet, practical data cleaning tools need to incorporate statistical reasoning to be effective in real-world data cleaning tasks. Motivated by empirical successes, we propose a formal framework for unclean databases, where two types of statistical knowledge are incorporated: The first represents a belief of how intended (clean) data is generated, and the second represents a belief of how noise is introduced in the actual observed database. To capture this noisy channel model, we introduce the concept of a Probabilistic Unclean Database (PUD), a triple that consists of a probabilistic database that we call the intention, a probabilistic data transformator that we call the realization and captures how noise is introduced, and an observed unclean database that we call the observation. We define three computational problems in the PUD framework: cleaning (infer the most probable intended database, given a PUD), probabilistic query answering (compute the probability of an answer tuple over the unclean observed database), and learning (estimate the most likely intention and realization models of a PUD, given examples as training data). We illustrate the PUD framework on concrete representations of the intention and realization, show that they generalize traditional concepts of repairs such as cardinality and value repairs, draw connections to consistent query answering, and prove tractability results. We further show that parameters can be learned in some practical instantiations, and in fact, prove that under certain conditions we can learn a PUD directly from a single dirty database without any need for clean examples.", "text_perturb": "Most theoretical frameworks that focus on data errors and repugnance follow logic-based reasoning. Yet , practical data point cleaning tools need to incorporate statistical reasoning to be effective in real-world data point cleaning tasks. Motivated by empirical successes , we project a formal framework for unclean databases , where two types of statistical knowledge are incorporated : The first represents a belief of how intended ( clean ) data is generated , and the second represents a belief of how noise is introduced in the actual observed database. To capture this noisy channel model , we introduce the concept of a probabilistic Unclean Database ( PUD ) , a triple that consists of a probabilistic database that we call the intention , a probabilistic data transformator that we call the realization and captures how noise is introduced , and an observed unclean database that we call the observation. We define three computational problems in the PUD framework : cleaning ( infer the most probable intended database , given a PUD ) , probabilistic query answering ( compute the probability of an solvent tuple over the unclean observed database ) , and learning ( estimate the most likely intention and realization models of a PUD , given examples as training data ). We instance the PUD framework on concrete representations of the intention and realization , show that they generalize traditional concepts of repairs such as cardinality and value repairs , draw connections to consistent query answering , and prove tractability results. We further show that argument can be learned in some practical instantiations , and in fact , prove that under certain conditions we can learn a PUD directly from a single dirty database without any need for clean examples. ", "label": 1}
{"original_text": "Search is a central problem in artificial intelligence, and BFS and DFS the two most fundamental ways to search. In this report we derive results for average BFS and DFS runtime: For tree search, we employ a probabilistic model of goal distribution; for graph search, the analysis depends on an additional statistic of path redundancy and average branching factor. As an application, we use the results on two concrete grammar problems. The runtime estimates can be used to select the faster out of BFS and DFS for a given problem, and may form the basis for further analysis of more advanced search methods. Finally, we verify our results experimentally; the analytical approximations come surprisingly close to empirical reality.", "text_perturb": "Search is a central problem in artificial intelligence , and BFS and DFS the two most fundamental ways to look. In this news report we derive results for average BFS and DFS runtime : For tree search , we employ a probabilistic model of goal distribution ; for graph search , the analysis depends on an additional statistic of path redundancy and average branching factor. As an application , we use the resolution on two concrete grammar problems. The runtime estimates can be used to select the faster out of BFS and DFS for a given problem , and may mould the basis for further analysis of more advanced search methods. Finally , we verify our results through an experiment ; the analytical approximations come surprisingly close to empirical reality. ", "label": 1}
{"original_text": "Neural Architecture Search (NAS) has been a source of dramatic improvements in neural network design, with recent results meeting or exceeding the performance of hand-tuned architectures. However, our understanding of how to represent the search space for neural net architectures and how to search that space efficiently are both still in their infancy. We have performed an in-depth analysis to identify limitations in a widely used search space and a recent architecture search method, Differentiable Architecture Search (DARTS). These findings led us to introduce novel network blocks with a more general, balanced, and consistent design; a better-optimized Cosine Power Annealing learning rate schedule; and other improvements. Our resulting sharpDARTS search is 50 faster with a 20-30 relative improvement in final model error on CIFAR-10 when compared to DARTS. Our best single model run has 1.93 (1.98 - 0.07) validation error on CIFAR-10 and 5.5 error (5.8 - 0.3) on the recently released CIFAR-10.1 test set. To our knowledge, both are state of the art for models of similar size. This model also generalizes competitively to ImageNet at 25.1 top-1 (7.8 top-5) error. We found improvements for existing search spaces but does DARTS generalize to new domains? We propose Differentiable Hyperparameter Grid Search and the HyperCuboid search space, which are representations designed to leverage DARTS for more general parameter optimization. Here we find that DARTS fails to generalize when compared against a human's one shot choice of models. We look back to the DARTS and sharpDARTS search spaces to understand why, and an ablation study reveals an unusual generalization gap. We finally propose Max-W regularization to solve this problem, which proves significantly better than the handmade design. Code will be made available.", "text_perturb": "Neural Architecture Search ( NAS ) has been a source of dramatic improvements in neural network design , with recent result meeting or exceeding the performance of hand-tuned architectures. However , our understanding of how to constitute the search space for neural net architectures and how to search that space efficiently are both still in their infancy. We have performed an in-depth analysis to identify limitations in a widely used search space and a recent computer architecture search method , Differentiable Architecture Search ( DARTS ). These findings led us to introduce novel network blocks with a more general , balanced , and consistent design ; a better-optimized cosine Power Annealing learning rate schedule ; and other improvements. Our resulting sharpDARTS search is 50 faster with a 20-30 relative improvement in final model error on CIFAR-10 when compared to scoot. Our best single model run birth 1. 93 ( 1. 98 - 0. 07 ) validation error on CIFAR-10 and 5. 5 erroneous belief ( 5. 8 - 0. 3 ) on the late released CIFAR-10. 1 run set. To our knowledge , both are body politic of the art for models of similar size. This model also generalizes competitively to ImageNet at 25. 1 top-1 ( 7. 8 top-5 ) erroneousness. We found improvements for existing search spaces but does DARTS generalize to novel domains ? We propose Differentiable Hyperparameter Grid Search and the HyperCuboid search space , which are representations designed to leverage DARTS for more general parameter optimization. Here we find that DARTS fails to generalize when compared against a human 's one dig choice of models. We look back to the DARTS and sharpDARTS search spaces to understand why , and an ablation study reveals an strange generalization gap. We finally propose Max-W regulation to solve this problem , which proves significantly better than the handmade design. codification will be made available. ", "label": 1}
{"original_text": "Crowd flow prediction has been increasingly investigated in intelligent urban computing field as a fundamental component of urban management system. The most challenging part of predicting crowd flow is to measure the complicated spatial-temporal dependencies. A prevalent solution employed in current methods is to divide and conquer the spatial and temporal information by various architectures (e.g., CNNGCN, LSTM). However, this strategy has two disadvantages: (1) the sophisticated dependencies are also divided and therefore partially isolated; (2) the spatial-temporal features are transformed into latent representations when passing through different architectures, making it hard to interpret the predicted crowd flow. To address these issues, we propose a Spatial-Temporal Self-Attention Network (STSAN) with an ST encoding gate that calculates the entire spatial-temporal representation with positional and time encodings and therefore avoids dividing the dependencies. Furthermore, we develop a Multi-aspect attention mechanism that applies scaled dot-product attention over spatial-temporal information and measures the attention weights that explicitly indicate the dependencies. Experimental results on traffic and mobile data demonstrate that the proposed method reduces inflow and outflow RMSE by 16 and 8 on the Taxi-NYC dataset compared to the SOTA baselines. Codes:", "text_perturb": "gang flow prediction has been increasingly investigated in intelligent urban computing field as a fundamental component of urban management system. The most challenging percentage of predicting crowd flow is to measure the complicated spatial-temporal dependencies. A prevalent solution employed in current methods is to carve up and conquer the spatial and temporal information by various architectures ( e. gram. , CNNGCN , LSTM ). However , this strategy has two disadvantages : ( 1 ) the sophisticated dependencies are also divided and therefore partially isolated ; ( 2 ) the spatial-temporal features are transformed into latent representations when excrete through different architectures , making it hard to interpret the predicted crowd flow. To address these issues , we propose a Spatial-Temporal Self-Attention Network ( STSAN ) with an ST encoding logic gate that calculates the entire spatial-temporal representation with positional and time encodings and therefore avoids dividing the dependencies. Furthermore , we produce a Multi-aspect attention mechanism that applies scaled dot-product attention over spatial-temporal information and measures the attention weights that explicitly indicate the dependencies. Experimental results on traffic and mobile data demonstrate that the proposed method reduces inflow and outflow RMSE by 16 and 8 on the Taxi-NYC dataset liken to the SOTA baselines. computer code :", "label": 1}
{"original_text": "Model compression is essential for serving large deep neural nets on devices with limited resources or applications that require real-time responses. As a case study, a state-of-the-art neural language model usually consists of one or more recurrent layers sandwiched between an embedding layer used for representing input tokens and a softmax layer for generating output tokens. For problems with a very large vocabulary size, the embedding and the softmax matrices can account for more than half of the model size. For instance, the bigLSTM model achieves state-of-the-art performance on the One-Billion-Word (OBW) dataset with around 800k vocabulary, and its word embedding and softmax matrices use more than 6GBytes space, and are responsible for over 90 of the model parameters. In this paper, we propose GroupReduce, a novel compression method for neural language models, based on vocabulary-partition (block) based low-rank matrix approximation and the inherent frequency distribution of tokens (the power-law distribution of words). The experimental results show our method can significantly outperform traditional compression methods such as low-rank approximation and pruning. On the OBW dataset, our method achieved 6.6 times compression rate for the embedding and softmax matrices, and when combined with quantization, our method can achieve 26 times compression rate, which translates to a factor of 12.8 times compression for the entire model with very little degradation in perplexity.", "text_perturb": "Model compression is essential for serving large deep neural nets on devices with limited resources or coating that require real-time responses. As a case study , a state-of-the-art neural language model commonly consists of one or more recurrent layers sandwiched between an embedding layer used for representing input tokens and a softmax layer for generating output tokens. For problems with a very large vocabulary sizing , the embedding and the softmax matrices can account for more than half of the model sizing. For instance , the bigLSTM model achieves state-of-the-art performance on the One-Billion-Word ( OBW ) dataset with around 800k vocabulary , and its christian bible embedding and softmax matrices use more than 6GBytes space , and are responsible for over 90 of the model parameters. In this paper , we propose GroupReduce , a novel compression method for neural language models , based on vocabulary-partition ( block ) based low-rank matrix approximation and the inherent frequency distribution of keepsake ( the power-law distribution of words ). The experimental results show our method can significantly outperform traditional compaction methods such as low-rank approximation and pruning. On the OBW dataset , our method achieved 6. 6 clock time compression rate for the embedding and softmax matrices , and when combined with quantization , our method can achieve 26 clock time compression rate , which translates to a factor of 12. 8 times compression for the entire good example with very little degradation in perplexity. ", "label": 1}
{"original_text": "Why and why-not provenance have been studied extensively in recent years. However, why-not provenance and - to a lesser degree - why provenance, can be very large resulting in severe scalability and usability challenges. In this paper, we introduce a novel approximate summarization technique for provenance which overcomes these challenges. Our approach uses patterns to encode (why-not) provenance concisely. We develop techniques for efficiently computing provenance summaries balancing informativeness, conciseness, and completeness. To achieve scalability, we integrate sampling techniques into provenance capture and summarization. Our approach is the first to scale to large datasets and to generate comprehensive and meaningful summaries.", "text_perturb": "Why and why-not provenance let been studied extensively in recent years. However , why-not provenance and - to a lesser degree - why provenance , can be very large resulting in severe scalability and usability challenge. In this paper , we introduce a novel approximate summarization technique for provenance which overcomes these challenge. Our approach uses patterns to encode ( why-not ) provenience concisely. We develop techniques for efficiently computing birthplace summaries balancing informativeness , conciseness , and completeness. To achieve scalability , we integrate sampling technique into provenance capture and summarization. Our approach is the first to scale to enceinte datasets and to generate comprehensive and meaningful summaries. ", "label": 1}
{"original_text": "In this paper we show how to efficiently produce unbiased estimates of subgraph frequencies from a probability sample of egocentric networks (i.e., focal nodes, their neighbors, and the induced subgraphs of ties among their neighbors). A key feature of our proposed method that differentiates it from prior methods is the use of egocentric data. Because of this, our method is suitable for estimation in large unknown graphs, is easily parallelizable, handles privacy sensitive network data (e.g. egonets with no neighbor labels), and supports counting of large subgraphs (e.g. maximal clique of size 205 in Section) by building on top of existing exact subgraph counting algorithms that may not support sampling. It gracefully handles a variety of sampling designs such as uniform or weighted independence or random walk sampling. Our method can be used for subgraphs that are: (i) undirected or directed; (ii) induced or non-induced; (iii) maximal or non-maximal; and (iv) potentially annotated with attributes. We compare our estimators on a variety of real-world graphs and sampling methods and provide suggestions for their use. Simulation shows that our method outperforms the state-of-the-art approach for relative subgraph frequencies by up to an order of magnitude for the same sample size. Finally, we apply our methodology to a rare sample of Facebook users across the social graph to estimate and interpret the clique size distribution and gender composition of cliques.", "text_perturb": "In this paper we show how to efficiently produce unbiased estimates of subgraph frequencies from a probability sample of egoistic networks ( i. es. , focal nodes , their neighbour , and the induced subgraphs of ties among their neighbour ). A key feature of our proposed method that differentiates it from prior method acting is the use of egocentric data. Because of this , our method is suitable for estimation in large unknown graphs , is easily parallelizable , address privacy sensitive network data ( e. gib. egonets with no neighbor labels ) , and supports counting of great subgraphs ( e. one thousand. maximum clique of size 205 in Section ) by building on top of existing exact subgraph counting algorithms that may not support sampling. It gracefully handles a variety of try designs such as uniform or weighted independence or random walk try. Our method can be used for subgraphs that are : ( i ) undirected or directed ; ( ii ) induced or non-induced ; (  ) maximal or non-maximal ; and ( iv ) potentially annotated with attributes. We liken our estimators on a variety of real-world graphs and sampling methods and provide suggestions for their use. Simulation shows that our method acting outperforms the state-of-the-art approach for relative subgraph frequencies by up to an order of magnitude for the same sample size. Finally , we apply our methodology to a rare sample of Facebook users across the social graph to estimate and construe the clique size distribution and gender composition of cliques. ", "label": 1}
{"original_text": "Instant messaging is one of the major channels of computer mediated communication. However, humans are known to be very limited in understanding others' emotions via text-based communication. Aiming on introducing emotion sensing technologies to instant messaging, we developed EmotionPush, a system that automatically detects the emotions of the messages end-users received on Facebook Messenger and provides colored cues on their smartphones accordingly. We conducted a deployment study with 20 participants during a time span of two weeks. In this paper, we revealed five challenges, along with examples, that we observed in our study based on both user's feedback and chat logs, including (i) the continuum of emotions, (ii) multi-user conversations, (iii) different dynamics between different users, (iv) misclassification of emotions, and (v) unconventional content. We believe this discussion will benefit the future exploration of affective computing for instant messaging, and also shed light on research of conversational emotion sensing.", "text_perturb": "exigent messaging is one of the major channels of computer mediated communication. However , humans are known to be real limited in understanding others ' emotions via text-based communication. Aiming on introducing emotion sensing technologies to instant messaging , we developed EmotionPush , a system that automatically detects the emotion of the messages end-users received on Facebook Messenger and provides colored cues on their smartphones accordingly. We conducted a deployment study with 20 participants during a meter span of two weeks. In this paper , we revealed five challenges , along with examples , that we observed in our study based on both user 's feedback and chat logs , including ( i ) the continuum of emotions , ( ii ) multi-user conversations , ( iii ) different dynamics between different users , ( quadruplet ) misclassification of emotions , and ( v ) unconventional content. We believe this discussion will benefit the future exploration of affective computing for instant electronic messaging , and also shed light on research of conversational emotion sensing. ", "label": 1}
{"original_text": "In this paper, a mathematical theory of learning is proposed that has many parallels with information theory. We consider Vapnik's General Setting of Learning in which the learning process is defined to be the act of selecting a hypothesis in response to a given training set. Such hypothesis can, for example, be a decision boundary in classification, a set of centroids in clustering, or a set of frequent item-sets in association rule mining. Depending on the hypothesis space and how the final hypothesis is selected, we show that a learning process can be assigned a numeric score, called learning capacity, which is analogous to Shannon's channel capacity and satisfies similar interesting properties as well such as the data-processing inequality and the information-cannot-hurt inequality. In addition, learning capacity provides the tightest possible bound on the difference between true risk and empirical risk of the learning process for all loss functions that are parametrized by the chosen hypothesis. It is also shown that the notion of learning capacity equivalently quantifies how sensitive the choice of the final hypothesis is to a small perturbation in the training set. Consequently, algorithmic stability is both necessary and sufficient for generalization. While the theory does not rely on concentration inequalities, we finally show that analogs to classical results in learning theory using the Probably Approximately Correct (PAC) model can be immediately deduced using this theory, and conclude with information-theoretic bounds to learning capacity.", "text_perturb": "In this paper , a mathematical theory of learning is propose that has many parallels with information theory. We consider Vapnik 's General Setting of Learning in which the learning process is defined to be the human activity of selecting a hypothesis in response to a given training set. Such hypothesis can , for example , represent a decision boundary in classification , a set of centroids in clustering , or a set of frequent item-sets in association rule mining. Depending on the hypothesis space and how the final hypothesis is selected , we show that a learning process can be assigned a numeric score , called learning capability , which is analogous to Shannon 's channel capability and satisfies similar interesting properties as well such as the data-processing inequality and the information- can not -hurt inequality. In addition , learning capacity provides the tightest possible bound on the difference between true endangerment and empirical endangerment of the learning process for all loss functions that are parametrized by the chosen hypothesis. It is also shown that the notion of learning electrical capacity equivalently quantifies how sensitive the choice of the final hypothesis is to a small perturbation in the training set. accordingly , algorithmic stability is both necessary and sufficient for generalization. While the possibility does not rely on concentration inequalities , we finally show that analogs to classical results in learning possibility using the Probably Approximately Correct ( PAC ) model can be immediately deduced using this possibility , and conclude with information-theoretic bounds to learning capacity. ", "label": 1}
{"original_text": "The ABSTRACT is to be in fully-justified italicized text, at the top of the left-hand column, below the author and affiliation information. Use the word \"Abstract\" as the title, in 12-point Times, boldface type, centered relative to the column, initially capitalized. The abstract is to be in 10-point, single-spaced type. Leave two blank lines after the Abstract, then begin the main text. Look at previous WACV abstracts to get a feel for style and length.", "text_perturb": "The ABSTRACT is to be in fully-justified italicized text , at the top of the left-hand column , below the author and affiliation entropy. Use the word `` abstract '' as the title , in 12-point Times , boldface type , centered relative to the column , initially capitalized. The abstract is to be in 10-point , single-spaced character. Leave two clean lines after the Abstract , then begin the main text. Look at previous WACV abstracts to get a spirit for style and length. ", "label": 1}
{"original_text": "The weight of a subgraph H in G is the sum of the degrees in G of vertices of H. The height of a subgraph H in G is the maximum degree of vertices of H in G. A star in a given graph is minor if its center has degree at most five in the given graph. Lebesgue (1940) gave an approximate description of minor 5 -stars in the class of normal plane maps with minimum degree five. In this paper, we give two descriptions of minor 5 -stars in plane graphs with minimum degree five. By these descriptions, we can extend several results and give some new results on the weight and height for some special plane graphs with minimum degree five.", "text_perturb": "The weight of a subgraph h in G is the sum of the degrees in G of vertices of h. The height of a subgraph H in G embody the maximum degree of vertices of H in G. A star in a given graphical record is minor if its center has degree at most five in the given graphical record. Lebesgue ( 1940 ) make an approximate description of minor 5 -stars in the class of normal plane maps with minimum degree five. In this paper , we impart two descriptions of minor 5 -stars in plane graphs with minimum degree five. By these descriptions , we can extend several solution and give some new solution on the weight and height for some special plane graphs with minimum degree five. ", "label": 1}
{"original_text": "Imitation learning has traditionally been applied to learn a single task from demonstrations thereof. The requirement of structured and isolated demonstrations limits the scalability of imitation learning approaches as they are difficult to apply to real-world scenarios, where robots have to be able to execute a multitude of tasks. In this paper, we propose a multi-modal imitation learning framework that is able to segment and imitate skills from unlabelled and unstructured demonstrations by learning skill segmentation and imitation learning jointly. The extensive simulation results indicate that our method can efficiently separate the demonstrations into individual skills and learn to imitate them using a single multi-modal policy. The video of our experiments is available at", "text_perturb": "Imitation learning has traditionally been utilize to learn a single task from demonstrations thereof. The requirement of structured and isolated demonstrations limits the scalability of imitation learning approaches as they are difficult to apply to real-world scenarios , where robots have to be able to execute a masses of tasks. In this paper , we propose a multi-modal imitation learning framework that is able to segment and imitate skills from unlabelled and amorphous demonstrations by learning skill segmentation and imitation learning jointly. The extensive simulation results indicate that our method can efficiently separate the demonstrations into individual skill and learn to imitate them using a single multi-modal policy. The video of our experiments is usable at", "label": 1}
{"original_text": "Tensor completion is a challenging problem with various applications. Many related models based on the low-rank prior of the tensor have been proposed. However, the low-rank prior may not be enough to recover the original tensor from the observed incomplete tensor. In this paper, we prose a tensor completion method by exploiting both the low-rank and sparse prior of tensor. Specifically, the tensor completion task can be formulated as a low-rank minimization problem with a sparse regularizer. The low-rank property is depicted by the tensor truncated nuclear norm based on tensor singular value decomposition (T-SVD) which is a better approximation of tensor tubal rank than tensor nuclear norm. While the sparse regularizer is imposed by a l 1 -norm in a discrete cosine transformation (DCT) domain, which can better employ the local sparse property of completed data. To solve the optimization problem, we employ an alternating direction method of multipliers (ADMM) in which we only need to solve several subproblems which have closed-form solutions. Substantial experiments on real world images and videos show that the proposed method has better performances than the existing state-of-the-art methods.", "text_perturb": "Tensor completion exist a challenging problem with various applications. Many related models based on the low-rank prior of the tensor receive been proposed. However , the low-rank prior may not be enough to recuperate the original tensor from the observed incomplete tensor. In this paper , we prose a tensor pass completion method by exploiting both the low-rank and sparse prior of tensor. Specifically , the tensor completion chore can be formulated as a low-rank minimization problem with a sparse regularizer. The low-rank property is depicted by the tensor truncated nuclear average based on tensor singular value decomposition ( T-SVD ) which is a better approximation of tensor tubal rank than tensor nuclear average. While the sparse regularizer is imposed by a l 1 -norm in a discrete cosine transformation ( DCT ) domain , which tin better employ the local sparse property of completed data. To solve the optimization trouble , we employ an alternating direction method of multipliers ( ADMM ) in which we only need to solve several subproblems which have closed-form solutions. Substantial experiments on real world images and videos show that the offer method has better performances than the existing state-of-the-art methods. ", "label": 1}
{"original_text": "In this paper we systematically study the importance, i.e., the influence on performance, of the main design elements that differentiate scalarizing functions-based multiobjective evolutionary algorithms (MOEAs). This class of MOEAs includes Multiobjecitve Genetic Local Search (MOGLS) and Multiobjective Evolutionary Algorithm Based on Decomposition (MOEAD) and proved to be very successful in multiple computational experiments and practical applications. The two algorithms share the same common structure and differ only in two main aspects. Using three different multiobjective combinatorial optimization problems, i.e., the multiobjective symmetric traveling salesperson problem, the traveling salesperson problem with profits, and the multiobjective set covering problem, we show that the main differentiating design element is the mechanism for parent selection, while the selection of weight vectors, either random or uniformly distributed, is practically negligible if the number of uniform weight vectors is sufficiently large.", "text_perturb": "In this paper we consistently study the importance , i. einsteinium. , the influence on performance , of the main blueprint elements that differentiate scalarizing functions-based multiobjective evolutionary algorithms ( MOEAs ). This class of MOEAs includes Multiobjecitve Genetic Local Search ( MOGLS ) and Multiobjective Evolutionary Algorithm Based on chemical decomposition reaction ( MOEAD ) and proved to be very successful in multiple computational experiments and practical applications. The two algorithms share the same vulgar structure and differ only in two main aspects. Using three different multiobjective combinatorial optimization problems , i. einsteinium. , the multiobjective symmetric traveling salesperson problem , the traveling salesperson problem with profits , and the multiobjective set covering problem , we show that the main differentiating design element represent the mechanism for parent selection , while the selection of weight vectors , either random or uniformly distributed , represent practically negligible if the number of uniform weight vectors represent sufficiently large. ", "label": 1}
{"original_text": "Search advertising, a popular method for online marketing, has been employed to improve health by eliciting positive behavioral change. However, writing effective advertisements requires expertise and experimentation, which may not be available to health authorities wishing to elicit such changes, especially when dealing with public health crises such as epidemic outbreaks. Here we develop a framework, comprised of two neural networks models, that automatically generate ads. First, it employs a generator model, which create ads from web pages. It then employs a translation model, which transcribes ads to improve performance. We trained the networks using 114K health-related ads shown on Microsoft Advertising. We measure ads performance using the click-through rates (CTR). Our experiments show that the generated advertisements received approximately the same CTR as human-authored ads. The marginal contribution of the generator model was, on average, 28 lower than that of human-authored ads, while the translator model received, on average, 32 more clicks than human-authored ads. Our analysis shows that the translator model produces ads reflecting higher values of psychological attributes associated with a user action, including higher valance and arousal, and more calls-to-actions. In contrast, levels of these attributes in ads produced by the generator model are similar to those of human-authored ads. Our results demonstrate the ability to automatically generate useful advertisements for the health domain. We believe that our work offers health authorities an improved ability to nudge people towards healthier behaviors while saving the time and cost needed to build effective advertising campaigns.", "text_perturb": "hunting advertising , a popular method for online marketing , has been employed to improve health by eliciting positive behavioral change. However , writing effective advertisements requires expertise and experimentation , which may not be available to health authorities wishing to elicit such changes , especially when dealing with public health crises such as epidemic irruption. here we develop a framework , comprised of two neural networks models , that automatically generate ads. First , it employs a generator model , which create ads from web varlet. It then employs a translation model , which transcribe ads to improve performance. We trained the networks using 114K health-related ads shown on Microsoft advertising. We measure ads performance using the click-through rates ( CTR ). Our experiments depict that the generated advertisements received approximately the same CTR as human-authored ads. The marginal donation of the generator model was , on average , 28 lower than that of human-authored ads , while the translator model received , on average , 32 more clicks than human-authored ads. Our analysis shows that the translator model get ads reflecting higher values of psychological attributes associated with a user action , including higher valance and arousal , and more calls-to-actions. In contrast , levels of these attributes in ad produced by the generator model are similar to those of human-authored ad. Our results demonstrate the ability to automatically generate useful advertisements for the health knowledge domain. We believe that our work offers health potency an improved ability to nudge people towards healthier behaviors while saving the time and cost needed to build effective advertising campaigns. ", "label": 1}
{"original_text": "In the Graph Isomorphism (GI) problem two N -vertex graphs G and G ' are given and the task is to determine whether there exists a permutation of the vertices of G that preserves adjacency and transforms - G G '. If yes, then G and G ' are said to be isomorphic; otherwise they are non-isomorphic. The GI problem is an important problem in computer science and is thought to be of comparable difficulty to integer factorization. In this paper we present a quantum algorithm that solves arbitrary instances of GI and which also provides a novel approach to determining all automorphisms of a given graph. We show how the GI problem can be converted to a combinatorial optimization problem that can be solved using adiabatic quantum evolution. We numerically simulate the algorithm's quantum dynamics and show that it correctly: (i) distinguishes non-isomorphic graphs; (ii) recognizes isomorphic graphs and determines the permutation (s) that connect them; and (iii) finds the automorphism group of a given graph G. We then discuss the GI quantum algorithm's experimental implementation, and close by showing how it can be leveraged to give a quantum algorithm that solves arbitrary instances of the NP-Complete Sub-Graph Isomorphism problem. The computational complexity of an adiabatic quantum algorithm is largely determined by the minimum energy gap D (N) separating the ground- and first-excited states in the limit of large problem size N 1. Calculating D (N) in this limit is a fundamental open problem in adiabatic quantum computing, and so it is not possible to determine the computational complexity of adiabatic quantum algorithms in general, nor consequently, of the specific adiabatic quantum algorithms presented here. Adiabatic quantum computing has been shown to be equivalent to the circuit-model of quantum computing, and so development of adiabatic quantum algorithms continues to be of great interest.", "text_perturb": "In the Graph isomorphy ( GI ) problem two N -vertex graphs G and G ' are given and the task is to determine whether there exists a permutation of the vertices of G that preserves adjacency and transforms - G G '. If yes , then gibibyte and gibibyte ' are said to be isomorphic ; otherwise they are non-isomorphic. The GI problem is an important problem in computer skill and is thought to be of comparable difficulty to integer factorization. In this paper we present a quantum algorithmic program that solves arbitrary instances of GI and which also provides a novel approach to determining all automorphisms of a given graph. We show how the GI job can be converted to a combinatorial optimization job that can be solved using adiabatic quantum evolution. We numerically simulate the algorithm 's quantum dynamics and show that it correctly : ( i ) distinguishes non-isomorphic graphs ; ( ii ) recognizes isomorphic graphs and determines the transposition ( s ) that connect them ; and ( iii ) finds the automorphism group of a given graph G. We then discuss the GI quantum algorithm 's experimental implementation , and closely by showing how it can be leveraged to give a quantum algorithm that solves arbitrary instances of the NP-Complete Sub-Graph Isomorphism problem. The computational complexity of an adiabatic quantum algorithm is largely determined by the minimal energy gap D ( N ) separating the ground- and first-excited states in the limit of large problem size N 1. Calculating D ( N ) in this limit is a fundamental open problem in adiabatic quantum calculation , and so it is not possible to determine the computational complexity of adiabatic quantum algorithms in general , nor consequently , of the specific adiabatic quantum algorithms presented here. Adiabatic quantum computing has been evidence to be equivalent to the circuit-model of quantum computing , and so development of adiabatic quantum algorithms continues to be of great interest. ", "label": 1}
{"original_text": "Gibbs sampling is a Markov Chain Monte Carlo sampling technique that iteratively samples variables from their conditional distributions. There are two common scan orders for the variables: random scan and systematic scan. Due to the benefits of locality in hardware, systematic scan is commonly used, even though most statistical guarantees are only for random scan. While it has been conjectured that the mixing times of random scan and systematic scan do not differ by more than a logarithmic factor, we show by counterexample that this is not the case, and we prove that that the mixing times do not differ by more than a polynomial factor under mild conditions. To prove these relative bounds, we introduce a method of augmenting the state space to study systematic scan using conductance.", "text_perturb": "Gibbs sampling is a Markov Chain Monte Carlo sampling proficiency that iteratively samples variables from their conditional distributions. There are two common scan club for the variables : random scan and systematic scan. Due to the benefits of vicinity in hardware , systematic scan is commonly used , even though most statistical guarantees are only for random scan. While it has been conjectured that the mixing times of random scan and systematic scan do not differ by more than a logarithmic factor , we show by counterexample that this be not the case , and we prove that that the mixing times do not differ by more than a polynomial factor under mild conditions. To prove these relative bounds , we innovate a method of augmenting the state space to study systematic scan using conductance. ", "label": 1}
{"original_text": "The kernel k -means is an effective method for data clustering which extends the commonly-used k -means algorithm to work on a similarity matrix over complex data structures. It is, however, computationally very complex as it requires the complete kernel matrix to be calculated and stored. Further, its kernelized nature hinders the parallelization of its computations on modern scalable infrastructures for distributed computing. In this paper, we are defining a family of kernel-based low-dimensional embeddings that allows for scaling kernel k -means on MapReduce via an efficient and unified parallelization strategy. Afterwards, we propose two practical methods for low-dimensional embedding that adhere to our definition of the embeddings family. Exploiting the proposed parallelization strategy, we present two scalable MapReduce algorithms for kernel k -means. We demonstrate the effectiveness and efficiency of the proposed algorithms through an empirical evaluation on benchmark datasets.", "text_perturb": "The kernel k -means is an effective method for data clump which extends the commonly-used k -means algorithm to work on a similarity matrix over complex data structures. It exist , however , computationally very complex as it requires the complete kernel matrix to be calculated and stored. Further , its kernelized nature hinders the parallelization of its computations on modern scalable base for distributed computing. In this paper , we are defining a family of kernel-based low-dimensional embeddings that allows for surmount kernel k -means on MapReduce via an efficient and unified parallelization strategy. Afterwards , we propose two practical method for low-dimensional embedding that adhere to our definition of the embeddings family. Exploiting the proposed parallelization scheme , we present two scalable MapReduce algorithms for kernel k -means. We show the effectiveness and efficiency of the proposed algorithms through an empirical evaluation on benchmark datasets. ", "label": 1}
{"original_text": "The problem of mesh matching is addressed in this work. For a given n -sided planar region bounded by one loop of n polylines we are selecting optimal quadrilateral mesh from existing catalogue of meshes. The formulation of matching between planar shape and quadrilateral mesh from the catalogue is based on the problem of finding longest common subsequence (LCS). Theoretical foundation of mesh matching method is provided. Suggested method represents a viable technique for selecting best mesh for planar region and stepping stone for further parametrization of the region.", "text_perturb": "The problem of mesh matching embody addressed in this work. For a given n -sided planar region bounded by one loop of n polylines we are choose optimal quadrilateral mesh from existing catalogue of meshes. The formulation of matching between planar shape and quadrilateral mesh from the catalog is based on the problem of finding longest common subsequence ( LCS ). Theoretical foundation of mesh fit method is provided. Suggested method represents a viable technique for selecting best mesh for planar region and stepping harlan fisk stone for further parametrization of the region. ", "label": 1}
{"original_text": "Fast Magnetic Resonance Imaging (MRI) is highly in demand for many clinical applications in order to reduce the scanning cost and improve the patient experience. This can also potentially increase the image quality by reducing the motion artefacts and contrast washout. However, once an image field of view and the desired resolution are chosen, the minimum scanning time is normally determined by the requirement of acquiring sufficient raw data to meet the Nyquist-Shannon sampling criteria. Compressive Sensing (CS) theory has been perfectly matched to the MRI scanning sequence design with much less required raw data for the image reconstruction. Inspired by recent advances in deep learning for solving various inverse problems, we propose a conditional Generative Adversarial Networks-based deep learning framework for de-aliasing and reconstructing MRI images from highly undersampled data with great promise to accelerate the data acquisition process. By coupling an innovative content loss with the adversarial loss our de-aliasing results are more realistic. Furthermore, we propose a refinement learning procedure for training the generator network, which can stabilise the training with fast convergence and less parameter tuning. We demonstrate that the proposed framework outperforms state-of-the-art CS-MRI methods, in terms of reconstruction error and perceptual image quality. In addition, our method can reconstruct each image in 0.22ms-0.37ms, which is promising for real-time applications.", "text_perturb": "Fast Magnetic Resonance Imaging ( MRI ) is highly in demand for many clinical applications in order to reduce the scanning cost and ameliorate the patient experience. This can also potentially increase the image quality by slenderize the motion artefacts and contrast washout. However , once an trope field of view and the desired resolution are chosen , the minimum scanning time is normally determined by the requirement of acquiring sufficient raw data to meet the Nyquist-Shannon sampling criteria. Compressive Sensing ( CS ) theory has been perfectly oppose to the MRI scanning sequence design with much less required raw data for the image reconstruction. Inspired by recent advances in deep learning for solving various inverse problems , we propose a conditional Generative Adversarial Networks-based deep learning framework for de-aliasing and reconstructing MRI images from highly undersampled data with enceinte promise to accelerate the data acquisition process. By coupling an innovative content loss with the adversarial loss our de-aliasing results are more naturalistic. Furthermore , we propose a refinement erudition procedure for training the generator network , which can stabilise the training with fast convergence and less parameter tuning. We demonstrate that the proposed framework outperforms state-of-the-art CS-MRI methods , in terms of reconstruction period error and perceptual image quality. In addition , our method can reconstruct each look alike in 0. 22ms-0. 37ms , which make up promising for real-time applications. ", "label": 1}
{"original_text": "In training speech recognition systems, labeling audio clips can be expensive, and not all data is equally valuable. Active learning aims to label only the most informative samples to reduce cost. For speech recognition, confidence scores and other likelihood-based active learning methods have been shown to be effective. Gradient-based active learning methods, however, are still not well-understood. This work investigates the Expected Gradient Length (EGL) approach in active learning for end-to-end speech recognition. We justify EGL from a variance reduction perspective, and observe that EGL 's measure of informativeness picks novel samples uncorrelated with confidence scores. Experimentally, we show that EGL can reduce word errors by 11, or alternatively, reduce the number of samples to label by 50, when compared to random sampling.", "text_perturb": "In training speech recognition organisation , labeling audio clips can be expensive , and not all data is equally valuable. Active learning aims to label solely the most informative samples to reduce cost. For speech recognition , confidence scores and other likelihood-based combat ready learning methods have been shown to be effective. Gradient-based active learning methods , even so , are still not well-understood. This work investigates the Expected Gradient Length ( EGL ) approach in active learning for end-to-end words recognition. We justify EGL from a variance reduction perspective , and observe that EGL 's measure of informativeness picks novel sample uncorrelated with confidence scores. experimentally , we show that EGL can reduce word errors by 11 , or alternatively , reduce the number of samples to label by 50 , when compared to random sampling. ", "label": 1}
{"original_text": "Recent studies have shown that the environment where people eat can affect their nutritional behaviour. In this work, we provide automatic tools for personalised analysis of a person's health habits by the examination of daily recorded egocentric photo-streams. Specifically, we propose a new automatic approach for the classification of food-related environments, that is able to classify up to 15 such scenes. In this way, people can monitor the context around their food intake in order to get an objective insight into their daily eating routine. We propose a model that classifies food-related scenes organized in a semantic hierarchy. Additionally, we present and make available a new egocentric dataset composed of more than 33000 images recorded by a wearable camera, over which our proposed model has been tested. Our approach obtains an accuracy and F-score of 56 and 65, respectively, clearly outperforming the baseline methods.", "text_perturb": "Recent studies have shown that the environment where people eat can affect their nutritional deportment. In this work , we provide automatic tools for personalised analytic thinking of a person 's health habits by the examination of daily recorded egocentric photo-streams. Specifically , we advise a new automatic approach for the classification of food-related environments , that is able to classify up to 15 such scenes. In this way , people can monitor the context around their food intake in order to have an objective insight into their daily eating routine. We propose a model that classifies food-related scenes unionise in a semantic hierarchy. Additionally , we present and make available a new self centred dataset composed of more than 33000 images recorded by a wearable camera , over which our proposed model has been tested. Our approach obtains an accuracy and F-score of 56 and 65 , respectively , intelligibly outperforming the baseline methods. ", "label": 1}
{"original_text": "One of the biggest hurdles for customers when purchasing fashion online, is the difficulty of finding products with the right fit. In order to provide a better online shopping experience, platforms need to find ways to recommend the right product sizes and the best fitting products to their customers. These recommendation systems, however, require customer feedback in order to estimate the most suitable sizing options. Such feedback is rare and often only available as natural text. In this paper, we examine the extraction of product fit feedback from customer reviews using natural language processing techniques. In particular, we compare traditional methods with more recent transfer learning techniques for text classification, and analyze their results. Our evaluation shows, that the transfer learning approach ULMFit is not only comparatively fast to train, but also achieves highest accuracy on this task. The integration of the extracted information with actual size recommendation systems is left for future work.", "text_perturb": "One of the biggest hurdles for customers when purchasing fashion online , is the difficulty of finding ware with the right fit. In order to provide a better online shopping experience , platforms need to find ways to recommend the right product sizes and the best fitting mathematical product to their customers. These recommendation systems , however , require customer feedback in order to count on the most suitable sizing options. Such feedback is rare and often only usable as natural text. In this paper , we examine the extraction of product fit feedback from customer recap using natural language processing techniques. In particular , we compare traditional method acting with more recent transfer learning techniques for text classification , and analyze their results. Our evaluation shows , that the transfer learning approach ULMFit is not only comparatively fast to train , but also achieves gamy accuracy on this task. The integration of the extracted information with actual size recommendation systems make up left for future work. ", "label": 1}
{"original_text": "Visual localization is the problem of estimating a camera within a scene and a key technology for autonomous robots. State-of-the-art approaches for accurate visual localization use scene-specific representations, resulting in the overhead of constructing these models when applying the techniques to new scenes. Recently, learned approaches based on relative pose estimation have been proposed, carrying the promise of easily adapting to new scenes. However, they are currently significantly less accurate than state-of-the-art approaches. In this paper, we are interested in analyzing this behavior. To this end, we propose a novel framework for visual localization from relative poses. Using a classical feature-based approach within this framework, we show state-of-the-art performance. Replacing the classical approach with learned alternatives at various levels, we then identify the reasons for why deep learned approaches do not perform well. Based on our analysis, we make recommendations for future work.", "text_perturb": "Visual localization is the problem of estimating a camera within a scene and a key technology for self governing robots. State-of-the-art approaches for accurate visual localization of function use scene-specific representations , resulting in the overhead of constructing these models when applying the techniques to new scenes. Recently , learned approaches based on relative pose estimation deliver been proposed , carrying the promise of easily adapting to new scenes. However , they are currently significantly to a lesser extent accurate than state-of-the-art approaches. In this paper , we are concerned in analyzing this behavior. To this end , we propose a novel framework for visual localization from proportional poses. Using a classical feature-based plan of attack within this framework , we show state-of-the-art performance. Replacing the classical plan of attack with learned alternatives at various levels , we then identify the reasons for why deep learned approaches do not perform well. Based on our analysis , we make recommendations for future employment. ", "label": 1}
{"original_text": "We consider a scenario where multiple infrastructure components have been damaged after a disaster and the health value of each component continues to deteriorate if it is not being targeted by a repair agency, until it fails irreversibly. There are multiple agencies that seek to repair the components and there is an authority whose task is to allocate the components to the agencies within a given budget, so that the total number of components that are fully repaired by the agencies is maximized. We characterize the optimal policy for allocation and repair sequencing when the repair rates are sufficiently larger than the deterioration rates. For the case when the deterioration rates are larger than or equal to the repair rates, the rates are homogeneous across the components, and the costs charged by the entities for repair are equal, we characterize a policy for allocation and repair sequencing that permanently repairs at least half the number of components as that by an optimal policy.", "text_perturb": "We consider a scenario where multiple infrastructure components have been damage after a disaster and the health value of each component continues to deteriorate if it is not being targeted by a repair agency , until it fails irreversibly. There are multiple agencies that seek to repair the components and there is an authority whose undertaking is to allocate the components to the agencies within a given budget , so that the total number of components that are fully repaired by the agencies is maximized. We characterize the optimal insurance for allocation and repair sequencing when the repair rates are sufficiently larger than the deterioration rates. For the case when the deterioration rates are larger than or equal to the repair rates , the rates are homogeneous across the portion , and the costs charged by the entities for repair are equal , we characterize a policy for allocation and repair sequencing that permanently repairs at least half the number of portion as that by an optimal policy. ", "label": 1}
{"original_text": "Recognizing text from natural images is a hot research topic in computer vision due to its various applications. Despite the enduring research of several decades on optical character recognition (OCR), recognizing texts from natural images is still a challenging task. This is because scene texts are often in irregular (e.g. curved, arbitrarily-oriented or seriously distorted) arrangements, which have not yet been well addressed in the literature. Existing methods on text recognition mainly work with regular (horizontal and frontal) texts and cannot be trivially generalized to handle irregular texts. In this paper, we develop the arbitrary orientation network (AON) to directly capture the deep features of irregular texts, which are combined into an attention-based decoder to generate character sequence. The whole network can be trained end-to-end by using only images and word-level annotations. Extensive experiments on various benchmarks, including the CUTE80, SVT-Perspective, IIIT5k, SVT and ICDAR datasets, show that the proposed AON-based method achieves the-state-of-the-art performance in irregular datasets, and is comparable to major existing methods in regular datasets.", "text_perturb": "Recognizing text from raw images is a hot research topic in computer vision due to its various applications. Despite the support research of several decades on optical character recognition ( OCR ) , recognizing texts from natural images is still a challenging task. This is because scene texts equal often in irregular ( e. . curved , arbitrarily-oriented or seriously distorted ) musical arrangement , which have not yet been well addressed in the literature. Existing methods on text recognition mainly work with regular ( horizontal and frontal ) texts and send away not be trivially generalized to handle irregular texts. In this paper , we develop the arbitrary orientation network ( AON ) to directly capture the deep features of irregular texts , which are combined into an attention-based decoder to beget character sequence. The whole network can be trained end-to-end by using only images and word-level note. Extensive experiments on various benchmarks , including the CUTE80 , SVT-Perspective , IIIT5k , SVT and ICDAR datasets , show that the proposed AON-based method achieves the-state-of-the-art performance in irregular datasets , and is comparable to major existing method in regular datasets. ", "label": 1}
{"original_text": "Wikidata constraints, albeit useful, are represented and processed in an incomplete, ad hoc fashion. Constraint declarations do not fully express their meaning, and thus do not provide a precise, unambiguous basis for constraint specification, or a logical foundation for constraint-checking implementations. In prior work we have proposed a logical framework for Wikidata as a whole, based on multi-attributed relational structures (MARS) and related logical languages. In this paper we explain how constraints are handled in the proposed framework, and show that nearly all of Wikidata's existing property constraints can be completely characterized in it, in a natural and economical fashion. We also give characterizations for several proposed property constraints, and show that a variety of non-property constraints can be handled in the same framework.", "text_perturb": "Wikidata constraints , albeit useful , are represented and processed in an uncompleted , ad hoc fashion. Constraint declarations do not fully express their meaning , and thus do not provide a precise , unambiguous basis for constraint specification , or a logical foundation for constraint-checking implementation. In prior work we have proposed a logical framework for Wikidata as a whole , based on multi-attributed relational structures ( blemish ) and related logical languages. In this paper we excuse how constraints are handled in the proposed framework , and show that nearly all of Wikidata 's existing property constraints can be completely characterized in it , in a natural and economical fashion. We also give characterizations for several proposed property constraints , and show that a variety of non-property constraints can be handled in the same theoretical account. ", "label": 1}
{"original_text": "A profile matching algorithm takes as input a user profile of one social network and returns, if existing, the profile of the same person in another social network. Such methods have immediate applications in Internet marketing, search, security, and a number of other domains, which is why this topic saw a recent surge in popularity. In this paper, we present a user identity resolution approach that uses minimal supervision and achieves a precision of 0.98 at a recall of 0.54. Furthermore, the method is computationally efficient and easily parallelizable. We show that the method can be used to match Facebook, the most popular social network globally, with VKontakte, the most popular social network among Russian-speaking users.", "text_perturb": "A profile matching algorithm takes as input a user profile of one social net and returns , if existing , the profile of the same person in another social net. Such methods have immediate applications in Internet selling , search , security , and a number of other domains , which is why this topic saw a recent surge in popularity. In this paper , we present a user identity resolution approach that uses minimal superintendence and achieves a precision of 0. 98 at a recollection of 0. 54. Furthermore , the method is computationally efficient and well parallelizable. We show that the method acting can be used to match Facebook , the most popular social network globally , with VKontakte , the most popular social network among Russian-speaking users. ", "label": 1}
{"original_text": "In certain applications, relay terminals can be employed to simultaneously deliver information and energy to a designated receiver and a radio frequency (RF) energy harvester, respectively. In such scenarios, the relay that is preferable for information transmission does not necessarily coincide with the relay with the strongest channel to the energy harvester, since the corresponding channels fade independently. Relay selection thus entails a tradeoff between the efficiency of the information transfer to the receiver and the amount of energy transferred to the energy harvester. The study of this tradeoff is the subject on which this work mainly focuses. Specifically, we investigate the behavior of the ergodic capacity and the outage probability of the information transmission to the receiver, for a given amount of energy transferred to the RF energy harvester. We propose two relay selection methods that apply to any number of available relays. Furthermore, for the case of two relays, we develop the optimal relay selection method in a maximum capacity minimum outage probability sense, for a given energy transfer constraint. A close-to-optimal selection method that is easier to analyze than the optimal one is also examined. Closed-form expressions for the capacity-energy and the outage-energy tradeoffs of the developed schemes are provided and corroborated by simulations. Interesting insights on the aforementioned tradeoffs are obtained.", "text_perturb": "In certain applications , relay terminals put up be employed to simultaneously deliver information and energy to a designated receiver and a radio frequency ( RF ) energy harvester , respectively. In such scenarios , the relay that is preferable for information transmission does not necessarily coincide with the relay with the strongest channel to the energy harvester , since the corresponding channels fade severally. Relay selection thus entails a tradeoff between the efficiency of the information transfer to the receiver and the amount of energy change to the energy harvester. The study of this tradeoff personify the subject on which this work mainly focuses. Specifically , we investigate the doings of the ergodic capacity and the outage probability of the information transmission to the receiver , for a given amount of energy transferred to the RF energy harvester. We propose two relay selection methods that apply to any number of available relay. Furthermore , for the case of two relays , we develop the optimal relay selection method in a maximum capacitance minimum outage probability sense , for a given energy transfer constraint. A close-to-optimal selection method acting that is easier to analyze than the optimal one is also examined. Closed-form expressions for the capacity-energy and the outage-energy tradeoffs of the developed schemes are provided and corroborated by simulation. Interesting insights on the aforementioned trade off are obtained. ", "label": 1}
{"original_text": "An innovative 3-D radar imaging technique is developed for fast and efficient identification and characterization of radar backscattering components of complex objects, when the collected scattered field is made of polarization-diverse measurements. In this context, all the polarimetric information seems irretrievably mixed. A direct model, derived from a simple but original extension of the widespread \"multiple scattering model\" leads to a high dimensional linear inverse problem. It is solved by a fast dedicated imaging algorithm that performs to determine at a time three huge 3-D scatterer maps which correspond to HH, VV and HV polarizations at emission and reception. It is applied successfully to various mock-ups and data sets collected from an accurate and dedicated 3D spherical experimental layout that provides concentric polarization-diverse RCS measurements.", "text_perturb": "An innovative 3-D radar imaging technique is developed for fasting and efficient identification and characterization of radar backscattering components of complex objects , when the collected scattered field is made of polarization-diverse measurements. In this context , all the polarimetric selective information seems irretrievably mixed. A direct model , derived from a simple but original extension of the widespread `` multiple scattering model '' leads to a gamy dimensional linear inverse problem. It is solved by a fast dedicated imaging algorithm that perform to determine at a time three huge 3-D scatterer maps which correspond to HH , VV and HV polarizations at emission and reception. It is applied successfully to various mock-ups and data sets collected from an accurate and dedicated 3D spherical experimental layout that provides concentrical polarization-diverse RCS measurements. ", "label": 1}
{"original_text": "Formalizing self reproduction in dynamical hierarchies is one of the important problems in Artificial Life (AL) studies. We study, in this paper, an inductively defined algebraic framework for self reproduction on macroscopic organizational levels under dynamical system setting for simulated AL models and explore some existential results. Starting with defining self reproduction for atomic entities we define self reproduction with possible mutations on higher organizational levels in terms of hierarchical sets and the corresponding inductively defined 'meta' - reactions. We introduce constraints to distinguish a collection of entities from genuine cases of emergent organizational structures.", "text_perturb": "Formalizing self procreation in dynamical hierarchies is one of the important problems in Artificial Life ( AL ) studies. We study , in this paper , an inductively defined algebraic framework for self reproduction on macroscopic organizational levels under dynamical system setting for simulated camellia state models and explore some existential results. Starting with defining self reproduction for nuclear entities we define self reproduction with possible mutations on higher organizational levels in terms of hierarchical sets and the corresponding inductively defined 'meta ' - reactions. We introduce constraints to distinguish a collection of entities from genuine cases of emergent organisational structures. ", "label": 1}
{"original_text": "This paper presents a design methodology for optimal transmission energy allocation at a sensor equipped with energy harvesting technology for remote state estimation of linear stochastic dynamical systems. In this framework, the sensor measurements as noisy versions of the system states are sent to the receiver over a packet dropping communication channel. The packet dropout probabilities of the channel depend on both the sensor's transmission energies and time varying wireless fading channel gains. The sensor has access to an energy harvesting source which is an everlasting but unreliable energy source compared to conventional batteries with fixed energy storages. The receiver performs optimal state estimation with random packet dropouts to minimize the estimation error covariances based on received measurements. The receiver also sends packet receipt acknowledgments to the sensor via an erroneous feedback communication channel which is itself packet dropping. The objective is to design optimal transmission energy allocation at the energy harvesting sensor to minimize either a finite-time horizon sum or a long term average (infinite-time horizon) of the trace of the expected estimation error covariance of the receiver's Kalman filter. These problems are formulated as Markov decision processes with imperfect state information. The optimal transmission energy allocation policies are obtained by the use of dynamic programming techniques. Using the concept of submodularity, the structure of the optimal transmission energy policies are studied. Suboptimal solutions are also discussed which are far less computationally intensive than optimal solutions. Numerical simulation results are presented illustrating the performance of the energy allocation algorithms.", "text_perturb": "This paper presents a design methodology for optimal transmission energy allocation at a sensing element equipped with energy harvesting technology for remote state estimation of linear stochastic dynamical systems. In this framework , the sensor measurements as noisy versions of the system states are sent to the receiver over a packet dropping communicating channel. The packet dropout probabilities of the channel depend on both the sensor 's transmission push and time varying wireless fading channel gains. The sensor has access to an energy harvesting generator which is an everlasting but unreliable energy generator compared to conventional batteries with fixed energy storages. The receiver performs optimal state estimation with random parcel dropouts to minimize the estimation error covariances based on received measurements. The receiver also sends packet receipt mention to the sensor via an erroneous feedback communication channel which is itself packet dropping. The objective is to design optimal transmission energy allocation at the energy harvesting sensor to minimize either a finite-time horizon sum or a long term average ( infinite-time horizon ) of the trace of the expected estimation mistake covariance of the receiver 's Kalman filter. These problems are formulated as Markov decision processes with imperfect commonwealth information. The optimal transmittal energy allocation policies are obtained by the use of dynamic programming techniques. Using the concept of submodularity , the structure of the optimal transmission energy policies are meditate. Suboptimal result are also discussed which are far less computationally intensive than optimal result. Numerical simulation results are presented illustrating the performance of the energy allocation algorithmic rule. ", "label": 1}
{"original_text": "Automatic facial behavior analysis has a long history of studies in the intersection of computer vision, physiology and psychology. However it is only recently, with the collection of large-scale datasets and powerful machine learning methods such as deep neural networks, that automatic facial behavior analysis started to thrive. Three of its iconic tasks are automatic recognition of basic expressions (e.g. happiness, sadness, surprise), estimation of continuous affect (e.g., valence and arousal), and detection of facial action units (activations of e.g. upperinner eyebrows, nose wrinkles). Up until now these tasks have been studied independently by collecting a dedicated dataset and training a single-task model. We present the first and the largest study of all facial behaviour tasks learned jointly in a single holistic framework, which we call FaceBehaviorNet. For this we utilize all publicly available datasets in the community (over 5M images) that study facial behaviour tasks in-the-wild. We demonstrate that training jointly an end-to-end network for all tasks has consistently better performance than training each of the single-task networks. Furthermore, we propose two simple strategies for coupling the tasks during training, co-annotation and distribution matching, and show the advantages of this approach. Finally we show that FaceBehaviorNet has learned features that encapsulate all aspects of facial behaviour, and can be successfully applied to perform tasks (compound emotion recognition) beyond the ones that it has been trained in a zero- and few-shot learning setting. The model and source code will be made publicly available.", "text_perturb": "machine rifle facial behavior analysis has a long history of studies in the intersection of computer vision , physiology and psychology. However it is only recently , with the collection of large-scale datasets and brawny machine learning methods such as deep neural networks , that automatic facial behavior analysis started to thrive. Three of its iconic tasks are automatonlike recognition of basic expressions ( e. grand. happiness , sadness , surprise ) , estimation of uninterrupted affect ( e. thou. , valence and arousal ) , and detection of facial action whole ( activations of e. gm. upperinner eyebrows , nose wrinkles ). Up until now these tasks have been canvas independently by collecting a dedicated dataset and training a single-task model. We present the first and the largest work of all facial behaviour tasks learned jointly in a single holistic framework , which we call FaceBehaviorNet. For this we utilize all publicly available datasets in the community ( over 5M images ) that study facial behaviour undertaking in-the-wild. We demonstrate that training together with an end-to-end network for all tasks has consistently better performance than training each of the single-task networks. Furthermore , we propose two unsubdivided strategies for coupling the tasks during training , co-annotation and distribution matching , and show the advantages of this approach. at last we show that FaceBehaviorNet has learned features that encapsulate all aspects of facial behaviour , and can be successfully applied to perform tasks ( compound emotion recognition ) beyond the ones that it has been trained in a zero- and few-shot learning setting. The poser and source code will be made publicly available. ", "label": 1}
{"original_text": "This paper investigates the problem of resource allocation for a wireless communication network with distributed reconfigurable intelligent surfaces (RISs). In this network, multiple RISs are spatially distributed to serve wireless users and the energy efficiency of the network is maximized by dynamically controlling the on-off status of each RIS as well as optimizing the reflection coefficients matrix of the RISs. This problem is posed as a joint optimization problem of transmit beamforming and RIS control, whose goal is to maximize the energy efficiency under minimum rate constraints of the users. To solve this problem, two iterative algorithms are proposed for the single-user case and multi-user case. For the single-user case, the phase optimization problem is solved by using a successive convex approximation method, which admits a closed-form solution at each step. Moreover, the optimal RIS on-off status is obtained by using the dual method. For the multi-user case, a low-complexity greedy searching method is proposed to solve the RIS on-off optimization problem. Simulation results show that the proposed scheme achieves up to 33 and 68 gains in terms of the energy efficiency in both single-user and multi-user cases compared to the conventional RIS scheme and amplify-and-forward relay scheme, respectively.", "text_perturb": "This paper investigates the problem of resource allocation for a wireless communication meshing with distributed reconfigurable intelligent surfaces ( RISs ). In this network , multiple RISs are spatially distributed to serve wireless users and the energy efficiency of the network is maximized by dynamically controlling the on-off status of each RIS equally well as optimizing the reflection coefficients matrix of the RISs. This problem personify posed as a joint optimization problem of transmit beamforming and RIS control , whose goal personify to maximize the energy efficiency under minimum rate constraints of the users. To solve this problem , two reiterative algorithms are proposed for the single-user case and multi-user case. For the single-user case , the phase optimisation problem is solved by using a successive convex approximation method , which admits a closed-form solution at each step. Moreover , the optimal RIS on-off status is get by using the dual method. For the multi-user case , a low-complexity greedy searching method is proposed to solve the ocean state on-off optimization problem. Simulation results show that the proposed strategy achieves up to 33 and 68 gains in terms of the energy efficiency in both single-user and multi-user cases compared to the conventional RIS strategy and amplify-and-forward relay strategy , respectively. ", "label": 1}
{"original_text": "We consider convolutional networks from a reproducing kernel Hilbert space viewpoint. We establish harmonic decompositions of convolutional networks, that is expansions into sums of elementary functions of increasing order. The elementary functions are related to the spherical harmonics, a fundamental class of special functions on spheres. The harmonic decompositions allow us to characterize the integral operators associated with convolutional networks, and obtain as a result statistical bounds for convolutional networks.", "text_perturb": "We consider convolutional networks from a reproducing kernel david hilbert space viewpoint. We establish harmonic decompositions of convolutional meshing , that is expansions into sums of elementary functions of increasing order. The unproblematic functions are related to the spherical harmonics , a fundamental class of special functions on spheres. The harmonic decompositions allow us to characterize the constitutional operators associated with convolutional networks , and obtain as a result statistical bounds for convolutional networks. ", "label": 1}
{"original_text": "Consider a general machine learning setting where the output is a set of labels or sequences. This output set is unordered and its size varies with the input. Whereas multi-label classification methods seem a natural first resort, they are not readily applicable to set-valued outputs because of the growth rate of the output space; and because conventional sequence generation doesn't reflect sets' order-free nature. In this paper, we propose a unified framework - sequential set generation (SSG) - that can handle output sets of labels and sequences. SSG is a meta-algorithm that leverages any probabilistic learning method for label or sequence prediction, but employs a proper regularization such that a new label or sequence is generated repeatedly until the full set is produced. Though SSG is sequential in nature, it does not penalize the ordering of the appearance of the set elements and can be applied to a variety of set output problems, such as a set of classification labels or sequences. We perform experiments with both benchmark and synthetic data sets and demonstrate SSG's strong performance over baseline methods.", "text_perturb": "believe a general machine learning setting where the output is a set of labels or sequences. This output localise is unordered and its size varies with the input. Whereas multi-label classification methods seem a natural first resort , they are non readily applicable to set-valued outputs because of the growth rate of the output space ; and because conventional sequence generation does n't reflect sets ' order-free nature. In this paper , we propose a unified theoretical account - sequential set generation ( SSG ) - that can handle output sets of labels and sequences. SSG is a meta-algorithm that leverages any probabilistic learning method for label or succession prediction , but employs a proper regularization such that a new label or succession is generated repeatedly until the full set is produced. Though SSG exist sequential in nature , it does not penalize the ordering of the appearance of the set elements and can be applied to a variety of set output problems , such as a set of classification labels or sequences. We perform experiments with both benchmark and synthetic data bent and demonstrate SSG 's strong performance over baseline methods. ", "label": 1}
{"original_text": "Many researchers work on improving the data efficiency of machine learning. What would happen if they succeed? This paper explores the social-economic impact of increased data efficiency. Specifically, we examine the intuition that data efficiency will erode the barriers to entry protecting incumbent data-rich AI firms, exposing them to more competition from data-poor firms. We find that this intuition is only partially correct: data efficiency makes it easier to create ML applications, but large AI firms may have more to gain from higher performing AI systems. Further, we find that the effect on privacy, data markets, robustness, and misuse are complex. For example, while it seems intuitive that misuse risk would increase along with data efficiency - as more actors gain access to any level of capability - the net effect crucially depends on how much defensive measures are improved. More investigation into data efficiency, as well as research into the \"AI production function,\" will be key to understanding the development of the AI industry and its societal impacts.", "text_perturb": "Many investigator work on improving the data efficiency of machine learning. What would happen if they succeed ? This paper explores the social-economic impact of increase data efficiency. Specifically , we examine the hunch that data efficiency will erode the barriers to entry protecting incumbent data-rich AI firms , exposing them to more competition from data-poor firms. We find that this intuition is only partially correct : data efficiency makes it easier to create ML applications , but bombastic AI firms may have more to gain from higher performing AI systems. Further , we find that the effect on privacy , data mart , robustness , and misuse are complex. For example , while it seems intuitive that misuse risk would increase along with data efficiency - as more actors gain access to any level of capability - the last effect crucially depends on how much defensive measures are improved. More investigation into data efficiency , as well as research into the `` AI production function , '' leave be key to understanding the development of the AI industry and its societal impacts. ", "label": 1}
{"original_text": "Signed graphs, i.e., undirected graphs with edges labelled with a plus or minus sign, are commonly used to model relationships in social networks. Recently, Kermarrec and Thraves initiated the study of the problem of appropriately visualising the network: They asked whether any signed graph can be embedded into the metric space R l in such a manner that every vertex is closer to all its friends (neighbours via positive edges) than to all its enemies (neighbours via negative edges). Interestingly, embeddability into R 1 can be expressed as a purely combinatorial problem. In this paper we pursue a deeper study of this particular case, answering several questions posed by Kermarrec and Thraves. First, we refine the approach of Kermarrec and Thraves for the case of complete signed graphs by showing that the problem is closely related to the recognition of proper interval graphs. Second, we prove that the general case, whose polynomial-time tractability remained open, is in fact N P -complete. Finally, we provide lower and upper bounds for the time complexity of the general case: we prove that the existence of a subexponential time (in the number of vertices and edges of the input signed graph) algorithm would violate the Exponential Time Hypothesis, whereas a simple dynamic programming approach gives a running time single-exponential in the number of vertices.", "text_perturb": "contract graphs , i. vitamin e. , undirected graphs with boundary labelled with a plus or minus sign , are commonly used to model relationships in social networks. Recently , Kermarrec and Thraves initiated the study of the problem of befittingly visualising the network : They asked whether any signed graph can be embedded into the metric space R l in such a manner that every vertex is closer to all its friends ( neighbours via positive edges ) than to all its enemies ( neighbours via negative edges ). Interestingly , embeddability into R 1 can equal expressed as a purely combinatorial problem. In this paper we pursue a deeper study of this particular showcase , answering several questions posed by Kermarrec and Thraves. First , we refine the approach of Kermarrec and Thraves for the case of complete signed graphs by showing that the problem is closely related to the recognition of proper musical interval graphs. Second , we prove that the general case , whose polynomial-time tractability persist open , is in fact N P -complete. Finally , we provide lower and upper bounds for the time complexity of the general case : we prove that the existence of a subexponential time ( in the number of vertices and edges of the input signed graph ) algorithm would violate the Exponential prison term Hypothesis , whereas a simple dynamic programming approach gives a running time single-exponential in the number of vertices. ", "label": 1}
{"original_text": "In this paper, we study robust stability of sparse LTI systems using the stability radius (SR) as a robustness measure. We consider real perturbations with an arbitrary and pre-specified sparsity pattern of the system matrix and measure their size using the Frobenius norm. We formulate the SR problem as an equality-constrained minimization problem. Using the Lagrangian method for optimization, we characterize the optimality conditions of the SR problem, thereby revealing the relation between an optimal perturbation and the eigenvectors of an optimally perturbed system. Further, we use the Sylvester equation based parametrization to develop a penalty based gradientNewton descent algorithm which converges to the local minima of the optimization problem. Finally, we illustrate how our framework provides structural insights into the robust stability of sparse networks.", "text_perturb": "In this paper , we study robust stability of sparse LTI systems using the stability radius ( SR ) as a hardiness measure. We consider real perturbations with an arbitrary and pre-specified sparsity pattern of the system matrix and measure their sizing using the Frobenius norm. We formulate the SR trouble as an equality-constrained minimization trouble. Using the Lagrangian method for optimization , we characterize the optimality conditions of the SR problem , thereby revealing the relation between an optimal perturbation and the eigenvectors of an optimally perturbed organisation. Further , we use the Sylvester equation based parametrization to develop a penalty based gradientNewton descent algorithm which converges to the local minimum of the optimization problem. Finally , we illustrate how our framework allow structural insights into the robust stability of sparse networks. ", "label": 1}
{"original_text": "Preterm infants' limb-pose estimation is a crucial but challenging task, which may improve patients' care and facilitate clinicians in infant's movements monitoring. Work in the literature either provides approaches to whole-body segmentation and tracking, which, however, has poor clinical value, or retrieve a posteriori limb pose from limb segmentation, increasing computational costs and introducing inaccuracy sources. In this paper, we address the problem of limb-pose estimation under a different point of view. We proposed a 2D fully-convolutional neural network for roughly detecting limb joints and joint connections, followed by a regression convolutional neural network for accurate joint and joint-connection position estimation. Joints from the same limb are then connected with a maximum bipartite matching approach. Our analysis does not require any prior modeling of infants' body structure, neither any manual interventions. For developing and testing the proposed approach, we built a dataset of four videos (video length 90 s) recorded with a depth sensor in a neonatal intensive care unit (NICU) during the actual clinical practice, achieving median root mean square distance [pixels] of 10.790 (right arm), 10.542 (left arm), 8.294 (right leg), 11.270 (left leg) with respect to the ground-truth limb pose. The idea of estimating limb pose directly from depth images may represent a future paradigm for addressing the problem of preterm-infants' movement monitoring and offer all possible support to clinicians in NICUs.", "text_perturb": "Preterm infants ' limb-pose estimation is a crucial but challenging task , which may ameliorate patients ' care and facilitate clinicians in infant 's movements monitoring. Work in the literature either provides approaches to whole-body segmentation and trailing , which , however , has poor clinical value , or retrieve a posteriori limb pose from limb segmentation , increasing computational costs and introducing inaccuracy sources. In this paper , we direct the problem of limb-pose estimation under a different point of view. We proposed a 2D fully-convolutional neural network for roughly detecting limb joints and joint connections , followed by a regress convolutional neural network for accurate joint and joint-connection position estimation. Joints from the same branch are then connected with a maximum bipartite matching approach. Our analysis does not require any prior modeling of infants ' soundbox structure , neither any manual interventions. For developing and testing the proposed approach , we built a dataset of four videos ( video length 90 atomic number  ) recorded with a depth sensor in a neonatal intensive care unit ( NICU ) during the actual clinical practice , achieving median root mean square distance [ pixels ] of 10. 790 ( right branch ) , 10. 542 ( leftover arm ) , 8. 294 ( proper leg ) , 11. 270 ( go forth leg ) with respect to the ground-truth limb pose. The idea of estimating limb pose directly from depth images may represent a future paradigm for accost the problem of preterm-infants ' movement monitoring and offer all possible support to clinicians in NICUs. ", "label": 1}
{"original_text": "The theory of quantum cryptography aims to guarantee unconditional information-theoretic security against an omnipotent eavesdropper. In many practical scenarios, however, the assumption of an all-powerful adversary is excessive and can be ded considerably. In this paper we study secret key distillation across a lossy and noisy quantum wiretap channel between Alice and Bob, with a separately parameterized realistically lossy quantum channel to the eavesdropper Eve. We show that under such restricted eavesdropping, the key rates achievable can exceed the secret key distillation capacity against an unrestricted eavesdropper in the quantum wiretap channel. Further, we show upper bounds on the key rates based on the relative entropy of entanglement. This simple restricted eavesdropping model is widely applicable, e.g., to free-space quantum optical communication, where realistic collection of light by Eve is limited by the finite size of her optical aperture. Future work will include calculating bounds on the amount of light Eve can collect under various realistic scenarios.", "text_perturb": "The theory of quantum cryptography aims to ensure unconditional information-theoretic security against an omnipotent eavesdropper. In many practical scenarios , however , the assumption of an all-powerful adversary is undue and can be ded considerably. In this paper we study secret key distillment across a lossy and noisy quantum wiretap channel between Alice and Bob , with a separately parameterized realistically lossy quantum channel to the eavesdropper Eve. We show that under such restricted eavesdropping , the key rates achievable can exceed the secret key distillation capacity against an unrestricted eavesdropper in the quantum tap channel. Further , we show upper bounds on the key rates found on the relative entropy of entanglement. This simple restricted eavesdropping model is wide applicable , e. k. , to free-space quantum optical communication , where realistic collection of light by eventide is limited by the finite size of her optical aperture. Future work will include calculating bounds on the amount of loose Eve can collect under various realistic scenarios. ", "label": 1}
{"original_text": "Generative Adversarial Networks (GANs) have recently achieved impressive results for many real-world applications, and many GAN variants have emerged with improvements in sample quality and training stability. However, they have not been well visualized or understood. How does a GAN represent our visual world internally? What causes the artifacts in GAN results? How do architectural choices affect GAN learning? Answering such questions could enable us to develop new insights and better models. In this work, we present an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. We first identify a group of interpretable units that are closely related to object concepts using a segmentation-based network dissection method. Then, we quantify the causal effect of interpretable units by measuring the ability of interventions to control objects in the output. We examine the contextual relationship between these units and their surroundings by inserting the discovered object concepts into new images. We show several practical applications enabled by our framework, from comparing internal representations across different layers, models, and datasets, to improving GANs by locating and removing artifact-causing units, to interactively manipulating objects in a scene. We provide open source interpretation tools to help researchers and practitioners better understand their GAN models footnote footnote Interactive demos, video, code, and data are available at GitHub and gandissect.csail.mit.edu..", "text_perturb": "Generative Adversarial Networks ( GANs ) have recently achieved impressive results for many real-world applications , and many GAN variants have issue with improvements in sample quality and training stability. However , they have non been well visualized or understood. How does a GAN represent our visual world internally ? What causes the artifacts in GAN results ? How do architectural choices affect GAN learning ? Answering such questions could enable us to develop new sixth sense and better models. In this oeuvre , we present an analytic framework to visualize and understand GANs at the unit- , object- , and scene-level. We first identify a group of interpretable units that are closely related to object concepts using a segmentation-based web dissection method. Then , we quantify the causal effect of interpretable units by measuring the ability of interventions to manipulate objects in the output. We examine the contextual relationship between these units and their surroundings by inserting the discovered object concepts into young images. We show several practical applications enabled by our framework , from comparing internal representations across different layers , models , and datasets , to ameliorate GANs by locating and removing artifact-causing units , to interactively manipulating objects in a scene. We provide open source interpretation tools to help researchers and practitioners better understand their GAN models footnote footnote Interactive demos , picture , code , and data are available at GitHub and gandissect. csail. massachusetts institute of technology. edu. . ", "label": 1}
{"original_text": "In this paper we consider a number of natural decision problems involving k -regular sequences. Specifically, they arise from item 1st item lower and upper bounds on growth rate; in particular boundedness, item 2nd item images, item 3rd item regularity (recognizability by a deterministic finite automaton) of preimages, and item 4th item factors, such as squares and palindromes of such sequences. We show that the decision problems are undecidable.", "text_perturb": "In this paper we consider a number of natural decision problem involving k -regular sequences. Specifically , they arise from point 1st point lower and upper bounds on growth rate ; in particular boundedness , point 2nd point images , point 3rd point regularity ( recognizability by a deterministic finite automaton ) of preimages , and point 4th point factors , such as squares and palindromes of such sequences. We evince that the decision problems are undecidable. ", "label": 1}
{"original_text": "Function inversion is the problem that given a random function: f - [ M ] [ N ], we want to find pre-image of any image f - 1 (y) in time T. In this work, we revisit this problem under the preprocessing model where we can compute some auxiliary information or advice of size S that only depends on f but not on y. It is a well-studied problem in the classical settings, however, it is not clear how quantum algorithms can solve this task any better besides invoking Grover's algorithm, which does not leverage the power of preprocessing. Nayebi et al. proved a lower bound S T 2 O (N) for quantum algorithms inverting permutations, however, they only consider algorithms with classical advice. Hhan et al. subsequently extended this lower bound to fully quantum algorithms for inverting permutations. In this work, we give the same asymptotic lower bound to fully quantum algorithms for inverting functions for fully quantum algorithms under the regime where M O (N). In order to prove these bounds, we generalize the notion of quantum random access code, originally introduced by Ambainis et al., to the setting where we are given a list of (not necessarily independent) random variables, and we wish to compress them into a variable-length encoding such that we can retrieve a random element just using the encoding with high probability. As our main technical contribution, we give a nearly tight lower bound (for a wide parameter range) for this generalized notion of quantum random access codes, which may be of independent interest.", "text_perturb": "Function inversion is the problem that given a random function : f - [ M ] [ N ] , we want to find pre-image of any image f - 1 ( atomic number  ) in time T. In this work , we revisit this problem under the preprocessing model where we can compute some auxiliary data or advice of size S that only depends on f but not on y. It is a well-studied problem in the classical settings , however , it is not clear how quantum algorithms can solve this job any better besides invoking Grover 's algorithm , which does not leverage the power of preprocessing. Nayebi et atomic number . proved a lower bound S T 2 O ( newton ) for quantum algorithms inverting permutations , however , they only consider algorithms with classical advice. Hhan et al. subsequently extended this lower bound to fully quantum algorithms for inverting substitution. In this work , we give the same asymptotic lower bound to fully quantum algorithms for inverting functions for fully quantum algorithms under the regime where m O ( N ). In order to prove these edge , we generalize the notion of quantum random access code , originally introduced by Ambainis et al. , to the setting where we are given a lean of ( not necessarily independent ) random variables , and we wish to compress them into a variable-length encoding such that we can retrieve a random element just using the encoding with high probability. As our master technical contribution , we give a nearly tight lower bound ( for a wide parameter range ) for this generalized notion of quantum random access codes , which may be of independent interest. ", "label": 1}
{"original_text": "It is an ill-posed problem to recover the true scene colors from a color biased image by discounting the effects of scene illuminant and camera spectral sensitivity (CSS) at the same time. Most color constancy (CC) models have been designed to first estimate the illuminant color, which is then removed from the color biased image to obtain an image taken under white light, without the explicit consideration of CSS effect on CC. This paper first studies the CSS effect on illuminant estimation arising in the inter-dataset-based CC (inter-CC), i.e., training a CC model on one dataset and then testing on another dataset captured by a distinct CSS. We show the clear degradation of existing CC models for inter-CC application. Then a simple way is proposed to overcome such degradation by first learning quickly a transform matrix between the two distinct CSSs (CSS-1 and CSS-2). The learned matrix is then used to convert the data (including the illuminant ground truth and the color biased images) rendered under CSS-1 into CSS-2, and then train and apply the CC model on the color biased images under CSS-2, without the need of burdensome acquiring of training set under CSS-2. Extensive experiments on synthetic and real images show that our method can clearly improve the inter-CC performance for traditional CC algorithms. We suggest that by taking the CSS effect into account, it is more likely to obtain the truly color constant images invariant to the changes of both illuminant and camera sensors.", "text_perturb": "It follow an ill-posed problem to recover the true scene colors from a color biased image by discounting the effects of scene illuminant and camera spectral sensitivity ( CSS ) at the same time. Most color constancy ( CC ) models have been designed to first judge the illuminant color , which is then removed from the color biased image to obtain an image taken under white light , without the explicit consideration of CSS effect on CC. This paper first studies the CSS effect on illuminant estimation arising in the inter-dataset-based CC ( inter-CC ) , iodin. vitamin e. , training a millilitre model on one dataset and then testing on another dataset captured by a distinct CSS. We record the clear degradation of existing CC models for inter-CC application. Then a mere way is proposed to overcome such degradation by first learning quickly a transform matrix between the two distinct CSSs ( CSS-1 and CSS-2 ). The learned matrix is then used to convert the data ( including the illuminant ground truth and the color biased images ) rendered under CSS-1 into CSS-2 , and then train and apply the CC model on the color biased images under CSS-2 , without the need of burdensome acquiring of civilize set under CSS-2. wide experiments on synthetic and real images show that our method can clearly improve the inter-CC performance for traditional CC algorithms. We suggest that by taking the CSS effect into account , it is more potential to obtain the truly color constant images invariant to the changes of both illuminant and camera sensors. ", "label": 1}
{"original_text": "At the heart of machine learning lies the question of generalizability of learned rules over previously unseen data. While over-parameterized models based on neural networks are now ubiquitous in machine learning applications, our understanding of their generalization capabilities is incomplete. This task is made harder by the non-convexity of the underlying learning problems. We provide a general framework to characterize the asymptotic generalization error for single-layer neural networks (i.e., generalized linear models) with arbitrary non-linearities, making it applicable to regression as well as classification problems. This framework enables analyzing the effect of (i) over-parameterization and non-linearity during modeling; and (ii) choices of loss function, initialization, and regularizer during learning. Our model also captures mismatch between training and test distributions. As examples, we analyze a few special cases, namely linear regression and logistic regression. We are also able to rigorously and analytically explain the double descent phenomenon in generalized linear models.", "text_perturb": "At the heart of machine encyclopedism lies the question of generalizability of learned rules over previously unseen data. While over-parameterized models based on neural networks are now ubiquitous in machine learning applications , our understanding of their generalization capacity is incomplete. This task is made harder by the non-convexity of the underlying learning problem. We provide a general framework to characterize the asymptotic generalization error for single-layer neural networks ( iodine. east. , generalized elongate models ) with arbitrary non-linearities , making it applicable to regression as well as classification problems. This framework enables examine the effect of ( i ) over-parameterization and non-linearity during modeling ; and ( ii ) choices of loss function , initialization , and regularizer during learning. Our mannikin also captures mismatch between training and test distributions. As examples , we analyze a few special display case , namely linear regression and logistic regression. We are also able to rigorously and analytically explain the double descent phenomenon in generalised linear models. ", "label": 1}
{"original_text": "The popularization of cloud computing has provided the emergence of large volumes of data that are stored in Data Centers (DCs). These locations store data of different types, origins, and priorities for their owners. The DCs are subject to natural or man-made attacks. The attacks are diverse and happen quickly after their detection. Therefore, this paper proposes two techniques to evacuate data from threatened DCs to those who are outside the risk zone of the attack. The first technique is based on the Service Level Agreement (SLA) of the data and the second one is based on the order that they arrive at the DC, using the algorithm LIFO. Both techniques performed similarly on the amount of evacuated data and at the time for evacuation. However, the SLA policy distributes the data on a priority scale according to the SLA, while the LIFO policy ranks data on the same scale's priority.", "text_perturb": "The popularization of cloud computing has provided the emergence of large volumes of data that are store in Data Centers ( DCs ). These locations store data of different types , origins , and anteriority for their owners. The DCs are capable to natural or man-made attacks. The attacks live diverse and happen quickly after their detection. Therefore , this paper declare oneself two techniques to evacuate data from threatened DCs to those who are outside the risk zone of the attack. The first technique is based on the Service Level Agreement ( SLA ) of the data and the second one is based on the order that they arrive at the DC , habituate the algorithm LIFO. Both techniques performed similarly on the amount of evacuated data and at the time for excretion. However , the SLA policy distributes the information on a priority scale according to the SLA , while the LIFO policy ranks information on the same scale 's priority. ", "label": 1}
{"original_text": "Recently, the popularity of depth-sensors such as Kinect has made depth videos easily available while its advantages have not been fully exploited. This paper investigates, for gesture recognition, to explore the spatial and temporal information complementarily embedded in RGB and depth sequences. We propose a convolutional two-stream consensus voting network (2SCVN) which explicitly models both the short-term and long-term structure of the RGB sequences. To alleviate distractions from background, a 3d depth-saliency ConvNet stream (3DDSN) is aggregated in parallel to identify subtle motion characteristics. These two components in an unified framework significantly improve the recognition accuracy. On the challenging Chalearn IsoGD benchmark, our proposed method outperforms the first place on the leader-board by a large margin (10.29) while also achieving the best result on RGBD-HuDaAct dataset (96.74). Both quantitative experiments and qualitative analysis shows the effectiveness of our proposed framework and codes will be released to facilitate future research.", "text_perturb": "Recently , the popularity of depth-sensors such as Kinect has made depth videos easily available while its advantages have non been fully exploited. This paper investigates , for gesture realization , to explore the spatial and temporal information complementarily embedded in RGB and depth sequences. We propose a convolutional two-stream consensus voting network ( 2SCVN ) which explicitly models both the short-term and long-term structure of the RGB chronological succession. To alleviate distractions from background , a 3d depth-saliency ConvNet stream ( 3DDSN ) is aggregated in parallel to identify subtle motion characteristic. These two components in an interconnected framework significantly improve the recognition accuracy. On the challenging Chalearn IsoGD benchmark , our proposed method outperforms the first place on the leader-board by a expectant margin ( 10. 29 ) while also achieving the ripe result on RGBD-HuDaAct dataset ( 96. 74 ). Both quantitative experiments and qualitative analysis shows the effectiveness of our proposed framework and codes will be released to facilitate next research. ", "label": 1}
{"original_text": "We study computational aspects of relational marginal polytopes which are statistical relational learning counterparts of marginal polytopes, well-known from probabilistic graphical models. Here, given some first-order logic formula, we can define its relational marginal statistic to be the fraction of groundings that make this formula true in a given possible world. For a list of first-order logic formulas, the relational marginal polytope is the set of all points that correspond to the expected values of the relational marginal statistics that are realizable. In this paper, we study the following two problems: (i) Do domain-liftability results for the partition functions of Markov logic networks (MLNs) carry over to the problem of relational marginal polytope construction? (ii) Is the relational marginal polytope containment problem hard under some plausible complexity-theoretic assumptions? Our positive results have consequences for lifted weight learning of MLNs. In particular, we show that weight learning of MLNs is domain-liftable whenever the computation of the partition function of the respective MLNs is domain-liftable (this result has not been rigorously proven before).", "text_perturb": "We read computational aspects of relational marginal polytopes which are statistical relational learning counterparts of marginal polytopes , well-known from probabilistic graphical models. Here , given some first-order logic formula , we can define its relational marginal statistic to be the fraction of groundings that make this formula true in a given potential world. For a list of first-order logic formulas , the relational bare polytope is the set of all points that correspond to the expected values of the relational bare statistics that are realizable. In this paper , we study the following two problems : ( i ) Do domain-liftability results for the partition functions of Markov logic networks ( MLNs ) carry over to the problem of relational marginal polytope construction ? ( two ) Is the relational marginal polytope containment problem hard under some plausible complexity-theoretic assumptions ? Our positive results have consequences for lifted weight learning of MLNs. In particular , we show that weight learning of MLNs is domain-liftable whenever the computation of the partition function of the respective MLNs is domain-liftable ( this result has not been rigorously raise before ). ", "label": 1}
{"original_text": "This paper proposes a methodology to calculate both the first and second derivatives of a vector function of one variable in a single computation step. The method is based on the nested application of the dual number approach for first order derivatives. It has been implemented in Fortran language, a module which contains the dual version of elementary functions as well as more complex functions, which are common in the field of rotational kinematics. Since we have three quantities of interest, namely the function itself and its first and second derivative, our basic numerical entity has three elements. Then, for a given vector function: f - R R m, its dual version will have the form: f - R 3 R 3 m. As a study case, the proposed methodology is used to calculate the velocity and acceleration of a point moving on the coupler-point curve generated by a spherical four-bar mechanism.", "text_perturb": "This paper proposes a methodology to calculate both the first and second derivatives of a vector function of one variable in a single figuring step. The method is based on the nested application of the dual number approach for world class order derivatives. It has been implemented in fortran language , a module which contains the dual version of elementary functions as well as more complex functions , which are common in the field of rotational kinematics. Since we have three quantities of interest , namely the function itself and its first and second derivative , our basic numerical entity experience three elements. Then , for a given vector function : f - R R m , its dual interpretation will have the form : f - R 3 R 3 m. As a study case , the proposed methodology make up used to calculate the velocity and acceleration of a point moving on the coupler-point curve generated by a spherical four-bar mechanism. ", "label": 1}
{"original_text": "Hierarchical models for deep reinforcement learning (RL) have emerged as powerful methods for generating meaningful control strategies in difficult long time horizon tasks. Training of said hierarchical models, however, continue to suffer from instabilities that limit their applicability. In this paper, we address instabilities that arise from the concurrent optimization of goal-assignment and goal-achievement policies. Drawing connections between this concurrent optimization scheme and communication and cooperation in multi-agent RL, we redefine the standard optimization procedure to explicitly promote cooperation between these disparate tasks 1 footnote 1 1 footnote 1 For the purposes of reproducibility, the presented algorithms, environments, and results are available online at: Our method is demonstrated to achieve superior results to existing techniques in a set of difficult long time horizon tasks, and serves to expand the scope of solvable tasks by hierarchical reinforcement learning. Videos of the results are available at:", "text_perturb": "Hierarchical models for deep reinforcement acquisition ( RL ) have emerged as powerful methods for generating meaningful control strategies in difficult long time horizon tasks. Training of said hierarchical manikin , however , continue to suffer from instabilities that limit their applicability. In this paper , we address instabilities that arise from the concurrent optimisation of goal-assignment and goal-achievement policies. Drawing connections between this concurrent optimization scheme and communication and cooperation in multi-agent RL , we redefine the standard optimization procedure to explicitly promote cooperation between these disparate tasks 1 footnote 1 1 footnote 1 For the purposes of reproducibility , the presented algorithms , environments , and results are available online at : Our method is demonstrated to achieve superior results to existing techniques in a set of difficult long time horizon tasks , and serves to thrive the scope of solvable tasks by hierarchical reinforcement learning. video recording of the results are available at :", "label": 1}
{"original_text": "We consider the correlated multiarmed bandit (MAB) problem in which the rewards associated with each arm are modeled by a multivariate Gaussian random variable, and we investigate the influence of the assumptions in the Bayesian prior on the performance of the upper credible limit (UCL) algorithm and a new correlated UCL algorithm. We rigorously characterize the influence of accuracy, confidence, and correlation scale in the prior on the decision-making performance of the algorithms. Our results show how priors and correlation structure can be leveraged to improve performance.", "text_perturb": "We consider the correlated multiarmed bandit ( MAB ) problem in which the payoff associated with each arm are modeled by a multivariate Gaussian random variable , and we investigate the influence of the assumptions in the Bayesian prior on the performance of the upper credible limit ( UCL ) algorithm and a new correlated UCL algorithm. We rigorously characterize the influence of truth , confidence , and correlation scale in the prior on the decision-making performance of the algorithms. Our results show how prior and correlation structure can be leveraged to improve performance. ", "label": 1}
{"original_text": "Missing data is a crucial issue when applying machine learning algorithms to real-world datasets. Starting from the simple assumption that two batches extracted randomly from the same dataset should share the same distribution, we leverage optimal transport distances to quantify that criterion and turn it into a loss function to impute missing data values. We propose practical methods to minimize these losses using end-to-end learning, that can exploit or not parametric assumptions on the underlying distributions of values. We evaluate our methods on datasets from the UCI repository, in MCAR, MAR and MNAR settings. These experiments show that OT-based methods match or out-perform state-of-the-art imputation methods, even for high percentages of missing values.", "text_perturb": "Missing data is a crucial issuance when applying machine learning algorithms to real-world datasets. Starting from the simple assumption that two batches extracted randomly from the same dataset should share the same distribution , we leverage optimum transport distances to quantify that criterion and turn it into a loss function to impute missing data values. We propose practical methods to minimize these losses using end to end learning , that can exploit or not parametric assumptions on the underlying distributions of values. We evaluate our methods on datasets from the UCI depository , in MCAR , MAR and MNAR settings. These experiments show that OT-based methods match or out-perform state-of-the-art imputation methods , even for high percentages of pretermit values. ", "label": 1}
{"original_text": "A singularly perturbed parabolic problem of convection-diffusion type with a discontinuous initial condition is examined. An analytic function is identified which matches the discontinuity in the initial condition and also satisfies the homogenous parabolic differential equation associated with the problem. The difference between this analytical function and the solution of the parabolic problem is approximated numerically, using an upwind finite difference operator combined with an appropriate layer-adapted mesh. The numerical method is shown to be parameter-uniform. Numerical results are presented to illustrate the theoretical error bounds established in the paper. Keywords: Convection diffusion, discontinuous initial condition, interior layer, Shishkin mesh. AMS subject classifications: 65M15, 65M12, 65M06", "text_perturb": "A singularly perturbed parabolic problem of convection-diffusion type with a noncontinuous initial condition is examined. An analytic function is identified which matches the discontinuity in the initial condition and also satisfies the homogenous parabolical differential equation associated with the problem. The difference between this analytical function and the solution of the parabolic problem is approximated numerically , using an weather finite difference operator combined with an appropriate layer-adapted mesh. The numerical method is shown to follow parameter-uniform. Numerical termination are presented to illustrate the theoretical error bounds established in the paper. Keywords : convection diffusion , discontinuous initial condition , interior layer , Shishkin mesh. AMS capable classifications : 65M15 , 65M12 , 65M06", "label": 1}
{"original_text": "Artificial Neural Networks (ANN) has been phenomenally successful on various pattern recognition tasks. However, the design of neural networks rely heavily on the experience and intuitions of individual developers. In this article, the author introduces a mathematical structure called MLP algebra on the set of all Multilayer Perceptron Neural Networks (MLP), which can serve as a guiding principle to build MLPs accommodating to the particular data sets, and to build complex MLPs from simpler ones.", "text_perturb": "hokey Neural Networks ( ANN ) has been phenomenally successful on various pattern recognition tasks. However , the design of neural networks rely hard on the experience and intuitions of individual developers. In this article , the author introduces a mathematical structure called MLP algebra on the set of all Multilayer Perceptron Neural Networks ( MLP ) , which can serve as a guiding principle to build MLPs accommodating to the particular data point sets , and to build complex MLPs from simpler ones. ", "label": 1}
{"original_text": "Correlative microscopy is a methodology combining the functionality of light microscopy with the high resolution of electron microscopy and other microscopy technologies. Image registration for correlative microscopy is quite challenging because it is a multi-modal, multi-scale and multi-dimensional registration problem. In this report, I introduce two methods of image registration for correlative microscopy. The first method is based on fiducials (beads). I generate landmarks from the fiducials and compute the similarity transformation matrix based on three pairs of nearest corresponding landmarks. A least-squares matching process is applied afterwards to further refine the registration. The second method is inspired by the image analogies approach. I introduce the sparse representation model into image analogies. I first train representative image patches (dictionaries) for pre-registered datasets from two different modalities, and then I use the sparse coding technique to transfer a given image to a predicted image from one modality to another based on the learned dictionaries. The final image registration is between the predicted image and the original image corresponding to the given image in the different modality. The method transforms a multi-modal registration problem to a mono-modal one. I test my approaches on Transmission Electron Microscopy (TEM) and confocal microscopy images. Experimental results of the methods are also shown in this report.", "text_perturb": "Correlative microscopy constitute a methodology combining the functionality of light microscopy with the high resolution of electron microscopy and other microscopy technologies. Image registration for correlative microscopy exist quite challenging because it exist a multi-modal , multi-scale and multi-dimensional registration problem. In this report , I introduce two methods of image enrollment for correlative microscopy. The first method is based on fiducials ( beads ). I generate landmarks from the fiducials and cypher the similarity transformation matrix based on three pairs of nearest corresponding landmarks. A least-squares matching process is applied afterwards to further polish the registration. The second method is inspired by the paradigm analogies approach. I introduce the sparse representation model into paradigm analogies. I first off train representative image patches ( dictionaries ) for pre-registered datasets from two different modalities , and then I use the sparse coding technique to transfer a given image to a predicted image from one modality to another based on the learned dictionaries. The final effigy registration is between the predicted effigy and the original effigy corresponding to the given effigy in the different modality. The method transforms a multi-modal readjustment problem to a mono-modal one. I test my approaches on Transmission Electron Microscopy ( TEM ) and confocal microscopy epitome. Experimental result of the methods are also shown in this report. ", "label": 1}
{"original_text": "In this paper, a deterministic equivalent of ergodic sum rate and an algorithm for evaluating the capacity-achieving input covariance matrices for the uplink large-scale multiple-input multiple-output (MIMO) antenna channels are proposed. We consider a large-scale MIMO system consisting of multiple users and one base station with several distributed antenna sets. Each link between a user and an antenna set forms a two-sided spatially correlated MIMO channel with line-of-sight (LOS) components. Our derivations are based on novel techniques from large dimensional random matrix theory (RMT) under the assumption that the numbers of antennas at the terminals approach to infinity with a fixed ratio. The deterministic equivalent results (the deterministic equivalent of ergodic sum rate and the capacity-achieving input covariance matrices) are easy to compute and shown to be accurate for realistic system dimensions. In addition, they are shown to be invariant to several types of fading distribution.", "text_perturb": "In this paper , a deterministic equivalent of ergodic sum rate and an algorithm for evaluating the capacity-achieving input covariance matrices for the uplink large-scale multiple-input multiple-output ( MIMO ) antenna channels make up proposed. We consider a large-scale MIMO system consisting of multiple users and one home station with several distributed antenna sets. Each link between a user and an antenna countersink forms a two-sided spatially correlated MIMO channel with line-of-sight ( LOS ) components. Our derivations are based on novel techniques from large dimensional random matrix hypothesis ( RMT ) under the assumption that the numbers of antennas at the terminals approach to infinity with a fixed ratio. The deterministic equivalent result ( the deterministic equivalent of ergodic sum rate and the capacity-achieving input covariance matrices ) are easy to compute and shown to be accurate for realistic system dimensions. In addition , they are shown to be invariant to several types of fading dispersion. ", "label": 1}
{"original_text": "Deep neural networks have achieved remarkable accuracy in many artificial intelligence applications, e.g. computer vision, at the cost of a large number of parameters and high computational complexity. Weight pruning can compress DNN models by removing redundant parameters in the networks, but it brings sparsity in the weight matrix, and therefore makes the computation inefficient on GPUs. Although pruning can remove more than 80 of the weights, it actually hurts inference performance (speed) when running models on GPUs. Two major problems cause this unsatisfactory performance on GPUs. First, lowering convolution onto matrix multiplication reduces data reuse opportunities and wastes memory bandwidth. Second, the sparsity brought by pruning makes the computation irregular, which leads to inefficiency when running on massively parallel GPUs. To overcome these two limitations, we propose Escort, an efficient sparse convolutional neural networks on GPUs. Instead of using the lowering method, we choose to compute the sparse convolutions directly. We then orchestrate the parallelism and locality for the direct sparse convolution kernel, and apply customized optimization techniques to further improve performance. Evaluation on NVIDIA GPUs show that Escort can improve sparse convolution speed by 2.63 x and 3.07 x, and inference speed by 1.38 x and 1.60 x, compared to CUBLAS and CUSPARSE respectively.", "text_perturb": "rich neural networks have achieved remarkable accuracy in many artificial intelligence applications , e. k. computer vision , at the cost of a tumid number of parameters and high computational complexity. Weight pruning can compress DNN models by removing redundant parameters in the networks , but it brings sparsity in the weight matrix , and therefore realise the computation inefficient on GPUs. Although pruning can remove more than than 80 of the weights , it actually hurts inference performance ( speed ) when running models on GPUs. Two major problems cause this unsatisfactory performance on GPUs. First , lowering convolution onto matrix multiplication reduces data reuse opportunities and waste matter memory bandwidth. Second , the sparsity brought by pruning score the computation irregular , which leads to inefficiency when running on massively parallel GPUs. To overcome these two limitation , we propose Escort , an efficient sparse convolutional neural networks on GPUs. Instead of using the lowering method acting , we choose to compute the sparse convolutions directly. We then orchestrate the parallelism and neighbourhood for the direct sparse convolution kernel , and apply customized optimization techniques to further improve performance. Evaluation on NVIDIA GPUs show that date can improve sparse convolution speed by 2. 63 ex and 3. 07  , and inference speed by 1. 38 ex and 1. 60 x , liken to CUBLAS and CUSPARSE respectively. ", "label": 1}
{"original_text": "The Web is a tangled mass of interconnected services, where websites import a range of external resources from various third-party domains. However, the latter can further load resources hosted on other domains. For each website, this creates a dependency chain underpinned by a form of implicit trust between the first-party and transitively connected third-parties. The chain can only be loosely controlled as first-party websites often have little, if any, visibility of where these resources are loaded from. This paper performs a large-scale study of dependency chains in the Web, to find that around 50 of first-party websites render content that they did not directly load. Although the majority (84.91) of websites have short dependency chains (below 3 levels), we find websites with dependency chains exceeding 30. Using VirusTotal, we show that 1.2 of these third-parties are classified as suspicious - although seemingly small, this limited set of suspicious third-parties have remarkable reach into the wider ecosystem. By running sandboxed experiments, we observe a range of activities with the majority of suspicious JavaScript downloading malware; worryingly, we find this propensity is greater among implicitly trusted JavaScripts.", "text_perturb": "The Web is a tangled mass of interconnected services , where websites import a range of external resources from various third-party field. However , the latter fire further load resources hosted on other domains. For each site , this creates a dependency chain underpinned by a form of implicit trust between the first-party and transitively connected third-parties. The chain can only be loosely controlled as first-party websites often have little , if any , visibility of where these resources be loaded from. This paper performs a large-scale study of dependency chains in the Web , to find that around 50 of first-party website render content that they did not directly load. Although the bulk ( 84. 91 ) of websites have short habituation chains ( below 3 levels ) , we find websites with habituation chains exceeding 30. Using VirusTotal , we designate that 1. 2 of these third-parties are classified as suspicious - although seemingly small , this modified set of suspicious third-parties have remarkable reach into the wider ecosystem. By running sandboxed experiments , we observe a mountain chain of activities with the majority of suspicious JavaScript downloading malware ; worryingly , we find this propensity is greater among implicitly trusted JavaScripts. ", "label": 1}
{"original_text": "Despite substantial progress in signal source separation, results for richly structured data continue to contain perceptible artifacts. In contrast, recent deep generative models can produce authentic samples in a variety of domains that are indistinguishable from samples of the data distribution. This paper introduces a Bayesian approach to source separation that uses generative models as priors over the components of a mixture of sources, and Langevin dynamics to sample from the posterior distribution of sources given a mixture. This decouples the source separation problem from generative modeling, enabling us to directly use cutting-edge generative models as priors. The method achieves state-of-the-art performance for MNIST digit separation. We introduce new methodology for evaluating separation quality on richer datasets, providing quantitative evaluation of separation results on CIFAR-10. We also provide qualitative results on LSUN.", "text_perturb": "Despite substantial progress in signal source separation , results for richly structured data continue to contain perceptible artifact. In contrast , recent deep generative models can produce authentic samples in a variety of domains that are identical from samples of the data distribution. This paper introduces a bayesian approach to source separation that uses generative models as priors over the components of a mixture of sources , and Langevin dynamics to sample from the posterior distribution of sources given a mixture. This decouples the source separation problem from generative modeling , enabling us to directly use cutting-edge generative simulation as priors. The method achieves state-of-the-art carrying into action for MNIST digit separation. We introduce new methodology for evaluating legal separation quality on richer datasets , providing quantitative evaluation of legal separation results on CIFAR-10. We besides provide qualitative results on LSUN. ", "label": 1}
{"original_text": "When faced with learning a set of inter-related tasks from a limited amount of usable data, learning each task independently may lead to poor generalization performance. exploits the latent relations between tasks and overcomes data scarcity limitations by co-learning all these tasks simultaneously to offer improved performance. We propose a novel framework based on for binary classification tasks. By considering pair-wise task affinity in terms of similarity between a pair's respective feature spaces, the new framework, compared to other similar approaches, offers a high degree of flexibility in determining how similar feature spaces should be, as well as which pairs of tasks should share a common feature space in order to benefit overall performance. The associated optimization problem is solved via a block coordinate descent, which employs a consensus-form algorithm to optimize the weights and, hence, to determine task affinities. Empirical evaluation on seven data sets exhibits a statistically significant improvement of our framework's results compared to the ones of several other methods.", "text_perturb": "When faced with learning a set of inter-related tasks from a limited measure of usable data , learning each task independently may lead to poor generalization performance. exploits the latent relations between tasks and overcomes data scarceness limitations by co-learning all these tasks simultaneously to offer improved performance. We propose a novel framework based on for binary sorting tasks. By considering pair-wise task affinity in terms of similarity between a pair 's respective feature spaces , the new framework , compared to other similar approaches , offers a high degree of flexibility in determining how similar feature spaces should be , as well as which twain of tasks should share a common feature space in order to benefit overall performance. The associated optimization problem be solved via a block coordinate descent , which employs a consensus-form algorithm to optimize the weights and , hence , to determine task affinities. Empirical evaluation on seven data sets exhibits a statistically significant improvement of our framework 's results compare to the ones of several other methods. ", "label": 1}
{"original_text": "Recently, a new polynomial basis over binary extension fields was proposed such that the fast Fourier transform (FFT) over such fields can be computed in the complexity of order O (n lg (n, where n is the number of points evaluated in FFT. In this work, we reformulate this FFT algorithm such that it can be easier understood and be extended to develop frequency-domain decoding algorithms for (n 2 m, k) systematic Reed-Solomon (RS) codes over F 2 m, m Z , with - n k a power of two. First, the basis of syndrome polynomials is reformulated in the decoding procedure so that the new transforms can be applied to the decoding procedure. A fast extended Euclidean algorithm is developed to determine the error locator polynomial. The computational complexity of the proposed decoding algorithm is O (n lg n k) n k) lg 2 n k, improving upon the best currently available decoding complexity O (n lg 2 (n) lg lg (n, and reaching the best known complexity bound that was established by Justesen in 1976. However, Justesen's approach is only for the codes over some specific fields, which can apply Cooley-Tucky FFTs. As revealed by the computer simulations, the proposed decoding algorithm is 50 times faster than the conventional one for the (2 16, 2 15) RS code over F 2 16.", "text_perturb": "Recently , a new polynomial basis over binary extension fields was proposed such that the fast Fourier transform ( FFT ) over such fields can cost computed in the complexity of order O ( n lg ( n , where n is the number of points evaluated in FFT. In this work , we reformulate this FFT algorithm such that it can be easier understood and be extended to develop frequency-domain decoding algorithms for ( n 2 m , k ) systematic Reed-Solomon ( RS ) codes over F 2 m , m Z , with - northward k a power of two. First , the basis of syndrome polynomial is reformulated in the decoding procedure so that the new transforms can be applied to the decoding procedure. A fast extended Euclidean algorithm is developed to determine the error locater polynomial. The computational complexity of the proposed decoding algorithm is oxygen ( n lg n k ) n k ) lg 2 n k , improving upon the best currently available decoding complexity oxygen ( n lg 2 ( n ) lg lg ( n , and reaching the best known complexity bound that was established by Justesen in 1976. However , Justesen 's approach follow only for the codes over some specific fields , which can apply Cooley-Tucky FFTs. As revealed by the computer simulations , the proposed decoding algorithmic program is 50 times faster than the conventional one for the ( 2 16 , 2 15 ) RS code over F 2 16. ", "label": 1}
{"original_text": "MapReduce is a popular programming paradigm for developing large-scale, data-intensive computation. Many frameworks that implement this paradigm have recently been developed. To leverage these frameworks, however, developers must become familiar with their APIs and rewrite existing code. We present Casper, a new tool that automatically translates sequential Java programs into the MapReduce paradigm. Casper identifies potential code fragments to rewrite and translates them in two steps: (1) Casper uses program synthesis to search for a program summary (i.e., a functional specification) of each code fragment. The summary is expressed using a high-level intermediate language resembling the MapReduce paradigm and verified to be semantically equivalent to the original using a theorem prover. (2) Casper generates executable code from the summary, using either the Hadoop, Spark, or Flink API. We evaluated Casper by automatically converting real-world, sequential Java benchmarks to MapReduce. The resulting benchmarks perform up to 48.2 x faster compared to the original.", "text_perturb": "MapReduce is a popular programming prototype for developing large-scale , data-intensive computation. Many framework that implement this paradigm have recently been developed. To leverage these frameworks , however , developers must become conversant with their APIs and rewrite existing code. We present Casper , a new tool that automatically translates sequential java programs into the MapReduce paradigm. Casper identifies potential code fragments to rewrite and translates them in two steps : ( 1 ) Casper uses computer programme synthesis to search for a computer programme summary ( i. tocopherol. , a functional specification ) of each codification fragment. The summary is expressed using a high-level intermediate language resemble the MapReduce paradigm and verified to be semantically equivalent to the original using a theorem prover. ( 2 ) casper generates executable code from the summary , using either the Hadoop , Spark , or Flink API. We evaluated Casper by automatically exchange real-world , sequential Java benchmarks to MapReduce. The resulting bench mark perform up to 48. 2 x faster compared to the original. ", "label": 1}
{"original_text": "Neural Machine Translation (NMT) models usually use large target vocabulary sizes to capture most of the words in the target language. The vocabulary size is a big factor when decoding new sentences as the final softmax layer normalizes over all possible target words. To address this problem, it is widely common to restrict the target vocabulary with candidate lists based on the source sentence. Usually, the candidate lists are a combination of external word-to-word aligner, phrase table entries or most frequent words. In this work, we propose a simple and yet novel approach to learn candidate lists directly from the attention layer during NMT training. The candidate lists are highly optimized for the current NMT model and do not need any external computation of the candidate pool. We show significant decoding speedup compared with using the entire vocabulary, without losing any translation quality for two language pairs.", "text_perturb": "neuronic Machine Translation ( NMT ) models usually use large target vocabulary sizes to capture most of the words in the target language. The vocabulary size exist a big factor when decoding new sentences as the final softmax layer normalizes over all possible target words. To address this problem , it is widely vernacular to restrict the target vocabulary with candidate lists based on the source sentence. Usually , the candidate lists are a combination of external word-to-word aligner , phrase table entryway or most frequent words. In this work , we propose a simple and yet novel approach to learn candidate lists directly from the aid layer during NMT training. The candidate lists are highly optimized for the current NMT model and do not need any outside computation of the candidate pool. We show significant decoding speedup compared with using the entire vocabulary , without losing any displacement quality for two language pairs. ", "label": 1}
{"original_text": "Lloyd's k -means algorithm is one of the most classical clustering method, which is widely used in data mining or as a data pre-processing procedure. However, due to the thin-tailed property of the Gaussian distribution, k -means suffers from relatively poor performance on the heavy-tailed data or outliers. In addition, k -means have a relatively weak stability, i. e. its result has a large variance, which reduces the credibility of the model. In this paper, we propose a robust and stable k -means variant, the t - k -means, as well as its fast version in solving the flat clustering problem. Theoretically, we detail the derivations of t - k -means and analyze its robustness and stability from the aspect of loss function, influence function and the expression of clustering center. A large number of experiments are conducted, which empirically demonstrates that our method has empirical soundness while preserving running efficiency.", "text_perturb": "Lloyd 's k -means algorithm is one of the most classical clustering method , which is widely used in data excavation or as a data pre-processing procedure. However , due to the thin-tailed property of the Gaussian distribution , green -means suffers from relatively poor performance on the heavy-tailed data or outliers. In addition , k -means have a relatively weak stability , single. vitamin e. its result has a large variance , which reduces the credibility of the example. In this paper , we propose a robust and stable k -means variant , the t - k -means , as well as its fast version in solving the monotonic clustering problem. Theoretically , we detail the derivations of t - k -means and examine its robustness and stability from the aspect of loss function , influence function and the expression of clustering center. A large number of experiments are conducted , which empirically demonstrates that our method has empirical soundness while maintain running efficiency. ", "label": 1}
{"original_text": "It is prohibitively expensive to annotate a large-scale video-based person re-identification (re-ID) dataset, which makes fully supervised methods inapplicable to real-world deployment. How to maximally reduce the annotation cost while retaining the re-ID performance becomes an interesting problem. In this paper, we address this problem by integrating an active learning scheme into a deep learning framework. Noticing that the truly matched tracklet-pairs, also denoted as true positives (TP), are the most informative samples for our re-ID model, we propose a sampling criterion to choose the most TP-likely tracklet-pairs for annotation. A view-aware sampling strategy considering view-specific biases is designed to facilitate candidate selection, followed by an adaptive resampling step to leave out the selected candidates that are unnecessary to annotate. Our method learns the re-ID model and updates the annotation set iteratively. The re-ID model is supervised by the tracklets' pesudo labels that are initialized by treating each tracklet as a distinct class. With the gained annotations of the actively selected candidates, the tracklets' pesudo labels are updated by label merging and further used to re-train our re-ID model. While being simple, the proposed method demonstrates its effectiveness on three video-based person re-ID datasets. Experimental results show that less than 3 pairwise annotations are needed for our method to reach comparable performance with the fully-supervised setting.", "text_perturb": "It is prohibitively expensive to annotate a large-scale video-based person re-identification ( re-ID ) dataset , which makes fully manage methods inapplicable to real-world deployment. How to maximally reduce the annotation cost while retaining the re-ID performance become an interesting problem. In this paper , we call this problem by integrating an active learning scheme into a deep learning framework. Noticing that the truly matched tracklet-pairs , too denoted as true positives ( TP ) , are the most informative samples for our re-ID model , we propose a sampling criterion to choose the most TP-likely tracklet-pairs for annotation. A view-aware sampling strategy considering view-specific biases is contrive to facilitate candidate selection , followed by an adaptive resampling step to leave out the selected candidates that are unnecessary to annotate. Our method learns the re-ID model and updates the annotation coiffe iteratively. The re-ID model is supervised by the tracklets ' pesudo labels that are initialize by treating each tracklet as a distinct class. With the gained annotations of the actively selected campaigner , the tracklets ' pesudo labels are updated by label merging and further used to re-train our re-ID model. While being simple , the proposed method manifest its effectiveness on three video-based person re-ID datasets. Experimental results show that less than 3 pairwise annotations are needed for our method to reach comparable performance with the fully-supervised scene. ", "label": 1}
{"original_text": "Monte Carlo simulations employed for the analysis of portfolios of catastrophic risk process large volumes of data. Often times these simulations are not performed in real-time scenarios as they are slow and consume large data. Such simulations can benefit from a framework that exploits parallelism for addressing the computational challenge and facilitates a distributed file system for addressing the data challenge. To this end, the Apache Hadoop framework is chosen for the simulation reported in this paper so that the computational challenge can be tackled using the MapReduce model and the data challenge can be addressed using the Hadoop Distributed File System. A parallel algorithm for the analysis of aggregate risk is proposed and implemented using the MapReduce model in this paper. An evaluation of the performance of the algorithm indicates that the Hadoop MapReduce model offers a framework for processing large data in aggregate risk analysis. A simulation of aggregate risk employing 100,000 trials with 1000 catastrophic events per trial on a typical exposure set and contract structure is performed on multiple worker nodes in less than 6 minutes. The result indicates the scope and feasibility of MapReduce for tackling the computational and data challenge in the analysis of aggregate risk for real-time use.", "text_perturb": "monte Carlo simulations employed for the analysis of portfolios of catastrophic risk process large volumes of data. Often times these simulations are not performed in real-time scenarios as they are boring and consume large data. Such simulations can benefit from a framework that exploits parallelism for addressing the computational challenge and facilitates a deal out file system for addressing the data challenge. To this end , the Apache Hadoop framework is chosen for the simulation reported in this paper so that the computational challenge can be tackled using the MapReduce model and the data challenge can be addressed using the Hadoop Distributed file System. A parallel algorithmic rule for the analysis of aggregate risk is proposed and implemented using the MapReduce model in this paper. An evaluation of the performance of the algorithm indicates that the Hadoop MapReduce model offers a framework for processing large data in aggregate risk depth psychology. A simulation of total risk employing 100,000 trials with 1000 catastrophic events per trial on a typical exposure set and contract structure is performed on multiple worker nodes in less than 6 minutes. The result indicates the scope and feasibleness of MapReduce for tackling the computational and data challenge in the analysis of aggregate risk for real-time use. ", "label": 1}
{"original_text": "Patient movement in emission tomography deteriorates reconstruction quality because of motion blur. Gating the data improves the situation somewhat: each gate contains a movement phase which is approximately stationary. A standard method is to use only the data from a few gates, with little movement between them. However, the corresponding loss of data entails an increase of noise. Motion correction algorithms have been implemented to take into account all the gated data, but they do not scale well, especially not in 3D. We propose a novel motion correction algorithm which addresses the scalability issue. Our approach is to combine an enhanced ML-EM algorithm with deep learning based movement registration. The training is unsupervised, and with artificial data. We expect this approach to scale very well to higher resolutions and to 3D, as the overall cost of our algorithm is only marginally greater than that of a standard ML-EM algorithm. We show that we can significantly decrease the noise corresponding to a limited number of gates.", "text_perturb": "Patient move in emission tomography deteriorates reconstruction quality because of motion blur. Gating the data improves the situation fairly : each gate contains a movement phase which is approximately stationary. A standard method acting is to use only the data from a few gates , with little movement between them. However , the like loss of data entails an increase of noise. question correction algorithms have been implemented to take into account all the gated data , but they do not scale well , especially not in 3D. We pop the question a novel motion correction algorithm which addresses the scalability issue. Our approach is to conflate an enhanced ML-EM algorithm with deep learning based movement registration. The training is unsupervised , and with artificial data. We expect this attack to scale very well to higher resolutions and to 3D , as the overall cost of our algorithm is only marginally greater than that of a standard ML-EM algorithm. We show that we can significantly decrease the noise corresponding to a limited routine of gates. ", "label": 1}
{"original_text": "Bode's sensitivity integral constraints define a fundamental rule about the limitations of feedback and is referred to as the waterbed effect. In a companion paper [35], we took a fresh look at this problem using a direct approach to derive our results. In this paper, we will address the same problem, but now in discrete time. Although similar to the continuous case, the discrete-time case poses its own peculiarities and subtleties. The main result is that the sensitivity integral constraint is crucially related to the locations of the unstable open-loop poles of the system. This makes much intuitive sense. Similar results are also derived for the complementary sensitivity function. In that case the integral constraint is related to the locations of the transmission zeros outside the unit circle. Hence all performance limitations are inherently related to the open-loop poles and the transmission zeros outside the unit circle. A number of illustrative examples are presented.", "text_perturb": "Bode 's sensitivity integral constraints define a fundamental rule about the limitation of feedback and is referred to as the waterbed effect. In a companion paper [ 35 ] , we took a brisk look at this problem using a direct approach to derive our results. In this paper , we will address the like problem , but now in discrete time. Although similar to the continuous case , the discrete-time case poses its own peculiarities and subtlety. The main result is that the sensitivity integral constraint is crucially related to the positioning of the unstable open-loop poles of the system. This ready much intuitive sense. Similar results live also derived for the complementary sensitivity function. In that case the integral restraint is related to the locations of the transmission zeros outside the unit circle. Hence all performance limitations are inherently bear on to the open-loop poles and the transmission zeros outside the unit circle. A act of illustrative examples are presented. ", "label": 1}
{"original_text": "We introduce a general and simple structural design called \"Multiplicative Integration\" (MI) to improve recurrent neural networks (RNNs). MI changes the way in which information from difference sources flows and is integrated in the computational building block of an RNN, while introducing almost no extra parameters. The new structure can be easily embedded into many popular RNN models, including LSTMs and GRUs. We empirically analyze its learning behaviour and conduct evaluations on several tasks using different RNN models. Our experimental results demonstrate that Multiplicative Integration can provide a substantial performance boost over many of the existing RNN models.", "text_perturb": "We introduce a general and simple structural design called `` Multiplicative integrating '' ( MI ) to improve recurrent neural networks ( RNNs ). MI changes the way in which information from difference sources flows and is mix in the computational building block of an RNN , while introducing almost no extra parameters. The new structure can make up easily embedded into many popular RNN models , including LSTMs and GRUs. We empirically analyze its learning behaviour and demeanor evaluations on several tasks using different RNN models. Our experimental results establish that Multiplicative Integration can provide a substantial performance boost over many of the existing RNN models. ", "label": 1}
{"original_text": "[Summary]The value of remote sensing images is of vital importance in many areas and needs to be refined by some cognitive approaches. The remote sensing detection is an appropriate way to achieve the semantic cognition. However, such detection is a challenging issue for scale diversity, diversity of views, small objects, sophisticated light and shadow backgrounds. In this article, inspired by the state-of-the-art detection framework FPN, we propose a novel approach for constructing a feature fusion module that optimizes feature context utilization in detection, calling our system LFFN for Layer-weakening Feature Fusion Network. We explore the inherent relevance of different layers to the final decision, and the incentives of higher-level features to lower-level features. More importantly, we explore the characteristics of different backbone networks in the mining of basic features and the correlation utilization of convolutional channels, and call our upgraded version as advanced LFFN. Based on experiments on the remote sensing dataset from Google Earth, our LFFN has proved effective and practical for the semantic cognition of remote sensing, achieving 89 mAP which is 4.1 higher than that of FPN. Moreover, in terms of the generalization performance, LFFN achieves 79.9 mAP on VOC 2007 and achieves 73.0 mAP on VOC 2012 test, and advacned LFFN obtains the mAP values of 80.7 and 74.4 on VOC 2007 and 2012 respectively, outperforming the comparable state-of-the-art SSD and Faster R-CNN models.", "text_perturb": "[ Summary ] The value of remote sensing images is of vital importance in many areas and needs to be complicate by some cognitive approaches. The remote detection detection is an appropriate way to achieve the semantic cognition. However , such detection is a challenging issue for scale diversity , diversity of vista , small objects , sophisticated light and shadow backgrounds. In this article , inspired by the state-of-the-art spying framework FPN , we propose a novel approach for constructing a feature fusion module that optimizes feature context utilization in spying , calling our system LFFN for Layer-weakening Feature Fusion Network. We explore the inherent relevance of different layers to the final decision , and the incentives of higher-level feature article to lower-level feature article. More importantly , we explore the characteristics of different backbone networks in the mining of basic features and the correlational statistics utilization of convolutional channels , and call our upgraded version as advanced LFFN. Based on experiments on the remote sensing dataset from google Earth , our LFFN has proved effective and practical for the semantic cognition of remote sensing , achieving 89 mAP which is 4. 1 higher than that of FPN. Moreover , in terms of the generalization performance , LFFN reach 79. 9 mAP on VOC 2007 and achieve 73. 0 mapping on VOC 2012 test , and advacned LFFN obtains the mapping values of 80. 7 and 74. 4 on VOC 2007 and 2012 respectively , outperforming the like state-of-the-art SSD and Faster R-CNN models. ", "label": 1}
{"original_text": "We study the problem of distributed coverage control in a network of mobile agents arranged on a line. The goal is to design distributed dynamics for the agents to achieve optimal coverage positions with respect to a scalar density field that measures the relative importance of each point on the line. Unlike previous work, which implicitly assumed the agents know this density field, we only assume that each agent can access noisy samples of the field at points close to its current location. We provide a simple randomized protocol wherein every agent samples the scalar field at three nearby points at each step and which guarantees convergence to the optimal positions. We further analyze the convergence time of this protocol and show that, under suitable assumptions, the squared distance to the optimal coverage configuration decays as O (1 t) with the number of iterations t, where the constant scales polynomially with the number of agents n. We illustrate these results with simulations.", "text_perturb": "We study the problem of distributed coverage control in a network of mobile agents set up on a line. The goal is to design distributed dynamics for the agents to achieve optimal coverage positions with respect to a scalar density line of business that measures the relative importance of each point on the line. Unlike previous work , which implicitly assumed the agents know this density field , we only wear that each agent can access noisy samples of the field at points close to its current location. We provide a simple randomized protocol wherein every agent samples the scalar field at three nearby pointedness at each step and which guarantees convergence to the optimal positions. We promote analyze the convergence time of this protocol and show that , under suitable assumptions , the squared distance to the optimal coverage configuration decays as O ( 1 t ) with the number of iterations t , where the constant scales polynomially with the number of agents n. We illustrate these results with feigning. ", "label": 1}
{"original_text": "We consider the problem of estimating the weight of a maximum weighted matching of a weighted graph G (V, E) whose edges are revealed in a streaming fashion. Extending the framework from Crouch and Stubbs (APPROX 2014), we develop a reduction from the maximum weighted matching problem to the maximum cardinality matching problem that only doubles the approximation factor of a streaming algorithm developed for the maximum cardinality matching problem. Our results hold for the insertion-only and the dynamic (i.e, insertion and deletion) edge-arrival streaming models. The previous best-known reduction is due to Bury and Schwiegelshohn (ESA 2015) who develop an algorithm whose approximation guarantee scales by a polynomial factor. As an application, we obtain improved estimators for weighted planar graphs and, more generally, for weighted bounded-arboricity graphs, by feeding into our reduction the recent estimators due to Esfandiari et al. (SODA 2015) and to Chitnis et al. (SODA 2016). In particular, we obtain a (48) -approximation estimator for the weight of a maximum weighted matching in planar graphs.", "text_perturb": "We consider the problem of estimating the weight of a maximum weighted matching of a weighted graph G ( V , E ) whose border are revealed in a streaming fashion. Extending the framework from crouch and Stubbs ( APPROX 2014 ) , we develop a reduction from the maximum weighted matching problem to the maximum cardinality matching problem that only doubles the approximation factor of a streaming algorithm developed for the maximum cardinality matching problem. Our results retain for the insertion-only and the dynamic ( i. e , insertion and deletion ) edge-arrival streaming models. The previous best-known reduction is due to Bury and Schwiegelshohn ( ESA 2015 ) who develop an algorithm whose approximation guarantee plate by a polynomial factor. As an application , we obtain improved estimators for weighted planar graphs and , more generally , for weighted bounded-arboricity graphs , by eat into our reduction the recent estimators due to Esfandiari et al. ( SODA 2015 ) and to Chitnis et alabama. ( soda 2016 ). In particular , we obtain a ( 48 ) -approximation estimator for the exercising weight of a maximum weighted matching in planar graphs. ", "label": 1}
{"original_text": "An identifying code in a graph is a subset of vertices having a nonempty and distinct intersection with the closed neighborhood of every vertex. We prove that the infimum density of any identifying code in S k (an infinite strip of k rows in the square grid) can always be achieved by a periodic identifying code with pattern length at most 2 4 k. Assisted by a compute program implementing Karp's algorithm for minimum cycle mean, we find a periodic identifying code in S 4 with the minimum density 11 28, and a periodic identifying code in S 5 with the minimum density 19 50. Keywords: identifying code, minimum cycle mean.", "text_perturb": "An identifying code in a graphical record is a subset of vertices having a nonempty and distinct intersection with the closed neighborhood of every vertex. We prove that the infimum density of any identifying code in S k ( an infinite strip show of k rows in the square grid ) can always be achieved by a periodic identifying code with pattern length at most 2 4 k. Assisted by a compute program implementing Karp 's algorithm for minimum cycle mean , we find a periodic identifying computer code in S 4 with the minimum density 11 28 , and a periodic identifying computer code in S 5 with the minimum density 19 50. Keywords : identifying code , minimum cycle per second mean. ", "label": 1}
{"original_text": "Traditional approaches for handwritten Chinese character recognition suffer in classifying similar characters. In this paper, we propose to discriminate similar handwritten Chinese characters by using weakly supervised learning. Our approach learns a discriminative SVM for each similar pair which simultaneously localizes the discriminative region of similar character and makes the classification. For the first time, similar handwritten Chinese character recognition (SHCCR) is formulated as an optimization problem extended from SVM. We also propose a novel feature descriptor, Gradient Context, and apply bag-of-words model to represent regions with different scales. In our method, we do not need to select a sized-fixed sub-window to differentiate similar characters. This? unconstrained? property makes our method well adapted to high variance in the size and position of discriminative regions in similar handwritten Chinese characters. We evaluate our proposed approach over the CASIA Chinese character data set and the results show that our method outperforms the state of the art.", "text_perturb": "Traditional approaches for handwritten Chinese character recognition suffer in classifying alike characters. In this paper , we propose to discriminate similar handwritten Chinese characters by using weakly supervised get wind. Our approach learns a judicial SVM for each similar pair which simultaneously localizes the judicial region of similar character and makes the classification. For the first time , similar handwritten Chinese character identification ( SHCCR ) is formulated as an optimization problem extended from SVM. We also propose a novel feature film descriptor , Gradient Context , and apply bag-of-words model to represent regions with different scales. In our method , we do not need to select a sized-fixed sub-window to secernate similar characters. This ? unconstrained ? property makes our method well adapted to high variance in the size and position of discriminative part in similar handwritten Chinese characters. We evaluate our proposed approach over the CASIA Chinese character data set and the results show that our method acting outperforms the state of the art. ", "label": 1}
{"original_text": "Existing deep convolutional neural networks (CNNs) have shown their great success on image classification. CNNs mainly consist of convolutional and pooling layers, both of which are performed on local image areas without considering the dependencies among different image regions. However, such dependencies are very important for generating explicit image representation. In contrast, recurrent neural networks (RNNs) are well known for their ability of encoding contextual information among sequential data, and they only require a limited number of network parameters. General RNNs can hardly be directly applied on non-sequential data. Thus, we proposed the hierarchical RNNs (HRNNs). In HRNNs, each RNN layer focuses on modeling spatial dependencies among image regions from the same scale but different locations. While the cross RNN scale connections target on modeling scale dependencies among regions from the same location but different scales. Specifically, we propose two recurrent neural network models: 1) hierarchical simple recurrent network (HSRN), which is fast and has low computational cost; and 2) hierarchical long-short term memory recurrent network (HLSTM), which performs better than HSRN with the price of more computational cost. In this manuscript, we integrate CNNs with HRNNs, and develop end-to-end convolutional hierarchical recurrent neural networks (C-HRNNs). C-HRNNs not only make use of the representation power of CNNs, but also efficiently encodes spatial and scale dependencies among different image regions. On four of the most challenging objectscene image classification benchmarks, our C-HRNNs achieve state-of-the-art results on Places 205, SUN 397, MIT indoor, and competitive results on ILSVRC 2012.", "text_perturb": "Existing thick convolutional neural networks ( CNNs ) have shown their great success on image classification. CNNs mainly consist of convolutional and pooling layers , both of which are performed on local image areas without considering the dependencies among different image realm. However , such dependencies are very of import for generating explicit image representation. In contrast , recurrent neural networks ( RNNs ) are well known for their ability of encoding contextual information among consecutive data , and they only require a limited number of network parameters. General RNNs can hardly exist directly applied on non-sequential data. Thus , we proposed the hierarchical RNNs ( HRNNs ). In HRNNs , each RNN layer focuses on modeling spatial dependencies among image regions from the same scale but different emplacement. While the crossing RNN scale connections target on modeling scale dependencies among regions from the same location but different scales. Specifically , we propose two recurrent neural network models : 1 ) hierarchical simple recurrent network ( HSRN ) , which is fast and has low computational cost ; and 2 ) hierarchical long-short term memory recurrent network ( HLSTM ) , which performs better than HSRN with the cost of more computational cost. In this holograph , we integrate CNNs with HRNNs , and develop end-to-end convolutional hierarchical recurrent neural networks ( C-HRNNs ). C-HRNNs not only make use of the representation mightiness of CNNs , but also efficiently encodes spatial and scale dependencies among different image regions. On four of the nearly challenging objectscene image classification benchmarks , our C-HRNNs achieve state-of-the-art results on Places 205 , SUN 397 , MIT indoor , and competitive results on ILSVRC 2012. ", "label": 1}
{"original_text": "Spatially coupled (SC) interleaving is proposed to improve the performance of iterative multiuser detection and decoding (MUDD) for quasi-static fading multiple-input multiple-output systems. The linear minimum mean-squared error (LMMSE) demodulator is used to reduce the complexity and to avoid error propagation. Furthermore, sliding window MUDD is proposed to circumvent an increase of the decoding latency due to SC interleaving. Theoretical and numerical analyses show that SC interleaving can improve the performance of the iterative LMMSE MUDD for regular low-density parity-check codes.", "text_perturb": "Spatially coupled ( SC ) interleaving is proposed to improve the performance of iterative multiuser detection and decipherment ( MUDD ) for quasi-static fading multiple-input multiple-output systems. The linear minimum mean-squared error ( LMMSE ) demodulator is used to reduce the complexity and to avoid error generation. Furthermore , sliding window MUDD exist proposed to circumvent an increase of the decoding latency due to SC interleaving. Theoretical and numeral analyses show that SC interleaving can improve the performance of the iterative LMMSE MUDD for regular low-density parity-check codes. ", "label": 1}
{"original_text": "Different from the writing systems of many Romance and Germanic languages, some languages or language families show complex conjunct forms in character composition. For such cases where the conjuncts consist of the components representing consonant (s) and vowel, various character encoding schemes can be adopted beyond merely making up a one-hot vector. However, there has been little work done on intra-language comparison regarding performances using each representation. In this study, utilizing the Korean language which is character-rich and agglutinative, we investigate an encoding scheme that is the most effective among Jamo 1 1 footnote 1 Letters of Korean alphabet Hangul. -level one-hot, character-level one-hot, character-level dense, and character-level multi-hot. Classification performance with each scheme is evaluated on two corpora: one on binary sentiment analysis of movie reviews, and the other on multi-class identification of intention types. The result displays that the character-level features show higher performance in general, although the Jamo -level features may show compatibility with the attention-based models if guaranteed adequate parameter set size.", "text_perturb": "Different from the writing systems of many Romance and Germanic languages , some languages or language families depict complex conjunct forms in character composition. For such cases where the conjuncts consist of the components representing consonant ( s ) and vowel sound , various character encoding schemes can be adopted beyond merely making up a one-hot vector. However , there has been little work done on intra-language compare regarding performances using each representation. In this study , utilizing the Korean language which is character-rich and agglutinative , we look into an encoding scheme that is the most effective among Jamo 1 1 footnote 1 Letters of Korean alphabet Hangul. -level one-hot , character-level one-hot , character-level dense , and character-level multi-hot. Classification performance with each schema is evaluated on two corpora : one on binary sentiment analysis of movie reviews , and the other on multi-class identification of intention types. The upshot displays that the character-level features show higher performance in general , although the Jamo -level features may show compatibility with the attention-based models if guaranteed adequate parameter set size. ", "label": 1}
{"original_text": "In this paper we present the problem of saturation of a given morphism in the database category DB, which is the base category for the functiorial semantics of the database schema mapping systems used in Data Integration theory. This phenomena appears in the case when we are using the Second-Order tuple-generating dependencies (SOtgd) with existentially quantified non-built-in functions, for the database schema mappings. We provide the algorithm of the saturation for a given morphism, which represents a mapping between two relational databases, and show that the original morphism in DB can be equivalently substituted by its more powerful saturated version in any commutative diagram in DB.", "text_perturb": "In this paper we demonstrate the problem of saturation of a given morphism in the database category DB , which is the base category for the functiorial semantics of the database schema mapping systems used in Data Integration theory. This phenomena appears in the case when we are using the Second-Order tuple-generating dependencies ( SOtgd ) with existentially quantified non-built-in functions , for the database outline mappings. We provide the algorithm of the saturation for a given morphism , which represents a single valued function between two relational databases , and show that the original morphism in DB can be equivalently substituted by its more powerful saturated version in any commutative diagram in DB. ", "label": 1}
{"original_text": "We present an efficient spacetime optimization method to automatically generate animations for a general volumetric, elastically deformable body. Our approach can model the interactions between the body and the environment and automatically generate active animations. We model the frictional contact forces using contact invariant optimization and the fluid drag forces using a simplified model. To handle complex objects, we use a reduced deformable model and present a novel hybrid optimizer to search for the local minima efficiently. This allows us to use long-horizon motion planning to automatically generate animations such as walking, jumping, swimming, and rolling. We evaluate the approach on different shapes and animations, including deformable body navigation and combining with an open-loop controller for realtime forward simulation.", "text_perturb": "We present an efficient spacetime optimization method acting to automatically generate animations for a general volumetric , elastically deformable body. Our approach can model the interactions between the body and the environment and mechanically generate active animations. We model the frictional contact forces using contact invariant optimization and the fluid retarding force forces using a simplified model. To handle complex objects , we apply a reduced deformable model and present a novel hybrid optimizer to search for the local minima efficiently. This allows us to use long-horizon motion planning to automatically generate invigoration such as walking , jumping , swimming , and rolling. We evaluate the approach on different shapes and invigoration , including deformable body navigation and combining with an open-loop controller for realtime forward simulation. ", "label": 1}
{"original_text": "Stock return predictability is an important research theme as it reflects our economic and social organization, and significant efforts are made to explain the dynamism therein. Statistics of strong explanative power, called \"factor\" have been proposed to summarize the essence of predictive stock returns. Although machine learning methods are increasingly popular in stock return prediction, an inference of the stock returns is highly elusive, and still most investors, if partly, rely on their intuition to build a better decision making. The challenge here is to make an investment strategy that is consistent over a reasonably long period, with the minimum human decision on the entire process. To this end, we propose a new stock return prediction framework that we call Ranked Information Coefficient Neural Network (RIC-NN). RIC-NN is a deep learning approach and includes the following three novel ideas: (1) nonlinear multi-factor approach, (2) stopping criteria with ranked information coefficient (rank IC), and (3) deep transfer learning among multiple regions. Experimental comparison with the stocks in the Morgan Stanley Capital International (MSCI) indices shows that RIC-NN outperforms not only off-the-shelf machine learning methods but also the average return of major equity investment funds in the last fourteen years.", "text_perturb": "Stock return predictability is an important inquiry theme as it reflects our economic and social organization , and significant efforts are made to explain the dynamism therein. Statistics of strong explanative power , called `` factor '' ingest been proposed to summarize the essence of predictive stock returns. Although machine learning methods are increasingly popular in stock return prediction , an illation of the stock returns is highly elusive , and still most investors , if partly , rely on their intuition to build a better decision making. The challenge here be to make an investment strategy that be consistent over a reasonably long period , with the minimum human decision on the entire process. To this end , we propose a new stock return prediction framework that we call Ranked info Coefficient Neural Network ( RIC-NN ). RIC-NN is a deep learning approach and includes the following three novel ideas : ( 1 ) nonlinear multi-factor approach , ( 2 ) stopping criteria with ranked information coefficient ( glaring IC ) , and ( 3 ) deep transfer learning among multiple regions. Experimental comparison with the stocks in the Morgan Stanley Capital International ( MSCI ) indices shows that RIC-NN outperforms not only off-the-shelf machine learning method but also the average return of major equity investment funds in the last fourteen years. ", "label": 1}
{"original_text": "Motivated by biochemical reaction networks, a generalization of the classical secant condition for the stability analysis of cyclic interconnected commensurate fractional-order systems is provided. The main result presents a sufficient condition for stability of networks of cyclic interconnection of fractional-order systems when the digraph describing the network conforms to a single circuit. The condition becomes necessary under a special situation where coupling weights are uniform. We then investigate the robustness of fractional-order linear networks. Robustness performance of a fractional-order linear network is quantified using the H 2 -norm of the dynamical system. Finally, the theoretical results are confirmed via some numerical illustrations.", "text_perturb": "Motivated by biochemical reaction networks , a generalization of the classical secant condition for the stability analysis of cyclic interconnected commensurate fractional-order scheme is provided. The main result presents a sufficient condition for stability of meshing of cyclic interconnection of fractional-order systems when the digraph describing the network conforms to a single circuit. The condition becomes necessary under a special situation where coupling weightiness are uniform. We then investigate the robustness of fractional-order additive networks. Robustness performance of a fractional-order elongate network is quantified using the H 2 -norm of the dynamical system. Finally , the theoretical resultant role are confirmed via some numerical illustrations. ", "label": 1}
{"original_text": "High-performance implementations of graph algorithms are challenging toimplement on new parallel hardware such as GPUs because of three challenges: (1) the difficulty of coming up with graph building blocks, (2) load imbalanceon parallel hardware, and (3) graph problems having low arithmetic intensity.To address some of these challenges, GraphBLAS is an innovative, on-goingeffort by the graph analytics community to propose building blocks based onsparse linear algebra, which will allow graph algorithms to be expressed in aperformant, succinct, composable and portable manner. In this paper, we examinethe performance challenges of a linear-algebra-based approach to building graphframeworks and describe new design principles for overcoming these bottlenecks.Among the new design principles is exploiting input sparsity, which allowsusers to write graph algorithms without specifying push and pull direction.Exploiting output sparsity allows users to tell the backend which values of theoutput in a single vectorized computation they do not want computed.Load-balancing is an important feature for balancing work amongst parallelworkers. We describe the important load-balancing features for handling graphswith different characteristics. The design principles described in this paperhave been implemented in \"GraphBLAST,\" the first high-performance linearalgebra-based graph framework on NVIDIA GPUs that is open-source. The resultsshow that on a single GPU, GraphBLAST has on average at least an order ofmagnitude speedup over previous GraphBLAS implementations SuiteSparse and GBTL,comparable performance to the fastest GPU hardwired primitives andshared-memory graph frameworks Ligra and Gunrock, and better performance thanany other GPU graph framework, while offering a simpler and more conciseprogramming model.", "text_perturb": "High-performance implementations of graphical record algorithms are challenging toimplement on new parallel hardware such as GPUs because of three challenges : ( 1 ) the difficulty of coming up with graphical record building blocks , ( 2 ) load imbalanceon parallel hardware , and ( 3 ) graphical record problems having low arithmetic intensity. To address some of these challenges , GraphBLAS is an innovative , on-goingeffort by the graph analytics community to propose building blocks based onsparse linear algebra , which will allow graph algorithms to represent expressed in aperformant , succinct , composable and portable manner. In this paper , we examinethe performance challenges of a linear-algebra-based approach to building graphframeworks and describe new design principle for overcoming these bottlenecks. Among the new design principles personify exploiting input sparsity , which allowsusers to write graph algorithms without specifying push and pull direction. Exploiting output sparsity allows users to tell the backend which values of theoutput in a single vectorized computation they make not want computed. Load-balancing is an important feature for equilibrise work amongst parallelworkers. We describe the important load-balancing features for deal graphswith different characteristics. The design principles described in this paperhave been implemented in `` GraphBLAST , '' the initiatory high-performance linearalgebra-based graph framework on NVIDIA GPUs that is open-source. The resultsshow that on a single GPU , GraphBLAST has on average at least an rules of order ofmagnitude speedup over previous GraphBLAS implementations SuiteSparse and GBTL , comparable performance to the fastest GPU hardwired primitives andshared-memory graph frameworks Ligra and Gunrock , and better performance thanany other GPU graph framework , while offering a simpler and more conciseprogramming model. ", "label": 1}
{"original_text": "We propose a variant of the Frank-Wolfe algorithm for solving a class of sparselow-rank optimization problems. Our formulation includes Elastic Net, regularized SVMs and phase retrieval as special cases. The proposed Primal-Dual Block Frank-Wolfe algorithm reduces the per-iteration cost while maintaining linear convergence rate. The per iteration cost of our method depends on the structural complexity of the solution (i.e. sparsitylow-rank) instead of the ambient dimension. We empirically show that our algorithm outperforms the state-of-the-art methods on (multi-class) classification tasks.", "text_perturb": "We propose a variant of the Frank-Wolfe algorithm for figure out a class of sparselow-rank optimization problems. Our formulation includes Elastic Net , regularized SVMs and phase recovery as special cases. The purpose Primal-Dual Block Frank-Wolfe algorithm reduces the per-iteration cost while maintaining linear convergence rate. The per iteration cost of our method look on the structural complexity of the solution ( i. due east. sparsitylow-rank ) or else of the ambient dimension. We empirically show that our algorithm outperforms the state of the art methods on ( multi-class ) classification tasks. ", "label": 1}
{"original_text": "Land cover mapping is essential for monitoring the environment and understanding the effects of human activities on it. The automatic approaches to land cover mapping (i.e., image segmentation) mostly used traditional machine learning that requires heuristic feature design. On the natural images, deep learning has outperformed traditional machine learning approaches on a range of tasks, including the image segmentation. On remote sensing images, recent studies are demonstrating successful application of specific deep learning models or their adaptations to particular small-scale land cover mapping tasks (e.g., to classify wetland complexes). However, it is not readily clear which of the existing state-of-the-art models for natural images are the best candidates to be taken for the particular remote sensing task and data. In this study, we answer that question for mapping the fundamental land cover classes using the satellite imaging radar data. We took ESA Sentinel-1 C-band SAR images available at no cost to users as representative data. CORINE land cover map produced by the Finnish Environment Institute was used as a reference, and the models were trained to distinguish between the 5 Level-1 CORINE classes. We selected seven among the state-of-the-art semantic segmentation models so that they cover a diverse set of approaches: U-Net, DeepLabV3, PSPNet, BiSeNet, SegNet, FC-DenseNet, and FRRN-B. These models were pre-trained on the ImageNet dataset and further fine-tuned in this study. Specifically, we used 14 ESA Sentinel-1 scenes acquired during the summer season in Finland, which are representative of the land cover in the country. Upon the evaluation and benchmarking, all the models demonstrated solid performance. The best model, FC-DenseNet (Fully Convolutional DenseNets), achieved the overall accuracy of 90.7. Except for the producer accuracy of two classes (urban and water bodies), FC-DenseNet has outperformed all the other models across the accuracy measures and the classes. Overall, our results indicate that the semantic segmentation models are suitable for efficient wide-area mapping using satellite SAR imagery. Our results also provide baseline accuracy against which the newly proposed models should be evaluated and suggest the DenseNet-based models are the first candidate for this task.", "text_perturb": "Land cover mapping is essential for monitor the environment and understanding the effects of human activities on it. The automatic approaches to land cover charge mapping ( i. es. , image segmentation ) mostly victimised traditional machine learning that requires heuristic feature design. On the natural images , deep learning has outperformed traditional machine learning approaches on a range of tasks , including the trope segmentation. On remote sensing images , recent studies are demonstrating successful practical application of specific deep learning models or their adaptations to particular small-scale land cover mapping tasks ( e. gravitational constant. , to classify wetland complexes ). However , it is not readily clear which of the existing state-of-the-art models for natural images are the best candidates to be taken for the finical remote sensing task and data. In this study , we answer that question for mapping the fundamental land cover song classes using the satellite imaging radar data. We took ESA Sentinel-1 C-band SAR images usable at no cost to users as representative data. CORINE land cover map produced by the finnish Environment Institute was used as a reference , and the models were trained to distinguish between the 5 Level-1 CORINE classes. We selected seven among the state-of-the-art semantic segmentation models so that they overcompensate a diverse set of approaches : U-Net , DeepLabV3 , PSPNet , BiSeNet , SegNet , FC-DenseNet , and FRRN-B. These exemplar were pre-trained on the ImageNet dataset and further fine-tuned in this study. Specifically , we use 14 ESA Sentinel-1 scenes acquired during the summer season in Finland , which are representative of the land cover in the country. Upon the evaluation and benchmarking , all the manikin demonstrated solid performance. The undecomposed model , FC-DenseNet ( Fully Convolutional DenseNets ) , achieved the overall accuracy of 90. 7. Except for the producer truth of two classes ( urban and water bodies ) , FC-DenseNet has outperformed all the other models across the truth measures and the classes. Overall , our results indicate that the semantic segmentation models are suited for efficient wide-area mapping using satellite SAR imagery. Our results also provide baseline accuracy against which the newly proposed models should be assess and suggest the DenseNet-based models are the first candidate for this task. ", "label": 1}
{"original_text": "This paper focuses on the expressive power of disjunctive and normal logic programs under the stable model semantics over finite, infinite, or arbitrary structures. A translation from disjunctive logic programs into normal logic programs is proposed and then proved to be sound over infinite structures. The equivalence of expressive power of two kinds of logic programs over arbitrary structures is shown to coincide with that over finite structures, and coincide with whether or not NP is closed under complement. Over finite structures, the intranslatability from disjunctive logic programs to normal logic programs is also proved if arities of auxiliary predicates and functions are bounded in a certain way.", "text_perturb": "This paper focuses on the expressive power of disjunctive and normal logic programs under the stable modeling semantics over finite , infinite , or arbitrary structures. A translation from disjunctive logic curriculum into normal logic curriculum is proposed and then proved to be sound over infinite structures. The equivalence of expressive power of two kinds of logic programs over arbitrary social organisation is shown to coincide with that over finite social organisation , and coincide with whether or not NP is closed under complement. Over finite structures , the intranslatability from disjunctive logic programs to normal logic programs is also proved if arities of ancillary predicates and functions are bounded in a certain way. ", "label": 1}
{"original_text": "We make a minimal, but very effective alteration to the VAE model. This is about a drop-in replacement for the (sample-dependent) approximate posterior to change it from the standard white Gaussian with diagonal covariance to the first-order autoregressive Gaussian. We argue that this is a more reasonable choice to adopt for natural signals like images, as it does not force the existing correlation in the data to disappear in the posterior. Moreover, it allows more freedom for the approximate posterior to match the true posterior. This allows for the repararametrization trick, as well as the KL-divergence term to still have closed-form expressions, obviating the need for its sample-based estimation. Although providing more freedom to adapt to correlated distributions, our parametrization has even less number of parameters than the diagonal covariance, as it requires only two scalars, r and s, to characterize correlation and scaling, respectively. As validated by the experiments, our proposition noticeably and consistently improves the quality of image generation in a plug-and-play manner, needing no further parameter tuning, and across all setups. The code to reproduce our experiments is available at", "text_perturb": "We make a minimum , but very effective alteration to the VAE model. This is about a drop-in replacement for the ( sample-dependent ) approximate posterior to change it from the standard blanched Gaussian with diagonal covariance to the first-order autoregressive Gaussian. We argue that this is a more reasonable choice to adopt for natural sign like images , as it does not force the existing correlation in the data to disappear in the posterior. Moreover , it allows more freedom for the approximate bottom to match the true bottom. This allows for the repararametrization trick , as well as the KL-divergence term to nonetheless have closed-form expressions , obviating the need for its sample-based estimation. Although providing more freedom to adapt to correlated distributions , our parametrization has even less number of parameters than the diagonal covariance , as it requires solely two scalars , r and s , to characterize correlation and scaling , respectively. As validated by the experiments , our proposition noticeably and consistently improves the quality of image propagation in a plug-and-play manner , needing no further parameter tuning , and across all setups. The code to reproduce our experiments personify available at", "label": 1}
{"original_text": "This paper presents eight PAC-Bayes bounds to analyze the generalization performance of multi-view classifiers. These bounds adopt data dependent Gaussian priors which emphasize classifiers with high view agreements. The center of the prior for the first two bounds is the origin, while the center of the prior for the third and fourth bounds is given by a data dependent vector. An important technique to obtain these bounds is two derived logarithmic determinant inequalities whose difference lies in whether the dimensionality of data is involved. The centers of the fifth and sixth bounds are calculated on a separate subset of the training set. The last two bounds use unlabeled data to represent view agreements and are thus applicable to semi-supervised multi-view learning. We evaluate all the presented multi-view PAC-Bayes bounds on benchmark data and compare them with previous single-view PAC-Bayes bounds. The usefulness and performance of the multi-view bounds are discussed.", "text_perturb": "This paper presents eight PAC-Bayes bounds to analyze the inductive reasoning performance of multi-view classifiers. These bounds adopt data dependent Gaussian priors which accent classifiers with high view agreements. The center of the prior for the first two bounds is the origin , while the center of the prior for the third and fourth bounds is given by a data point dependent vector. An important technique to obtain these bounds follow two derived logarithmic determinant inequalities whose difference lies in whether the dimensionality of data follow involved. The centers of the fifth and sixth saltation are calculated on a separate subset of the training set. The last two bounds utilize unlabeled data to represent view agreements and are thus applicable to semi-supervised multi-view learning. We appraise all the presented multi-view PAC-Bayes bounds on benchmark data and compare them with previous single-view PAC-Bayes bounds. The usefulness and execution of the multi-view bounds are discussed. ", "label": 1}
{"original_text": "The fuzzy K -means problem is a generalization of the classical K -means problem to soft clusterings, i.e. clusterings where each points belongs to each cluster to some degree. Although popular in practice, prior to this work the fuzzy K -means problem has not been studied from a complexity theoretic or algorithmic perspective. We show that optimal solutions for fuzzy K -means cannot, in general, be expressed by radicals over the input points. Surprisingly, this already holds for very simple inputs in one-dimensional space. Hence, one cannot expect to compute optimal solutions exactly. We give the first (1) -approximation algorithms for the fuzzy K -means problem. First, we present a deterministic approximation algorithm whose runtime is polynomial in N and linear in the dimension D of the input set, given that K is constant, i.e. a polynomial time approximation algorithm given a fixed K. We achieve this result by showing that for each soft clustering there exists a hard clustering with comparable properties. Second, by using techniques known from coreset constructions for the K -means problem, we develop a deterministic approximation algorithm that runs in time almost linear in N but exponential in the dimension D. We complement these results with a randomized algorithm which imposes some natural restrictions on the input set and whose runtime is comparable to some of the most efficient approximation algorithms for K -means, i.e. linear in the number of points and the dimension, but exponential in the number of clusters.", "text_perturb": "The foggy K -means problem is a generalization of the classical K -means problem to soft clusterings , i. eastward. clusterings where each points belong to each cluster to some degree. Although popular in practice , prior to this work the bleary K -means problem has not been studied from a complexity theoretic or algorithmic perspective. We show that optimal solutions for fuzzy grand -means can not , in general , be expressed by radicals over the input points. Surprisingly , this already holds for very simple inputs in one-dimensional infinite. Hence , one can not expect to compute optimal solutions on the dot. We give the world class ( 1 ) -approximation algorithms for the fuzzy K -means problem. First , we lay out a deterministic approximation algorithm whose runtime is polynomial in N and linear in the dimension D of the input set , given that K is constant , i. east. a polynomial metre approximation algorithm given a fixed K. We achieve this result by showing that for each soft clump there exists a hard clump with comparable properties. Second , by using techniques known from coreset constructions for the K -means problem , we build up a deterministic approximation algorithm that runs in time almost linear in N but exponential in the dimension D. We complement these results with a randomized algorithm which imposes some natural confinement on the input set and whose runtime is comparable to some of the most efficient approximation algorithms for K -means , i. es. linear in the number of points and the proportion , but exponential in the number of clusters. ", "label": 1}
{"original_text": "Explosive growth in the use of smart wireless devices has necessitated the provision of higher data rates and always-on connectivity, which are the main motivators for designing the fifth generation (5G) systems. To achieve higher system efficiency, massive antenna deployment with tight coordination is one potential strategy for designing 5G systems, but has two types of associated system overhead. First is the synchronization overhead, which can be reduced by implementing a cloud radio access network (CRAN) -based architecture design, that separates the baseband processing and radio access functionality to achieve better system synchronization. Second is the overhead for acquiring channel state information (CSI) of the users present in the system, which, however, increases tremendously when instantaneous CSI is used to serve high-mobility users. To serve a large number of users, a CRAN system with a dense deployment of remote radio heads (RRHs) is considered, such that each user has a line-of-sight (LOS) link with the corresponding RRH. Since, the trajectory of movement for high-mobility users is predictable, therefore, fairly accurate position estimates for those users can be obtained, and can be used for resource allocation to serve the considered users. The resource allocation is dependent upon various correlated system parameters, and these correlations can be learned using well-known machine learning algorithms. This paper proposes a novel learning-based resource allocation scheme for time division duplex (TDD) based 5G CRAN systems with dense RRH deployment, by using only the users' position estimates for resource allocation, thus avoiding the need for CSI acquisition. Also, an overhead model based on the proposed frame structure for 5G TDD is presented, both for user's position and its CSI acquisition. The proposed scheme achieves about 86 of the optimal system performance, with an overhead of 2.4, compared to the traditional CSI-based resource allocation scheme which has an overhead of about 19. The proposed scheme is also fairly robust to changes in the propagation environment with a maximum performance loss of 5 when either the scatterers' density or the shadowing effect varies. Avoiding the need for CSI acquisition reduces the overall system overhead significantly, while still achieving near-optimal system performance, and thus, better system efficiency is achieved at reduced cost.", "text_perturb": "Explosive growth in the use of smart wireless devices experience necessitated the provision of higher data rates and always-on connectivity , which are the main motivators for designing the fifth generation ( 5G ) systems. To achieve higher arrangement efficiency , massive antenna deployment with tight coordination is one potential strategy for designing 5G systems , but has two types of associated arrangement overhead. First is the synchronising overhead , which can be reduced by implementing a cloud radio access network ( CRAN ) -based architecture design , that separates the baseband processing and radio access functionality to achieve better system synchronising. Second is the overhead for acquiring channel state information ( CSI ) of the users present in the system , which , nonetheless , increases tremendously when instantaneous CSI is used to serve high-mobility users. To serve a large number of users , a CRAN system with a dense deployment of remote radio pass ( RRHs ) is considered , such that each user has a line-of-sight ( LOS ) link with the corresponding RRH. Since , the trajectory of movement for high-mobility users is predictable , therefore , fairly accurate position estimates for those users can be obtained , and can be used for resource parceling to serve the considered users. The imagination allocation is dependent upon various correlated system parameters , and these correlations can be learned using well-known machine learning algorithms. This paper proposes a novel learning-based resourcefulness allocation scheme for time division duplex ( TDD ) based 5G CRAN systems with dense RRH deployment , by using only the users ' position estimates for resourcefulness allocation , thus avoiding the need for CSI acquisition. Also , an overhead model based on the suggest frame structure for 5G TDD is presented , both for user 's position and its CSI acquisition. The proposed scheme attain about 86 of the optimal system performance , with an overhead of 2. 4 , compared to the traditional CSI-based resource allocation scheme which have an overhead of about 19. The project scheme is also fairly robust to changes in the propagation environment with a maximum performance loss of 5 when either the scatterers ' density or the shadowing effect varies. Avoiding the need for CSI acquisition reduces the overall system overhead significantly , while still achieving near-optimal system performance , and thus , better system efficiency is achieved at reduced price. ", "label": 1}
{"original_text": "In this paper, a new graph partitioning problem is introduced. The depth of each part is constrained, i.e., the node count in the longest path of the corresponding sub-graph is no more than a predetermined positive integer value p. An additional constraint is enforced such that each part contains only nodes selected from consecutive levels in the graph. The problem is therefore transformed into a Depth-bounded Levelized Graph Partitioning (DLGP) problem, which is solved optimally using a dynamic programming algorithm. As an example application, we have shown that DLGP can effectively generate timing-correct circuit solutions for Single Flux Quantum (SFQ) logic, which is a magnetic-pulse-based, gate-level pipelined superconductive computing fabric. Experimental results confirm that DLGP generates circuits with considerably lower path balancing overheads compared with a baseline full-path-balancing approach. For example, the balancing overhead (a critical measure of quality metric) for the SFQ circuit realization in terms of D-Flip-Flop count is reduced by 3.61 x on average for 10 benchmark circuit, given p 5.", "text_perturb": "In this paper , a new graph partitioning trouble is introduced. The depth of each component is constrained , i. einsteinium. , the node count in the longest path of the corresponding sub-graph is no more than a predetermined convinced integer value p. An additional constraint is enforced such that each part contains alone nodes selected from consecutive levels in the graph. The problem constitute therefore transformed into a Depth-bounded Levelized Graph Partitioning ( DLGP ) problem , which constitute solved optimally using a dynamic programming algorithm. As an example application , we deliver shown that DLGP can effectively generate timing-correct circuit solutions for Single Flux Quantum ( SFQ ) logic , which is a magnetic-pulse-based , gate-level pipelined superconductive computing fabric. Experimental results confirm that DLGP generates circuits with considerably lower path equilibrate overheads compared with a baseline full-path-balancing approach. For example , the poise overhead ( a critical measure of quality metric ) for the SFQ circuit realization in terms of D-Flip-Flop count is reduced by 3. 61 x on average for 10 benchmark circuit , devote p 5. ", "label": 1}
{"original_text": "Most computational models of analogy assume they are given a delineated source domain and often a specified target domain. These systems do not address how analogs can be isolated from large domains and spontaneously retrieved from long-term memory, a process we call spontaneous analogy. We present a system that represents relational structures as feature bags. Using this representation, our system leverages perceptual algorithms to automatically create an ontology of relational structures and to efficiently retrieve analogs for new relational structures from long-term memory. We provide a demonstration of our approach that takes a set of unsegmented stories, constructs an ontology of analogical schemas (corresponding to plot devices), and uses this ontology to efficiently find analogs within new stories, yielding significant time-savings over linear analog retrieval at a small accuracy cost.", "text_perturb": "Most computational models of analogy assume they are given a delineated root domain and often a specified target domain. These systems do non address how analogs can be isolated from large domains and spontaneously retrieved from long-term memory , a process we call spontaneous analogy. We present a system that represents relational structures as feature film bags. Using this representation , our system leverages perceptual algorithms to automatically create an ontology of relational structures and to efficiently retrieve analogs for new relational structures from long term memory. We provide a demonstration of our approach that takes a set of unsegmented stories , constructs an ontology of analogical schemas ( corresponding to plot devices ) , and uses this ontology to efficiently find analogs within new stories , yielding significant time-savings over linear analog retrieval at a small truth cost. ", "label": 1}
{"original_text": "Legged robots have the ability to adapt their walking posture to navigate confined spaces due to their high degrees of freedom. However, this has not been exploited in most common multilegged platforms. This paper presents a deformable bounding box abstraction of the robot model, with accompanying mapping and planning strategies, that enable a legged robot to autonomously change its body shape to navigate confined spaces. The mapping is achieved using robot-centric multi-elevation maps generated with distance sensors carried by the robot. The path planning is based on the trajectory optimisation algorithm CHOMP which creates smooth trajectories while avoiding obstacles. The proposed method has been tested in simulation and implemented on the hexapod robot Weaver, which is 33 cm tall and 82 cm wide when walking normally. We demonstrate navigating under 25 cm overhanging obstacles, through 70 cm wide gaps and over 22 cm high obstacles in both artificial testing spaces and realistic environments, including a subterranean mining tunnel.", "text_perturb": "Legged robots have the ability to accommodate their walking posture to navigate confined spaces due to their high degrees of freedom. However , this has not been exploit in most common multilegged platforms. This paper presents a deformable bounding box abstraction of the robot model , with accompanying mapping and planning strategies , that enable a legged robot to autonomously change its body shape to navigate jailed spaces. The mapping is achieved practice robot-centric multi-elevation maps generated with distance sensors carried by the robot. The path planning is based on the trajectory optimisation algorithm CHOMP which creates smooth trajectories while debar obstacles. The proposed method has been tested in simulation and implemented on the hexapod robot Weaver , which is 33 cm tall and 82 cm wide when walk normally. We demonstrate navigating under 25 cm overhanging obstacles , through 70 cm wide gaps and over 22 cm high obstacles in both artificial examination spaces and realistic environments , including a subterranean mining tunnel. ", "label": 1}
{"original_text": "In multi-channel Wireless Mesh Networks (WMN), each node is able to use multiple non-overlapping frequency channels. Raniwala et al. (MC2R 2004, INFOCOM 2005) propose and study several such architectures in which a computer can have multiple network interface cards. These architectures are modeled as a graph problem named maximum edge q -coloring and studied in several papers by Feng et. al (TAMC 2007), Adamaszek and Popa (ISAAC 2010, JDA 2016). Later on Larjomaa and Popa (IWOCA 2014, JGAA 2015) define and study an alternative variant, named the min-max edge q -coloring. The above mentioned graph problems, namely the maximum edge q -coloring and the min-max edge q -coloring are studied mainly from the theoretical perspective. In this paper, we study the min-max edge 2-coloring problem from a practical perspective. More precisely, we introduce, implement and test four heuristic approximation algorithms for the min-max edge 2 -coloring problem. These algorithms are based on a Breadth First Search (BFS) -based heuristic and on local search methods like basic hill climbing, simulated annealing and tabu search techniques, respectively. Although several algorithms for particular graph classes were proposed by Larjomaa and Popa (e.g., trees, planar graphs, cliques, bi-cliques, hypergraphs), we design the first algorithms for general graphs. We study and compare the running data for all algorithms on Unit Disk Graphs, as well as some graphs from the DIMACS vertex coloring benchmark dataset.", "text_perturb": "In multi-channel Wireless interlocking Networks ( WMN ) , each node is able to use multiple non-overlapping frequency channels. Raniwala et heart of dixie. ( MC2R 2004 , INFOCOM 2005 ) propose and study several such architectures in which a reckoner can have multiple network interface cards. These architectures are modeled as a graph problem named maximum edge q -coloring and studied in respective papers by Feng et. aluminum ( TAMC 2007 ) , Adamaszek and Popa ( ISAAC 2010 , JDA 2016 ). Later on Larjomaa and Popa ( IWOCA 2014 , JGAA 2015 ) define and study an alternative random variable , named the min-max edge q -coloring. The above mentioned graph problems , namely the maximum boundary q -coloring and the min-max boundary q -coloring are studied mainly from the theoretical perspective. In this paper , we study the min-max edge 2-coloring problem from a pragmatic perspective. More precisely , we introduce , implement and test four heuristic estimate algorithms for the min-max edge 2 -coloring problem. These algorithms are based on a Breadth First Search ( BFS ) -based heuristic and on local search methods like basic hill climbing , simulated annealing and tabu search proficiency , respectively. Although several algorithms for particular graph classes were proposed by Larjomaa and Popa ( due east. gee. , trees , planar graphs , cliques , bi-cliques , hypergraphs ) , we design the st algorithms for general graphs. We analyze and compare the running data for all algorithms on Unit Disk Graphs , as well as some graphs from the DIMACS vertex coloring benchmark dataset. ", "label": 1}
{"original_text": "Frequent pattern mining is a key area of study that gives insights into the structure and dynamics of evolving networks, such as social or road networks. However, not only does a network evolve, but often the way that it evolves, itself evolves. Thus, knowing, in addition to patterns' frequencies, for how long and how regularly they have occurred - i.e., their persistence - can add to our understanding of evolving networks. In this work, we propose the problem of mining activity that persists through time in continually evolving networks - i.e., activity that repeatedly and consistently occurs. We extend the notion of temporal motifs to capture activity among specific nodes, in what we call activity snippets, which are small sequences of edge-updates that reoccur. We propose axioms and properties that a measure of persistence should satisfy, and develop such a persistence measure. We also propose PENminer, an efficient framework for mining activity snippets' Persistence in Evolving Networks, and design both offline and streaming algorithms. We apply PENminer to numerous real, large-scale evolving networks and edge streams, and find activity that is surprisingly regular over a long period of time, but too infrequent to be discovered by aggregate count alone, and bursts of activity exposed by their lack of persistence. Our findings with PENminer include neighborhoods in NYC where taxi traffic persisted through Hurricane Sandy, the opening of new bike-stations, characteristics of social network users, and more. Moreover, we use PENminer towards identifying anomalies in multiple networks, outperforming baselines at identifying subtle anomalies by 9.8-48 in AUC.", "text_perturb": "Frequent pattern mining is a key area of study that gives insights into the structure and dynamics of evolving networks , such as societal or road networks. However , not only does a network evolve , but often the way that it acquire , itself evolves. Thus , have a go at it , in addition to patterns ' frequencies , for how long and how regularly they have occurred - i. due east. , their persistence - can add to our understanding of germinate networks. In this piece of work , we propose the problem of mining activity that persists through time in continually evolving networks - i. einsteinium. , activity that repeatedly and systematically occurs. We extend the notion of temporal motifs to capture activity among specific nodes , in what we call activity snippets , which are small chronological succession of edge-updates that reoccur. We propose axioms and properties that a measure of persistence should satisfy , and uprise such a persistence measure. We besides propose PENminer , an efficient framework for mining activity snippets ' Persistence in Evolving Networks , and design both offline and streaming algorithms. We apply PENminer to numerous real , large-scale evolving networks and edge streams , and happen activity that is surprisingly regular over a long period of time , but too infrequent to be discovered by aggregate count alone , and bursts of activity exposed by their lack of persistence. Our findings with PENminer include neighborhoods in NYC where taxi dealings persisted through Hurricane Sandy , the opening of new bike-stations , characteristics of social network users , and more. what is more , we use PENminer towards identifying anomalies in multiple networks , outperforming baselines at identifying subtle anomalies by 9. 8-48 in AUC. ", "label": 1}
{"original_text": "We study the problem of recognizing visual entities from the textual descriptions of their classes. Specifically, given birds' images with free-text descriptions of their species, we learn to classify images of previously-unseen species based on specie descriptions. This setup has been studied in the vision community under the name zero-shot learning from text, focusing on learning to transfer knowledge about visual aspects of birds from seen classes to previously-unseen ones. Here, we suggest focusing on the textual description and distilling from the description the most relevant information to effectively match visual features to the parts of the text that discuss them. Specifically, (1) we propose to leverage the similarity between species, reflected in the similarity between text descriptions of the species. (2) we derive visual summaries of the texts, i.e., extractive summaries that focus on the visual features that tend to be reflected in images. We propose a simple attention-based model augmented with the similarity and visual summaries components. Our empirical results consistently and significantly outperform the state-of-the-art on the largest benchmarks for text-based zero-shot learning, illustrating the critical importance of texts for zero-shot image-recognition.", "text_perturb": "We study the problem of recognizing visual entities from the textual verbal description of their classes. Specifically , given birds ' images with free-text descriptions of their species , we read to classify images of previously-unseen species based on specie descriptions. This setup has been studied in the vision community under the name zero-shot learning from text , focusing on learning to transfer knowledge about visual aspects of birds from realise classes to previously-unseen ones. Here , we evoke focusing on the textual description and distilling from the description the most relevant information to effectively match visual features to the parts of the text that discuss them. Specifically , ( 1 ) we propose to leverage the law of similarity between species , reflected in the law of similarity between text descriptions of the species. ( 2 ) we derive optical summaries of the texts , i. east. , extractive summary that focus on the visual features that tend to be reflected in images. We propose a simple attention-based model augmented with the similarity and visual sum up components. Our empirical results systematically and significantly outperform the state-of-the-art on the largest benchmarks for text-based zero-shot learning , illustrating the critical importance of texts for zero-shot image-recognition. ", "label": 1}
{"original_text": "Current neural network-based conversational models lack diversity and generate boring responses to open-ended utterances. Priors such as persona, emotion, or topic provide additional information to dialog models to aid response generation, but annotating a dataset with priors is expensive and such annotations are rarely available. While previous methods for improving the quality of open-domain response generation focused on either the underlying model or the training objective, we present a method of filtering dialog datasets by removing generic utterances from training data using a simple entropy-based approach that does not require human supervision. We conduct extensive experiments with different variations of our method, and compare dialog models across 17 evaluation metrics to show that training on datasets filtered this way results in better conversational quality as chatbots learn to output more diverse responses.", "text_perturb": "Current neural network-based conversational models miss diversity and generate boring responses to open-ended utterances. Priors such as persona , emotion , or topic provide additional information to dialog models to aid response generation , but footnote a dataset with priors is expensive and such annotations are rarely available. While previous methods for improving the quality of open-domain response generation focused on either the underlying model or the training objective , we present a method acting of filtering dialog datasets by removing generic utterances from training data using a simple entropy-based approach that does not require human supervision. We conduct extensive experiments with different variations of our method , and compare dialog models across 17 evaluation metrics to show that training on datasets filtered this way results in better conversational timbre as chatbots learn to output more diverse responses. ", "label": 1}
{"original_text": "Recently, a tabletop molecular communication platform has been developed for transmitting short text messages across a room. The end-to-end system impulse response for this platform does not follow previously published theoretical works because of imperfect receiver, transmitter, and turbulent flows. Moreover, it is observed that this platform resembles a nonlinear system, which makes the rich body of theoretical work that has been developed by communication engineers not applicable to this platform. In this work, we first introduce corrections to the previous theoretical models of the end-to-end system impulse response based on the observed data from experimentation. Using the corrected impulse response models, we then formulate the nonlinearity of the system as noise and show that through simplifying assumptions it can be represented as Gaussian noise. Through formulating the system's nonlinearity as the output a linear system corrupted by noise, the rich toolbox of mathematical models of communication systems, most of which are based on linearity assumption, can be applied to this platform.", "text_perturb": "Recently , a tabletop molecular communication platform has been developed for transmitting curt text messages across a room. The end-to-end system impulse response for this platform does non follow previously published theoretical works because of imperfect receiver , transmitter , and turbulent flows. Moreover , it is observed that this platform resembles a nonlinear system , which makes the rich body of theoretical employment that has been developed by communication engineers not applicable to this platform. In this work , we for the first time introduce corrections to the previous theoretical models of the end-to-end system impulse response based on the observed data from experimentation. Using the corrected impulse response models , we then devise the nonlinearity of the system as noise and show that through simplifying assumptions it can be represented as Gaussian noise. Through formulating the scheme 's nonlinearity as the output a linear scheme corrupted by noise , the rich toolbox of mathematical models of communication systems , most of which are based on linearity assumption , can be applied to this platform. ", "label": 1}
{"original_text": "Zero-shot learning (ZSL) has received increasing attention in recent years especially in areas of fine-grained object recognition, retrieval, and image captioning. The key to ZSL is to transfer knowledge from the seen to the unseen classes via auxiliary class attribute vectors. However, the popularly learned projection functions in previous works cannot generalize well since they assume the distribution consistency between seen and unseen domains at sample-level. Besides, the provided non-visual and unique class attributes can significantly degrade the recognition performance in semantic space. In this paper, we propose a simple yet effective convolutional prototype learning (CPL) framework for zero-shot recognition. By assuming distribution consistency at task-level, our CPL is capable of transferring knowledge smoothly to recognize unseen samples. Furthermore, inside each task, discriminative visual prototypes are learned via a distance based training mechanism. Consequently, we can perform recognition in visual space, instead of semantic space. An extensive group of experiments are then carefully designed and presented, demonstrating that CPL obtains more favorable effectiveness, over currently available alternatives under various settings.", "text_perturb": "Zero-shot learning ( ZSL ) has received increasing attention in late years especially in areas of fine-grained object recognition , retrieval , and image captioning. The key to ZSL is to transfer knowledge from the seen to the unseen classes via ancillary class attribute vectors. However , the popularly learned projection functions in previous works can not generalize well since they assume the dispersion consistency between seen and unseen domains at sample-level. Besides , the provided non-visual and unique class dimension can significantly degrade the recognition performance in semantic space. In this paper , we propose a uncomplicated yet effective convolutional prototype learning ( CPL ) framework for zero-shot recognition. By assuming distribution consistency at task-level , our CPL make up capable of transferring knowledge smoothly to recognize unseen samples. Furthermore , inside each task , discriminative visual prototypes are learned via a distance based preparation mechanism. Consequently , we can perform recognition in visual space , rather of semantic space. An extensive group of experiments are then carefully designed and presented , demonstrating that CPL prevail more favorable effectiveness , over currently available alternatives under various settings. ", "label": 1}
{"original_text": "The Stixel World is a medium-level, compact representation of road scenes that abstracts millions of disparity pixels into hundreds or thousands of stixels. The goal of this work is to implement and evaluate a complete multi-stixel estimation pipeline on an embedded, energy-efficient, GPU-accelerated device. This work presents a full GPU-accelerated implementation of stixel estimation that produces reliable results at 26 frames per second (real-time) on the Tegra X1 for disparity images of 1024 x 440 pixels and stixel widths of 5 pixels, and achieves more than 400 frames per second on a high-end Titan X GPU card.", "text_perturb": "The Stixel World is a medium-level , compact representation of road aspect that abstracts millions of disparity pixels into hundreds or thousands of stixels. The goal of this work is to implement and evaluate a consummate multi-stixel estimation pipeline on an embedded , energy-efficient , GPU-accelerated device. This work presents a wide cut GPU-accelerated implementation of stixel estimation that produces reliable results at 26 frames per second ( real-time ) on the Tegra X1 for disparity images of 1024 x 440 pixels and stixel widths of 5 pixels , and achieves more than 400 frames per second on a high-end Titan X GPU card. ", "label": 1}
{"original_text": "Linear logic and the linear l -calculus have a long standing tradition in the study of natural language form and meaning. Among the proof calculi of linear logic, proof nets are of particular interest, offering an attractive geometric representation of derivations that is unburdened by the bureaucratic complications of conventional prooftheoretic formats. Building on recent advances in set-theoretic learning, we propose a neural variant of proof nets based on Sinkhorn networks, which allows us to translate parsing as the problem of extracting syntactic primitives and permuting them into alignment. Our methodology induces a batch-efficient, end-to-end differentiable architecture that actualizes a formally grounded yet highly efficient neuro-symbolic parser. We test our approach on AEthel, a dataset of type-logical derivations for written Dutch, where it manages to correctly transcribe raw text sentences into proofs and terms of the linear l -calculus with an accuracy of as high as 70.", "text_perturb": "Linear logic and the linear l -calculus have a farsighted standing tradition in the study of natural language form and meaning. Among the proof calculi of linear logic , proof nets follow of particular interest , offering an attractive geometric representation of derivations that is unburdened by the bureaucratic complications of conventional prooftheoretic formats. Building on recent advances in set-theoretic learning , we propose a neural var of proof nets based on Sinkhorn networks , which allows us to translate parsing as the problem of extracting syntactic primitives and permuting them into alignment. Our methodology induces a batch-efficient , end-to-end differentiable architecture that actualizes a formally grounded nonetheless highly efficient neuro-symbolic parser. We test our approach on AEthel , a dataset of type-logical derivations for written Dutch , where it manages to correctly transcribe raw text sentences into proof and terms of the linear l -calculus with an accuracy of as high as 70. ", "label": 1}
{"original_text": "We show that the query containment problem for monadic datalog on finite unranked labeled trees can be solved in 2-fold exponential time when (a) considering unordered trees using the axes child and descendant, and when (b) considering ordered trees using the axes firstchild, nextsibling, child, and descendant. When omitting the descendant -axis, we obtain that in both cases the problem is Exptime -complete.", "text_perturb": "We show that the query containment problem for monadic datalog on finite unranked labeled tree diagram can be solved in 2-fold exponential time when ( a ) considering unordered tree diagram using the axes child and descendant , and when ( b ) considering ordered tree diagram using the axes firstchild , nextsibling , child , and descendant. When omitting the descendant -axis , we find that in both cases the problem is Exptime -complete. ", "label": 1}
{"original_text": "Reo is an interaction-centric model of concurrency for compositional specification of communication and coordination protocols. Formal verification tools exist to ensure correctness and compliance of protocols specified in Reo, which can readily be (re) used in different applications, or composed into more complex protocols. Recent benchmarks show that compiling such high-level Reo specifications produces executable code that can compete with or even beat the performance of hand-crafted programs written in languages such as C or Java using conventional concurrency constructs. The original declarative graphical syntax of Reo does not support intuitive constructs for parameter passing, iteration, recursion, or conditional specification. This shortcoming hinders Reo's uptake in large-scale practical applications. Although a number of Reo-inspired syntax alternatives have appeared in the past, none of them follows the primary design principles of Reo: a) declarative specification; b) all channel types and their sorts are user-defined; and c) channels compose via shared nodes. In this paper, we offer a textual syntax for Reo that respects these principles and supports flexible parameter passing, iteration, recursion, and conditional specification. In on-going work, we use this textual syntax to compile Reo into target languages such as Java, Promela, and Maude.", "text_perturb": "Reo is an interaction-centric model of concurrency for compositional specification of communicating and coordination protocols. stately verification tools exist to ensure correctness and compliance of protocols specified in Reo , which can readily be ( re ) used in different applications , or composed into more complex protocols. Recent benchmarks show that compiling such high-level Reo specifications produces executable code that can compete with or even beat the operation of hand-crafted programs written in languages such as C or Java using conventional concurrency constructs. The original declarative graphical syntax of Reo does not support intuitive constructs for parameter passing , looping , recursion , or conditional specification. This shortcoming hinders Reo 's intake in large-scale practical applications. Although a number of Reo-inspired syntax alternatives have appeared in the past , none of them follows the primary design principles of Reo : a ) declarative specification ; b ) all transmit types and their sorts are user-defined ; and c ) channels compose via shared nodes. In this paper , we offer a textual syntax for Reo that respects these rule and supports flexible parameter passing , iteration , recursion , and conditional specification. In on-going work , we use this textual sentence structure to compile Reo into target languages such as Java , Promela , and Maude. ", "label": 1}
{"original_text": "Speech and speaker recognition systems are employed in a variety of applications, from personal assistants to telephony surveillance and biometric authentication. The wide deployment of these systems has been made possible by the improved accuracy in neural networks. Like other systems based on neural networks, recent research has demonstrated that speech and speaker recognition systems are vulnerable to attacks using manipulated inputs. However, as we demonstrate in this paper, the end-to-end architecture of speech and speaker systems and the nature of their inputs make attacks and defenses against them substantially different than those in the image space. We demonstrate this first by systematizing existing research in this space and providing a taxonomy through which the community can evaluate future work. We then demonstrate experimentally that attacks against these models almost universally fail to transfer. In so doing, we argue that substantial additional work is required to provide adequate mitigations in this space.", "text_perturb": "Speech and speaker recognition systems cost employed in a variety of applications , from personal assistants to telephony surveillance and biometric authentication. The wide deployment of these systems give been made possible by the improved accuracy in neural networks. Like other organization based on neural networks , recent research has demonstrated that speech and speaker recognition organization are vulnerable to attacks using manipulated inputs. However , as we show in this paper , the end-to-end architecture of speech and speaker systems and the nature of their inputs make attacks and defenses against them substantially different than those in the image space. We demonstrate this first by systematizing existing research in this space and cater a taxonomy through which the community can evaluate future work. We then demonstrate experimentally that attempt against these models almost universally fail to transfer. In so doing , we argue that substantial additional work is involve to provide adequate mitigations in this space. ", "label": 1}
{"original_text": "In this paper, we study the problem of minimizing regret in discounted-sum games played on weighted game graphs. We give algorithms for the general problem of computing the minimal regret of the controller (Eve) as well as several variants depending on which strategies the environment (Adam) is permitted to use. We also consider the problem of synthesizing regret-free strategies for Eve in each of these scenarios.", "text_perturb": "In this paper , we study the problem of belittle regret in discounted-sum games played on weighted game graphs. We give algorithms for the general problem of computing the minimal sorrow of the controller ( Eve ) as well as several variants depending on which strategies the environment ( Adam ) is permitted to use. We also consider the problem of synthesizing regret-free strategy for Eve in each of these scenarios. ", "label": 1}
{"original_text": "Video moment retrieval is to search the moment that is most relevant to the given natural language query. Existing methods are mostly trained in a fully-supervised setting, which requires the full annotations of temporal boundary for each query. However, manually labeling the annotations is actually time-consuming and expensive. In this paper, we propose a novel weakly-supervised moment retrieval framework requiring only coarse video-level annotations for training. Specifically, we devise a proposal generation module that aggregates the context information to generate and score all candidate proposals in one single pass. We then devise an algorithm that considers both exploitation and exploration to select top-K proposals. Next, we build a semantic completion module to measure the semantic similarity between the selected proposals and query, compute reward and provide feedbacks to the proposal generation module for scoring refinement. Experiments on the ActivityCaptions and Charades-STA demonstrate the effectiveness of our proposed method.", "text_perturb": "picture moment retrieval is to search the moment that is most relevant to the given natural language query. Existing methods are mostly trained in a fully-supervised setting , which requires the full annotations of temporal boundary for each interrogation. notwithstanding , manually labeling the annotations is actually time-consuming and expensive. In this theme , we propose a novel weakly-supervised moment retrieval framework requiring only coarse video-level annotations for training. Specifically , we devise a proposal generation module that aggregates the context information to generate and score all campaigner proposals in one single pass. We and then devise an algorithm that considers both exploitation and exploration to select top-K proposals. Next , we build a semantic completion mental faculty to measure the semantic similarity between the selected proposals and query , compute reward and provide feedbacks to the proposal generation mental faculty for scoring refinement. Experiments on the ActivityCaptions and Charades-STA march the effectiveness of our proposed method. ", "label": 1}
{"original_text": "This paper focuses on latent representations that could effectively decompose different aspects of textual information. Using a framework of style transfer for texts, we propose several empirical methods to assess information decomposition quality. We validate these methods with several state-of-the-art textual style transfer methods. Higher quality of information decomposition corresponds to higher performance in terms of bilingual evaluation understudy (BLEU) between output and human-written reformulations.", "text_perturb": "This paper focuses on latent representations that could effectively decompose different aspects of textual selective information. Using a framework of style transport for texts , we propose several empirical methods to assess information decomposition quality. We validate these methods with various state-of-the-art textual style transfer methods. Higher quality of information decomposition corresponds to higher performance in terms of bilingual valuation understudy ( BLEU ) between output and human-written reformulations. ", "label": 1}
{"original_text": "Edge computing is emerging as a new paradigm to allow processing data at the edge of the network, where data is typically generated and collected, by exploiting multiple devices at the edge collectively. However, offloading tasks to other devices leaves the edge computing applications at the complete mercy of an attacker. One of the attacks, which is also the focus of this work, is Byzantine attacks, where one or more devices can corrupt the offloaded tasks. Furthermore, exploiting the potential of edge computing is challenging mainly due to the heterogeneous and time-varying nature of the devices at the edge. In this paper, we develop a secure coded cooperative computation mechanism (SC 3) that provides both security and computation efficiency guarantees by gracefully combining homomorphic hash functions and coded cooperative computation. Homomorphic hash functions are used against Byzantine attacks and coded cooperative computation is used to improve computation efficiency when edge resources are heterogeneous and time-varying. Simulations results show that SC 3 improves task completion delay significantly.", "text_perturb": "Edge computing is emerging as a new paradigm to allow processing data at the edge of the mesh , where data is typically generated and collected , by exploiting multiple devices at the edge collectively. However , offloading tasks to other devices leaves the edge computing applications at the complete mercifulness of an attacker. One of the attacks , which is also the focus of this work , is Byzantine attacks , where one or more devices can bribe the offloaded tasks. Furthermore , exploiting the potential of edge computing is gainsay mainly due to the heterogeneous and time-varying nature of the devices at the edge. In this paper , we develop a secure coded cooperative computation mechanism ( SC 3 ) that provides both security measure and computation efficiency guarantees by gracefully combining homomorphic hash functions and coded cooperative computation. Homomorphic hash functions are used against Byzantine attacks and coded cooperative reckoning is used to improve reckoning efficiency when edge resources are heterogeneous and time-varying. Simulations results show that SC 3 improves task completion delay importantly. ", "label": 1}
{"original_text": "Local perturbations of an infinitely long rod travel to infinity. On the contrary, in the case of a finite length of the rod, the perturbations reach its boundary and are reflected. The boundary conditions constructed here for the implicit difference scheme imitate the Cauchy problem and provide almost no reflection. These boundary conditions are non-local with respect to time, and their practical implementation requires additional calculations at every time step. To minimise them, a special rational approximation, similar to the Hermite - Pade approximation is used. Numerical experiments confirm the high \"transparency\" of these boundary conditions and determine the conditional stability regions for finite-difference scheme.", "text_perturb": "Local perturbations of an infinitely long retinal rod travel to infinity. On the contrary , in the case of a finite length of the perch , the perturbations reach its boundary and are reflected. The boundary conditions constructed here for the implicit difference scheme imitate the Cauchy problem and provide about no reflection. These boundary conditions are non-local with respect to time , and their hard nosed implementation requires additional calculations at every time step. To minimise them , a peculiar rational approximation , similar to the Hermite - Pade approximation is used. Numerical experiments confirm the gamy `` transparency '' of these boundary conditions and determine the conditional stability regions for finite-difference scheme. ", "label": 1}
{"original_text": "The discriminator from generative adversarial nets (GAN) has been used by some researchers as a feature extractor in transfer learning and appeared worked well. However, there are also some studies that believe this is the wrong research direction because intuitively the task of the discriminator focuses on separating the real samples from the generated ones, making features extracted in this way useless for most of the downstream tasks. To avoid this dilemma, we first conducted a thorough theoretical analysis of the relationship between the discriminator task and the characteristics of the features extracted. We found that the connection between the task of the discriminator and the feature is not as strong as was thought, for that the main factor restricting the feature learned by the discriminator is not the task of the discriminator itself, but the need to prevent the entire GAN model from mode collapse during the training. From this perspective and combined with further analyses, we found that to avoid mode collapse in the training process of GAN, the features extracted by the discriminator are not guided to be different for the real samples, but divergence without noise is indeed allowed and occupies a large proportion of the feature space. This makes the features learned more robust and helps answer the question as to why the discriminator can succeed as a feature extractor in related research. Consequently, to expose the essence of the discriminator extractor as different from other extractors, we analyze the counterpart of the discriminator extractor, the classifier extractor that assigns the target samples to different categories. We found the performance of the discriminator extractor may be inferior to the classifier based extractor when the source classification task is similar to the target task, which is the common case, but the ability to avoid noise prevents the discriminator from being replaced by the classifier. Last but not least, as our research also revealed a ratio playing an important role in GAN's training to prevent mode collapse, it contributes to the basic GAN study.", "text_perturb": "The discriminator from generative adversarial nets ( GAN ) has follow used by some researchers as a feature extractor in transfer learning and appeared worked well. However , there are also some studies that believe this is the wrong research direction because intuitively the task of the discriminator focuses on separating the real samples from the generated  , making features extracted in this way useless for most of the downstream tasks. To avoid this dilemma , we first conducted a thorough theoretical analysis of the relationship between the discriminator task and the characteristics of the lineament extracted. We found that the connection between the task of the discriminator and the feature is non as strong as was thought , for that the main factor restricting the feature learned by the discriminator is non the task of the discriminator itself , but the need to prevent the entire GAN model from mode collapse during the training. From this perspective and combined with further analyses , we found that to avoid mode collapse in the training process of GAN , the features extracted by the discriminator are not guided to be different for the real samples , but divergence without noise is indeed allowed and lodge in a large proportion of the feature space. This makes the feature of speech learned more robust and helps answer the question as to why the discriminator can succeed as a feature extractor in related research. Consequently , to expose the essence of the discriminator extractor as different from other extractors , we analyze the vis a vis of the discriminator extractor , the classifier extractor that assigns the target samples to different categories. We found the performance of the discriminator extractor may constitute inferior to the classifier based extractor when the source classification task is similar to the target task , which is the common case , but the ability to avoid noise prevents the discriminator from being replaced by the classifier. Last but not least , as our research also revealed a ratio playing an important role in GAN 's training to prevent mode collapse , it contributes to the basic GAN work. ", "label": 1}
{"original_text": "This paper proposes a parallel optimization algorithm for cooperative automation of large-scale connected vehicles. The task of cooperative automation is formulated as a centralized optimization problem taking the whole decision space of all vehicles into account. Considering the uncertainty of the environment, the problem is solved in a receding horizon fashion. Then, we employ the alternating direction method of multipliers (ADMM) to solve the centralized optimization in a parallel way, which scales more favorably to large-scale instances. Also, Taylor series is used to linearize nonconvex constraints caused by coupling collision avoidance constraints among interactive vehicles. Simulations with two typical traffic scenes for multiple vehicles demonstrate the effectiveness and efficiency of our method.", "text_perturb": "This paper proposes a parallel optimization algorithm for accommodative automation of large-scale connected vehicles. The task of cooperative automation is formulated as a centralized optimization problem taking the whole decision quad of all vehicles into account. see the uncertainty of the environment , the problem is solved in a receding horizon fashion. Then , we employ the alternating direction method of multiplier ( ADMM ) to solve the centralized optimization in a parallel way , which scales more favorably to large-scale instances. Also , Taylor series make up used to linearize nonconvex constraints caused by coupling collision avoidance constraints among interactive vehicles. Simulations with two typical traffic scenes for multiple vehicles demonstrate the effectiveness and efficiency of our method acting. ", "label": 1}
{"original_text": "We propose a new optimization method for training feed-forward neural networks. By rewriting the activation function as an equivalent proximal operator, we approximate a feed-forward neural network by adding the proximal operators to the objective function as penalties, hence we call the lifted proximal operator machine (LPOM). LPOM is block multi-convex in all layer-wise weights and activations. This allows us to use block coordinate descent to update the layer-wise weights and activations in parallel. Most notably, we only use the mapping of the activation function itself, rather than its derivatives, thus avoiding the gradient vanishing or blow-up issues in gradient based training methods. So our method is applicable to various non-decreasing Lipschitz continuous activation functions, which can be saturating and non-differentiable. LPOM does not require more auxiliary variables than the layer-wise activations, thus using roughly the same amount of memory as stochastic gradient descent (SGD) does. We further prove the convergence of updating the layer-wise weights and activations. Experiments on MNIST and CIFAR-10 datasets testify to the advantages of LPOM.", "text_perturb": "We propose a new optimization method acting for training feed-forward neural networks. By rewriting the activating function as an equivalent proximal operator , we approximate a feed-forward neural network by adding the proximal operators to the objective function as penalties , hence we call the lifted proximal operator machine ( LPOM ). LPOM is block multi-convex in all layer-wise weight unit and activations. This allows us to use block coordinate descent to update the layer-wise weights and activations in latitude. Most notably , we only use the mapping of the activation function itself , rather than its derivatives , thus stave off the gradient vanishing or blow-up issues in gradient based training methods. So our method is applicable to various non-decreasing Lipschitz continuous activating functions , which can be saturating and non-differentiable. LPOM does not require more auxiliary variables than the layer-wise activations , thus using roughly the like amount of memory as stochastic gradient descent ( SGD ) does. We far prove the convergence of updating the layer-wise weights and activations. experiment on MNIST and CIFAR-10 datasets testify to the advantages of LPOM. ", "label": 1}
{"original_text": "CP-nets represent the dominant existing framework for expressing qualitative conditional preferences between alternatives, and are used in a variety of areas including constraint solving. Over the last fifteen years, a significant literature has developed exploring semantics, algorithms, implementation and use of CP-nets. This paper introduces a comprehensive new framework for conditional preferences: logical conditional preference theories (LCP theories). To express preferences, the user specifies arbitrary (constraint) Datalog programs over a binary ordering relation on outcomes. We show how LCP theories unify and generalize existing conditional preference proposals, and leverage the rich semantic, algorithmic and implementation frameworks of Datalog.", "text_perturb": "CP-nets constitute the dominant existing framework for expressing qualitative conditional preferences between alternatives , and are used in a variety of areas including constraint solving. Over the last fifteen years , a significant literature has developed research semantics , algorithms , implementation and use of CP-nets. This paper introduces a comprehensive new framework for conditional preferences : logical conditional taste theories ( LCP theories ). To express preferences , the user specifies arbitrary ( restraint ) Datalog programs over a binary ordering relation on outcomes. We show how LCP theories unify and generalize existing conditional penchant proposals , and leverage the rich semantic , algorithmic and implementation frameworks of Datalog. ", "label": 1}
{"original_text": "Quantum stabilizer codes (QSCs) suffer from a low quantum coding rate, since they have to recover the quantum bits (qubits) in the face of both bit-flip and phase-flip errors. In this treatise, we conceive a low-complexity concatenated quantum turbo code (QTC) design exhibiting a high quantum coding rate. The high quantum coding rate is achieved by combining the quantum-domain version of short-block codes (SBCs) also known as single parity check (SPC) codes as the outer codes and quantum unity-rate codes (QURCs) as the inner codes. Despite its design simplicity, the proposed QTC yields a near-hashing-bound error correction performance. For instance, compared to the best half-rate QTC known in the literature, namely the QIrCC-QURC scheme, which operates at the distance of D 0.037 from the quantum hashing bound, our novel QSBC-QURC scheme can operate at the distance of D 0.029. It is worth also mentioning that this is the first instantiation of QTCs capable of adjusting the quantum encoders according to the quantum coding rate required for mitigating the Pauli errors given the different depolarizing probabilities of the quantum channel.", "text_perturb": "Quantum stabilizer codes ( QSCs ) suffer from a low quantum coding rate , since they have to recover the quantum piece ( qubits ) in the face of both bit-flip and phase-flip errors. In this treatise , we conceive a low-complexity concatenated quantum turbo code ( QTC ) excogitation exhibiting a high quantum coding rate. The high quantum coding rate is achieved by combining the quantum-domain version of short-block codes ( SBCs ) as well known as single parity check ( SPC ) codes as the outer codes and quantum unity-rate codes ( QURCs ) as the inner codes. Despite its design simplicity , the proposed QTC yields a near-hashing-bound error correction carrying into action. For instance , compared to the best half-rate QTC known in the lit , namely the QIrCC-QURC scheme , which operates at the distance of D 0. 037 from the quantum hashing bound , our novel QSBC-QURC outline can operate at the distance of D 0. 029. It is deserving also mentioning that this is the first instantiation of QTCs capable of adjusting the quantum encoders according to the quantum coding rate required for mitigating the Pauli errors given the different depolarizing probabilities of the quantum channel. ", "label": 1}
{"original_text": "Automatic evaluation of language generation systems is a well-studied problem in Natural Language Processing. While novel metrics are proposed every year, a few popular metrics remain as the de facto metrics to evaluate tasks such as image captioning and machine translation, despite their known limitations. This is partly due to ease of use, and partly because researchers expect to see them and know how to interpret them. In this paper, we urge the community for more careful consideration of how they automatically evaluate their models by demonstrating important failure cases on multiple datasets, language pairs and tasks. Our experiments show that metrics (i) usually prefer system outputs to human-authored texts, (ii) can be insensitive to correct translations of rare words, (iii) can yield surprisingly high scores when given a single sentence as system output for the entire test set.", "text_perturb": "Automatic evaluation of language generation systems is a well-studied problem in natural Language Processing. While novel metrics are proposed every class , a few popular metrics remain as the de facto metrics to evaluate tasks such as image captioning and machine translation , despite their known limitations. This is partly due to ease of use , and partly because researcher expect to see them and know how to interpret them. In this paper , we urge the community for more careful consideration of how they automatically evaluate their models by demonstrating important failure cases on multiple datasets , language twosome and tasks. Our experiments show that metrics ( i ) usually prefer system outputs to human-authored texts , ( ii ) give the axe be insensitive to correct translations of rare words , ( iii ) give the axe yield surprisingly high scores when given a single sentence as system output for the entire test set. ", "label": 1}
{"original_text": "Distinction among nearby poses and among symmetries of an object is challenging. In this paper, we propose a unified, group-theoretic approach to tackle both. Different from existing works which directly predict absolute pose, our method measures the pose of an object relative to another pose, i.e., the pose difference. The proposed method generates the complete orbit of an object from a single view of the object with respect to the subgroup of S O (3) of rotations around the z -axis, and compares the orbit of the object with another orbit using a novel orbit metric to estimate the pose difference. The generated orbit in the latent space records all the differences in pose in the original observational space, and as a result, the method is capable of finding subtle differences in pose. We demonstrate the effectiveness of the proposed method on cars, where identifying the subtle pose differences is vital.", "text_perturb": "Distinction among nearby poses and among symmetries of an object represent challenging. In this paper , we propose a unified , group-theoretic approach to undertake both. Different from existing works which directly predict absolute affectation , our method measures the affectation of an object relative to another affectation , i. due east. , the pose difference of opinion. The proposed method generates the complete orbit of an object from a single view of the object with respect to the subgroup of S O ( 3 ) of rotations around the z -axis , and compares the orbit of the object with another orbit using a refreshing orbit metric to estimate the pose difference. The generated orbit in the latent space records all the differences in pose in the original observational space , and as a result , the method acting is capable of finding subtle differences in pose. We demo the effectiveness of the proposed method on cars , where identifying the subtle pose differences is vital. ", "label": 1}
{"original_text": "In processing human produced text using natural language processing (NLP) techniques, two fundamental subtasks that arise are (i) item (i) item Item items Items (i) item (i) segmentation of the plain text into meaningful subunits (e.g., entities), and (ii) item (ii) item Item items Items (ii) item (ii) dependency parsing, to establish relations between subunits. Such structural interpretation of text provides essential building blocks for upstream expert system tasks: e.g., from interpreting textual real estate ads, one may want to provide an accurate price estimate andor provide selection filters for end users looking for a particular property - which all could rely on knowing the types and number of rooms, etc. In this paper we develop a relatively simple and effective neural joint model that performs both segmentation and dependency parsing together, instead of one after the other as in most state-of-the-art works. We will focus in particular on the real estate ad setting, aiming to convert an ad to a structured description, which we name property tree, comprising the tasks of (1) item (1) item Item items Items (1) item (1) identifying important entities of a property (e.g., rooms) from classifieds and (2) item (2) item Item items Items (2) item (2) structuring them into a tree format. In this work, we propose a new joint model that is able to tackle the two tasks simultaneously and construct the property tree by (i) item (i) item Item items Items (i) item (i) avoiding the error propagation that would arise from the subtasks one after the other in a pipelined fashion, and (ii) item (ii) item Item items Items (ii) item (ii) exploiting the interactions between the subtasks. For this purpose, we perform an extensive comparative study of the pipeline methods and the new proposed joint model, reporting an improvement of over three percentage points in the overall edge F 1 score of the property tree. Also, we propose attention methods, to encourage our model to focus on salient tokens during the construction of the property tree. Thus we experimentally demonstrate the usefulness of attentive neural architectures for the proposed joint model, showcasing a further improvement of two percentage points in edge F 1 score for our application. While the results demonstrated are for the particular real estate setting, the model is generic in nature, and thus could be equally applied to other expert system scenarios requiring the general tasks of both (i) item (i) item Item items Items (i) item (i) detecting entities (segmentation) and (ii) item (ii) item Item items Items (ii) item (ii) establishing relations among them (dependency parsing).", "text_perturb": "In processing human produced text using natural language processing ( NLP ) techniques , two fundamental subtasks that arise are ( i ) item ( i ) item Item items Items ( i ) item ( i ) segmentation of the knit text into meaningful subunits ( e. deoxyguanosine monophosphate. , entities ) , and ( ii ) item ( ii ) item detail items Items ( ii ) item ( ii ) dependency parsing , to establish relations between subunits. Such structural interpretation of text provides essential building blocks for upstream expert system tasks : vitamin e. grand. , from interpreting textual real estate ads , one may want to provide an accurate price estimate andor provide selection filter for end users looking for a particular property - which all could rely on knowing the types and number of rooms , etc. In this paper we develop a relatively simple and effective nervous joint model that performs both segmentation and dependency parsing together , instead of one after the other as in most state-of-the-art works. We will focus in particular on the real estate ad setting , aiming to convert an ad to a structured description , which we name attribute tree , comprising the tasks of ( 1 ) item ( 1 ) item Item items Items ( 1 ) item ( 1 ) identifying important entities of a attribute ( e. gravitational constant. , rooms ) from classified ad and ( 2 ) item ( 2 ) item Item items Items ( 2 ) item ( 2 ) structuring them into a tree format. In this work , we propose a new joint model that is able to tackle the two tasks simultaneously and construct the property tree by (  ) item (  ) item Item items Items (  ) item (  ) avoiding the error propagation that would arise from the subtasks one after the other in a pipelined fashion , and ( ii ) item ( ii ) item Item items Items ( ii ) item ( ii ) exploiting the interactions between the subtasks. For this purpose , we perform an extensive comparative study of the pipeline methods and the new proposed joint model , reporting an improvement of over three percentage points in the overall boundary F 1 score of the property tree. Also , we propose attention methods , to encourage our model to focus on salient tokens during the building of the property tree. Thus we experimentally demonstrate the usefulness of attentive neural architectures for the purpose joint model , showcasing a further improvement of two percentage points in edge F 1 score for our application. While the results demonstrated are for the particular real estate setting , the model is generic in nature , and thus could be equally applied to other expert system scenarios requiring the general tasks of both ( i ) detail ( i ) detail Item items Items ( i ) detail ( i ) detecting entities ( segmentation ) and ( ii ) detail ( ii ) detail Item items Items ( ii ) detail ( ii ) establishing relations among them ( dependency parsing ). ", "label": 1}
{"original_text": "Skew polynomials, which have a noncommutative multiplication rule between coefficients and an indeterminate, are the most general polynomial concept that admits the degree function with desirable properties. This paper presents the first algorithms to compute the maximum degree of the Dieudonne determinant of a x k k submatrix in a matrix A whose entries are skew polynomials over a skew field F. Our algorithms make use of the discrete Legendre conjugacy between the sequences of the maximum degrees and the ranks of block matrices over F obtained from coefficient matrices of A. Three applications of our algorithms are provided: (i) computing the dimension of the solution spaces of linear differential and difference equations, (ii) determining the Smith-McMillan form of transfer function matrices of linear time-varying systems and (iii) solving the \"weighted\" version of noncommutative Edmonds' problem with polynomial bit complexity. We also show that the deg-det computation for matrices over sparse polynomials is at least as hard as solving commutative Edmonds' problem. Keywords: skew polynomials, Dieudonne determinant, matrix expansion, discrete Legendre conjugacy, differential equations, difference equations, Smith-McMillan form, Edmonds' problem", "text_perturb": "Skew multinomial , which have a noncommutative multiplication rule between coefficients and an indeterminate , are the most general polynomial concept that admits the degree function with desirable properties. This paper presents the first algorithms to compute the maximum degree of the Dieudonne determinant of a x honey oil honey oil submatrix in a matrix A whose entries are skew polynomials over a skew field F. Our algorithms make use of the discrete Legendre conjugacy between the sequences of the maximal degrees and the ranks of block matrices over F obtained from coefficient matrices of A. Three applications of our algorithms are provided : ( i ) computing the dimension of the solution spaces of linear differential and difference equations , ( ii ) determining the Smith-McMillan form of transfer single valued function matrices of linear time-varying systems and ( iii ) solving the `` weighted '' version of noncommutative Edmonds ' problem with polynomial bit complexity. We also show that the deg-det computation for matrices over sparse polynomials is at least as hard as solving commutative Edmonds ' trouble. Keywords : skew polynomials , Dieudonne determinant , matrix expansion , discrete Legendre conjugacy , differential par , difference par , Smith-McMillan form , Edmonds ' problem", "label": 1}
{"original_text": "The aim of this study is to find key areas of research that can be useful to fight against disinformation on Wikipedia. To address this problem we perform a literature review trying to answer three main questions: (i) What is disinformation? (ii) What are the most popular mechanisms to spread online disinformation? and (iii) Which are the mechanisms that are currently being used to fight against disinformation?. In all these three questions we take first a general approach, considering studies from different areas such as journalism and communications, sociology, philosophy, information and political sciences. And comparing those studies with the current situation on the Wikipedia ecosystem. We found that disinformation can be defined as non-accidentally misleading information that is likely to create false beliefs. While the exact definition of misinformation varies across different authors, they tend to agree that disinformation is different from other types of misinformation, because it requires the intention of deceiving the receiver. A more actionable way to scope disinformation is to define it as a problem of information quality. In Wikipedia quality of information is mainly controlled by the policies of neutral point of view and verifiability. The mechanisms used to spread online disinformation include the coordinated action of online brigades, the usage of bots, and other techniques to create fake content. Underresouced topics and communities are especially vulnerable to such attacks. The usage of sock-puppets is one of the most important problems for Wikipedia. The techniques used to fight against information on the internet, include manual fact checking done by agencies and communities, as well as automatic techniques to assess the quality and credibility of a given information. Machine learning approaches can be fully automatic or can be used as tools by human fact checkers. Wikipedia and especially Wikidata play double role here, because they are used by automatic methods as ground-truth to determine the credibility of an information, and at the same time (and for that reason) they are the target of many attacks. Currently, the main defense of Wikimedia projects against fake news is the work done by community members and especially by patrollers, that use mixed techniques to detect and control disinformation campaigns on Wikipedia. We conclude that in order to keep Wikipedia as free as possible from disinformation, it's necessary to help patrollers to early detect disinformation and assess the credibility of external sources. More research is needed to develop tools that use state-of-the-art machine learning techniques to detect potentially dangerous content, empowering patrollers to deal with attacks that are becoming more complex and sophisticated.", "text_perturb": "The aim of this study is to find key areas of research that give notice be useful to fight against disinformation on Wikipedia. To address this problem we perform a literature review trying to answer three main questions : ( i ) What is disinformation ? ( ii ) What are the most popular mechanisms to spread online disinformation ? and ( iii ) Which are the mechanisms that are currently being used to defend against disinformation ?. In all these three questions we take first a general approach , considering studies from different areas such as news media and communications , sociology , philosophy , information and political sciences. And equate those studies with the current situation on the Wikipedia ecosystem. We found that disinformation send away be defined as non-accidentally misleading information that is likely to create false beliefs. While the exact definition of misinformation varies across different authors , they tend to agree that disinformation is different from other eccentric of misinformation , because it requires the intention of deceiving the receiver. A more actionable way to scope disinformation is to define it as a trouble of information quality. In Wikipedia quality of information is mainly controlled by the policy of neutral point of view and verifiability. The mechanics used to spread online disinformation include the coordinated action of online brigades , the usage of bots , and other techniques to create fake content. Underresouced topics and communities are especially vulnerable to such fire. The usage of sock-puppets is one of the nigh important problems for Wikipedia. The techniques used to fight against information on the internet , include manual fact watch done by agencies and communities , as well as automatic techniques to assess the quality and credibility of a given information. Machine learning approaches can be fully automatic or can be used as tools by human fact checker. Wikipedia and especially Wikidata play double role here , because they are used by automatic methods as ground-truth to determine the credibility of an information , and at the same time ( and for that intellect ) they are the target of many attacks. Currently , the main defense of Wikimedia projects against fake news is the work done by residential area members and especially by patrollers , that use mixed techniques to detect and control disinformation campaigns on Wikipedia. We conclude that in order to keep Wikipedia as free as possible from disinformation , it 's necessary to avail patrollers to early detect disinformation and assess the credibility of external sources. More research is needed to develop tools that use state-of-the-art machine learning techniques to detect potentially dangerous content , empowering patrollers to deal with attacks that are go more complex and sophisticated. ", "label": 1}
{"original_text": "Rank position forecasting in car racing is a challenging problem, which is featured with highly complex global dependency among the cars, with uncertainty resulted from existing exogenous factors, and as a sparse data problem. Existing methods, including statistical models, machine learning regression models, and several state-of-the-art deep forecasting models all perform not well on this problem. By elaborative analysis of pit stops events, we find it is critical to decompose the cause effects and model them, the rank position and pit stop events, separately. In the choice of sub-model from different deep models, we find the model with weak assumptions on the global dependency structure performs the best. Based on these observations, we propose RankNet, a combination of encoder-decoder network and separate MLP network that capable of delivering probabilistic forecasting to model the pit stop events and rank position in car racing. Further with the help of feature optimizations, RankNet demonstrates a significant performance improvement over the baselines, e.g., MAE improves more than 10 consistently, and is also more stable when adapting to unseen new data. Details of model optimization, performance profiling are presented. It is promising to provide useful forecasting tools for the car racing analysis and shine a light on solutions to similar challenging issues in general forecasting problems.", "text_perturb": "Rank position forecasting in car racing is a challenging problem , which is featured with highly complex global dependence among the cars , with uncertainty resulted from existing exogenous factors , and as a sparse data problem. Existing methods , including statistical models , machine learning regression models , and several state-of-the-art deep forecasting models all execute not well on this problem. By elaborative analysis of pit stops events , we find it is critical to decompose the cause effect and model them , the rank position and pit stop events , separately. In the choice of sub-model from different deep models , we find the model with weak assumption of mary on the global dependency structure performs the best. Based on these observation , we propose RankNet , a combination of encoder-decoder network and separate MLP network that capable of delivering probabilistic forecasting to model the pit stop events and rank position in car racing. Further with the help of feature optimizations , RankNet demonstrates a significant execution improvement over the baselines , e. thou. , MAE improves more than 10 consistently , and is also to a greater extent stable when adapting to unseen new data. Details of mannequin optimization , performance profiling are presented. It is promising to provide useful forecasting tools for the cable car racing analysis and shine a light on solutions to similar challenging issues in general forecasting problems. ", "label": 1}
{"original_text": "From video streaming to security and surveillance applications, video data play an important role in our daily living today. However, managing a large amount of video data and retrieving the most useful information for the user remain a challenging task. In this paper, we propose a novel video classification system that would benefit the scene understanding task. We define our classification problem as classifying background and foreground motions using the same feature representation for outdoor scenes. This means that the feature representation needs to be robust enough and adaptable to different classification tasks. We propose a lightweight Loss Switching Fusion Network (LSFNet) for the fusion of spatiotemporal descriptors and a similarity search scheme with soft voting to boost the classification performance. The proposed system has a variety of potential applications such as content-based video clustering, video filtering, etc. Evaluation results on two private industry datasets show that our system is robust in both classifying different background motions and detecting human motions from these background motions.", "text_perturb": "From video recording streaming to security and surveillance applications , video recording data play an important role in our daily living today. still , managing a large amount of video data and retrieving the most useful information for the user remain a challenging task. In this paper , we propose a novel video classification system that would benefit the vista understanding task. We define our classification problem as classifying background and foreground motions utilise the same feature representation for outdoor scenes. This mean that the feature representation needs to be robust enough and adaptable to different classification tasks. We propose a lightweight Loss Switching Fusion Network ( LSFNet ) for the fusion of spatiotemporal descriptors and a similarity search scheme with soft balloting to boost the classification performance. The proposed arrangement has a variety of potential applications such as content-based video clustering , video filtering , etc. Evaluation results on two private industry datasets show that our system is robust in both classifying different background apparent movement and detecting human apparent movement from these background apparent movement. ", "label": 1}
{"original_text": "Software requirement analysis can certainly benefit from prevention and early detection of failures, in particular by some kind of automatic analysis. Formal methods offer means to represent and analyze requirements with rigorous tools, avoiding ambiguities and allowing automatic verification of requirement consistency. However, formalisms often clash in the culture or lack of skills of software analysts, making them challenging to apply. In this article, we propose a Domain-Specific Language (DSL) based on Set Theory for requirement analysts. The Graphical InvaRiant Language (GIRL) can be used to specify software requirement structural invariants, with entities and their relationships. Those invariants can then have their consistency evaluated by the Alloy Analyzer, based on a mapping semantics we provide for transforming GIRL models into Alloy specifications with no user intervention. With a prototypical language editor and transformations implemented into an Eclipse plugin, we carried out a qualitative study with requirement analysts working for a government software company in Brazil, to evaluate usability and effectiveness of the GIRL-based analysis of real software requirements. The participants were able to effectively use the underlying formal analysis, since 79 out of 80 assigned invariants were correctly modeled. While participants perceived as low the complexity of learning and using GIRL's simplest, set-based structures and relationships, the most complex logical structures, such as quantification and implication, were challenging. Furthermore, almost all post-study evaluations from the participants were positive, especially as a tool for discovering requirement inconsistencies.", "text_perturb": "Software requirement analysis can certainly benefit from prevention and early detection of failures , in finical by some kind of automatic analysis. Formal methods offer means to represent and take apart requirements with rigorous tools , avoiding ambiguities and allowing automatic verification of requirement consistency. However , formalisms often clash in the culture or lack of skills of software package analysts , making them challenging to apply. In this article , we propose a Domain-Specific Language ( DSL ) base on Set Theory for requirement analysts. The Graphical InvaRiant spoken communication ( GIRL ) can be used to specify software requirement structural invariants , with entities and their relationships. Those invariants can then have their consistency evaluated by the Alloy Analyzer , based on a mapping semantics we provide for transforming GIRL models into Alloy stipulation with no user intervention. With a prototypical language editor and transformations implemented into an Eclipse plugin , we carried out a qualitative study with requirement analysts working for a government software company in brasil , to evaluate usability and effectiveness of the GIRL-based analysis of real software requirements. The participants were able to effectively use the underlying formal analytic thinking , since 79 out of 80 assigned invariants were correctly modeled. While participants perceived as low the complexity of learning and practice GIRL 's simplest , set-based structures and relationships , the most complex logical structures , such as quantification and implication , were challenging. Furthermore , almost all post-study evaluations from the participants were positive , especially as a tool for discovering necessary inconsistencies. ", "label": 1}
{"original_text": "We investigate the following problem: Given two embeddings G 1 and G 2 of the same abstract graph G on an orientable surface S, decide whether G 1 and G 2 are isotopic; in other words, whether there exists a continuous family of embeddings between G 1 and G 2. We provide efficient algorithms to solve this problem in two models. In the first model, the input consists of the arrangement of G 1 (resp., G 2) with a fixed graph cellularly embedded on S; our algorithm is linear in the input complexity, and thus, optimal. In the second model, G 1 and G 2 are piecewise-linear embeddings in the plane minus a finite set of points; our algorithm runs in O (n 3 2 log n) time, where n is the complexity of the input. The graph isotopy problem is a natural variation of the homotopy problem for closed curves on surfaces and on the punctured plane, for which algorithms have been given by various authors; we use some of these algorithms as a subroutine. As a by-product, we reprove the following mathematical characterization, first observed by Ladegaillerie (1984): Two graph embeddings are isotopic if and only if they are homotopic and congruent by an oriented homeomorphism.", "text_perturb": "We investigate the following problem : Given two embeddings G 1 and G 2 of the same abstract graphical record G on an orientable surface S , decide whether G 1 and G 2 are isotopic ; in other words , whether there exists a continuous family of embeddings between G 1 and G 2. We provide efficient algorithms to solve this job in two models. In the first simulation , the input consists of the arrangement of G 1 ( resp. , G 2 ) with a fixed graph cellularly embedded on S ; our algorithm is linear in the input complexity , and thus , optimum. In the second model , G 1 and G 2 are piecewise-linear embeddings in the plane minus a finite set of percentage point ; our algorithm runs in O ( n 3 2 log n ) time , where n is the complexity of the input. The graph isotopy problem equal a natural variation of the homotopy problem for closed curves on surfaces and on the punctured plane , for which algorithms have been given by various authors ; we use some of these algorithms as a subroutine. As a by-product , we reprove the following mathematical characterization , first observed by Ladegaillerie ( 1984 ) : Two graphical record embeddings are isotopic if and only if they are homotopic and congruent by an oriented homeomorphism. ", "label": 1}
{"original_text": "In this paper, we address unsupervised pose-guided person image generation, which is known challenging due to non-rigid deformation. Unlike previous methods learning a rock-hard direct mapping between human bodies, we propose a new pathway to decompose the hard mapping into two more accessible subtasks, namely, semantic parsing transformation and appearance generation. Firstly, a semantic generative network is proposed to transform between semantic parsing maps, in order to simplify the non-rigid deformation learning. Secondly, an appearance generative network learns to synthesize semantic-aware textures. Thirdly, we demonstrate that training our framework in an end-to-end manner further refines the semantic maps and final results accordingly. Our method is generalizable to other semantic-aware person image generation tasks, eg, clothing texture transfer and controlled image manipulation. Experimental results demonstrate the superiority of our method on DeepFashion and Market-1501 datasets, especially in keeping the clothing attributes and better body shapes.", "text_perturb": "In this paper , we handle unsupervised pose-guided person image generation , which is known challenging due to non-rigid deformation. Unlike previous methods larn a rock-hard direct mapping between human bodies , we propose a new pathway to decompose the hard mapping into two more accessible subtasks , namely , semantic parsing transformation and appearance generation. Firstly , a semantic generative network is proposed to translate between semantic parsing maps , in order to simplify the non-rigid deformation learning. Secondly , an appearance generative network learns to synthesise semantic-aware textures. Thirdly , we show that training our framework in an end-to-end manner further refines the semantic maps and final results accordingly. Our method acting is generalizable to other semantic-aware person image generation tasks , eg , clothing texture transfer and controlled image manipulation. observational results demonstrate the superiority of our method on DeepFashion and Market-1501 datasets , especially in keeping the clothing attributes and better body shapes. ", "label": 1}
{"original_text": "This paper deals with a complete bipartite matching problem with the objective of finding an optimal matching that maximizes a certain generic predefined utility function on the set of all matchings. After proving the NP-hardness of the problem using reduction from the 3-SAT problem, we propose a randomized algorithm based on Markov Chain Monte Carlo (MCMC) technique for solving this. We sample from Gibb's distribution and construct a reversible positive recurrent discrete time Markov chain (DTMC) that has the steady state distribution same as the Gibb's distribution. In one of our key contributions, we show that the constructed chain is 'rapid mixing', i.e. the convergence time to reach within a specified distance to the desired distribution is polynomial in the problem size. The rapid mixing property is established by obtaining a lower bound on the conductance of the DTMC graph and this result is of independent interest.", "text_perturb": "This paper deals with a complete bipartite matching problem with the objective of finding an optimal matching that maximise a certain generic predefined utility function on the set of all matchings. After proving the NP-hardness of the problem using reduction from the 3-SAT problem , we propose a randomized algorithm based on Markov Chain four card monte Carlo ( MCMC ) technique for solving this. We sample from Gibb 's distribution and concept a reversible positive recurrent discrete time Markov chain ( DTMC ) that has the steady state distribution same as the Gibb 's distribution. In one of our key contributions , we show that the constructed chain constitute 'rapid mixing ' , i. eastward. the convergence fourth dimension to reach within a specified distance to the desired distribution is polynomial in the problem size. The rapid mixing place is established by obtaining a lower bound on the conductance of the DTMC graph and this result is of independent interest. ", "label": 1}
{"original_text": "We propose a compressive sensing algorithm that exploits geometric properties of images to recover images of high quality from few measurements. The image reconstruction is done by iterating the two following steps: 1) estimation of normal vectors of the image level curves and 2) reconstruction of an image fitting the normal vectors, the compressed sensing measurements and the sparsity constraint. The proposed technique can naturally extend to non local operators and graphs to exploit the repetitive nature of textured images in order to recover fine detail structures. In both cases, the problem is reduced to a series of convex minimization problems that can be efficiently solved with a combination of variable splitting and augmented Lagrangian methods, leading to fast and easy-to-code algorithms. Extended experiments show a clear improvement over related state-of-the-art algorithms in the quality of the reconstructed images and the robustness of the proposed method to noise, different kind of images and reduced measurements.", "text_perturb": "We propose a compressive sensing algorithm that exploits geometric properties of images to recover images of high quality from few measurement. The trope reconstruction is done by iterating the two following steps : 1 ) estimation of normal vectors of the trope level curves and 2 ) reconstruction of an trope fitting the normal vectors , the compressed sensing measurements and the sparsity constraint. The proposed technique can naturally extend to non local operators and graphs to exploit the repetitive nature of coarse textured images in order to recover fine detail structures. In both cases , the problem is reduced to a series of convex minimization problems that can be efficiently solved with a combination of varying splitting and augmented Lagrangian methods , leading to fast and easy-to-code algorithms. Extended experiments show a clear improvement over related to state-of-the-art algorithms in the quality of the reconstructed images and the robustness of the proposed method to noise , different kind of images and reduced measurements. ", "label": 1}
{"original_text": "In this work we explore the method of style transfer presented in. We first demonstrate the power of the suggested style space on a few examples. We then vary different hyper-parameters and program properties that were not discussed in, among which are the recognition network used, starting point of the gradient descent and different ways to partition style and content layers. We also give a brief comparison of some of the existing algorithm implementations and deep learning frameworks used. To study the style space further, an idea similar to is used to generate synthetic images by maximizing a single entry in one of the Gram matrices G l and some interesting results are observed. Next, we try to mimic the sparsity and intensity distribution of Gram matrices obtained from a real painting and generate more complex textures. Finally, we propose two new style representations built on top of network's features and discuss how one could be used to achieve local and potentially content-aware style transfer.", "text_perturb": "In this body of work we explore the method of style transfer presented in. We first show the power of the suggested style space on a few examples. We then vary different hyper-parameters and program properties that were not discussed in , among which are the recognition network used , starting detail of the gradient descent and different ways to partition style and content layers. We also give a brief comparison of some of the existing algorithm implementations and deep learning fabric used. To study the style space further , an idea similar to is used to generate synthetic images by maximizing a single entry in one of the Gram matrices G l and some interesting outcome are observed. Next , we judge to mimic the sparsity and intensity distribution of Gram matrices obtained from a real painting and generate more complex textures. at last , we propose two new style representations built on top of network 's features and discuss how one could be used to achieve local and potentially content-aware style transfer. ", "label": 1}
{"original_text": "Last-mile logistics is regarded as an essential yet highly expensive component of parcel logistics. In dense urban environments, this is partially caused by inherent inefficiencies due to traffic congestion and the disparity and accessibility of customer locations. In parcel logistics, access hubs are facilities supporting relay-based last-mile activities by offering temporary storage locations enabling the decoupling of last-mile activities from the rest of the urban distribution chain. This paper focuses on a novel tactical problem: the geographically dynamic deployment of pooled relocatable storage capacity modules in an urban parcel network operating under space-time uncertainty. In particular, it proposes a two-stage stochastic optimization model for the access hub dynamic pooled capacity deployment problem with synchronization of underlying operations through travel time estimates, and a solution approach based on a rolling horizon algorithm with lookahead and a benders decomposition able to solve large scale instances of a real-sized megacity. Numerical results, inspired by the case of a large parcel express carrier, are provided to evaluate the computational performance of the proposed approach and suggest up to 28 last-mile cost savings and 26 capacity savings compared to a static capacity deployment strategy. Keywords - Parcel Logistics, Urban Networks, Dynamic Deployment, Capacity Relocation, Capacity Pooling, Stochastic Optimization, Physical Internet", "text_perturb": "Last-mile logistics is regarded as an essential yet highly expensive ingredient of parcel logistics. In dense urban environments , this is partially caused by inherent inefficiency due to traffic congestion and the disparity and accessibility of customer locations. In parcel logistics , access hubs cost facilities supporting relay-based last-mile activities by offering temporary storage locations enabling the decoupling of last-mile activities from the rest of the urban distribution chain. This paper focuses on a novel tactical problem : the geographically dynamical deployment of pooled relocatable storage capacity modules in an urban parcel network operating under space-time uncertainty. In particular , it proposes a two-stage stochastic optimization model for the access hub dynamic pooled capacity deployment problem with synchronization of underlying operations through travel time estimate , and a solution approach based on a rolling horizon algorithm with lookahead and a benders decomposition able to solve large scale instances of a real-sized megacity. Numerical results , inspired by the case of a large parcel limited carrier , are provided to evaluate the computational performance of the proposed approach and suggest up to 28 last-mile cost savings and 26 capacity savings compared to a static capacity deployment strategy. Keywords - Parcel Logistics , Urban Networks , Dynamic deployment , Capacity Relocation , Capacity Pooling , Stochastic Optimization , Physical Internet", "label": 1}
{"original_text": "We consider delay differential algebraic equations (DDAEs) to model interconnected systems with time-delays. The DDAE framework does not require any elimination techniques and can directly deal with any interconnection of systems and controllers with time-delays. In this framework, we analyze the properties of the H norm of systems described by delay differential algebraic equations. We show that the standard H norm may be sensitive to arbitrarily small delay perturbations. We introduce the strong H norm which is insensitive to small delay perturbations and describe its properties. We conclude that the strong H norm is more appropriate in any practical control application compared to the standard H norm for systems with time-delays whenever there are high-frequency paths in control loops.", "text_perturb": "We consider delay differential algebraic equations ( DDAEs ) to mould interconnected systems with time-delays. The DDAE framework does not require any elimination techniques and can directly cover with any interconnection of systems and controllers with time-delays. In this fabric , we analyze the properties of the H norm of systems described by delay differential algebraic equations. We point that the standard H norm may be sensitive to arbitrarily small delay perturbations. We introduce the strong H norm which is insensitive to small delay perturbations and describe its attribute. We conclude that the strong H norm is more appropriate in any practical control application compared to the standard H norm for organisation with time-delays whenever there are high-frequency paths in control loops. ", "label": 1}
{"original_text": "Achieving transparency in black-box deep learning algorithms is still an open challenge. High dimensional features and decisions given by deep neural networks (NN) require new algorithms and methods to expose its mechanisms. Current state-of-the-art NN interpretation methods (e.g. Saliency maps, DeepLIFT, LIME, etc.) focus more on the direct relationship between NN outputs and inputs rather than the NN structure and operations itself. In current deep NN operations, there is uncertainty over the exact role played by neurons with fixed activation functions. In this paper, we achieve partially explainable learning model by symbolically explaining the role of activation functions (AF) under a scalable topology. This is carried out by modelling the AFs as adaptive Gaussian Processes (GP), which sit within a novel scalable NN topology, based on the Kolmogorov-Arnold Superposition Theorem (KST). In this scalable NN architecture, the AFs are generated by GP interpolation between control points and can thus be tuned during the back-propagation procedure via gradient descent. The control points act as the core enabler to both local and global adjustability of AF, where the GP interpolation constrains the intrinsic autocorrelation to avoid over-fitting. We show that there exists a trade-off between the NN's expressive power and interpretation complexity, under linear KST topology scaling. To demonstrate this, we perform a case study on a binary classification dataset of banknote authentication. Our model converge at better precision rate than state-of-the-art SVM algorithms which indicates that we do not make performance sacrifices in our approach. Meanwhile, by quantitatively and qualitatively investigating the mapping relationship between inputs and output, our explainable model can provide interpretation over each of the one-dimensional attributes. These early results suggest that our model has the potential to act as the final interpretation layer for deep neural networks.", "text_perturb": "achieve transparency in black-box deep learning algorithms is still an open challenge. High dimensional features and decisions given by deep neural networks ( NN ) require new algorithms and methods to display its mechanisms. Current state-of-the-art NN interpretation method ( e. gibibyte. Saliency maps , DeepLIFT , LIME , etc. ) focus more on the direct relationship between NN yield and inputs rather than the NN structure and operations itself. In current deep NN surgery , there is uncertainty over the exact role played by neurons with fixed activation functions. In this paper , we achieve partially explainable learning mannequin by symbolically explaining the role of activation functions ( AF ) under a scalable topology. This is carried out by modelling the AFs as adaptive Gaussian Processes ( GP ) , which sit within a novel scalable NN topology , found on the Kolmogorov-Arnold Superposition Theorem ( KST ). In this scalable NN architecture , the AFs are generated by GP interpolation between control points and can thus be tuned during the back-propagation procedure via slope descent. The mastery points act as the core enabler to both local and global adjustability of AF , where the GP interpolation constrains the intrinsic autocorrelation to avoid over-fitting. We show that there exists a tradeoff between the NN 's expressive power and interpretation complexity , under linear KST topology scaling. To manifest this , we perform a case study on a binary classification dataset of banknote authentication. Our model converge at better precision rate than state-of-the-art SVM algorithms which indicates that we do non make performance sacrifices in our approach. Meanwhile , by quantitatively and qualitatively investigating the mapping relationship between inputs and output , our explainable mannequin can provide interpretation over each of the one-dimensional attributes. These early results suggest that our model has the potential to act as the final interpreting layer for deep neural networks. ", "label": 1}
{"original_text": "We develop a general framework for proving rigorous guarantees on the performance of the EM algorithm and a variant known as gradient EM. Our analysis is divided into two parts: a treatment of these algorithms at the population level (in the limit of infinite data), followed by results that apply to updates based on a finite set of samples. First, we characterize the domain of attraction of any global maximizer of the population likelihood. This characterization is based on a novel view of the EM updates as a perturbed form of likelihood ascent, or in parallel, of the gradient EM updates as a perturbed form of standard gradient ascent. Leveraging this characterization, we then provide non-asymptotic guarantees on the EM and gradient EM algorithms when applied to a finite set of samples. We develop consequences of our general theory for three canonical examples of incomplete-data problems: mixture of Gaussians, mixture of regressions, and linear regression with covariates missing completely at random. In each case, our theory guarantees that with a suitable initialization, a relatively small number of EM (or gradient EM) steps will yield (with high probability) an estimate that is within statistical error of the MLE. We provide simulations to confirm this theoretically predicted behavior.", "text_perturb": "We develop a general model for proving rigorous guarantees on the performance of the EM algorithm and a variant known as gradient EM. Our analysis is divided into two parts : a treatment of these algorithms at the population level ( in the limit of infinite data ) , followed by results that apply to update based on a finite set of samples. First , we characterize the domain of attraction of any global maximizer of the population likeliness. This word picture is based on a novel view of the EM updates as a perturbed form of likelihood ascent , or in parallel , of the gradient EM updates as a perturbed form of standard gradient ascent. Leveraging this characterization , we then provide non-asymptotic guarantees on the EM and gradient EM algorithms when applied to a finite set of sampling. We develop consequences of our general theory for three basic examples of incomplete-data problems : mixture of Gaussians , mixture of regressions , and linear regression with covariates missing completely at random. In each case , our theory guarantees that with a suitable initialization , a relatively small number of EM ( or gradient EM ) steps will yield ( with high probability ) an estimate that follow within statistical error of the MLE. We provide simulations to confirm this theoretically predicted behavior. ", "label": 1}
{"original_text": "We consider data transmission over a network where each edge is an erasure channel and where the inner nodes transmit a random linear combination of their incoming information. We distinguish two channel models in this setting, the row and the column erasure channel model. For both models we derive the symbol erasure correction capabilities of spread codes and compare them to other known codes suitable for those models. Furthermore, we explain how to decode these codes in the two channel models and compare their decoding complexities. The results show that, depending on the application and the to-be-optimized aspect, any combination of codes and channel models can be the best choice.", "text_perturb": "We consider data transmission over a network where each edge is an erasure channel and where the inner nodes transmit a random analogue combination of their incoming information. We distinguish two channel models in this setting , the row and the column expunction channel model. For both models we come the symbol erasure correction capabilities of spread codes and compare them to other known codes suitable for those models. Furthermore , we explain how to decode these codes in the two channel model and compare their decoding complexities. The results show that , depending on the application and the to-be-optimized aspect , any combination of codes and duct models can be the best choice. ", "label": 1}
{"original_text": "Human-robot interactions (HRI) can be modeled as dynamic or differential games with incomplete information, where each agent holds private reward parameters. Due to the open challenge in finding perfect Bayesian equilibria of such games, existing studies often consider approximated solutions composed of parameter estimation and motion planning steps, in order to decouple the belief and physical dynamics. In parameter estimation, current approaches often assume that the reward parameters of the robot are known by the humans. We argue that by falsely conditioning on this assumption, the robot performs non-empathetic estimation of the humans' parameters, leading to undesirable values even in the simplest interactions. We test this argument by studying a two-vehicle uncontrolled intersection case with short reaction time. Results show that when both agents are unknowingly aggressive (or non-aggressive), empathy leads to more effective parameter estimation and higher reward values, suggesting that empathy is necessary when the true parameters of agents mismatch with their common belief. The proposed estimation and planning algorithms are therefore more robust than the existing approaches, by fully acknowledging the nature of information asymmetry in HRI. Lastly, we introduce value approximation techniques for real-time execution of the proposed algorithms.", "text_perturb": "Human-robot interactions ( HRI ) can be modeled as dynamic or differential games with incomplete information , where each agent arrest private reward parameters. Due to the open challenge in finding perfect Bayesian equilibria of such games , existing studies often consider approximated solutions composed of parametric quantity estimation and motion planning steps , in order to decouple the belief and physical dynamics. In parameter estimation , current approaches often assume that the reward parameters of the robot are known by the homo. We argue that by falsely conditioning on this assumption , the robot performs non-empathetic estimation of the humans ' parameters , leading to undesirable values yet in the simplest interactions. We test this argument by studying a two-vehicle uncontrolled intersection pillow slip with short reaction time. Results show that when both agents are unknowingly aggressive ( or non-aggressive ) , empathy leads to more effective parameter estimation and higher reward values , suggesting that empathy is necessary when the true parameters of agents mismatch with their usual belief. The proposed estimation and planning algorithms make up therefore more robust than the existing approaches , by fully acknowledging the nature of information asymmetry in HRI. Lastly , we introduce value approximation techniques for real-time execution of the nominate algorithms. ", "label": 1}
{"original_text": "This work presents a novel method to generate secret keys shared between a legitimate node pair (Alice and Bob) to safeguard the communication between them from an unauthorized node (Eve). To this end, we exploit the reciprocal carrier frequency offset (CFO) between the legitimate node pair to extract common randomness out of it to generate shared secret keys. The proposed key generation algorithm involves standard steps: the legitimate nodes exchange binary phase-shift keying (BPSK) signals to perform blind CFO estimation on the received signals, and do equi-probable quantization of the noisy CFO estimates followed by information reconciliation-to distil a shared secret key. Furthermore, guided by the Allan deviation curve, we distinguish between the two frequency-stability regimes - when the randomly time-varying CFO process i) has memory, ii) is memoryless; thereafter, we compute the key generation rate for both regimes. Simulation results show that the key disagreement rate decreases exponentially with increase in the signal to noise ratio of the link between Alice and Bob. Additionally, the decipher probability of Eve decreases as soon as either of the two links observed by the Eve becomes more degraded compared to the link between Alice and Bob.", "text_perturb": "This work presents a novel method to generate secret keys shared between a legitimate node pair ( Alice and bobber ) to safeguard the communication between them from an unauthorized node ( Eve ). To this end , we exploit the mutual carrier frequency offset ( CFO ) between the legitimate node pair to extract common randomness out of it to generate shared secret keys. The proposed key generation algorithm involves standard steps : the legitimate nodes exchange binary phase-shift keying ( BPSK ) signals to perform blind CFO estimation on the received signals , and do equi-probable quantization of the noisy CFO estimates followed by information reconciliation-to distil a shared closed book key. Furthermore , guided by the Allan deviation curve , we distinguish between the two frequency-stability regimes - when the randomly time-varying cfo process i ) has memory , ii ) is memoryless ; thereafter , we compute the key generation rate for both regimes. Simulation results show that the key disagreement rate decreases exponentially with increase in the signal to noise ratio of the link between Alice and british shilling. Additionally , the decipher probability of Eve decreases equally soon as either of the two links observed by the Eve becomes more degraded compared to the link between Alice and Bob. ", "label": 1}
{"original_text": "The feasibility pump algorithm is an efficient primal heuristic for finding feasible solutions to mixed-integer programming problems. The algorithm suffers mainly from fast convergence to local optima. In this paper, we investigate the effect of an alternative approach to circumvent this challenge by designing a two-stage approach that embeds the feasibility pump heuristic into an annealing framework. The algorithm dynamically breaks the discrete decision variables into two subsets based on the fractionality information obtained from prior runs, and enforces integrality on each subset separately. The feasibility pump algorithm iterates between rounding a fractional solution to one that is integral and projecting an infeasible integral solution onto the solution space of the relaxed mixed-integer programming problem. These two components are used in a Monte Carlo search framework to initially promote diversification and focus on intensification later. The computational results obtained from solving 91 mixed-binary problems demonstrate the superiority of our new approach over Feasibility Pump 2.0.", "text_perturb": "The feasibility pump algorithm is an efficient primal heuristic rule for finding feasible solutions to mixed-integer programming problems. The algorithm suffers mainly from libertine convergence to local optima. In this paper , we investigate the effect of an alternative approach to put off this challenge by designing a two-stage approach that embeds the feasibility pump heuristic into an annealing framework. The algorithm dynamically burst the discrete decision variables into two subsets based on the fractionality information obtained from prior runs , and enforces integrality on each subset separately. The feasibility pump algorithm iterates between snipe a fractional solution to one that is integral and projecting an infeasible integral solution onto the solution space of the relaxed mixed-integer programming problem. These two components are used in a Monte Carlo search framework to initially promote variegation and focus on intensification later. The computational results prevail from solving 91 mixed-binary problems demonstrate the superiority of our new approach over Feasibility Pump 2. 0. ", "label": 1}
{"original_text": "New cryptographic techniques such as homomorphic encryption (HE) allow computations to be outsourced to and evaluated blindfolded in a resourceful cloud. These computations often require private data owned by multiple participants, engaging in joint evaluation of some functions. For example, Genome-Wide Association Study (GWAS) is becoming feasible because of recent proliferation of genome sequencing technology. Due to the sensitivity of genomic data, these data should be encrypted using different keys. However, supporting computation on ciphertexts encrypted under multiple keys is a non-trivial task. In this paper, we present a comprehensive survey on different state-of-the-art cryptographic techniques and schemes that are commonly used. We review techniques and schemes including Attribute-Based Encryption (ABE), Proxy Re-Encryption (PRE), Threshold Homomorphic Encryption (ThHE), and Multi-Key Homomorphic Encryption (MKHE). We analyze them based on different system and security models, and examine their complexities. We share lessons learned and draw observations for designing better schemes with reduced overheads.", "text_perturb": "New cryptographic techniques such as homomorphic encryption ( HE ) allow computations to be outsource to and evaluated blindfolded in a resourceful cloud. These reckoning often require private data owned by multiple participants , engaging in joint evaluation of some functions. For example , Genome-Wide connection Study ( GWAS ) is becoming feasible because of recent proliferation of genome sequencing technology. Due to the sensitivity of genomic data , these data should be encrypted expend different keys. However , supporting computation on ciphertexts encrypted under multiple keys is a non-trivial project. In this paper , we present a comprehensive survey on different state of the art cryptographic techniques and schemes that are commonly used. We review technique and schemes including Attribute-Based Encryption ( ABE ) , Proxy Re-Encryption ( PRE ) , Threshold Homomorphic Encryption ( ThHE ) , and Multi-Key Homomorphic Encryption ( MKHE ). We analyze them based on different system and security mannequin , and examine their complexities. We share lessons discover and draw observations for designing better schemes with reduced overheads. ", "label": 1}
{"original_text": "Physical unclonable functions (PUF) extract secrets from randomness inherent in manufacturing processes. PUFs are utilized for basic cryptographic tasks such as authentication and key generation, and more recently, to realize key exchange and bit commitment requiring a large number of error free responses from a strong PUF. We propose an approach to eliminate the need to implement expensive on-chip error correction logic implementation and the associated helper data storage to reconcile naturally noisy PUF responses. In particular, we exploit a statistical model of an Arbiter PUF (APUF) constructed under the nominal operating condition during the challenge response enrollment phase by a trusted party to judiciously select challenges that yield error-free responses even across a wide operating conditions, specifically, a - 20 supply voltage variation and a 40 celsius temperature variation. We validate our approach using measurements from two APUF datasets. Experimental results indicate that large number of error-free responses can be generated on demand under worst-case when PUF response error rate is up to 16.68.", "text_perturb": "Physical unclonable functions ( PUF ) extract secret from randomness inherent in manufacturing processes. PUFs are utilized for basic cryptographic tasks such as authentication and key generation , and more recently , to realize key exchange and bit commitment require a large number of error free responses from a strong PUF. We propose an approach to eliminate the need to implement expensive on-chip error correction logic implementation and the associated helper data storage to reconcile naturally noisy PUF answer. In particular , we exploit a statistical model of an Arbiter PUF ( APUF ) constructed under the nominal operating condition during the challenge reaction enrollment phase by a trusted party to judiciously select challenges that yield error-free responses even across a wide operating conditions , specifically , a - 20 supply voltage variation and a 40 celsius temperature variation. We validate our approach employ measurements from two APUF datasets. Experimental results indicate that large number of error-free responses can be sire on demand under worst-case when PUF response error rate is up to 16. 68. ", "label": 1}
{"original_text": "Deep video recognition is more computationally expensive than image recognition, especially on large-scale datasets like Kinetics. Therefore, training scalability is essential to handle a large amount of videos. In this paper, we study the factors that impact the training scalability of video networks. We recognize three bottlenecks, including data loading (data movement from disk to GPU), communication (data movement over networking), and computation FLOPs. We propose three design guidelines to improve the scalability: (1) fewer FLOPs and hardware-friendly operator to increase the computation efficiency; (2) fewer input frames to reduce the data movement and increase the data loading efficiency; (3) smaller model size to reduce the networking traffic and increase the networking efficiency. With these guidelines, we designed a new operator Temporal Shift Module (TSM) that is efficient and scalable for distributed training. TSM model can achieve 1.8 x higher throughput compared to previous I3D models. We scale up the training of the TSM model to 1,536 GPUs, with a mini-batch of 12,288 video clips98,304 images, without losing the accuracy. With such hardware-aware model design, we are able to scale up the training on Summit supercomputer and reduce the training time on Kinetics dataset from 49 hours 55 minutes to 14 minutes 13 seconds, achieving a top-1 accuracy of 74.0, which is 1.6 x and 2.9 x faster than previous 3D video models with higher accuracy. The code and more details can be found here: .", "text_perturb": "Deep video recognition is more computationally expensive than image recognition , especially on large-scale datasets like dynamics. Therefore , training scalability is all important to handle a large amount of videos. In this paper , we study the agent that impact the training scalability of video networks. We recognize three bottlenecks , including data loading ( data bowel movement from disk to GPU ) , communication ( data bowel movement over networking ) , and computation FLOPs. We propose three design guidelines to improve the scalability : ( 1 ) few FLOPs and hardware-friendly operator to increase the computation efficiency ; ( 2 ) few input frames to reduce the data movement and increase the data loading efficiency ; ( 3 ) smaller model size to reduce the networking traffic and increase the networking efficiency. With these guidelines , we designed a new operator Temporal sack Module ( TSM ) that is efficient and scalable for distributed training. TSM model can reach 1. 8 x high pitched throughput compared to previous I3D models. We scale up the grooming of the TSM model to 1,536 GPUs , with a mini-batch of 12,288 video clips98,304 images , without losing the accuracy. With such hardware-aware model design , we are able to scale up the preparation on Summit supercomputer and reduce the preparation time on Kinetics dataset from 49 hours 55 minutes to 14 minutes 13 seconds , achieving a top-1 accuracy of 74. 0 , which be 1. 6 go and 2. 9 x faster than old 3D video models with higher accuracy. The code and more details send away be found here :. ", "label": 1}
{"original_text": "We address scene layout modeling for recognizing agent-in-place actions, which are actions associated with agents who perform them and the places where they occur, in the context of outdoor home surveillance. We introduce a novel representation to model the geometry and topology of scene layouts so that a network can generalize from the layouts observed in the training scenes to unseen scenes in the test set. This Layout-Induced Video Representation (LIVR) abstracts away low-level appearance variance and encodes geometric and topological relationships of places to explicitly model scene layout. LIVR partitions the semantic features of a scene into different places to force the network to learn generic place-based feature descriptions which are independent of specific scene layouts; then, LIVR dynamically aggregates features based on connectivities of places in each specific scene to model its layout. We introduce a new Agent-in-Place Action (APA) dataset 1 footnote 1 1 footnote 1 The dataset is pending legal review and will be released upon the acceptance of this paper. to show that our method allows neural network models to generalize significantly better to unseen scenes.", "text_perturb": "We come up to scene layout modeling for recognizing agent-in-place actions , which are actions associated with agents who perform them and the places where they occur , in the context of outdoor home surveillance. We introduce a novel representation to model the geometry and topology of scene layouts so that a net can generalize from the layouts observed in the training scenes to unseen scenes in the test set. This Layout-Induced Video Representation ( LIVR ) abstracts away low-level appearance discrepancy and encodes geometric and topological relationships of places to explicitly model scene layout. LIVR partitions the semantic features of a scene into unlike places to force the network to learn generic place-based feature descriptions which are independent of specific scene layouts ; then , LIVR dynamically aggregates features based on connectivities of places in each specific scene to model its layout. We introduce a new Agent-in-Place Action ( APA ) dataset 1 footer 1 1 footer 1 The dataset is pending legal review and will be released upon the acceptance of this paper. to show that our method allows neural network models to generalize significantly better to unobserved scenes. ", "label": 1}
{"original_text": "Evaluating conjunctive queries and solving constraint satisfaction problems are fundamental problems in database theory and artificial intelligence, respectively. These problems are NP-hard, so that several research efforts have been made in the literature for identifying tractable classes, known as islands of tractability, as well as for devising clever heuristics for solving efficiently real-world instances. Many heuristic approaches are based on enforcing on the given instance a property called local consistency, where (in database terms) each tuple in every query atom matches at least one tuple in every other query atom. Interestingly, it turns out that, for many well-known classes of queries, such as for the acyclic queries, enforcing local consistency is even sufficient to solve the given instance correctly. However, the precise power of such a procedure was unclear, but for some very restricted cases. The paper provides full answers to the long-standing questions about the precise power of algorithms based on enforcing local consistency. In particular, the paper deals with both the general framework of tree projections, where local consistency is enforced among arbitrary views defined over the given database instance, and the specific cases where such views are computed according to so-called structural decomposition methods, such as generalized hypertree width, component hypertree decompositions, and so on. The classes of instances where enforcing local consistency turns out to be a correct query-answering procedure are however not efficiently recognizable. In fact, the paper finally focuses on certain subclasses defined in terms of the novel notion of greedy tree projections. These latter classes are shown to be efficiently recognizable and strictly larger than most islands of tractability known so far, both in the general case of tree projections and for specific structural decomposition methods.", "text_perturb": "Evaluating conjunctive queries and solving constraint satisfaction problems are fundamental problems in database possibility and artificial intelligence , respectively. These problem are NP-hard , so that several research efforts have been made in the literature for identifying tractable classes , known as islands of tractability , as well as for devising clever heuristics for solving efficiently real-world instances. Many heuristic approaches are free base on enforcing on the given instance a property called local consistency , where ( in database terms ) each tuple in every query atom matches at least one tuple in every other query atom. Interestingly , it turns out that , for many well-known classes of queries , such as for the acyclic queries , enforcing local consistency embody even sufficient to solve the given instance correctly. However , the exact power of such a procedure was unclear , but for some very restricted cases. The paper provides full solution to the long-standing questions about the precise power of algorithms based on enforcing local consistency. In particular , the paper deals with both the general framework of tree projections , where local consistency is enforced among arbitrary views defined over the given database instance , and the specific cases where such views are computed according to so-called structural decomposition method , such as generalized hypertree width , component hypertree decompositions , and so on. The classes of instances where impose local consistency turns out to be a correct query-answering procedure are however not efficiently recognizable. In fact , the paper finally focuses on certain subclasses defined in damage of the novel notion of greedy tree projections. These latter classes are shown to be expeditiously recognizable and strictly larger than most islands of tractability known so far , both in the general case of tree projections and for specific structural decomposition methods. ", "label": 1}
{"original_text": "We develop a scalable, computationally efficient method for the task of energy disaggregation for home appliance monitoring. In this problem the goal is to estimate the energy consumption of each appliance over time based on the total energy-consumption signal of a household. The current state of the art is to model the problem as inference in factorial HMMs, and use quadratic programming to find an approximate solution to the resulting quadratic integer program. Here we take a more principled approach, better suited to integer programming problems, and find an approximate optimum by combining convex semidefinite relaxations randomized rounding, as well as a scalable ADMM method that exploits the special structure of the resulting semidefinite program. Simulation results both in synthetic and real-world datasets demonstrate the superiority of our method.", "text_perturb": "We develop a scalable , computationally efficient method for the task of energy disaggregation for menage appliance monitoring. In this problem the finish is to estimate the energy consumption of each appliance over time based on the total energy-consumption signal of a household. The current state of the art is to simulate the problem as inference in factorial HMMs , and use quadratic programming to find an approximate solution to the resulting quadratic integer program. Here we take a more principled approach , better suited to integer programming problems , and find an approximate optimum by combining convex semidefinite relaxations randomized rounding , as well as a scalable ADMM method that exploits the limited structure of the resulting semidefinite program. Simulation results both in synthetic and real-world datasets demonstrate the superiority of our method acting. ", "label": 1}
{"original_text": "A dynamical neural network consists of a set of interconnected neurons that interact over time continuously. It can exhibit computational properties in the sense that the dynamical system's evolution andor limit points in the associated state space can correspond to numerical solutions to certain mathematical optimization or learning problems. Such a computational system is particularly attractive in that it can be mapped to a massively parallel computer architecture for power and throughput efficiency, especially if each neuron can rely solely on local information (i.e., local memory). Deriving gradients from the dynamical network's various states while conforming to this last constraint, however, is challenging. We show that by combining ideas of top-down feedback and contrastive learning, a dynamical network for solving the l 1 -minimizing dictionary learning problem can be constructed, and the true gradients for learning are provably computable by individual neurons. Using spiking neurons to construct our dynamical network, we present a learning process, its rigorous mathematical analysis, and numerical results on several dictionary learning problems.", "text_perturb": "A dynamical neural network consists of a set of interconnected neurons that interact over prison term continuously. It can exhibit computational properties in the sense that the dynamical system 's evolution andor limit points in the associated state infinite can correspond to numerical solutions to certain mathematical optimization or learning problems. Such a computational system is particularly attractive in that it can be mapped to a massively parallel electronic computer architecture for power and throughput efficiency , especially if each neuron can rely solely on local information ( i. einsteinium. , local memory board ). Deriving slope from the dynamical network 's various states while conforming to this last constraint , however , is challenging. We show that by combining ideas of top-down feedback and contrastive learning , a dynamical network for solving the l 1 -minimizing dictionary learning problem can be constructed , and the true slope for learning are provably computable by individual neurons. Using spiking neurons to construct our dynamical network , we present a learning process , its rigorous mathematical analysis , and numeric results on several dictionary learning problems. ", "label": 1}
{"original_text": "This paper introduces the notion of exact common information, which is the minimum description length of the common randomness needed for the exact distributed generation of two correlated random variables (X, Y). We introduce the quantity G (X; Y) min X - W - Y H (W) as a natural bound on the exact common information and study its properties and computation. We then introduce the exact common information rate, which is the minimum description rate of the common randomness for the exact generation of a 2-DMS (X, Y). We give a multiletter characterization for it as the limit G - (X; Y) lim - n (1 n) G (X n; Y n). While in general G - (X; Y) is greater than or equal to the Wyner common information, we show that they are equal for the Symmetric Binary Erasure Source. We do not know, however, if the exact common information rate has a single letter characterization in general.", "text_perturb": "This paper introduces the notion of exact common selective information , which is the minimum description length of the common randomness needed for the exact distributed generation of two correlated random variables ( X , Y ). We introduce the quantity G ( X ; Y ) min X - W - Y H ( W ) as a natural bound on the exact vernacular information and study its properties and computation. We then introduce the exact common information rate , which is the minimum description rate of the common noise for the exact generation of a 2-DMS ( X , Y ). We give a multiletter characterization for it as the limit G - ( X ; wye ) lim - n ( 1 n ) G ( X n ; wye n ). While in general G - ( X ; Y ) is corking than or equal to the Wyner common information , we show that they are equal for the Symmetric Binary Erasure Source. We do not know , however , if the exact usual information rate has a single letter characterization in general. ", "label": 1}
{"original_text": "We study robust PCA for the fully observed setting, which is about separating a low rank matrix L and a sparse matrix S from their sum D L S. In this paper, a new algorithm, dubbed accelerated alternating projections, is introduced for robust PCA which significantly improves the computational efficiency of the existing alternating projections proposed in when updating the low rank factor. The acceleration is achieved by first projecting a matrix onto some low dimensional subspace before obtaining a new estimate of the low rank matrix via truncated SVD. Exact recovery guarantee has been established which shows linear convergence of the proposed algorithm. Empirical performance evaluations establish the advantage of our algorithm over other state-of-the-art algorithms for robust PCA.", "text_perturb": "We study robust PCA for the fully discovered setting , which is about separating a low rank matrix L and a sparse matrix S from their sum D L S. In this paper , a new algorithm , dubbed accelerated alternating ejection , is introduced for robust PCA which significantly improves the computational efficiency of the existing alternating ejection proposed in when updating the low rank factor. The acceleration is achieved by first projecting a matrix onto some low dimensional subspace before obtaining a modern estimate of the low rank matrix via truncated SVD. Exact recovery guarantee has been established which shows linear convergence of the proposed algorithmic rule. empiric performance evaluations establish the advantage of our algorithm over other state-of-the-art algorithms for robust PCA. ", "label": 1}
{"original_text": "Recently it has been proved that a simple algorithm configurator called ParamRLS can efficiently identify the optimal neighbourhood size to be used by stochastic local search to optimise two standard benchmark problem classes. In this paper we analyse the performance of algorithm configurators for tuning the more sophisticated global mutation operator used in standard evolutionary algorithms, which flips each of the n bits independently with probability kh n and the best value for kh has to be identified. We compare the performance of configurators when the best-found fitness values within the cutoff time k are used to compare configurations against the actual optimisation time for two standard benchmark problem classes, Ridge and LeadingOnes. We rigorously prove that all algorithm configurators that use optimisation time as performance metric require cutoff times that are at least as large as the expected optimisation time to identify the optimal configuration. Matters are considerably different if the fitness metric is used. To show this we prove that the simple ParamRLS-F configurator can identify the optimal mutation rates even when using cutoff times that are considerably smaller than the expected optimisation time of the best parameter value for both problem classes.", "text_perturb": "Recently it has been proved that a simple algorithm configurator called ParamRLS can efficiently identify the optimal neighbourhood size to be use by stochastic local search to optimise two standard benchmark problem classes. In this paper we analyse the performance of algorithm configurators for tuning the more sophisticated global mutation operator used in standard evolutionary algorithmic program , which flips each of the n bits independently with probability kh n and the best value for kh has to be identified. We compare the performance of configurators when the best-found fitness values within the cutoff time k are used to compare configurations against the actual optimisation time for two standard benchmark problem stratum , Ridge and LeadingOnes. We rigorously prove that all algorithm configurators that use optimisation time as performance measured require cutoff times that are at least as large as the expected optimisation time to identify the optimal configuration. Matters equal considerably different if the fitness metric is used. To show this we prove that the simple ParamRLS-F configurator can identify the optimal mutation rates even when using cutoff times that are considerably smaller than the expected optimisation time of the proficient parameter value for both problem classes. ", "label": 1}
{"original_text": "Positive-definite kernel functions are fundamental elements of kernel methods and Gaussian processes. A well-known construction of such functions comes from Bochner's characterization, which connects a positive-definite function with a probability distribution. Another construction, which appears to have attracted less attention, is Polya's criterion that characterizes a subset of these functions. In this paper, we study the latter characterization and derive a number of novel kernels little known previously. In the context of large-scale kernel machines, Rahimi and Recht (2007) proposed a random feature map (random Fourier) that approximates a kernel function, through independent sampling of the probability distribution in Bochner's characterization. The authors also suggested another feature map (random binning), which, although not explicitly stated, comes from Polya's characterization. We show that with the same number of random samples, the random binning map results in an Euclidean inner product closer to the kernel than does the random Fourier map. The superiority of the random binning map is confirmed empirically through regressions and classifications in the reproducing kernel Hilbert space.", "text_perturb": "Positive-definite heart and soul functions are fundamental elements of heart and soul methods and Gaussian processes. A well-known construction of such functions comes from Bochner 's characterization , which connects a positive-definite routine with a probability distribution. Another construction , which appears to feature attracted less attention , is Polya 's criterion that characterizes a subset of these functions. In this composition , we study the latter characterization and derive a number of novel kernels little known previously. In the context of large-scale kernel machines , Rahimi and Recht ( 2007 ) proposed a random feature map ( random Fourier ) that approximates a kernel function , through independent sampling of the chance distribution in Bochner 's characterization. The writer also suggested another feature map ( random binning ) , which , although not explicitly stated , comes from Polya 's characterization. We show that with the same number of random samples , the random binning map results in an euclidean inner product closer to the kernel than does the random Fourier map. The superiority of the random binning map is confirmed empirically through regressions and assortment in the reproducing kernel Hilbert space. ", "label": 1}
{"original_text": "We provide easy and readable GNU OctaveMATLAB code for the simulation of mathematical models described by ordinary differential equations and for the solution of optimal control problems through Pontryagin's maximum principle. For that, we consider a normalized HIVAIDS transmission dynamics model based on the one proposed in our recent contribution (Silva, C.J.; Torres, D.F.M. A SICA compartmental model in epidemiology with application to HIVAIDS in Cape Verde. Ecol. Complex. 2017, 30, 70-75), given by a system of four ordinary differential equations. An HIV initial value problem is solved numerically using the ode45 GNU Octave function and three standard methods implemented by us in OctaveMATLAB: Euler method and second-order and fourth-order Runge-Kutta methods. Afterwards, a control function is introduced into the normalized HIV model and an optimal control problem is formulated, where the goal is to find the optimal HIV prevention strategy that maximizes the fraction of uninfected HIV individuals with the least HIV new infections and cost associated with the control measures. The optimal control problem is characterized analytically using the Pontryagin Maximum Principle, and the extremals are computed numerically by implementing a forward-backward fourth-order Runge-Kutta method. Complete algorithms, for both uncontrolled initial value and optimal control problems, developed under the free GNU Octave software and compatible with MATLAB are provided along the article.", "text_perturb": "We provide easy and readable GNU OctaveMATLAB code for the simulation of mathematical models described by ordinary differential equations and for the solution of optimal control problems through Pontryagin 's maximum rationale. For that , we consider a normalized HIVAIDS transmission moral force model based on the one proposed in our recent contribution ( Silva , C. j. ; Torres , D. fluorine. yard. A SICA compartmental model in epidemiology with diligence to HIVAIDS in Cape Verde. Ecol. complex. 2017 , 30 , 70-75 ) , afford by a system of four ordinary differential equations. An HIV initial value problem is work out numerically using the ode45 GNU Octave function and three standard methods implemented by us in OctaveMATLAB : Euler method and second-order and fourth-order Runge-Kutta methods. Afterwards , a control function is introduced into the normalized HIV model and an optimal control problem is formulated , where the goal is to find the optimal HIV prevention strategy that maximizes the fraction of uninfected HIV mortal with the least HIV new infections and cost associated with the control measures. The optimal control problem represent characterized analytically using the Pontryagin Maximum Principle , and the extremals are computed numerically by implementing a forward-backward fourth-order Runge-Kutta method. Complete algorithms , for both uncontrolled initial value and optimal control problems , rise under the free GNU Octave software and compatible with MATLAB are provided along the article. ", "label": 1}
{"original_text": "Change-point detection (CPD) aims at detecting the abrupt property changes lying behind time series data. The property changes in a multivariate time series often result from highly entangled reasons, ranging from independent changes of variables to correlation changes between variables. Learning to uncover the reasons behind the changes in an unsupervised setting is a new and challenging task. Previous CPD methods usually detect change-points by a divergence estimation of statistical features, without delving into the reasons behind the detected changes. In this paper, we propose a correlation-aware dynamics model which separately predicts the correlation change and independent change by incorporating graph neural networks into the encoder-decoder framework. Through experiments on synthetic and real-world datasets, we demonstrate the enhanced performance of our model on the CPD tasks as well as its ability to interpret the nature and degree of the predicted changes.", "text_perturb": "Change-point detection ( CPD ) aims at detecting the abrupt property changes dwell behind time series data. The property changes in a multivariate time series often result from highly entangled reasons , ranging from independent changes of variable quantity to correlation changes between variable quantity. Learning to uncover the reasons behind the variety in an unsupervised setting is a new and challenging task. Previous CPD methods commonly detect change-points by a divergence estimation of statistical features , without delving into the reasons behind the detected changes. In this paper , we propose a correlation-aware moral force model which separately predicts the correlation change and independent change by incorporating graph neural networks into the encoder-decoder framework. Through experiments on synthetic and real-world datasets , we demonstrate the enhanced performance of our model on the CPD tasks as well as its power to interpret the nature and degree of the predicted changes. ", "label": 1}
{"original_text": "In this manuscript, we investigate the abrupt breakdown behavior of coupled distribution grids under load growth. This scenario mimics the ever-increasing customer demand and the foreseen introduction of energy hubs interconnecting the different energy vectors. We extend an analytical model of cascading behavior due to line overloads to the case of interdependent networks and find evidence of first order transitions due to the long-range nature of the flows. Our results indicate that the foreseen increase in the couplings between the grids has two competing effects: on the one hand, it increases the safety region where grids can operate without withstanding systemic failures; on the other hand, it increases the possibility of a joint systems' failure.", "text_perturb": "In this holograph , we investigate the abrupt breakdown behavior of coupled distribution grids under load growth. This scenario mimic the ever-increasing customer demand and the foreseen introduction of energy hubs interconnecting the different energy vectors. We extend an analytical model of cascading behavior due to line overloads to the case of interdependent networks and find evidence of foremost order transitions due to the long-range nature of the flows. Our results indicate that the foreseen increase in the couplings between the grids has two competing effects : on the one hand , it increase the safety region where grids can operate without withstanding systemic failures ; on the other hand , it increase the possibility of a joint systems ' failure. ", "label": 1}
{"original_text": "We give a (2) -approximation algorithm for minimizing total weighted completion time on a single machine under release time and precedence constraints. This settles a recent conjecture made in", "text_perturb": "We give a ( 2 ) -approximation algorithm for understate total weighted completion time on a single machine under release time and precedence constraints. This settles a recent conjecture realize in", "label": 1}
{"original_text": "We investigate bounded state estimation of linear systems over finite-state erasure and additive noise channels in which the noise is governed by a finite-state machine without any statistical structure. Upper and lower bounds on their zero-error capacities are derived, revealing a connection with the topological entropy of the channel dynamics. Some examples are introduced and separate capacity bounds based on their specific features are derived and compared with bounds from topological entropy. Necessary and sufficient conditions for linear state estimation with bounded errors via such channels are then obtained, by extending previous results for nonstochastic memoryless channels to finite-state channels. These estimation conditions bring together the topological entropies of the linear system and the discrete channel.", "text_perturb": "We investigate bounded state idea of linear systems over finite-state erasure and additive noise channels in which the noise is governed by a finite-state machine without any statistical structure. Upper and lower bounds on their zero-error capacities are derived , revealing a connection with the topological entropy of the transmission channel dynamics. Some examples exist introduced and separate capacity bounds based on their specific features exist derived and compared with bounds from topological entropy. Necessary and sufficient conditions for linear state estimation with bounded errors via such channels are and so obtained , by extending previous results for nonstochastic memoryless channels to finite-state channels. These estimation conditions bring together the topological entropies of the linear arrangement and the discrete channel. ", "label": 1}
{"original_text": "In this paper, we provide details of a robotic system that can automate the task of picking and stowing objects from and to a rack in an e-commerce fulfillment warehouse. The system primarily comprises of four main modules: (1) Perception module responsible for recognizing query objects and localizing them in the 3-dimensional robot workspace; (2) Planning module generates necessary paths that the robot end-effector has to take for reaching the objects in the rack or in the tote; (3) Calibration module that defines the physical workspace for the robot visible through the on-board vision system; and (4) Gripping and suction system for picking and stowing different kinds of objects. The perception module uses a faster region-based Convolutional Neural Network (R-CNN) to recognize objects. We designed a novel two finger gripper that incorporates pneumatic valve based suction effect to enhance its ability to pick different kinds of objects. The system was developed by IITK-TCS team for participation in the Amazon Picking Challenge 2016 event. The team secured a fifth place in the stowing task in the event. The purpose of this article is to share our experiences with students and practicing engineers and enable them to build similar systems. The overall efficacy of the system is demonstrated through several simulation as well as real-world experiments with actual robots.", "text_perturb": "In this paper , we provide details of a robotic system that can automate the task of picking and stowing objects from and to a wrack in an e-commerce fulfillment warehouse. The system primarily comprises of four main modules : ( 1 ) Perception module responsible for recognizing query objects and localizing them in the 3-dimensional robot workspace ; ( 2 ) Planning module generates necessary paths that the robot end-effector has to take for touch the objects in the rack or in the tote ; ( 3 ) Calibration module that defines the physical workspace for the robot visible through the on-board vision system ; and ( 4 ) Gripping and suction system for picking and stowing different kinds of objects. The perception module uses a faster region-based Convolutional Neural Network ( R-CNN ) to recognize object. We designed a fresh two finger gripper that incorporates pneumatic valve based suction effect to enhance its ability to pick different kinds of objects. The system was spring up by IITK-TCS team for participation in the Amazon Picking Challenge 2016 event. The team secured a th place in the stowing task in the event. The purpose of this article is to share our experiences with students and practicing engineers and enable them to construct similar systems. The overall efficacy of the system is demonstrated through several simulation as well as real-world experiments with genuine robots. ", "label": 1}

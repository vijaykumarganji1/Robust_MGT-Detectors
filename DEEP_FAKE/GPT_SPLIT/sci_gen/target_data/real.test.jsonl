{"original_text": "Recent work by (,) looks at semantic parser induction and question answering in the domain of source code libraries and APIs. In this brief note, we formalize the representations being learned in these studies and introduce a simple domain specific language and a systematic translation from this language to first-order logic. By recasting the target representations in terms of classical logic, we aim to broaden the applicability of existing code datasets for investigating more complex natural language understanding and reasoning problems in the software domain.", "text_perturb": "Recent work by ( , ) looks at semantic parser induction and doubtfulness answering in the domain of source code libraries and APIs. In this brief note , we formalize the representations being learned in these studies and premise a simple domain specific language and a systematic translation from this language to first-order logic. By recasting the target representations in terms of classical logic , we aim to broaden the applicability of survive code datasets for investigating more complex natural language understanding and reasoning problems in the software domain. ", "label": 1}
{"original_text": "The digital identity problem is a complex one in large part because it involves personal data, the algorithms which compute reputations on the data and the management of the identifiers that are linked to personal data. The reality of today is that personal data of an individual is distributed throughout the Internet, in both private and public institutions, and increasingly also on the user's devices. In order to empower individuals to have a say in who has access to their personal data and to enable individuals to make use of their data for their own purposes, a coherent and scalable access authorization architecture is required. Such an architecture must allow different data holders, data providers and user-content generators to respond to an individual's wishes with regards to consent in a federated fashion. This federation must allow an individual to easily manage access policies and provide consent as required by current and forthcoming data privacy regulations. This paper describes the User Managed Access (UMA) architecture and protocols that provide the foundation for scalable access authorization.", "text_perturb": "The digital identity problem is a complex i in large part because it involves personal data , the algorithms which compute reputations on the data and the management of the identifiers that are linked to personal data. The reality of today is that personal data of an individual is distributed throughout the Internet , in both private and public institutions , and increasingly likewise on the user 's devices. In parliamentary law to empower individuals to have a say in who has access to their personal data and to enable individuals to make use of their data for their own purposes , a coherent and scalable access authorization architecture is required. Such an architecture must allow different data holders , data providers and user-content generators to respond to an individual 's wishes with wish to consent in a federated fashion. This federation must allow an individual to easily manage access policies and allow for consent as required by current and forthcoming data privacy regulations. This paper describes the user Managed Access ( UMA ) architecture and protocols that provide the foundation for scalable access authorization. ", "label": 1}
{"original_text": "Batch normalization (BN) has become a standard technique for training the modern deep networks. However, its effectiveness diminishes when the batch size becomes smaller, since the batch statistics estimation becomes inaccurate. That hinders batch normalization's usage for 1) training larger model which requires small batches constrained by memory consumption, 2) training on mobile or embedded devices of which the memory resource is limited. In this paper, we propose a simple but effective method, called extended batch normalization (EBN). For NCHW format feature maps, extended batch normalization computes the mean along the (N, H, W) dimensions, as the same as batch normalization, to maintain the advantage of batch normalization. To alleviate the problem caused by small batch size, extended batch normalization computes the standard deviation along the (N, C, H, W) dimensions, thus enlarges the number of samples from which the standard deviation is computed. We compare extended batch normalization with batch normalization and group normalization on the datasets of MNIST, CIFAR-10100, STL-10, and ImageNet, respectively. The experiments show that extended batch normalization alleviates the problem of batch normalization with small batch size while achieving close performances to batch normalization with large batch size.", "text_perturb": "Batch normalization ( BN ) has become a stock technique for training the modern deep networks. However , its effectiveness diminishes when the batch size turn smaller , since the batch statistics estimation turn inaccurate. That hinders batch normalization 's usage for 1 ) training larger model which requires small batches encumber by memory consumption , 2 ) training on mobile or embedded devices of which the memory resource is limited. In this paper , we propose a simple but effective method , called extended tidy sum normalization ( EBN ). For NCHW format feature maps , extended spate normalization computes the mean along the ( N , H , W ) dimensions , as the same as spate normalization , to maintain the advantage of spate normalization. To alleviate the problem caused by small batch size , extended batch normalization computes the standard deviation along the ( N , C , H , W ) dimensions , thus enlarges the number of samples from which the standard deviation equal computed. We equate extended batch normalization with batch normalization and group normalization on the datasets of MNIST , CIFAR-10100 , STL-10 , and ImageNet , respectively. The experiments show that extended batch normalization alleviates the problem of batch normalization with small batch size while achieving stuffy performances to batch normalization with large batch size. ", "label": 1}
{"original_text": "How far and how fast does information spread in social media? Researchers have recently examined a number of factors that affect information diffusion in online social networks, including: the novelty of information, users' activity levels, who they pay attention to, and how they respond to friends' recommendations. Using URLs as markers of information, we carry out a detailed study of retweeting, the primary mechanism by which information spreads on the Twitter follower graph. Our empirical study examines how users respond to an incoming stimulus, i.e., a tweet (message) from a friend, and reveals that dynamically decaying visibility, which is the increasing cognitive effort required for discovering and acting upon a tweet, combined with limited attention play dominant roles in retweeting behavior. Specifically, we observe that users retweet information when it is most visible, such as when it near the top of their Twitter feed. Moreover, our measurements quantify how a user's limited attention is divided among incoming tweets, providing novel evidence that highly connected individuals are less likely to propagate an arbitrary tweet. Our study indicates that the finite ability to process incoming information constrains social contagion, and we conclude that rapid decay of visibility is the primary barrier to information propagation online.", "text_perturb": "How far and how fast does information spread in social media ? Researchers have recently examined a number of factors that pretend information diffusion in online social networks , including : the novelty of information , users ' activity levels , who they pay attention to , and how they respond to friends ' recommendations. Using URLs as markers of information , we carry out a detailed study of retweeting , the primary mechanism by which information spreading on the Twitter follower graph. Our empirical study examines how users respond to an incoming stimulant , i. eastward. , a tweet ( message ) from a friend , and reveals that dynamically decaying visibility , which is the increasing cognitive effort required for discovering and acting upon a tweet , meld with limited attention play dominant roles in retweeting behavior. Specifically , we observe that users retweet information when it is most visible , such as when it near the top of their chirrup feed. Moreover , our measurements quantify how a user 's limited attention embody divided among incoming tweets , providing novel evidence that highly connected individuals are less likely to propagate an arbitrary tweet. Our subject indicates that the finite ability to process incoming information constrains social contagion , and we conclude that rapid decay of visibility is the primary barrier to information propagation online. ", "label": 1}
{"original_text": "In this work we focus on the problem of colorization for image compression. Since color information occupies a large proportion of the total storage size of an image, a method that can predict accurate color from its grayscale version can produce a dramatic reduction in image file size. But colorization for compression poses several challenges. First, while colorization for artistic purposes simply involves predicting plausible chroma, colorization for compression requires generating output colors that are as close as possible to the ground truth. Second, many objects in the real world exhibit multiple possible colors. Thus, in order to disambiguate the colorization problem some additional information must be stored to reproduce the true colors with good accuracy. To account for the multimodal color distribution of objects we propose a deep tree-structured network that generates for every pixel multiple color hypotheses, as opposed to a single color produced by most prior colorization approaches. We show how to leverage the multimodal output of our model to reproduce with high fidelity the true colors of an image by storing very little additional information. In the experiments we show that our proposed method outperforms traditional JPEG color coding by a large margin, producing colors that are nearly indistinguishable from the ground truth at the storage cost of just a few hundred bytes for high-resolution pictures!", "text_perturb": "In this work we focus on the trouble of colorization for image compression. Since color information occupies a large proportion of the total storage size of an trope , a method that can predict accurate color from its grayscale version can produce a dramatic reduction in trope file size. But colorization for compaction poses several challenges. First , while colorization for artistic purposes simply involves predicting plausible chroma , colorization for compression requires engender output colors that are as close as possible to the ground truth. Second , many objects in the real world exhibit multiple possible colours. Thus , in order to disambiguate the colorization problem some additional information must be stored to reproduce the true colours with good accuracy. To account for the multimodal color dispersion of objects we propose a deep tree-structured network that generates for every pixel multiple color hypotheses , as opposed to a single color produced by most prior colorization approaches. We show how to leverage the multimodal output of our model to reproduce with high fidelity the true colors of an image by lay in very little additional information. In the experiments we show that our proposed method outperforms traditional JPEG color coding by a large margin , producing colors that are nearly indistinguishable from the ground truth at the storage cost of only a few hundred bytes for high-resolution pictures !", "label": 1}
{"original_text": "Understanding the formation of subjective human traits, such as preference and opinions, is an important, but poorly explored problem. An essential aspect is that traits collectively evolve under the repeated action of social influence interactions, which is the focus of many quantitative studies of cultural dynamics. In this paradigm, dynamical models require that all traits are fixed when specifying the \"initial cultural state.\" Typically, this initial state is randomly generated, from a uniform distribution over the set of possible combinations of traits. However, recent work has shown that the outcome of social influence dynamics strongly depends on the nature of the initial state: if this is sampled from empirical data instead of being generated in a uniformly random way, a higher level of cultural diversity is found after long-term dynamics, for the same level of propensity towards collective behavior in the short-term; moreover, if the initial state is obtained by shuffling the empirical traits among people, the level of long-term cultural diversity is in-between those obtained for the empirical and random counterparts. The current study repeats the analysis for multiple empirical data sets, showing that the results are remarkably similar, although the matrix of correlations between cultural variables clearly differs across data sets. This points towards robust structural properties inherent in empirical cultural states, likely due to universal laws governing the dynamics of culture in the real world. The analysis suggests, first, that this dynamics operates close to criticality and second, that it is driven by more than just social influence, implications which were not recognized previously.", "text_perturb": "Understanding the formation of subjective human traits , such as preference and opinions , is an important , but poorly search problem. An essential aspect make up that traits collectively evolve under the repeated action of social influence interactions , which make up the focus of many quantitative studies of cultural dynamics. In this paradigm , dynamical models require that all traits are fixed when limit the `` initial cultural state. `` Typically , this initial state live randomly generated , from a uniform distribution over the set of possible combinations of traits. However , recent work has shown that the outcome of social influence dynamics strongly depends on the nature of the initial state : if this is sampled from empirical data instead of being generated in a uniformly random way , a higher level of cultural diversity is found after long-term dynamics , for the same level of propensity towards collective behavior in the short-term ; moreover , if the initial state is obtained by shuffling the empirical traits among people , the level of long-term cultural diversity is middle those obtained for the empirical and random counterparts. The current study repeats the analysis for multiple empirical data sets , showing that the results are remarkably similar , although the matrix of correlations between cultural variables understandably differs across data sets. This points towards robust structural properties inherent in empirical cultural states , likely due to universal laws regularize the dynamics of culture in the real world. The analysis suggests , first , that this dynamics operates close to criticality and second , that it is driven by more than just social influence , significance which were not recognized previously. ", "label": 1}
{"original_text": "Hex is a complex game with a high branching factor. For the first time Hex is being attempted to be solved without the use of game tree structures and associated methods of pruning. We also are abstaining from any heuristic information about Virtual Connections or Semi Virtual Connections which were previously used in all previous known computer versions of the game. The H-search algorithm which was the basis of finding such connections and had been used with success in previous Hex playing agents has been forgone. Instead what we use is reinforcement learning through self play and approximations through neural networks to by pass the problem of high branching factor and maintaining large tables for state-action evaluations. Our code is based primarily on NeuroHex. The inspiration is drawn from the recent success of AlphaGo Zero.", "text_perturb": "Hex is a complex game with a mellow branching factor. For the first time Hex cost being attempted to be solved without the use of game tree structures and associated methods of pruning. We also are abstaining from any heuristic information about Virtual Connections or Semi Virtual Connections which were previously employ in all previous known computer versions of the game. The H-search algorithm which was the basis of finding such connections and had been used with succeeder in previous Hex playing agents has been forgone. Instead what we use is reinforcement learning through self play and approximations through neural networks to by qualifying the problem of high branching factor and maintaining large tables for state-action evaluations. Our code exist based primarily on NeuroHex. The inspiration is drawn from the recent winner of AlphaGo Zero. ", "label": 1}
{"original_text": "Although artificial neural networks have shown great promise in applications including computer vision and speech recognition, there remains considerable practical and theoretical difficulty in optimizing their parameters. The seemingly unreasonable success of gradient descent methods in minimizing these non-convex functions remains poorly understood. In this work we offer some theoretical guarantees for networks with piecewise affine activation functions, which have in recent years become the norm. We prove three main results. Firstly, that the network is piecewise convex as a function of the input data. Secondly, that the network, considered as a function of the parameters in a single layer, all others held constant, is again piecewise convex. Finally, that the network as a function of all its parameters is piecewise multi-convex, a generalization of biconvexity. From here we characterize the local minima and stationary points of the training objective, showing that they minimize certain subsets of the parameter space. We then analyze the performance of two optimization algorithms on multi-convex problems: gradient descent, and a method which repeatedly solves a number of convex sub-problems. We prove necessary convergence conditions for the first algorithm and both necessary and sufficient conditions for the second, after introducing regularization to the objective. Finally, we remark on the remaining difficulty of the global optimization problem. Under the squared error objective, we show that by varying the training data, a single rectifier neuron admits local minima arbitrarily far apart, both in objective value and parameter space.", "text_perturb": "Although artificial neural network have shown great promise in applications including computer vision and speech recognition , there remains considerable practical and theoretical difficulty in optimizing their parameters. The seemingly unreasonable success of gradient descent methods in minimizing these non-convex mapping remains poorly understood. In this work we offer some theoretical guarantees for networks with piecewise affine activation functions , which have in late years become the norm. We test three main results. Firstly , that the mesh is piecewise convex as a function of the input data. second , that the network , considered as a function of the parameters in a single layer , all others held constant , is again piecewise convex. Finally , that the meshwork as a function of all its parameters is piecewise multi-convex , a generalization of biconvexity. From here we characterize the local minima and stationary points of the preparation objective , showing that they minimize certain subsets of the parameter space. We then analyze the performance of two optimization algorithms on multi-convex trouble : gradient descent , and a method which repeatedly solves a number of convex sub-problems. We prove necessary convergence conditions for the first algorithm and both necessary and sufficient conditions for the second , after enter regularization to the objective. Finally , we remark on the remaining trouble of the global optimization problem. Under the squared error object lens , we show that by varying the training data , a single rectifier neuron admits local minima arbitrarily far apart , both in objective value and parameter space. ", "label": 1}
{"original_text": "This document serves to complement our website which was developed with the aim of exposing the students to Gaussian Processes (GPs). GPs are non-parametric bayesian regression models that are largely used by statisticians and geospatial data scientists for modeling spatial data. Several open source libraries spanning from Matlab , Python , R etc. are already available for simple plug-and-use. The objective of this handout and in turn the website was to allow the users to develop stand-alone GPs in Python by relying on minimal external dependencies. To this end, we only use the default python modules and assist the users in developing their own GPs from scratch giving them an in-depth knowledge of what goes on under the hood. The module covers GP inference using maximum likelihood estimation (MLE) and gives examples for 1D (dummy) spatial data.", "text_perturb": "This document serves to complement our website which was developed with the aim of exposing the students to gaussian Processes ( GPs ). GPs represent non-parametric bayesian regression models that represent largely used by statisticians and geospatial data scientists for modeling spatial data. Several open source libraries spanning from Matlab , python , R etc. are already available for simple plug-and-use. The objective of this handout and in turn the website was to allow the drug user to develop stand-alone GPs in Python by relying on minimal external dependencies. To this end , we only use the default python modules and assist the users in developing their own GPs from scratch giving them an in-depth knowledge of what goes on under the strong armer. The module cross GP inference using maximum likelihood estimation ( MLE ) and gives examples for 1D ( dummy ) spatial data. ", "label": 1}
{"original_text": "Multi-compartment modeling of diffusion-weighted magnetic resonance imaging measurements is necessary for accurate brain connectivity analysis. Existing methods for estimating the number and orientations of fascicles in an imaging voxel either depend on non-convex optimization techniques that are sensitive to initialization and measurement noise, or are prone to predicting spurious fascicles. In this paper, we propose a machine learning-based technique that can accurately estimate the number and orientations of fascicles in a voxel. Our method can be trained with either simulated or real diffusion-weighted imaging data. Our method estimates the angle to the closest fascicle for each direction in a set of discrete directions uniformly spread on the unit sphere. This information is then processed to extract the number and orientations of fascicles in a voxel. On realistic simulated phantom data with known ground truth, our method predicts the number and orientations of crossing fascicles more accurately than several existing methods. It also leads to more accurate tractography. On real data, our method is better than or compares favorably with standard methods in terms of robustness to measurement down-sampling and also in terms of expert quality assessment of tractography results.", "text_perturb": "Multi-compartment modeling of diffusion-weighted magnetic resonance imaging measurements is necessary for exact brain connectivity analysis. Existing methods for estimating the number and orientations of fascicles in an imaging voxel either depend on non-convex optimization techniques that are sensitive to initialization and measurement randomness , or are prone to predicting spurious fascicles. In this paper , we propose a machine learning-based technique that can accurately estimate the bit and orientations of fascicles in a voxel. Our method can be trained with either simulated or veridical diffusion-weighted imaging data. Our method acting estimates the angle to the closest fascicle for each direction in a set of discrete directions uniformly spread on the unit sphere. This information is then processed to educe the number and orientations of fascicles in a voxel. On realistic simulated phantom data with known ground truth , our method call the number and orientations of crossing fascicles more accurately than several existing methods. It also leads to more accurate tractography. On real data point , our method is better than or compares favorably with standard methods in terms of robustness to measurement down-sampling and also in terms of expert quality assessment of tractography results. ", "label": 1}
{"original_text": "We propose a two-layer cache mechanism to speed up dynamic WFST decoding with personalized language models. The first layer is a public cache that stores most of the static part of the graph. This is shared globally among all users. A second layer is a private cache that caches the graph that represents the personalized language model, which is only shared by the utterances from a particular user. We also propose two simple yet effective pre-initialization methods, one based on breadth-first search, and another based on a data-driven exploration of decoder states using previous utterances. Experiments with a calling speech recognition task using a personalized contact list demonstrate that the proposed public cache reduces decoding time by factor of three compared to decoding without pre-initialization. Using the private cache provides additional efficiency gains, reducing the decoding time by a factor of five.", "text_perturb": "We propose a two-layer memory cache mechanism to speed up dynamic WFST decoding with personalized language models. The first layer is a public cache that stores most of the static part of the graphical record. This represent shared globally among all users. A second layer is a private cache that caches the graph that represents the individualized language model , which is only shared by the utterances from a particular user. We also propose two simple yet effective pre-initialization methods , one based on breadth-first search , and another based on a data-driven exploration of decoder states using previous utterance. Experiments with a calling speech recognition task using a personalized contact list demonstrate that the proposed public cache reduces decode time by factor of three compared to decode without pre-initialization. apply the private cache provides additional efficiency gains , reducing the decoding time by a factor of five. ", "label": 1}
{"original_text": "There are over 1.2 million applications on the Google Play store today with a large number of competing applications for any given use or function. This creates challenges for users in selecting the right application. Moreover, some of the applications being of dubious origin, there are no mechanisms for users to understand who the applications are talking to, and to what extent. In our work, we first develop a lightweight characterization methodology that can automatically extract descriptions of application network behavior, and apply this to a large selection of applications from the Google App Store. We find several instances of overly aggressive communication with tracking websites, of excessive communication with ad related sites, and of communication with sites previously associated with malware activity. Our results underscore the need for a tool to provide users more visibility into the communication of apps installed on their mobile devices. To this end, we develop an Android application to do just this; our application monitors outgoing traffic, associates it with particular applications, and then identifies destinations in particular categories that we believe suspicious or else important to reveal to the end-user.", "text_perturb": "There personify over 1. 2 million applications on the Google Play store today with a large number of competing applications for any generate use or function. This creates challenge for users in selecting the right application. Moreover , some of the applications being of dubious origin , there represent no mechanisms for users to understand who the applications represent talking to , and to what extent. In our work , we first develop a lightweight characterization methodology that dismiss automatically extract descriptions of application network behavior , and apply this to a large selection of applications from the Google App Store. We find several instances of overly aggressive communication with tracking websites , of excessive communication with advertizing related sites , and of communication with sites previously associated with malware activity. Our results underscore the need for a tool to provide users more visibility into the communication of apps installed on their mobile gimmick. To this end , we develop an Android application to do precisely this ; our application monitors outgoing traffic , associates it with particular applications , and then identifies destinations in particular categories that we believe suspicious or else important to reveal to the end-user. ", "label": 1}
{"original_text": "Sorting, a classical combinatorial process, forms the bedrock of numerous algorithms with varied applications. A related problem involves efficiently finding the corresponding ranks of all the elements - catering to rank queries, data partitioning and allocation, etc. Although, the element ranks can be subsequently obtained by initially sorting the elements, such procedures involve O (n log n) computations and might not be suitable with large input sizes for hard real-time systems or for applications with data re-ordering constraints. This paper proposes S O N I K, a non-comparison linear time and space algorithm using bit operations inspired by radix sort for computing the ranks of all input integer elements, thereby providing implicit sorting. The element ranks are generated in-situ, i.e., directly at the corresponding element position without re-ordering or recourse to any other sorting mechanism.", "text_perturb": "Sorting , a classical combinatorial process , forms the basics of numerous algorithms with varied applications. A related to problem involves efficiently finding the corresponding ranks of all the elements - catering to rank queries , data partitioning and allocation , etc. Although , the element ranks can be subsequently obtained by initially sorting the elements , such procedures involve O ( n log n ) computations and might not be suitable with large input sizes for toilsome real-time systems or for applications with data re-ordering constraints. This paper proposes S O N I K , a non-comparison analog time and space algorithm using bit operations inspired by radix sort for computing the ranks of all input integer elements , thereby providing implicit sorting. The element ranks are generated unmoved , i. es. , directly at the corresponding element position without re-ordering or resort to any other sorting mechanism. ", "label": 1}
{"original_text": "An uplink system with a single antenna transmitter and a single receiver with a large number of antennas is considered. We propose an energy-detection-based single-shot noncoherent communication scheme which does not use the instantaneous channel state information (CSI), but rather only the knowledge of the channel statistics. The suggested system uses a transmitter that modulates information on the power of the symbols, and a receiver which measures only the average energy across the antennas. We propose constellation designs which are asymptotically optimal with respect to symbol error rate (SER) with an increasing number of antennas, for any finite signal to noise ratio (SNR) at the receiver, under different assumptions on the availability of CSI statistics (exact channel fading distribution or the first few moments of the channel fading distribution). We also consider the case of imperfect knowledge of the channel statistics and describe in detail the case when there is a bounded uncertainty on the moments of the fading distribution. We present numerical results on the SER performance achieved by these designs in typical scenarios and find that they may outperform existing noncoherent constellations, e.g., conventional Amplitude Shift Keying (ASK), and pilot-based schemes, e.g., Pulse Amplitude Modulation (PAM). We also observe that an optimized constellation for a specific channel distribution makes it very sensitive to uncertainties in the channel statistics. In particular, constellation designs based on optimistic channel conditions could lead to significant performance degradation in terms of the achieved symbol error rates.", "text_perturb": "An uplink system with a unmarried antenna transmitter and a unmarried receiver with a large number of antennas is considered. We propose an energy-detection-based single-shot noncoherent communication scheme which does non use the instantaneous channel state information ( CSI ) , but rather only the knowledge of the channel statistics. The suggested system uses a transmitter that modulates information on the might of the symbols , and a receiver which measures only the average energy across the antennas. We propose constellation designs which are asymptotically optimal with respect to symbol error rate ( SER ) with an increase number of antennas , for any finite signal to noise ratio ( SNR ) at the receiver , under different assumptions on the availability of CSI statistics ( exact channel fading distribution or the first few moments of the channel fading distribution ). We also consider the case of imperfect knowledge of the channel statistics and describe in contingent the case when there is a bounded uncertainty on the moments of the fading distribution. We present numerical results on the SER performance achieved by these designs in typical scenarios and find that they may outperform existing noncoherent constellation , e. gibibyte. , conventional Amplitude Shift Keying ( ASK ) , and pilot-based outline , e. k. , Pulse Amplitude modulation ( PAM ). We also observe that an optimized constellation for a specific channel distribution makes it very sensitive to precariousness in the channel statistics. In particular , constellation innovation based on optimistic channel conditions could lead to significant performance degradation in terms of the achieved symbol error rates. ", "label": 1}
{"original_text": "We investigate the automatic classification of patient discharge notes into standard disease labels. We find that Convolutional Neural Networks with Attention outperform previous algorithms used in this task, and suggest further areas for improvement.", "text_perturb": "We investigate the robotlike classification of patient discharge notes into standard disease labels. We find that Convolutional Neural Networks with Attention outperform previous algorithmic rule used in this task , and suggest further areas for improvement. ", "label": 1}
{"original_text": "We present a novel family of C 1 quadrilateral finite elements, which define global C 1 spaces over a general quadrilateral mesh with vertices of arbitrary valency. The elements extend the construction by Brenner and Sung, which is based on polynomial elements of tensor-product degree p 6, to all degrees p 3. Thus, we call the family of C 1 finite elements Brenner-Sung quadrilaterals. The proposed C 1 quadrilateral can be seen as a special case of the Argyris isogeometric element of. The quadrilateral elements possess similar degrees of freedom as the classical Argyris triangles. Just as for the Argyris triangle, we additionally impose C 2 continuity at the vertices. In this paper we focus on the lower degree cases, not covered in, that may be desirable for their lower computational cost and better conditioning of the basis: We consider indeed the polynomial quadrilateral of (bi degree 5, and the polynomial degrees p 3 and p 4 by employing a splitting into x 3 3 or x 2 2 polynomial pieces, respectively. The proposed elements reproduce polynomials of total degree p. We show that the space provides optimal approximation order. Due to the interpolation properties, the error bounds are local on each element. In addition, we describe the construction of a simple, local basis and give for p {3, 4, 5 } explicit formulas for the Bezier or B-spline coefficients of the basis functions. Numerical experiments by solving the biharmonic equation demonstrate the potential of the proposed C 1 quadrilateral finite element for the numerical analysis of fourth order problems, also indicating that (for p 5) the proposed element performs comparable or in general even better than the Argyris triangle with respect to the number of degrees of freedom.", "text_perturb": "We present a novel family of C 1 four sided finite elements , which define global C 1 spaces over a general four sided mesh with vertices of arbitrary valency. The ingredient extend the construction by Brenner and Sung , which is based on polynomial ingredient of tensor-product degree p 6 , to all degrees p 3. Thus , we call the family of carbon 1 finite elements Brenner-Sung quadrilaterals. The proposed C 1 quadrilateral can be seen as a special grammatical case of the Argyris isogeometric element of. The quadrilateral elements possess similar degrees of freedom as the authoritative Argyris triangles. Just as for the Argyris triangle , we additionally impose atomic number  2 continuity at the vertices. In this paper we focus on the lower degree cases , not covered in , that may be desirable for their lower computational cost and better conditioning of the basis : We see indeed the polynomial quadrilateral of ( bi degree 5 , and the polynomial degrees p 3 and p 4 by employing a splitting into x 3 3 or x 2 2 polynomial pieces , respectively. The proposed elements procreate polynomials of total degree p. We show that the space provides optimum approximation order. Due to the interpolation properties , the error bounds personify local on each element. In addition , we describe the construction of a simple , local basis and commit for p { 3 , 4 , 5 } explicit formulas for the Bezier or B-spline coefficients of the basis functions. Numerical experiment by solving the biharmonic equation demonstrate the potential of the proposed C 1 quadrilateral finite element for the numerical analysis of fourth order problems , also indicating that ( for p 5 ) the proposed element performs comparable or in general even better than the Argyris triangle with respect to the number of degrees of freedom. ", "label": 1}
{"original_text": "In the last decade, social media has evolved as one of the leading platform to create, share, or exchange information; it is commonly used as a way for individuals to maintain social connections. In this online digital world, people use to post texts or pictures to express their views socially and create user-user engagement through discussions and conversations. Thus, social media has established itself to bear signals relating to human behavior. One can easily design user characteristic network by scraping through someone's social media profiles. In this paper, we investigate the potential of social media in characterizing and understanding predominant drunk texters from the perspective of their social, psychological and linguistic behavior as evident from the content generated by them. Our research aims to analyze the behavior of drunk texters on social media and to contrast this with non-drunk texters. We use Twitter social media to obtain the set of drunk texters and non-drunk texters and show that we can classify users into these two respective sets using various psycholinguistic features with an overall average accuracy of 96.78 with very high precision and recall. Note that such an automatic classification can have far-reaching impact - (i) on health research related to addiction prevention and control, and (ii) in eliminating abusive and vulgar contents from Twitter, borne by the tweets of drunk texters.", "text_perturb": "In the last decade , social media consume evolved as one of the leading platform to create , share , or exchange information ; it is commonly used as a way for individuals to maintain social connections. In this online digital world , people expend to post texts or pictures to express their views socially and create user-user engagement through discussions and conversations. thus , social media has established itself to bear signals relating to human behavior. One can well design user characteristic network by scraping through someone 's social media profiles. In this newspaper , we investigate the potential of social media in characterizing and understanding predominant drunk texters from the perspective of their social , psychological and linguistic behavior as evident from the content generated by them. Our research aims to analyze the conduct of drunk texters on social media and to contrast this with non-drunk texters. We use Twitter social media to obtain the set of drunk texters and non-drunk texters and show that we can classify users into these two respective sets utilise various psycholinguistic features with an overall average accuracy of 96. 78 with very high precision and recollection. Note that such an automatic classification can have far-reaching impact - ( i ) on health research related to addiction prevention and control , and ( ii ) in eliminating scurrilous and vulgar contents from Twitter , borne by the tweets of drunk texters. ", "label": 1}
{"original_text": "Unlike nonconvex optimization, where gradient descent is guaranteed to converge to a local optimizer, algorithms for nonconvex-nonconcave minimax optimization can have topologically different solution paths: sometimes converging to a solution, sometimes never converging and instead following a limit cycle, and sometimes diverging. In this paper, we study the limiting behaviors of three classic minimax algorithms: gradient decent ascent (GDA), alternating gradient decent ascent (AGDA), and the extragradient method (EGM). Numerically, we observe that all of these limiting behaviors can arise in Generative Adversarial Networks (GAN) training. To explain these different behaviors, we study the high-order resolution continuous-time dynamics that correspond to each algorithm, which results in the sufficient (and almost necessary) conditions for the local convergence by each method. Moreover, this ODE perspective allows us to characterize the phase transition between these different limiting behaviors caused by introducing regularization in the problem instance.", "text_perturb": "Unlike nonconvex optimization , where gradient descent is guaranteed to converge to a local optimizer , algorithms for nonconvex-nonconcave minimax optimization can have topologically different solution paths : sometimes converging to a solution , sometimes never converging and instead following a point of accumulation cycle , and sometimes diverging. In this paper , we study the limiting behaviors of three classic minimax algorithms : gradient decent rise ( GDA ) , alternating gradient decent rise ( AGDA ) , and the extragradient method ( EGM ). Numerically , we observe that all of these limiting behaviors can arise in Generative Adversarial Networks ( GAN ) preparation. To explain these different behaviors , we study the high-order resolution continuous-time dynamics that correspond to each algorithm , which results in the sufficient ( and about necessary ) conditions for the local convergence by each method. Moreover , this ODE perspective allows us to characterize the phase transition between these different limiting behaviors caused by introducing regulation in the problem instance. ", "label": 1}
{"original_text": "The analysis and quantification of sequence complexity is an open problem frequently encountered when defining trajectory prediction benchmarks. In order to enable a more informative assembly of a data basis, an approach for determining a dataset representation in terms of a small set of distinguishable prototypical sub-sequences is proposed. The approach employs a spatial sequence alignment, which enables a following learning vector quantization (LVQ) stage. A first proof of concept on synthetically generated and real-world datasets shows the viability of the approach.", "text_perturb": "The analysis and quantification of sequence complexity is an open problem frequently encountered when fix trajectory prediction benchmarks. In order to enable a more informative assembly of a data basis , an approach for determining a dataset representation in terms of a small circle of distinguishable prototypical sub-sequences is proposed. The attack employs a spatial sequence alignment , which enables a following learning vector quantization ( LVQ ) stage. A first proof of concept on synthetically generated and real-world datasets shows the viability of the advance. ", "label": 1}
{"original_text": "Disjunctive Answer Set Programming (ASP) is a powerful declarative programming paradigm whose main decision problems are located on the second level of the polynomial hierarchy. Identifying tractable fragments and developing efficient algorithms for such fragments are thus important objectives in order to complement the sophisticated ASP systems available to date. Hard problems can become tractable if some problem parameter is bounded by a fixed constant; such problems are then called fixed-parameter tractable (FPT). While several FPT results for ASP exist, parameters that relate to directed or signed graphs representing the program at hand have been neglected so far. In this paper, we first give some negative observations showing that directed width measures on the dependency graph of a program do not lead to FPT results. We then consider the graph parameter of signed clique-width and present a novel dynamic programming algorithm that is FPT w.r.t. this parameter. Clique-width is more general than the well-known treewidth, and, to the best of our knowledge, ours is the first FPT algorithm for bounded clique-width for reasoning problems beyond SAT.", "text_perturb": "Disjunctive Answer Set Programming ( ASP ) is a powerful declarative programming paradigm whose main decision problems are turn up on the second level of the polynomial hierarchy. Identifying tractable fragments and developing efficient algorithms for such fragments are thus important objectives in order to complement the advanced ASP systems available to date. Hard problems can become tractable if some job parameter is bounded by a fixed constant ; such problems are then called fixed-parameter tractable ( FPT ). While various FPT results for ASP exist , parameters that relate to directed or signed graphs representing the program at hand have been neglected so far. In this paper , we first give some disconfirming observations showing that directed width measures on the dependency graph of a program do not lead to FPT results. We then look at the graph parameter of signed clique-width and present a novel dynamic programming algorithm that is FPT w. roentgen. thyroxin. this argument. Clique-width is more general than the well-known treewidth , and , to the salutary of our knowledge , ours is the first FPT algorithm for bounded clique-width for reasoning problems beyond SAT. ", "label": 1}
{"original_text": "In the domain of emergency management during hazard crises, having sufficient situational awareness information is critical. It requires capturing and integrating information from sources such as satellite images, local sensors and social media content generated by local people. A bold obstacle to capturing, representing and integrating such heterogeneous and diverse information is lack of a proper ontology which properly conceptualizes this domain, aggregates and unifies datasets. Thus, in this paper, we introduce empathi ontology which conceptualizes the core concepts concerning with the domain of emergency managing and planning of hazard crises. Although empathi has a coarse-grained view, it considers the necessary concepts and relations being essential in this domain. This ontology is available at", "text_perturb": "In the domain of emergency management during hazard crises , having sufficient situational awareness information is vital. It requires capturing and integrating information from sources such as satellite images , local sensors and social media depicted object generated by local people. A bluff obstacle to capturing , representing and integrating such heterogeneous and diverse information is lack of a proper ontology which properly conceptualizes this domain , aggregates and unifies datasets. Thus , in this paper , we introduce empathi ontology which conceptualizes the core concepts concerning with the domain of emergency managing and preparation of hazard crises. Although empathi has a coarse-grained view , it considers the necessary concepts and relations cost essential in this domain. This ontology is useable at", "label": 1}
{"original_text": "A novel method for distributed estimation of the frequency of power systems is introduced based on the cooperation between multiple measurement nodes. The proposed distributed widely linear complex Kalman filter (D-ACKF) and the distributed widely linear extended complex Kalman filter (D-AECKF) employ a widely linear state space and augmented complex statistics to deal with unbalanced system conditions and the generality complex signals, both second order circular (proper) and second order noncircular (improper). It is shown that the current, strictly linear, estimators are inadequate for unbalanced systems, a typical case in smart grids, as they do not account for either the noncircularity of Clarke's a b voltage in unbalanced conditions or the correlated nature of nodal disturbances. We illuminate the relationship between the degree of circularity of Clarke's voltage and system imbalance, and prove that the proposed widely linear estimators are optimal for such conditions, while also accounting for the correlated and noncircular nature of real-world nodal disturbances. Synthetic and real world case studies over a range of power system conditions illustrate the theoretical and practical advantages of the proposed methodology.", "text_perturb": "A novel method for distributed approximation of the frequency of power systems is introduced based on the cooperation between multiple measurement nodes. The proposed distributed widely linear complex Kalman filter ( D-ACKF ) and the distributed widely linear extended complex Kalman filter ( D-AECKF ) employ a widely linear state space and augmented complex statistics to deal with unbalanced system conditions and the generality complex signals , both nd order circular ( proper ) and nd order noncircular ( improper ). It is shown that the current , strictly linear , estimators are inadequate for unbalanced systems , a typical case in smart grids , as they do not account for either the noncircularity of Clarke 's a b voltage in unbalanced conditions or the correlated nature of nodal mental disturbance. We illuminate the relationship between the degree of circularity of Clarke 's voltage and system unbalance , and prove that the proposed widely linear estimators are optimal for such conditions , while also accounting for the correlated and noncircular nature of real-world nodal disturbances. Synthetic and real world case studies over a mountain chain of power system conditions illustrate the theoretical and practical advantages of the proposed methodology. ", "label": 1}
{"original_text": "Breast cancer screening is one of the most common radiological tasks with over 39 million exams performed each year. While breast cancer screening has been one of the most studied medical imaging applications of artificial intelligence, the development and evaluation of the algorithms are hindered due to the lack of well-annotated large-scale publicly available datasets. This is particularly an issue for digital breast tomosynthesis (DBT) which is a relatively new breast cancer screening modality. We have curated and made publicly available a large-scale dataset of digital breast tomosynthesis images. It contains 22,032 reconstructed DBT volumes belonging to 5,610 studies from 5,060 patients. This included four groups: (1) 5,129 normal studies, (2) 280 studies where additional imaging was needed but no biopsy was performed, (3) 112 benign biopsied studies, and (4) 89 studies with cancer. Our dataset included masses and architectural distortions which were annotated by two experienced radiologists. Additionally, we developed a single-phase deep learning detection model and tested it using our dataset to serve as a baseline for future research. Our model reached a sensitivity of 65 at 2 false positives per breast. Our large, diverse, and highly-curated dataset will facilitate development and evaluation of AI algorithms for breast cancer screening through providing data for training as well as common set of cases for model validation. The performance of the model developed in our study shows that the task remains challenging and will serve as a baseline for future model development. Keywords: digital breast tomosynthesis; deep learning; detection", "text_perturb": "Breast cancer screening is one of the most common radiological tasks with over 39 million exams execute each year. While breast cancer screening has been one of the most studied medical imaging applications of artificial word , the development and evaluation of the algorithms are hindered due to the lack of well-annotated large-scale publicly available datasets. This cost particularly an issue for digital breast tomosynthesis ( DBT ) which cost a relatively new breast cancer screening modality. We possess curated and made publicly available a large-scale dataset of digital breast tomosynthesis images. It contains 22,032 reconstructed DBT volumes belonging to 5,610 survey from 5,060 patients. This included four groups : ( 1 ) 5,129 normal studies , ( 2 ) 280 studies where additional mental imagery was needed but no biopsy was performed , ( 3 ) 112 benign biopsied studies , and ( 4 ) 89 studies with cancer. Our dataset included masses and architectural deformation which were annotated by two experienced radiologists. Additionally , we developed a single-phase deep learning detection modelling and tested it using our dataset to serve as a baseline for future research. Our model reached a sensitivity of 65 at 2 false positive per breast. Our large , diverse , and highly-curated dataset will facilitate development and evaluation of AI algorithms for breast cancer screen through providing data for training as well as common set of cases for model validation. The performance of the model developed in our study shows that the task remains challenging and will wait on as a baseline for future model development. Keywords : digital breast tomosynthesis ; deep learning ; detection", "label": 1}
{"original_text": "Synergistic interactions are ubiquitous in the real world. Recent studies have revealed that, for a single-layer network, synergy can enhance spreading and even induce an explosive contagion. There is at the present a growing interest in behavior spreading dynamics on multiplex networks. What is the role of synergistic interactions in behavior spreading in such networked systems? To address this question, we articulate a synergistic behavior spreading model on a double layer network, where the key manifestation of the synergistic interactions is that the adoption of one behavior by a node in one layer enhances its probability of adopting the behavior in the other layer. A general result is that synergistic interactions can greatly enhance the spreading of the behaviors in both layers. A remarkable phenomenon is that the interactions can alter the nature of the phase transition associated with behavior adoption or spreading dynamics. In particular, depending on the transmission rate of one behavior in a network layer, synergistic interactions can lead to a discontinuous (first-order) or a continuous (second-order) transition in the adoption scope of the other behavior with respect to its transmission rate. A surprising two-stage spreading process can arise: due to synergy, nodes having adopted one behavior in one layer adopt the other behavior in the other layer and then prompt the remaining nodes in this layer to quickly adopt the behavior. Analytically, we develop an edge-based compartmental theory and perform a bifurcation analysis to fully understand, in the weak synergistic interaction regime where the dynamical correlation between the network layers is negligible, the role of the interactions in promoting the social behavioral spreading dynamics in the whole system.", "text_perturb": "synergistic interactions are ubiquitous in the real world. Recent studies have uncover that , for a single-layer network , synergy can enhance spreading and even induce an explosive contagion. There is at the present a growing interest in behavior go around dynamics on multiplex networks. What is the role of synergistic interactions in behavior spreading in such networked system of rules ? To address this question , we articulate a synergistic behavior spreading model on a double layer network , where the key manifestation of the synergistic interactions is that the adoption of one behavior by a node in one layer enhances its probability of adopting the behavior in the other layer. A general result is that synergistic interactions can greatly enhance the spreading of the doings in both layers. A remarkable phenomenon is that the interactions can alter the nature of the phase passage associated with behavior adoption or spreading dynamics. In particular , depending on the transmission rate of one behavior in a network layer , synergistic interactions can lead to a discontinuous ( first-order ) or a continuous ( second-order ) transition in the borrowing scope of the other behavior with respect to its transmission rate. A surprising two-stage spreading process can arise : due to synergy , nodes having adopted one behavior in one layer adopt the former behavior in the former layer and then prompt the remaining nodes in this layer to quickly adopt the behavior. Analytically , we develop an edge-based compartmental theory and perform a bifurcation analysis to fully understand , in the weak synergistic interaction regime where the dynamical correlation between the network layers is negligible , the role of the interactions in promoting the social behavioral overspread dynamics in the whole system. ", "label": 1}
{"original_text": "The task of event detection and classification is central to most information retrieval applications. We show that a Transformer based architecture can effectively model event extraction as a sequence labeling task. We propose a combination of sentence level and token level training objectives that significantly boosts the performance of a BERT based event extraction model. Our approach achieves a new state-of-the-art performance on ACE 2005 data for English and Chinese. We also test our model on ERE Spanish, achieving an average gain of 2 absolute F 1 points over prior best performing models.", "text_perturb": "The task of event detection and categorization is central to most information retrieval applications. We show that a Transformer based computer architecture can effectively model event extraction as a sequence labeling task. We propose a combination of sentence level and token level education objectives that significantly boosts the performance of a BERT based event extraction model. Our approach achieves a new state-of-the-art performance on ACE 2005 data for english and Chinese. We also test our poser on ERE Spanish , achieving an average gain of 2 absolute F 1 points over prior best performing models. ", "label": 1}
{"original_text": "This paper explores feedback systems using incremental redundancy (IR) with noiseless transmitter confirmation (NTC). For IR-NTC systems based on finite-length codes (with blocklength N) and decoding attempts only at certain specified decoding times, this paper presents the asymptotic expansion achieved by random coding, provides rate-compatible sphere-packing (RCSP) performance approximations, and presents simulation results of tail-biting convolutional codes. The information-theoretic analysis shows that values of N relatively close to the expected latency yield the same random-coding achievability expansion as with N . However, the penalty introduced in the expansion by limiting decoding times is linear in the interval between decoding times. For binary symmetric channels, the RCSP approximation provides an efficiently-computed approximation of performance that shows excellent agreement with a family of rate-compatible, tail-biting convolutional codes in the short-latency regime. For the additive white Gaussian noise channel, bounded-distance decoding simplifies the computation of the marginal RCSP approximation and produces similar results as analysis based on maximum-likelihood decoding for latencies greater than 200. The efficiency of the marginal RCSP approximation facilitates optimization of the lengths of incremental transmissions when the number of incremental transmissions is constrained to be small or the length of the incremental transmissions is constrained to be uniform after the first transmission. Finally, an RCSP-based decoding error trajectory is introduced that provides target error rates for the design of rate-compatible code families for use in feedback communication systems.", "text_perturb": "This paper explores feedback systems using incremental redundancy ( IR ) with noiseless transmitter substantiation ( NTC ). For IR-NTC systems based on finite-length computer code ( with blocklength N ) and decoding attempts only at certain specified decoding times , this paper presents the asymptotic expansion achieved by random coding , provides rate-compatible sphere-packing ( RCSP ) performance approximations , and presents simulation results of tail-biting convolutional computer code. The information-theoretic analysis shows that values of N relatively close to the expected latency give the same random-coding achievability expansion as with N. however , the penalty introduced in the expansion by limiting decoding times is linear in the interval between decoding times. For binary symmetric channels , the RCSP approximation provides an efficiently-computed approximation of performance that shows fantabulous agreement with a family of rate-compatible , tail-biting convolutional codes in the short-latency regime. For the additive white Gaussian noise channel , bounded-distance decoding simplifies the computation of the marginal RCSP estimate and produces similar results as analysis based on maximum-likelihood decoding for latencies greater than 200. The efficiency of the marginal RCSP approximation facilitates optimization of the lengths of incremental transmissions when the number of incremental transmissions is encumber to be small or the length of the incremental transmissions is encumber to be uniform after the first transmission. Finally , an RCSP-based decoding error trajectory is introduced that provides target error rates for the design of rate-compatible code family for use in feedback communication systems. ", "label": 1}
{"original_text": "The concept of nestedness, in particular for ecological and economical networks, has been introduced as a structural characteristic of real interacting systems. We suggest that the nestedness is in fact another way to express a mesoscale network property called the core-periphery structure. With real ecological mutualistic networks and synthetic model networks, we reveal the strong correlation between the nestedness and core-periphery-ness (likeness to the core-periphery structure), by defining the network-level measures for nestedness and core-periphery-ness in the case of weighted and bipartite networks. However, at the same time, via more sophisticated null-model analysis, we also discover that the degree (the number of connected neighbors of a node) distribution poses quite severe restrictions on the possible nestedness and core-periphery-ness parameter space. Therefore, there must exist structurally interwoven properties in more fundamental levels of network formation, behind this seemingly obvious relation between nestedness and core-periphery structures.", "text_perturb": "The concept of nestedness , in particular for ecological and economical networks , has been introduced as a structural characteristic of real interact systems. We indicate that the nestedness is in fact another way to express a mesoscale network property called the core-periphery structure. With real ecological mutualistic networks and synthetic model networks , we discover the strong correlation between the nestedness and core-periphery-ness ( likeness to the core-periphery structure ) , by defining the network-level measures for nestedness and core-periphery-ness in the case of weighted and bipartite networks. However , at the like time , via more sophisticated null-model analysis , we also discover that the degree ( the number of connected neighbors of a node ) distribution poses quite severe restrictions on the possible nestedness and core-periphery-ness parameter space. so , there must exist structurally interwoven properties in more fundamental levels of network formation , behind this seemingly obvious relation between nestedness and core-periphery structures. ", "label": 1}
{"original_text": "The contemporary literature on cloud resource allocation is mostly focused on studying the interactions between customers and cloud managers. Nevertheless, the recent growth in the customers' demands and the emergence of private cloud providers (CPs) entice the cloud managers to rent extra resources from the CPs so as to handle their backlogged tasks and attract more customers. This also makes studying the interactions between the cloud managers and the CPs essential. In this paper, we investigate both of the mentioned interactions. For the interactions between customers and cloud managers, we adopt the options-based sequential auctions (OBSAs) to the cloud resource allocation paradigm. As compared to existing works, our framework can handle customers with heterogeneous demands, provide truthfulness as the dominant strategy, enjoy a simple winner determination, and preclude the delayed entrance issue. We also provide the performance analysis of the OBSAs, which is among the first in literature. For the interactions between cloud managers and CPs, we propose an auction-based scheme for resource gathering. Through incorporating the offered prices, we capture the heterogeneous desires of the CPs in leasing their resources. We conduct a comprehensive mathematical analysis of the two markets and identify the bidding strategy of the cloud managers.", "text_perturb": "The contemporary literature on cloud resource allocation is mostly focused on studying the interactions between customers and swarm managers. Nevertheless , the recent growth in the customers ' demands and the egression of private cloud providers ( CPs ) entice the cloud managers to rent extra resources from the CPs so as to handle their backlogged tasks and attract more customers. This also relieve oneself studying the interactions between the cloud managers and the CPs essential. In this paper , we investigate both of the mentioned interaction. For the interactions between customers and cloud managers , we adopt the options-based sequential auctions ( OBSAs ) to the cloud resource allocation image. As compared to existing works , our framework can handle customers with heterogeneous demands , provide truthfulness as the prevalent strategy , enjoy a simple winner determination , and preclude the delayed entrance issue. We also provide the performance analysis of the OBSAs , which is among the first in lit. For the interactions between cloud managers and CPs , we advise an auction-based scheme for resource gathering. Through contain the offered prices , we capture the heterogeneous desires of the CPs in leasing their resources. We conduct a comprehensive mathematical analysis of the two markets and identify the bidding strategy of the swarm managers. ", "label": 1}
{"original_text": "We present a polynomial-space algorithm that computes the number of independent sets of any input graph in time O (1.1389 n) for graphs with maximum degree 3 and in time O (1.2356 n) for general graphs, where n is the number of vertices. Together with the inclusion-exclusion approach of Bjorklund, Husfeldt, and Koivisto [SIAM J. Comput. 2009], this leads to a faster polynomial-space algorithm for the graph coloring problem with running time O (2.2356 n). As a byproduct, we also obtain an exponential-space O (1.2330 n) time algorithm for counting independent sets. Our main algorithm counts independent sets in graphs with maximum degree 3 and no vertex with three neighbors of degree 3. This polynomial-space algorithm is analyzed using the recently introduced Separate, Measure and Conquer approach [Gaspers Sorkin, ICALP 2015]. Using Wahlstrom's compound measure approach, this improvement in running time for small degree graphs is then bootstrapped to larger degrees, giving the improvement for general graphs. Combining both approaches leads to some inflexibility in choosing vertices to branch on for the small-degree cases, which we counter by structural graph properties. The main complication is to upper bound the number of times the algorithm has to branch on vertices all of whose neighbors have degree 2, while still decreasing the size of the separator each time the algorithm branches.", "text_perturb": "We present a polynomial-space algorithm that computes the number of independent sets of any stimulation graph in time O ( 1. 1389 newton ) for graphs with maximum degree 3 and in time O ( 1. 2356 n ) for ecumenical graphs , where n is the number of vertices. Together with the inclusion-exclusion approach of Bjorklund , Husfeldt , and Koivisto [ SIAM j. Comput. 2009 ] , this leads to a faster polynomial-space algorithm for the graph coloring problem with tend time O ( 2. 2356 north ). As a byproduct , we too obtain an exponential-space O ( 1. 2330 n ) clock time algorithm for counting independent sets. Our chief algorithm counts independent sets in graphs with maximum degree 3 and no vertex with three neighbors of degree 3. This polynomial-space algorithm equal analyzed using the recently introduced Separate , Measure and Conquer approach [ Gaspers Sorkin , ICALP 2015 ]. Using Wahlstrom 's compound measure approach , this improvement in running time for small arcdegree graphs is then bootstrapped to larger degrees , giving the improvement for general graphs. Combining both approaches leads to some inflexibility in choosing vertices to furcate on for the small-degree cases , which we counter by structural graph properties. The main complication is to upper bound the number of fourth dimension the algorithm has to branch on vertices all of whose neighbors have degree 2 , while still decreasing the size of the separator each time the algorithm branches. ", "label": 1}
{"original_text": "Evolving graphs arise in problems where interrelations between data change over time. We present a breadth first search (BFS) algorithm for evolving graphs that computes the most direct influences between nodes at two different times. Using simple examples, we show that naive unfoldings of adjacency matrices miscount the number of temporal paths. By mapping an evolving graph to an adjacency matrix of an equivalent static graph, we prove that our generalization of the BFS algorithm correctly accounts for paths that traverse both space and time. Finally, we demonstrate how the BFS over evolving graphs can be applied to mine citation networks.", "text_perturb": "Evolving graphs arise in problems where interrelatedness between data change over time. We present a breadth first search ( BFS ) algorithm for evolving graphs that computes the most lineal influences between nodes at two different times. Using simple examples , we usher that naive unfoldings of adjacency matrices miscount the number of temporal paths. By mapping an evolving graph to an adjacency matrix of an equivalent static graph , we prove that our generalization of the BFS algorithm correctly accounts for paths that traverse both quad and time. Finally , we demonstrate how the BFS over evolving graphs can equal applied to mine citation networks. ", "label": 1}
{"original_text": "We design and implement an end-to-end system for real-time crime detection in low-light environments. Unlike Closed-Circuit Television, which performs reactively, the Low-Light Environment Neural Surveillance provides real time crime alerts. The system uses a low-light video feed processed in real-time by an optical-flow network, spatial and temporal networks, and a Support Vector Machine to identify shootings, assaults, and thefts. We create a low-light action-recognition dataset, LENS-4, which will be publicly available. An IoT infrastructure set up via Amazon Web Services interprets messages from the local board hosting the camera for action recognition and parses the results in the cloud to relay messages. The system achieves 71.5 accuracy at 20 FPS. The user interface is a mobile app which allows local authorities to receive notifications and to view a video of the crime scene. Citizens have a public app which enables law enforcement to push crime alerts based on user proximity.", "text_perturb": "We project and implement an end-to-end system for real-time crime detection in low-light environments. Unlike Closed-Circuit Television , which performs reactively , the Low-Light surroundings Neural Surveillance provides real time crime alerts. The organization uses a low-light video feed processed in real-time by an optical-flow network , spatial and temporal networks , and a Support Vector Machine to identify shootings , assaults , and thefts. We create a low-light action-recognition dataset , LENS-4 , which will comprise publicly available. An IoT infrastructure set up via Amazon Web Services interprets message from the local board hosting the camera for action recognition and parses the results in the cloud to relay messages. The system attain 71. 5 truth at 20 FPS. The user interface is a mobile app which allows local authorities to obtain notifications and to view a video of the crime scene. Citizens throw a public app which enables law enforcement to push crime alerts based on user proximity. ", "label": 1}
{"original_text": "Many clustering algorithms exist that estimate a cluster centroid, such as K -means, K -medoids or mean-shift, but no algorithm seems to exist that clusters data by returning exactly K meaningful modes. We propose a natural definition of a K -modes objective function by combining the notions of density and cluster assignment. The algorithm becomes K -means and K -medoids in the limit of very large and very small scales. Computationally, it is slightly slower than K -means but much faster than mean-shift or K -medoids. Unlike K -means, it is able to find centroids that are valid patterns, truly representative of a cluster, even with nonconvex clusters, and appears robust to outliers and misspecification of the scale and number of clusters.", "text_perturb": "Many clustering algorithms exist that estimate a bunch centroid , such as K -means , K -medoids or mean-shift , but no algorithm seems to exist that clusters data by returning exactly K meaningful modes. We propose a natural definition of a K -modes objective function by combining the notions of density and cluster naming. The algorithm becomes K -means and K -medoids in the limit of very large and very small musical scale. computationally , it is slightly slower than K -means but much faster than mean-shift or K -medoids. Unlike K -means , it is able to find centroids that are valid patterns , truly representative of a cluster , even with nonconvex clusters , and come out robust to outliers and misspecification of the scale and number of clusters. ", "label": 1}
{"original_text": "As light field images continue to increase in use and application, it becomes necessary to adapt existing image processing methods to this unique form of photography. In this paper we explore methods for applying neural style transfer to light field images. Feed-forward style transfer networks provide fast, high-quality results for monocular images, but no such networks exist for full light field images. Because of the size of these images, current light field data sets are small and are insufficient for training purely feed-forward style-transfer networks from scratch. Thus, it is necessary to adapt existing monocular style transfer networks in a way that allows for the stylization of each view of the light field while maintaining visual consistencies between views. To do this, we first generate disparity maps for each view given a single depth image for the light field. Then in a fashion similar to neural stylization of stereo images, we use disparity maps to enforce a consistency loss between views and to warp feature maps during the feed forward stylization. Unlike previous work, however, light fields have too many views to train a purely feed-forward network that can stylize the entire light field with angular consistency. Instead, the proposed method uses an iterative optimization for each view of a single light field image that backpropagates the consistency loss through the network. Thus, the network architecture allows for the incorporation of pre-trained fast monocular stylization network while avoiding the need for a large light field training set.", "text_perturb": "As light field images continue to increase in use and applications programme , it becomes necessary to adapt existing image processing methods to this unique form of photography. In this paper we explore methods for applying neural style transferral to light field images. Feed-forward style transfer networks provide fast , high-quality results for monocular images , but no such networks exist for full light discipline images. Because of the size of these images , current light field data sets are small and are insufficient for training purely feed-forward style-transfer meshing from scratch. Thus , it personify necessary to adapt existing monocular style transfer networks in a way that allows for the stylization of each view of the light field while maintaining visual consistencies between views. To do this , we first generate disparity function for each view given a single depth image for the light field. Then in a fashion like to neural stylization of stereo images , we use disparity maps to enforce a consistency loss between views and to warp feature maps during the feed forward stylization. Unlike previous work , however , light fields have to a fault many views to train a purely feed-forward network that can stylize the entire light field with angular consistency. Instead , the proposed method uses an iterative optimization for each view of a single light field image that backpropagates the consistency loss through the web. Thus , the web architecture allows for the incorporation of pre-trained fast monocular stylization web while avoiding the need for a large light field training set. ", "label": 1}
{"original_text": "Consider a collaborative task carried out by two autonomous agents that can communicate over a noisy channel. Each agent is only aware of its own state, while the accomplishment of the task depends on the value of the joint state of both agents. As an example, both agents must simultaneously reach a certain location of the environment, while only being aware of their own positions. Assuming the presence of feedback in the form of a common reward to the agents, a conventional approach would apply separately: (i) an off-the-shelf coding and decoding scheme in order to enhance the reliability of the communication of the state of one agent to the other; and (ii) a standard multi-agent reinforcement learning strategy to learn how to act in the resulting environment. In this work, it is argued that the performance of the collaborative task can be improved if the agents learn how to jointly communicate and act. In particular, numerical results for a baseline grid world example demonstrate that the jointly learned policy carries out compression and unequal error protection by leveraging information about the action policy.", "text_perturb": "Consider a collaborative task carried out by two autonomous agents that force out communicate over a noisy channel. Each agent is only aware of its own state , while the accomplishment of the task depend on the value of the joint state of both agents. As an example , both agents must at the same time reach a certain location of the environment , while only being aware of their own positions. Assuming the presence of feedback in the form of a common reward to the agents , a conventional approach would apply separately : ( i ) an off-the-shelf coding and decode scheme in order to enhance the reliability of the communication of the state of one agent to the other ; and ( ii ) a standard multi-agent reinforcement learning strategy to learn how to act in the resulting environment. In this work , it is fence that the performance of the collaborative task can be improved if the agents learn how to jointly communicate and act. In particular , numerical results for a baseline grid world example demonstrate that the jointly learned policy carries out concretion and unequal error protection by leveraging information about the action policy. ", "label": 1}
{"original_text": "Encoding a sequence of observations is an essential task with many applications. The encoding can become highly efficient when the observations are generated by a dynamical system. A dynamical system imposes regularities on the observations that can be leveraged to achieve a more efficient code. We propose a method to encode a given or learned dynamical system. Apart from its application for encoding a sequence of observations, we propose to use the compression achieved by this encoding as a criterion for model selection. Given a dataset, different learning algorithms result in different models. But not all learned models are equally good. We show that the proposed encoding approach can be used to choose the learned model which is closer to the true underlying dynamics. We provide experiments for both encoding and model selection, and theoretical results that shed light on why the approach works.", "text_perturb": "Encoding a sequence of watching is an essential task with many applications. The encoding can become highly effective when the observations are generated by a dynamical system. A dynamical system imposes geometrical regularity on the observations that can be leveraged to achieve a more efficient code. We propose a method to encode a dedicate or learned dynamical system. Apart from its application for encoding a sequence of observations , we propose to use the compression achieved by this encoding as a criterion for mannikin selection. Given a dataset , different memorise algorithms result in different models. But not all learned models cost equally good. We show that the proposed encoding approaching can be used to choose the learned model which is closer to the true underlying dynamics. We provide experiments for both encoding and model selection , and theoretical results that shed light on why the overture works. ", "label": 1}
{"original_text": "As inertial and visual sensors are becoming ubiquitous, visual-inertial navigation systems (VINS) have prevailed in a wide range of applications from mobile augmented reality to aerial navigation to autonomous driving, in part because of the complementary sensing capabilities and the decreasing costs and size of the sensors. In this paper, we survey thoroughly the research efforts taken in this field and strive to provide a concise but complete review of the related work - which is unfortunately missing in the literature while being greatly demanded by researchers and engineers - in the hope to accelerate the VINS research and beyond in our society as a whole.", "text_perturb": "As inertial and visual sensors are becoming ubiquitous , visual-inertial navigation systems ( VINS ) have prevailed in a wide range of applications from mobile augmented reality to aerial navigation to autonomous drive , in part because of the complementary sensing capabilities and the decreasing costs and size of the sensors. In this paper , we survey thoroughly the research efforts taken in this field and strive to provide a concise but complete review of the related work - which is unfortunately missing in the literature while being greatly demanded by researchers and locomotive engineer - in the hope to accelerate the VINS research and beyond in our society as a whole. ", "label": 1}
{"original_text": "Many sensors, such as range, sonar, radar, GPS and visual devices, produce measurements which are contaminated by outliers. This problem can be addressed by using fat-tailed sensor models, which account for the possibility of outliers. Unfortunately, all estimation algorithms belonging to the family of Gaussian filters (such as the widely-used extended Kalman filter and unscented Kalman filter) are inherently incompatible with such fat-tailed sensor models. The contribution of this paper is to show that any Gaussian filter can be made compatible with fat-tailed sensor models by applying one simple change: Instead of filtering with the physical measurement, we propose to filter with a pseudo measurement obtained by applying a feature function to the physical measurement. We derive such a feature function which is optimal under some conditions. Simulation results show that the proposed method can effectively handle measurement outliers and allows for robust filtering in both linear and nonlinear systems.", "text_perturb": "Many sensors , such as range , sonar , radar , GPS and visual devices , produce measure which are contaminated by outliers. This problem can be addressed by using fat-tailed detector models , which account for the possibility of outliers. Unfortunately , all estimation algorithms belonging to the family of gaussian filters ( such as the widely-used extended Kalman filter and unscented Kalman filter ) are inherently incompatible with such fat-tailed sensor models. The contribution of this paper is to show that any Gaussian filter can be made compatible with fat-tailed sensor model by applying one simple change : Instead of filtering with the physical measurement , we propose to filter with a pseudo measurement obtained by applying a feature function to the physical measurement. We derive such a feature function which is optimum under some conditions. Simulation results show that the purport method can effectively handle measurement outliers and allows for robust filtering in both linear and nonlinear systems. ", "label": 1}
{"original_text": "Due to their simple construction, LFSRs are commonly used as building blocks in various random number generators. Nonlinear feedforward logic is incorporated in LFSRs to increase the linear complexity of the generated sequence. In this work, we extend the idea of nonlinear feedforward logic to LFSRs over arbitrary finite fields and analyze the statistical properties of the generated sequences. Further, we propose a method of applying nonlinear feedforward logic to word-based s -LFSRs and show that the proposed scheme generates vector sequences that are statistically more balanced than those generated by an existing scheme.", "text_perturb": "Due to their simple construction , LFSRs are commonly used as building stop in various random number generators. Nonlinear feedforward system of logic is incorporated in LFSRs to increase the linear complexity of the generated sequence. In this work , we extend the idea of nonlinear feedforward logical system to LFSRs over arbitrary finite fields and analyze the statistical properties of the generated sequences. Further , we propose a method of applying nonlinear feedforward logic to word-based s -LFSRs and show that the project scheme generates vector sequences that are statistically more balanced than those generated by an existing scheme. ", "label": 1}
{"original_text": "The consequences of anthropogenic climate change are extensively debated through scientific papers, newspaper articles, and blogs. Newspaper articles may lack accuracy, while the severity of findings in scientific papers may be too opaque for the public to understand. Social media, however, is a forum where individuals of diverse backgrounds can share their thoughts and opinions. As consumption shifts from old media to new, Twitter has become a valuable resource for analyzing current events and headline news. In this research, we analyze tweets containing the word \"climate\" collected between September 2008 and July 2014. Through use of a previously developed sentiment measurement tool called the Hedonometer, we determine how collective sentiment varies in response to climate change news, events, and natural disasters. We find that natural disasters, climate bills, and oil-drilling can contribute to a decrease in happiness while climate rallies, a book release, and a green ideas contest can contribute to an increase in happiness. Words uncovered by our analysis suggest that responses to climate change news are predominately from climate change activists rather than climate change deniers, indicating that Twitter is a valuable resource for the spread of climate change awareness.", "text_perturb": "The moment of anthropogenic climate change are extensively debated through scientific papers , newspaper articles , and blogs. Newspaper articles may lack accuracy , while the severity of findings in scientific papers may represent too opaque for the public to understand. Social media , however , equal a forum where individuals of diverse backgrounds can share their thoughts and opinions. As consumption shifts from old media to new , Twitter induce become a valuable resource for analyzing current events and headline news. In this research , we analyze tweets containing the word `` climate '' collected between September 2008 and july 2014. Through use of a previously developed sentiment measurement tool called the Hedonometer , we determine how collective sentiment varies in response to climate change newsworthiness , events , and natural disasters. We find that natural disasters , climate bills , and oil-drilling terminate contribute to a decrease in happiness while climate rallies , a book release , and a green ideas contest terminate contribute to an increase in happiness. Words uncovered by our analysis suggest that responses to climate change news are predominately from climate change activists rather than climate change deniers , indicating that chirrup is a valuable resource for the spread of climate change awareness. ", "label": 1}
{"original_text": "In this paper, the authors aim to combine the latest state of the art models in image recognition with the best publicly available satellite images to create a system for landslide risk mitigation. We focus first on landslide detection and further propose a similar system to be used for prediction. Such models are valuable as they could easily be scaled up to provide data for hazard evaluation, as satellite imagery becomes increasingly available. The goal is to use satellite images and correlated data to enrich the public repository of data and guide disaster relief efforts for locating precise areas where landslides have occurred. Different image augmentation methods are used to increase diversity in the chosen dataset and create more robust classification. The resulting outputs are then fed into variants of 3-D convolutional neural networks. A review of the current literature indicates there is no research using CNNs (Convolutional Neural Networks) and freely available satellite imagery for classifying landslide risk. The model has shown to be ultimately able to achieve a significantly better than baseline accuracy.", "text_perturb": "In this paper , the authors aim to combine the latest state of the artistry models in image recognition with the best publicly available satellite images to create a system for landslide risk mitigation. We focus first on landslide signal detection and further propose a similar system to be used for prediction. Such models are valuable as they could easily be scaled up to provide data for hazard evaluation , as satellite imagery becomes increasingly usable. The goal is to use satellite images and correlated data to enrich the public repository of data and guide disaster relief efforts for locating precise areas where landslip have occurred. Different image augmentation methods are used to increase diversity in the chosen dataset and make more robust classification. The resulting outputs make up then fed into variants of 3-D convolutional neural networks. A recapitulation of the current literature indicates there is no research using CNNs ( Convolutional Neural Networks ) and freely available satellite imagery for classifying landslide risk. The model has shew to be ultimately able to achieve a significantly better than baseline accuracy. ", "label": 1}
{"original_text": "Recent transient-execution attacks, such as RIDL, Fallout, and ZombieLoad, demonstrated that attackers can leak information while it transits through microarchitectural buffers. Named Microarchitectural Data Sampling (MDS) by Intel, these attacks are likened to \"drinking from the firehose,\" as the attacker has little control over what data is observed and from what origin. Unable to prevent the buffers from leaking, Intel issued countermeasures via microcode updates that overwrite the buffers when the CPU changes security domains. In this work we present CacheOut, a new microarchitectural attack that is capable of bypassing Intel's buffer overwrite countermeasures. We observe that as data is being evicted from the CPU's L1 cache, it is often transferred back to the leaky CPU buffers where it can be recovered by the attacker. CacheOut improves over previous MDS attacks by allowing the attacker to choose which data to leak from the CPU's L1 cache, as well as which part of a cache line to leak. We demonstrate that CacheOut can leak information across multiple security boundaries, including those between processes, virtual machines, user and kernel space, and from SGX enclaves.", "text_perturb": "Recent transient-execution attacks , such as RIDL , Fallout , and ZombieLoad , demonstrated that attackers can leak data while it transits through microarchitectural buffers. Named Microarchitectural Data Sampling ( MDS ) by Intel , these attacks are likened to `` drinking from the firehose , '' as the attacker make little control over what data is observed and from what origin. Unable to prevent the buffers from leaking , Intel issued countermeasures via microcode updates that overwrite the buffers when the CPU modification security domains. In this body of work we present CacheOut , a new microarchitectural attack that is capable of bypassing Intel 's buffer overwrite countermeasures. We observe that as data is being evicted from the CPU 's L1 cache , it is often transferred back to the leaky CPU buffers where it can be recovered by the assaulter. CacheOut improves over former MDS attacks by allowing the attacker to choose which data to leak from the CPU 's L1 cache , as well as which part of a cache line to leak. We demonstrate that CacheOut can leak information across multiple security boundaries , including those between processes , virtual machines , drug user and kernel space , and from SGX enclaves. ", "label": 1}
{"original_text": "While large scale pre-trained language models such as BERT have achieved great success on various natural language understanding tasks, how to efficiently and effectively incorporate them into sequence-to-sequence models and the corresponding text generation tasks remains a non-trivial problem. In this paper, we propose to address this problem by taking two different BERT models as the encoder and decoder respectively, and fine-tuning them by introducing simple and lightweight adapter modules, which are inserted between BERT layers and tuned on the task-specific dataset. In this way, we obtain a flexible and efficient model which is able to jointly leverage the information contained in the source-side and target-side BERT models, while bypassing the catastrophic forgetting problem. Each component in the framework can be considered as a plug-in unit, making the framework flexible and task agnostic. Our framework is based on a parallel sequence decoding algorithm named Mask-Predict considering the bi-directional and conditional independent nature of BERT, and can be adapted to traditional autoregressive decoding easily. We conduct extensive experiments on neural machine translation tasks where the proposed method consistently outperforms autoregressive baselines while reducing the inference latency by half, and achieves 36.49 33.57 BLEU scores on IWSLT14 German-EnglishWMT14 German-English translation. When adapted to autoregressive decoding, the proposed method achieves 30.60 43.56 BLEU scores on WMT14 English-GermanEnglish-French translation, on par with the state-of-the-art baseline models.", "text_perturb": "While large scale pre-trained voice communication models such as BERT have achieved great success on various natural voice communication understanding tasks , how to efficiently and effectively incorporate them into sequence-to-sequence models and the corresponding text generation tasks remains a non-trivial problem. In this paper , we propose to address this problem by taking two different BERT models as the encoder and decoder respectively , and fine-tuning them by introducing simple and lightweight adapter modules , which are inserted between BERT layers and tune up on the task-specific dataset. In this way , we obtain a flexible and efficient model which is able to jointly leverage the information contained in the source-side and target-side BERT framework , while bypassing the catastrophic forgetting problem. Each component in the framework can be considered as a plug-in unit , making the framework pliant and task agnostic. Our framework is based on a parallel sequence decoding algorithm named Mask-Predict considering the bi-directional and conditional independent nature of BERT , and can be adapted to traditional autoregressive decryption easily. We conduct extensive experiments on neural machine version tasks where the proposed method consistently outperforms autoregressive baselines while reducing the inference latency by half , and achieves 36. 49 33. 57 BLEU scores on IWSLT14 German-EnglishWMT14 German-English translation. When adapted to autoregressive decoding , the proposed method accomplish 30. 60 43. 56 BLEU scores on WMT14 English-GermanEnglish-French translation , on par with the state-of-the-art service line models. ", "label": 1}
{"original_text": "Eigenvector continuation is a computational method that finds the extremal eigenvalues and eigenvectors of a Hamiltonian matrix with one or more control parameters. It does this by projection onto a subspace of eigenvectors corresponding to selected training values of the control parameters. The method has proven to be very efficient and accurate for interpolating and extrapolating eigenvectors. However, almost nothing is known about how the method converges, and its rapid convergence properties have remained mysterious. In this letter we present the first study of the convergence of eigenvector continuation. In order to perform the mathematical analysis, we introduce a new variant of eigenvector continuation that we call vector continuation. We first prove that eigenvector continuation and vector continuation have identical convergence properties and then analyze the convergence of vector continuation. Our analysis shows that, in general, eigenvector continuation converges more rapidly than perturbation theory. The faster convergence is achieved by eliminating a phenomenon that we call differential folding, the interference between non-orthogonal vectors appearing at different orders in perturbation theory. From our analysis we can predict how eigenvector continuation converges both inside and outside the radius of convergence of perturbation theory. While eigenvector continuation is a non-perturbative method, we show that its rate of convergence can be deduced from power series expansions of the eigenvectors. Our results also yield new insights into the nature of divergences in perturbation theory.", "text_perturb": "Eigenvector continuation equal a computational method that finds the extremal eigenvalues and eigenvectors of a Hamiltonian matrix with one or more control parameters. It does this by jut onto a subspace of eigenvectors corresponding to selected training values of the control parameters. The method has proven to live very efficient and accurate for interpolating and extrapolating eigenvectors. However , almost nothing is known about how the method converges , and its speedy convergence properties have remained mysterious. In this letter we confront the first study of the convergence of eigenvector continuation. In order to perform the mathematical analysis , we insert a new variant of eigenvector continuation that we call vector continuation. We first prove that eigenvector continuation and vector continuation have identical convergency properties and then analyze the convergency of vector continuation. Our analysis shows that , in general , eigenvector continuation converges more rapidly than perturbation possibility. The faster convergence is reach by eliminating a phenomenon that we call differential folding , the interference between non-orthogonal vectors appearing at different orders in perturbation theory. From our analysis we can predict how eigenvector continuation converges both inside and outside the radius of convergence of disruption theory. While eigenvector continuation embody a non-perturbative method , we show that its rate of convergence can be deduced from power series expansions of the eigenvectors. Our issue also yield new insights into the nature of divergences in perturbation theory. ", "label": 1}
{"original_text": "We devise a distributional variant of gradient temporal-difference (TD) learning. Distributional reinforcement learning has been demonstrated to outperform the regular one in the recent study (,). In the policy evaluation setting, we design two new algorithms called distributional GTD2 and distributional TDC using the Cramer distance on the distributional version of the Bellman error objective function, which inherits advantages of both the nonlinear gradient TD algorithms and the distributional RL approach. In the control setting, we propose the distributional Greedy-GQ using the similar derivation. We prove the asymptotic almost-sure convergence of distributional GTD2 and TDC to a local optimal solution for general smooth function approximators, which includes neural networks that have been widely used in recent study to solve the real-life RL problems. In each step, the computational complexities of above three algorithms are linear w.r.t. the number of the parameters of the function approximator, thus can be implemented efficiently for neural networks.", "text_perturb": "We devise a distributional strain of gradient temporal-difference ( TD ) learning. Distributional reinforcement learning has been demonstrated to outperform the regular one in the recent subject field ( , ). In the policy evaluation setting , we design two new algorithms called distributional GTD2 and distributional TDC using the Cramer distance on the distributional version of the Bellman error objective use , which inherits advantages of both the nonlinear gradient TD algorithms and the distributional RL approach. In the control setting , we pop the question the distributional Greedy-GQ using the similar derivation. We leaven the asymptotic almost-sure convergence of distributional GTD2 and TDC to a local optimal solution for general smooth function approximators , which includes neural networks that have been widely used in recent study to solve the real-life RL problems. In each step , the computational complexities of above three algorithms are analogue w. universal gas constant. thymine. the number of the parameters of the mathematical function approximator , thus can be implemented efficiently for neural networks. ", "label": 1}
{"original_text": "Roundabouts in conjunction with other traffic scenarios, e.g., intersections, merging roadways, speed reduction zones, can induce congestion in a transportation network due to driver responses to various disturbances. Research efforts have shown that smoothing traffic flow and eliminating stop-and-go driving can both improve fuel efficiency of the vehicles and the throughput of a roundabout. In this paper, we validate an optimal control framework developed earlier in a multi-lane roundabout scenario using the University of Delaware's scaled smart city (UDSSC). We first provide conditions where the solution is optimal. Then, we demonstrate the feasibility of the solution using experiments at UDSSC, and show that the optimal solution completely eliminates stop-and-go driving while preserving safety.", "text_perturb": "roundabout in conjunction with other traffic scenarios , e. gibibyte. , intersections , merging roadways , speed reduction zones , can induce congestion in a transportation network referable to driver responses to various disturbances. Research exertion have shown that smoothing traffic flow and eliminating stop-and-go driving can both improve fuel efficiency of the vehicles and the throughput of a roundabout. In this paper , we validate an optimal control framework developed earlier in a multi-lane roundabout scenario using the University of delaware river 's scaled smart city ( UDSSC ). We first offer conditions where the solution is optimal. Then , we demonstrate the feasibility of the solution using experiments at UDSSC , and bear witness that the optimal solution completely eliminates stop-and-go driving while preserving safety. ", "label": 1}
{"original_text": "The analysis of biological sequencing data has been one of the biggest applications of string algorithms. The approaches used in many such applications are based on the analysis of k -mers, which are short fixed-length strings present in a dataset. While these approaches are rather diverse, storing and querying k -mer sets has emerged as a shared underlying component. Sets of k -mers have unique features and applications that, over the last ten years, have resulted in many specialized approaches for their representation. In this survey, we give a unified presentation and comparison of the data structures that have been proposed to store and query k -mer sets. We hope this survey will not only serve as a resource for researchers in the field but also make the area more accessible to outsiders.", "text_perturb": "The depth psychology of biological sequencing data has been one of the biggest applications of string algorithms. The approaches used in many such applications are based on the analysis of one thousand -mers , which are short fixed-length strings present in a dataset. While these approaches are sooner diverse , storing and querying k -mer sets has emerged as a shared underlying component. Sets of  -mers have unique features and applications that , over the last ten years , have resulted in many specialized approaches for their representation. In this survey , we give a unified presentation and comparison of the data structures that get been proposed to store and query k -mer sets. We hope this survey will not only serve as a resource for researchers in the field but also make the area to a greater extent accessible to outsiders. ", "label": 1}
{"original_text": "Centrality measures such as the degree, k-shell, or eigenvalue centrality can identify a network's most influential nodes, but are rarely usefully accurate in quantifying the spreading power of the vast majority of nodes which are not highly influential. The spreading power of all network nodes is better explained by considering, from a continuous-time epidemiological perspective, the distribution of the force of infection each node generates. The resulting metric, the Expected Force (ExF), accurately quantifies node spreading power under all primary epidemiological models across a wide range of archetypical human contact networks. When node power is low, influence is a function of neighbor degree. As power increases, a node's own degree becomes more important. The strength of this relationship is modulated by network structure, being more pronounced in narrow, dense networks typical of social networking and weakening in broader, looser association networks such as Internet webpages. The ExF can be computed independently for individual nodes, making it applicable for networks whose adjacency matrix is dynamic, not well specified, or overwhelmingly large.", "text_perturb": "Centrality measures such as the degree , k-shell , or eigenvalue centrality can identify a network 's most influential nodes , but are rarely usefully accurate in quantifying the spreading king of the vast majority of nodes which are not highly influential. The spreading powerfulness of all network nodes is better explained by considering , from a continuous-time epidemiological perspective , the distribution of the force of infection each node generates. The resulting metric , the Expected Force ( ExF ) , accurately quantifies node spreading power under all basal epidemiological models across a wide range of archetypical human contact networks. When node power exist low , influence exist a function of neighbor degree. As power increases , a node 's own degree becomes to a greater extent important. The strength of this relationship is modulated by mesh structure , being more pronounced in narrow , dense networks typical of social networking and weakening in broader , looser association networks such as Internet webpages. The ExF can be computed independently for individual nodes , making it applicable for networks whose adjacency matrix is dynamical , not well specified , or overwhelmingly large. ", "label": 1}
{"original_text": "The security of cryptographic communication protocols that use X.509 certificates depends on the correctness of those certificates. This paper proposes a system that helps to ensure the correct operation of an X.509 certification authority and its registration authorities. We achieve this goal by enforcing a policy-defined, multi-party validation and authorization workflow of certificate signing requests. Besides, our system offers full accountability for this workflow for forensic purposes. As a foundation for our implementation, we leverage the distributed ledger and smart contract framework Hyperledger Fabric. Our implementation inherits the strong tamper-resistance of Fabric which strengthens the integrity of the computer processes that enforce the validation and authorization of the certificate signing request, and of the metadata collected during certificate issuance.", "text_perturb": "The security of cryptographic communication communications protocol that use X. 509 certificates depends on the rightness of those certificates. This paper aim a system that helps to ensure the correct operation of an X. 509 certification authority and its readjustment authorities. We achieve this goal by enforcing a policy-defined , multi-party validation and authorization work flow of certificate signing requests. Besides , our system offers wide cut accountability for this workflow for forensic purposes. As a foot for our implementation , we leverage the distributed ledger and smart contract framework Hyperledger Fabric. Our implementation inherit the strong tamper-resistance of Fabric which strengthens the integrity of the computer processes that enforce the validation and authorization of the certificate signing request , and of the metadata collected during certificate issuance. ", "label": 1}
{"original_text": "3D point cloud semantic and instance segmentation is crucial and fundamental for 3D scene understanding. Due to the complex structure, point sets are distributed off balance and diversely, which appears as both category imbalance and pattern imbalance. As a result, deep networks can easily forget the non-dominant cases during the learning process, resulting in unsatisfactory performance. Although re-weighting can reduce the influence of the well-classified examples, they cannot handle the non-dominant patterns during the dynamic training. In this paper, we propose a memory-augmented network to learn and memorize the representative prototypes that cover diverse samples universally. Specifically, a memory module is introduced to alleviate the forgetting issue by recording the patterns seen in mini-batch training. The learned memory items consistently reflect the interpretable and meaningful information for both dominant and non-dominant categories and cases. The distorted observations and rare cases can thus be augmented by retrieving the stored prototypes, leading to better performances and generalization. Exhaustive experiments on the benchmarks, i.e. S3DIS and ScanNetV2, reflect the superiority of our method on both effectiveness and efficiency. Not only the overall accuracy but also non-dominant classes have improved substantially.", "text_perturb": "3D point cloud semantic and instance segmentation is crucial and cardinal for 3D scene understanding. Due to the complex structure , point hardening are distributed off balance and diversely , which appears as both category imbalance and pattern imbalance. As a result , deep networks can easily block the non-dominant cases during the learning process , resulting in unsatisfactory performance. Although re-weighting can reduce the influence of the well-classified examples , they can not cover the non-dominant patterns during the dynamic training. In this paper , we propose a memory-augmented network to learn and memorize the representative prototypes that covering fire diverse samples universally. Specifically , a memory module is introduced to alleviate the forgetting issue by recording the patterns seen in mini-batch grooming. The learned memory items consistently reflect the interpretable and meaningful information for both dominant and non-dominant categories and vitrine. The distorted observations and rare cases can thus be augment by retrieving the stored prototypes , leading to better performances and generalization. thoroughgoing experiments on the benchmarks , i. due east. S3DIS and ScanNetV2 , reflect the favourable position of our method on both effectiveness and efficiency. Not only the overall accuracy but also non-dominant class have improved substantially. ", "label": 1}
{"original_text": "This paper proposes a deep learning architecture based on Residual Network that dynamically adjusts the number of executed layers for the regions of the image. This architecture is end-to-end trainable, deterministic and problem-agnostic. It is therefore applicable without any modifications to a wide range of computer vision problems such as image classification, object detection and image segmentation. We present experimental results showing that this model improves the computational efficiency of Residual Networks on the challenging ImageNet classification and COCO object detection datasets. Additionally, we evaluate the computation time maps on the visual saliency dataset cat2000 and find that they correlate surprisingly well with human eye fixation positions.", "text_perturb": "This paper proposes a deep learning architecture based on Residual Network that dynamically aline the number of executed layers for the regions of the image. This computer architecture is end-to-end trainable , deterministic and problem-agnostic. It is therefore applicable without any modifications to a wide range of computer vision problems such as image classification , object catching and image segmentation. We pose experimental results showing that this model improves the computational efficiency of Residual Networks on the challenging ImageNet classification and COCO object detection datasets. Additionally , we evaluate the computation time maps on the visual saliency dataset cat2000 and find that they correlate surprisingly well with human eye obsession positions. ", "label": 1}
{"original_text": "This paper proposes an adaptive human pilot model that is able to mimic the crossover model in the presence of uncertainties. The proposed structure is based on the model reference adaptive control, and the adaptive laws are obtained using the Lyapunov-Krasovskii stability criteria. The model can be employed for human-in-the-loop stability and performance analyses incorporating different types of controllers and plant types. For validation purposes, an experimental setup is employed to collect data and a statistical analysis is conducted to measure the predictive power of the pilot model.", "text_perturb": "This paper proposes an adaptative human pilot model that is able to mimic the crossover model in the presence of uncertainties. The proposed structure is based on the model reference adaptive control , and the adaptive laws are obtained using the Lyapunov-Krasovskii stableness criteria. The model can represent employed for human-in-the-loop stability and performance analyses incorporating different types of controllers and plant types. For validation purposes , an experimental setup is employed to collect data and a statistical analysis is conducted to measure the prognostic power of the pilot model. ", "label": 1}
{"original_text": "F-index of a graph is the sum of the cube of the degrees of the vertices. In this paper, we investigate the F-indices of unicyclic graphs by introducing some transformation, and characterize the unicyclic graphs with the first five largest F-indices and the unicyclic graphs with the first two smallest F-indices, respectively.", "text_perturb": "F-index of a graph exist the sum of the cube of the degrees of the vertices. In this theme , we investigate the F-indices of unicyclic graphs by introducing some transformation , and characterize the unicyclic graphs with the first five largest F-indices and the unicyclic graphs with the first two smallest F-indices , respectively. ", "label": 1}
{"original_text": "Various statistical analysis methods are studied for years to extract accurate trends of network traffic and predict the future load mainly to allocate required resources. Besides, many stochastic modeling techniques are offered to represent fundamental characteristics of different types of network traffic. In this study, we analyze autoregressive traffic forecasting techniques considering their popularity and wide-use in the domain. In comparison to similar works, we present important traffic characteristics and discussions from the literature to create a self-consistent guidance along with the survey. Then, we approach to techniques in the literature revealing which network characteristics they can capture offering a characteristic-based framework. Most importantly, we aim to fill the gap between the statistical analysis of those methods and their relevance with networking by dicussing significant aspects and requirements for accurate forecasting from a network-telemetric perspective.", "text_perturb": "Various statistical analysis methods are studied for years to extract accurate trends of network dealings and predict the future load mainly to allocate required resources. Besides , many stochastic modeling techniques are proffer to represent fundamental characteristics of different types of network traffic. In this study , we analyze autoregressive dealings forecasting techniques considering their popularity and wide-use in the domain. In comparison to similar works , we present important traffic characteristic and discussions from the literature to create a self-consistent guidance along with the survey. Then , we approach to techniques in the literature revealing which meshing characteristics they can capture offering a characteristic-based framework. Most importantly , we aim to fill the gap between the statistical analysis of those methods and their relevance with networking by dicussing significant aspects and requirements for precise forecasting from a network-telemetric perspective. ", "label": 1}
{"original_text": "The rapidly growing field of network analytics requires data sets for use in evaluation. Real world data often lack truth and simulated data lack narrative fidelity or statistical generality. This paper presents a novel, mixed-membership, agent-based simulation model to generate activity data with narrative power while providing statistical diversity through random draws. The model generalizes to a variety of network activity types such as Internet and cellular communications, human mobility, and social network interactions. The simulated actions over all agents can then drive an application specific observational model to render measurements as one would collect in real-world experiments. We apply this framework to human mobility and demonstrate its utility in generating high fidelity traffic data for network analytics. 1 footnote 1 1 footnote 1 This work is sponsored by the Assistant Secretary of Defense for Research Engineering under Air Force Contract FA8721-05-C-0002. Opinions, interpretations, conclusions and recommendations are those of the author and are not necessarily endorsed by the United States Government", "text_perturb": "The rapidly growing field of network analytics call for data sets for use in evaluation. Real world data often lack truth and imitate data lack narrative fidelity or statistical generality. This paper presents a novel , mixed-membership , agent-based simulation model to generate activity data with narrative power while providing statistical variety through random draws. The fashion model generalizes to a variety of network activity types such as Internet and cellular communications , human mobility , and social network interactions. The simulated actions over all agents can then drive an application specific observational model to furnish measurements as one would collect in real-world experiments. We apply this model to human mobility and demonstrate its utility in generating high fidelity traffic data for network analytics. 1 footnote 1 1 footnote 1 This work live sponsored by the Assistant Secretary of Defense for Research Engineering under Air Force Contract FA8721-05-C-0002. Opinions , rendering , conclusions and recommendations are those of the author and are not necessarily endorsed by the United States Government", "label": 1}
{"original_text": "GANs can generate photo-realistic images from the domain of their training data. However, those wanting to use them for creative purposes often want to generate imagery from a truly novel domain, a task which GANs are inherently unable to do. It is also desirable to have a level of control so that there is a degree of artistic direction rather than purely curation of random results. Here we present a method for interpolating between generative models of the StyleGAN architecture in a resolution dependent manner. This allows us to generate images from an entirely novel domain and do this with a degree of control over the nature of the output.", "text_perturb": "GANs can generate photo-realistic images from the domain of their grooming data. However , those wanting to use them for creative purposes often want to generate imagery from a truly novel domain , a task which GANs are inherently unable to get along. It is also desirable to have a point of control so that there is a degree of artistic direction rather than purely curation of random results. Here we present a method acting for interpolating between generative models of the StyleGAN architecture in a resolution dependent manner. This allows us to generate images from an entirely novel orbit and do this with a degree of control over the nature of the output. ", "label": 1}
{"original_text": "We prove that for every proper minor-closed class M of F p -representable matroids, there exists a O (1) -competitive algorithm for the matroid secretary problem on M. This result relies on the extremely powerful matroid minor structure theory being developed by Geelen, Gerards and Whittle. We also note that for asymptotically almost all matroids, the matroid secretary algorithm that selects a random basis, ignoring weights, is (2 o (1 -competitive. In fact, assuming the conjecture that almost all matroids are paving, there is a (1 o (1 -competitive algorithm for almost all matroids.", "text_perturb": "We prove that for every right minor-closed class M of F p -representable matroids , there exists a O ( 1 ) -competitive algorithm for the matroid secretary problem on M. This result relies on the extremely powerful matroid minor structure possibility being developed by Geelen , Gerards and Whittle. We also note that for asymptotically almost all matroids , the matroid secretary algorithm that selects a random basis , ignoring weights , constitute ( 2 o ( 1 -competitive. In fact , assuming the conjecture that almost all matroids constitute paving , there is a ( 1 o ( 1 -competitive algorithm for almost all matroids. ", "label": 1}
{"original_text": "Most studies on optical wireless communications (OWCs) have neglected the effect of random orientation in their performance analysis due to the lack of a proper model for the random orientation. Our recent empirical-based research illustrates that the random orientation follows a Laplace distribution for static user equipment (UE). In this paper, we analyze the device orientation and assess its importance on system performance. The probability of establishing a line-of-sight link is investigated and the probability density function (PDF) of signal-to-noise ratio (SNR) for a randomly-oriented device is derived. By means of the PDF of SNR, the bit-error ratio (BER) of DC biased optical orthogonal frequency division multiplexing (DCO-OFDM) in additive white Gaussian noise (AWGN) channels is evaluated. A closed form approximation for the BER of UE with random orientation is presented which shows a good match with Monte-Carlo simulation results.", "text_perturb": "Most studies on optical wireless communications ( OWCs ) have neglected the effect of random orientation in their performance psychoanalysis due to the lack of a proper model for the random orientation. Our recent empirical-based research illustrates that the random orientation follows a Laplace distribution for static drug user equipment ( UE ). In this theme , we analyze the device orientation and assess its importance on system performance. The probability of establishing a line-of-sight link is investigated and the probability tightness function ( PDF ) of signal-to-noise ratio ( SNR ) for a randomly-oriented device is derived. By means of the PDF of SNR , the bit-error ratio ( BER ) of DC biased optical orthogonal frequency division multiplexing ( DCO-OFDM ) in additive white Gaussian noise ( AWGN ) television channel is evaluated. A closed form approximation for the BER of UE with random orientation course is presented which shows a good match with Monte-Carlo simulation results. ", "label": 1}
{"original_text": "Flexibility at hardware level is the main driving force behind adaptive systems whose aim is to realise microarhitecture deconfiguration 'online'. This feature allows the softwarehardware stack to tolerate drastic changes of the workload in data centres. With emerge of FPGA reconfigurablity this technology is becoming a mainstream computing paradigm. Adaptivity is usually accompanied by the high-level tools to facilitate multi-dimensional space exploration. An essential aspect in this space is memory orchestration where on-chip and off-chip memory distribution significantly influences the architecture in coping with the critical spatial and timing constraints, e.g. Place Route. This paper proposes a memory smart technique for a particular class of adaptive systems: Elastic Circuits which enjoy slack elasticity at fine level of granularity. We explore retiming of a set of popular benchmarks via investigating the memory distribution within and among accelerators. The area, performance and power patterns are adopted by our high-level synthesis framework, with respect to the behaviour of the input descriptions, to improve the quality of the synthesised elastic circuits.", "text_perturb": "Flexibility at hardware level is the main driving effect behind adaptive systems whose aim is to realise microarhitecture deconfiguration 'online '. This feature article allows the softwarehardware stack to tolerate drastic changes of the workload in data centres. With emerge of FPGA reconfigurablity this applied science is becoming a mainstream computing paradigm. Adaptivity is usually attach to by the high-level tools to facilitate multi-dimensional space exploration. An essential aspect in this space is memory orchestration where on-chip and off-chip memory distribution importantly influences the architecture in coping with the critical spatial and timing constraints , e. m. home Route. This paper proposes a memory smart technique for a particular class of adaptive systems : Elastic Circuits which enjoy slack snap at fine level of granularity. We explore retiming of a set of popular benchmarks via investigating the memory distribution within and among gun. The area , performance and power normal are adopted by our high-level synthesis framework , with respect to the behaviour of the input descriptions , to improve the quality of the synthesised elastic circuits. ", "label": 1}
{"original_text": "In this paper, a novel experienced deep reinforcement learning (deep-RL) framework is proposed to provide model-free resource allocation for in the downlink of a wireless network. The goal is to guarantee high end-to-end reliability and low end-to-end latency, under explicit data rate constraints, for each wireless user without any models of or assumptions on the users' traffic. In particular, in order to enable the deep-RL framework to account for extreme network conditions and operate in highly reliable systems, a new approach based on generative adversarial networks (GANs) is proposed. This GAN approach is used to pre-train the deep-RL framework using a mix of real and synthetic data, thus creating an experienced deep-RL framework that has been exposed to a broad range of network conditions. The proposed deep-RL framework is particularly applied to a multi-user orthogonal frequency division multiple access (OFDMA) resource allocation system. Formally, this resource allocation problem in OFDMA systems is posed as a power minimization problem under reliability, latency, and rate constraints. To solve this problem using experienced deep-RL, first, the rate of each user is determined. Then, these rates are mapped to the resource block and power allocation vectors of the studied wireless system. Finally, the end-to-end reliability and latency of each user are used as feedback to the deep-RL framework. It is then shown that at the fixed-point of the deep-RL algorithm, the reliability and latency of the users are near-optimal. Moreover, for the proposed GAN approach, a theoretical limit for the generator output is analytically derived. Simulation results show how the proposed approach can achieve near-optimal performance within the rate-reliability-latency region, depending on the network and service requirements. The results also show that the proposed experienced deep-RL framework is able to remove the transient training time that makes conventional deep-RL methods unsuitable for. Moreover, during extreme conditions, it is shown that the proposed, experienced deep-RL agent can recover instantly while a conventional deep-RL agent takes several epochs to adapt to new extreme conditions.", "text_perturb": "In this paper , a novel experienced deep reinforcement learning ( deep-RL ) framework is aim to provide model-free resource allocation for in the downlink of a wireless network. The goal equal to guarantee high end-to-end reliability and low end-to-end latency , under explicit data rate constraints , for each wireless user without any models of or assumptions on the users ' traffic. In particular , in order to enable the deep-RL framework to account for extreme mesh conditions and operate in highly reliable systems , a new approach based on generative adversarial networks ( GANs ) is proposed. This GAN approach is used to pre-train the deep-RL framework using a mix of real and synthetic data , thus make an experienced deep-RL framework that has been exposed to a broad range of network conditions. The proposed deep-RL framework is particularly applied to a multi-user impertinent frequency division multiple access ( OFDMA ) resource allocation system. Formally , this resource allocation problem in OFDMA systems is posed as a power minimization problem under reliability , latent period , and rate constraints. To lick this problem using experienced deep-RL , first , the rate of each user is determined. Then , these rates are mapped to the imagination block and power allocation vectors of the studied wireless system. Finally , the end-to-end reliability and latency of each user follow used as feedback to the deep-RL framework. It is then shown that at the fixed-point of the deep-RL algorithmic program , the reliability and latency of the users are near-optimal. Moreover , for the proposed GAN approach , a theoretical limit for the generator output is analytically deduct. Simulation results show how the proposed approach can accomplish near-optimal performance within the rate-reliability-latency region , depending on the network and service requirements. The resultant role also show that the proposed experienced deep-RL framework is able to remove the transient training time that makes conventional deep-RL methods unsuitable for. Moreover , during extreme conditions , it is shown that the proposed , experienced deep-RL agent can recover in a flash while a conventional deep-RL agent takes several epochs to adapt to new extreme conditions. ", "label": 1}
{"original_text": "This paper presents an adaptive randomized algorithm for computing the butterfly factorization of a x m n matrix with m n provided that both the matrix and its transpose can be rapidly applied to arbitrary vectors. The resulting factorization is composed of O (log n) sparse factors, each containing O (n) nonzero entries. The factorization can be attained using O (n 3 2 log n) computation and O (n log n) memory resources. The proposed algorithm applies to matrices with strong and weak admissibility conditions arising from surface integral equation solvers with a rigorous error bound, and is implemented in parallel.", "text_perturb": "This paper presents an adaptive randomized algorithmic rule for computing the butterfly factorization of a x m n matrix with m n provided that both the matrix and its transpose can be rapidly applied to arbitrary vectors. The resulting factorization is composed of O ( log north ) sparse factors , each containing O ( north ) nonzero entries. The factorization can be attained using O ( n 3 2 log normality ) computation and O ( n log normality ) memory resources. The proposed algorithm applies to matrices with strong and weak admissibility conditions arising from surface integral equation solvers with a rigorous error bound , and is carry out in parallel. ", "label": 1}
{"original_text": "We investigate GPU-based parallelization of Iterative-Deepening A (IDA). We show that straightforward thread-based parallelization techniques which were previously proposed for massively parallel SIMD processors perform poorly due to warp divergence and load imbalance. We propose Block-Parallel IDA (BPIDA), which assigns the search of a subtree to a block (a group of threads with access to fast shared memory) rather than a thread. On the 15-puzzle, BPIDA on a NVIDIA GRID K520 with 1536 CUDA cores achieves a speedup of 4.98 compared to a highly optimized sequential IDA implementation on a Xeon E5-2670 core. 1 1 footnote 1 This is an extended manuscript based on a paper accepted to appear in SoCS2017.", "text_perturb": "We investigate GPU-based parallelization of Iterative-Deepening A ( ida ). We establish that straightforward thread-based parallelization techniques which were previously proposed for massively parallel SIMD processors perform poorly due to warp divergence and load imbalance. We propose Block-Parallel IDA ( BPIDA ) , which assigns the search of a subtree to a block ( a grouping of threads with access to fast shared memory ) rather than a thread. On the 15-puzzle , BPIDA on a NVIDIA GRID K520 with 1536 CUDA cores achieves a acceleration of 4. 98 compared to a highly optimized sequent IDA implementation on a Xeon E5-2670 core. 1 1 footnote 1 This is an extended ms based on a paper accepted to appear in SoCS2017. ", "label": 1}
{"original_text": "The task of linearization is to find a grammatical order given a set of words. Traditional models use statistical methods. Syntactic linearization systems, which generate a sentence along with its syntactic tree, have shown state-of-the-art performance. Recent work shows that a multi-layer LSTM language model outperforms competitive statistical syntactic linearization systems without using syntax. In this paper, we study neural syntactic linearization, building a transition-based syntactic linearizer leveraging a feed forward neural network, observing significantly better results compared to LSTM language models on this task.", "text_perturb": "The task of linearization is to find a grammatical order given a exercise set of words. traditional models use statistical methods. Syntactic linearization systems , which generate a sentence along with its syntactic tree , have picture state-of-the-art performance. Recent work shows that a multi-layer LSTM language model outperforms competitive statistical syntactic linearization systems without apply syntax. In this paper , we study neural syntactical linearization , building a transition-based syntactical linearizer leveraging a feed forward neural network , observing significantly better results compared to LSTM language models on this task. ", "label": 1}
{"original_text": "Besides advanced telecommunications techniques, the most prominent evolution of wireless networks is the densification of network deployment. In particular, the increasing access pointsusers density and reduced cell size significantly enhance spatial reuse, thereby improving network capacity. Nevertheless, does network ultra-densification and over-deployment always boost the performance of wireless networks? Since the distance from transmitters to receivers is greatly reduced in dense networks, signal is more likely to be propagated from far- to near-field region. Without considering near-field propagation features, conventional understandings of the impact of network densification become doubtful. With this regard, it is imperative to reconsider the pros and cons brought by network densification. In this article, we first discuss the near-field propagation features in densely deployed network and verify through experimental results the validity of the proposed near-field propagation model. Considering near-field propagation, we further explore how dense is ultra-dense for wireless networks and provide a concrete interpretation of ultra-densification from the spatial throughput perspective. Meanwhile, as near-field propagation makes interference more complicated and difficult to handle, we shed light on the key challenges of applying interference management in ultra-dense wireless networks. Moreover, possible solutions are presented to suggest future directions.", "text_perturb": "Besides advanced telecommunications techniques , the most prominent phylogenesis of wireless networks is the densification of network deployment. In particular , the increasing access pointsusers density and reduced cell size significantly enhance spatial reuse , thereby improving network capability. Nevertheless , does network ultra-densification and over-deployment always boost the performance of wireless networks ? Since the distance from transmitters to receivers make up greatly reduced in dense networks , signal make up more likely to be propagated from far- to near-field region. Without considering near-field generation features , conventional understandings of the impact of network densification become doubtful. With this regard , it is imperative to reconsider the pros and bunko brought by network densification. In this article , we first discuss the near-field propagation features in densely deployed web and verify through experimental results the validity of the proposed near-field propagation model. Considering near-field propagation , we further explore how dense exist ultra-dense for wireless networks and provide a concrete interpretation of ultra-densification from the spatial throughput perspective. Meanwhile , as near-field generation makes interference more complicated and difficult to handle , we shed light on the key challenges of applying interference management in ultra-dense wireless networks. Moreover , possible solutions are presented to suggest future way. ", "label": 1}
{"original_text": "Digitisation of fruit trees using LiDAR enables analysis which can be used to better growing practices to improve yield. Sophisticated analysis requires geometric and semantic understanding of the data, including the ability to discern individual trees as well as identifying leafy and structural matter. Extraction of this information should be rapid, as should data capture, so that entire orchards can be processed, but existing methods for classification and segmentation rely on high-quality data or additional data sources like cameras. We present a method for analysis of LiDAR data specifically for individual tree location, segmentation and matter classification, which can operate on low-quality data captured by handheld or mobile LiDAR. Results demonstrate viability both on real data for avocado and mango trees and virtual data with independently controlled sensor noise and tree spacing.", "text_perturb": "Digitisation of fruit trees using LiDAR enables analysis which can be used to easily growing practices to improve yield. Sophisticated analysis requires geometric and semantic discernment of the data , including the ability to discern individual trees as well as identifying leafy and structural matter. Extraction of this information should be rapid , as should data gaining control , so that entire orchards can be processed , but existing methods for classification and segmentation rely on high-quality data or additional data sources like cameras. We present a method for analysis of LiDAR information specifically for individual tree location , segmentation and matter classification , which can operate on low-quality information captured by handheld or mobile LiDAR. Results demonstrate viability both on real data for avocado and mango trees and virtual data with independently insure sensor noise and tree spacing. ", "label": 1}
{"original_text": "Image inpainting is one of the most challenging tasks in computer vision. Recently, generative-based image inpainting methods have been shown to produce visually plausible images. However, they still have difficulties to generate the correct structures and colors as the masked region grows large. This drawback is due to the training stability issue of the generative models. This work introduces a new curriculum-style training approach in the context of image inpainting. The proposed method increases the masked region size progressively in training time, during test time the user gives variable size and multiple holes at arbitrary locations. Incorporating such an approach in GANs may stabilize the training and provides better color consistencies and captures object continuities. We validate our approach on the MSCOCO and CelebA datasets. We report qualitative and quantitative comparisons of our training approach in different models.", "text_perturb": "Image inpainting is one of the most challenging tasks in computing machine vision. Recently , generative-based image inpainting methods have been shown to bring out visually plausible images. However , they still have trouble to generate the correct structures and colors as the masked region grows large. This drawback equal due to the training stability issue of the generative models. This work introduces a new curriculum-style training glide slope in the context of image inpainting. The proposed method increases the masked region size progressively in training metre , during test metre the user gives variable size and multiple holes at arbitrary locations. incorporate such an approach in GANs may stabilize the training and provides better color consistencies and captures object continuities. We formalize our approach on the MSCOCO and CelebA datasets. We report qualitative and quantitative comparisons of our training approach in different model. ", "label": 1}
{"original_text": "The Hotelling game consists of n servers each choosing a point on the line segment, so as to maximize the amount of clients it attracts. Clients are uniformly distributed along the line, and each client buys from the closest server. In this paper, we study a fault-prone version of the Hotelling game, where the line fails at multiple random locations. Each failure disconnects the line, blocking the passage of clients. We show that the game admits a Nash equilibrium if and only if the rate of faults exceeds a certain threshold, and calculate that threshold approximately. Moreover, when a Nash equilibrium exists we show it is unique and construct it explicitly. Hence, somewhat surprisingly, the potential occurrence of failures has a stabilizing effect on the game (provided there are enough of them). Additionally, we study the social cost of the game (measured in terms of the total transportation cost of the clients), which also seems to benefit in a certain sense from the potential presence of failures.", "text_perturb": "The Hotelling game consists of n servers each choosing a point on the line segment , so as to maximize the amount of clients it draw. Clients are uniformly disperse along the line , and each client buys from the closest server. In this paper , we study a fault-prone reading of the Hotelling game , where the line fails at multiple random locations. Each failure disconnect the line , blocking the passage of clients. We show that the game admits a Nash equilibrium if and only if the charge per unit of faults exceeds a certain threshold , and calculate that threshold approximately. furthermore , when a Nash equilibrium exists we show it is unique and construct it explicitly. Hence , somewhat surprisingly , the potential natural event of failures has a stabilizing effect on the game ( provided there are enough of them ). Additionally , we study the social cost of the game ( measured in terms of the total department of transportation cost of the clients ) , which also seems to benefit in a certain sense from the potential presence of failures. ", "label": 1}
{"original_text": "Shannon's theory of information was built on the assumption that the information carriers were classical systems. Its quantum counterpart, quantum Shannon theory, explores the new possibilities arising when the information carriers are quantum systems. Traditionally, quantum Shannon theory has focussed on scenarios where the internal state of the information carriers is quantum, while their trajectory is classical. Here we propose a second level of quantisation where both the information and its propagation in spacetime is treated quantum mechanically. The framework is illustrated with a number of examples, showcasing some of the counterintuitive phenomena taking place when information travels simultaneously through multiple transmission lines.", "text_perturb": "Shannon 's theory of info was built on the assumption that the info carriers were classical systems. Its quantum vis a vis , quantum Shannon theory , explores the new possibilities arising when the information carriers are quantum systems. Traditionally , quantum Shannon theory make focussed on scenarios where the internal state of the information carriers is quantum , while their trajectory is classical. Here we propose a second level of quantization where both the information and its propagation in spacetime is treated quantum mechanically. The framework is illustrated with a number of examples , showcasing some of the counterintuitive phenomenon taking place when information travels simultaneously through multiple transmission lines. ", "label": 1}
{"original_text": "Storage systems have a strong need for substantially improving their error correction capabilities, especially for long-term storage where the accumulating errors can exceed the decoding threshold of error-correcting codes (ECCs). In this work, a new scheme is presented that uses deep learning to perform soft decoding for noisy files based on their natural redundancy. The soft decoding result is then combined with ECCs for substantially better error correction performance. The scheme is representation-oblivious: it requires no prior knowledge on how data are represented (e.g., mapped from symbols to bits, compressed, and combined with meta data) in different types of files, which makes the solution more convenient to use for storage systems. Experimental results confirm that the scheme can substantially improve the ability to recover data for different types of files even when the bit error rates in the files have significantly exceeded the decoding threshold of the ECC. The code of this work has been publicly released. 1 1 footnote 1", "text_perturb": "Storage systems have a strong need for substantially improving their computer error correction capabilities , especially for long-term storage where the accumulating errors can exceed the decoding threshold of error-correcting codes ( ECCs ). In this work , a new scheme is presented that uses deeply learning to perform soft decoding for noisy files based on their natural redundancy. The soft decipherment result is then combined with ECCs for substantially better error correction performance. The scheme is representation-oblivious : it call for no prior knowledge on how data are represented ( e. gb. , mapped from symbols to bits , compressed , and combined with meta data ) in different types of files , which makes the solution more convenient to practice for storage systems. Experimental results confirm that the schema can substantially improve the ability to recover data for different types of files even when the bit error rates in the files have significantly exceeded the decoding threshold of the ECC. The computer code of this work has been publicly released. 1 1 footer 1", "label": 1}
{"original_text": "Deep neural networks are highly expressive machine learning models with the ability to interpolate arbitrary datasets. Deep nets are typically optimized via first-order methods and the optimization process crucially depends on the characteristics of the network as well as the dataset. This work sheds light on the relation between the network size and the properties of the dataset with an emphasis on deep residual networks (ResNets). Our contribution is that if the network Jacobian is full rank, gradient descent for the quadratic loss and smooth activation converges to the global minima even if the network width m of the ResNet scales linearly with the sample size n, and independently from the network depth. To the best of our knowledge, this is the first work which provides a theoretical guarantee for the convergence of neural networks in the m O (n) regime.", "text_perturb": "Deep neural networks comprise highly expressive machine learning models with the ability to interpolate arbitrary datasets. Deep nets are typically optimized via first-order methods and the optimization process crucially depends on the feature of the network as well as the dataset. This work sheds light on the relation between the network size and the properties of the dataset with an emphasis on deep residuary networks ( ResNets ). Our contribution is that if the network Jacobian is full rank , gradient descent for the quadratic loss and smooth activation converges to the global lower limit even if the network width m of the ResNet scales linearly with the sample size n , and independently from the network depth. To the best of our knowledge , this is the first work which provides a theoretical guarantee for the convergence of neural networks in the m O ( newton ) regime. ", "label": 1}
{"original_text": "We consider the stochastic extensible bin packing problem (SEBP) in which n items of stochastic size are packed into m bins of unit capacity. In contrast to the classical bin packing problem, the number of bins is fixed and they can be extended at extra cost. This problem plays an important role in stochastic environments such as in surgery scheduling: Patients must be assigned to operating rooms beforehand, such that the regular capacity is fully utilized while the amount of overtime is as small as possible. This paper focuses on essential ratios between different classes of policies: First, we consider the price of non-splittability, in which we compare the optimal non-anticipatory policy against the optimal fractional assignment policy. We show that this ratio has a tight upper bound of 2. Moreover, we develop an analysis of a fixed assignment variant of the LEPT rule yielding a tight approximation ratio of (1 e - 1) 1.368. Furthermore, we prove that the price of fixed assignments, related to the benefit of adaptivity, which describes the loss when restricting to fixed assignment policies, is within the same factor. This shows that in some sense, LEPT is the best fixed assignment policy we can hope for. We also provide a lower bound on the performance of this policy comparing against an optimal fixed assignment policy. Finally, we obtain improved bounds for the case where the processing times are drawn from a particular family of distributions, with either a bounded Pietra index or when the familly is stochastically dominated at the second order.", "text_perturb": "We debate the stochastic extensible bin packing problem ( SEBP ) in which n items of stochastic size are packed into m bins of unit capacity. In contrast to the hellenic bin packing problem , the number of bins is fixed and they can be extended at extra cost. This problem plays an important role in stochastic environments such as in surgery scheduling : Patients must equal assigned to operating rooms beforehand , such that the regular capacity is fully utilized while the amount of overtime is as small as possible. This paper focuses on essential ratios between different classes of policies : First , we consider the price of non-splittability , in which we compare the optimal non-anticipatory insurance against the optimal fractional assignment insurance. We show that this ratio has a tight upper spring of 2. Moreover , we develop an analysis of a fixed assignment variant of the LEPT rule yielding a blotto approximation ratio of ( 1 e - 1 ) 1. 368. Furthermore , we prove that the price of fixed assignments , related to the benefit of adaptivity , which describes the loss when restricting to fixed assignment policies , is within the like factor. This shows that in some sense , LEPT is the best fixed assignment insurance we can hope for. We as well provide a lower bound on the performance of this policy comparing against an optimal fixed assignment policy. Finally , we obtain improved bounds for the case where the processing times are drawn from a particular family of distributions , with either a bounded Pietra index or when the familly personify stochastically dominated at the second order. ", "label": 1}
{"original_text": "The kinetic battery model is a popular model of the dynamic behavior of a conventional battery, useful to predict or optimize the time until battery depletion. The model however lacks certain obvious aspects of batteries in-the-wild, especially with respect to (i) the effects of random influences and (ii) the behavior when charging up to capacity bounds. This paper considers the kinetic battery model with bounded capacity in the context of piecewise constant yet random charging and discharging. The resulting model enables the time-dependent evaluation of the risk of battery depletion. This is exemplified in a power dependability study of a nano satellite mission.", "text_perturb": "The kinetic battery model is a popular model of the dynamic deportment of a conventional battery , useful to predict or optimize the time until battery depletion. The model however lacks certain obvious aspects of bombardment in-the-wild , especially with respect to ( i ) the effects of random influences and ( ii ) the behavior when charging up to capacity bounds. This paper considers the kinetic battery model with bounded capacity in the context of piecewise invariant yet random charging and discharging. The resulting model enables the time-dependent evaluation of the risk of stamp battery depletion. This is exemplified in a power dependability bailiwick of a nano satellite mission. ", "label": 1}
{"original_text": "Many modern applications produce massive streams of data series that need to be analyzed, requiring efficient similarity search operations. However, the state-of-the-art data series indexes that are used for this purpose do not scale well for massive datasets in terms of performance, or storage costs. We pinpoint the problem to the fact that existing summarizations of data series used for indexing cannot be sorted while keeping similar data series close to each other in the sorted order. To address this problem, we present Coconut, the first data series index based on sortable summarizations, and the first efficient solution for indexing and querying streaming series. The first innovation in Coconut is an inverted, sortable data series summarization that organizes data series based on a z-order curve, keeping similar series close to each other in the sorted order. As a result, Coconut is able to use bulk-loading and updating techniques that rely on sorting to quickly build and maintain a contiguous index using large sequential disk IOs. We then explore prefix-based and median-based splitting policies for bottom-up bulk-loading, showing that median-based splitting outperforms the state of the art, ensuring that all nodes are densely populated. Finally, we explore the impact of sortable summarizations on variable size window queries, showing that they can be supported in the presence of updates through efficient merging of temporal partitions. Overall, we show analytically and empirically that Coconut dominates the state-of-the-art data series indexes in terms of construction speed, query speed, and storage costs.", "text_perturb": "Many modern diligence produce massive streams of data series that need to be analyzed , requiring efficient similarity search operations. However , the state-of-the-art data series power that are used for this purpose do not scale well for massive datasets in terms of performance , or storage costs. We pinpoint the problem to the fact that existing summarizations of data series used for indexing can not be sorted while keeping similar data series close to each other in the grouped order. To address this problem , we present Coconut , the inaugural data series index based on sortable summarizations , and the inaugural efficient solution for indexing and querying streaming series. The first innovation in Coconut is an inverted , sortable data serial summarization that organizes data serial based on a z-order curve , keeping similar serial close to each other in the sorted order. As a result , Coconut is able bodied to use bulk-loading and updating techniques that rely on sorting to quickly build and maintain a contiguous index using large sequential disk IOs. We then explore prefix-based and median-based splitting policies for bottom-up bulk-loading , showing that median-based splitting outperforms the state of the art , ensuring that all nodes are dumbly populated. Finally , we explore the impact of sortable summarizations on varying size window queries , showing that they can be supported in the presence of updates through efficient merging of temporal partitions. Overall , we show analytically and empirically that Coconut dominates the state-of-the-art information series indexes in terms of construction speed , query speed , and storage costs. ", "label": 1}
{"original_text": "Visible light communications (VLC) have emerged as strong candidates for meeting the escalating demand for high data rates. Consider a VLC network, where multiple access-points (APs) serve both energy-harvesting users (EHUs), i.e., users which harvest energy from light intensity, and information-users (IUs), i.e., users which gather data information. In order to jointly balance the achievable sum-rate at the IUs and the energy harvested by the EHUs, the paper considers maximizing a network-wide utility, which consists of a weighted-sum of the IUs sum-rate and the EHUs harvested-energy, subject to individual IU rate constraint, individual EHU harvested-energy constraint, and AP power constraints, so as to jointly determine the direct current (DC) -bias value at each AP, and the users' powers. The paper solves such a difficult non-convex optimization problem using an iterative approach which relies on inner convex approximations, and compensates for the used approximations using proper outer-loop updates. The paper further considers solving the special cases of the problem, i.e., maximizing the sum-rate, and maximizing the total harvested-energy, both subject to the same constraints. Numerical results highlight the significant performance improvement of the proposed algorithms, and illustrate the impacts of the network parameters on the performance trade-off between the sum-rate and harvested-energy.", "text_perturb": "Visible light communications ( VLC ) have emerged as strong candidates for meeting the escalating need for high data rates. Consider a VLC network , where multiple access-points ( APs ) serve both energy-harvesting drug user ( EHUs ) , i. east. , users which harvest energy from short intensity , and information-users ( IUs ) , i. es. , exploiter which gather data information. In order to jointly balance the achievable sum-rate at the IUs and the energy reap by the EHUs , the paper considers maximizing a network-wide utility , which consists of a weighted-sum of the IUs sum-rate and the EHUs harvested-energy , subject to individual IU rate constraint , individual EHU harvested-energy constraint , and AP power constraints , so as to jointly determine the direct current ( DC ) -bias value at each AP , and the users ' powers. The paper solves such a difficult non-convex optimization problem using an reiterative approach which relies on inner convex approximations , and compensates for the used approximations using proper outer-loop updates. The paper further considers solving the exceptional cases of the problem , i. vitamin e. , maximizing the sum-rate , and maximizing the total harvested-energy , both subject to the same restraint. Numerical results highlight the important performance improvement of the proposed algorithms , and illustrate the impacts of the network parameters on the performance trade-off between the sum-rate and harvested-energy. ", "label": 1}
{"original_text": "In optimization, the negative gradient of a function denotes the direction of steepest descent. Furthermore, traveling in any direction orthogonal to the gradient maintains the value of the function. In this work, we show that these orthogonal directions that are ignored by gradient descent can be critical in equilibrium problems. Equilibrium problems have drawn heightened attention in machine learning due to the emergence of the Generative Adversarial Network (GAN). We use the framework of Variational Inequalities to analyze popular training algorithms for a fundamental GAN variant: the Wasserstein Linear-Quadratic GAN. We show that the steepest descent direction causes divergence from the equilibrium, and convergence to the equilibrium is achieved through following a particular orthogonal direction. We call this successful technique Crossing-the-Curl, named for its mathematical derivation as well as its intuition: identify the game's axis of rotation and move \"across\" space in the direction towards smaller \"curling.\"", "text_perturb": "In optimization , the negative slope of a function denotes the direction of steepest descent. Furthermore , locomote in any direction orthogonal to the gradient maintains the value of the function. In this work , we show that these orthogonal directions that are ignored by gradient parentage can be critical in equilibrium problems. Equilibrium problems give drawn heightened attention in machine learning due to the emergence of the Generative Adversarial Network ( GAN ). We habituate the framework of Variational Inequalities to analyze popular training algorithms for a fundamental GAN variant : the Wasserstein Linear-Quadratic GAN. We show that the steepest descent direction causes variance from the equilibrium , and convergence to the equilibrium is achieved through following a particular orthogonal direction. We call this successful technique Crossing-the-Curl , named for its mathematical derivation as well as its intuition : describe the game 's axis of rotation and move `` across '' space in the direction towards smaller `` curling. ``", "label": 1}
{"original_text": "Great successes of deep neural networks have been witnessed in various real applications. Many algorithmic and implementation techniques have been developed; however, theoretical understanding of many aspects of deep neural networks is far from clear. A particular interesting issue is the usefulness of dropout, which was motivated from the intuition of preventing complex co-adaptation of feature detectors. In this paper, we study the Rademacher complexity of different types of dropout, and our theoretical results disclose that for shallow neural networks (with one or none hidden layer) dropout is able to reduce the Rademacher complexity in polynomial, whereas for deep neural networks it can amazingly lead to an exponential reduction.", "text_perturb": "Great achiever of deep neural networks have been witnessed in various real applications. Many algorithmic and implementation techniques have been developed ; however , theoretical understanding of many aspects of thick neural networks is far from clear. A particular interesting issue is the utility of dropout , which was motivated from the intuition of preventing complex co-adaptation of feature detectors. In this paper , we study the Rademacher complexness of different types of dropout , and our theoretical results disclose that for shallow neural networks ( with one or none hidden layer ) dropout is able to reduce the Rademacher complexness in polynomial , whereas for deep neural networks it can amazingly lead to an exponential reduction. ", "label": 1}
{"original_text": "This case for the Transformation Tool Contest 2013 is about evaluating the scope and usability of transformation languages and tools for a set of four tasks requiring very different capabilities. One task deals with typical model-to-model transformation problem, there's a model-to-text problem, there are two in-place transformation problems, and finally there's a task dealing with validation of models resulting from the transformations. The tasks build upon each other, but the transformation case project also provides all intermediate models, thus making it possible to skip tasks that are not suited for a particular tool, or for parallelizing the work among members of participating teams.", "text_perturb": "This case for the Transformation Tool Contest 2013 is about evaluating the scope and usability of transformation languages and tools for a set of four tasks requiring really different capabilities. One undertaking deals with typical model-to-model transformation problem , there 's a model-to-text problem , there are two in-place transformation problems , and finally there 's a undertaking dealing with validation of models resulting from the transformations. The undertaking build upon each other , but the transformation case project also provides all intermediate models , thus making it possible to skip undertaking that are not suited for a particular tool , or for parallelizing the work among members of participating teams. ", "label": 1}
{"original_text": "As of September 2020, the COVID-19 pandemic continues to devastate the health and well-being of the global population. With more than 33 million confirmed cases and over a million deaths, global health organizations are still a long way from fully containing the pandemic. This pandemic has raised serious questions about the emergency preparedness of health agencies, not only in terms of treatment of an unseen disease, but also in identifying its early symptoms. In the particular case of COVID-19, several studies have indicated that chest radiography images of the infected patients show characteristic abnormalities. However, at the onset of a given pandemic, such as COVID-19, there may not be sufficient data for the affected cases to train models for their robust detection. Hence, supervised classification is ill-posed for this problem because the time spent in collecting large amounts of infected peoples' data could lead to the loss of human lives and delays in preventive interventions. Therefore, we formulate this problem within a one-class classification framework, in which the data for healthy patients is abundantly available, whereas no training data is present for the class of interest (COVID-19 in our case). To solve this problem, we present COVIDomaly, a convolutional autoencoder framework to detect unseen COVID-19 cases from the chest radiographs. We tested two settings on a publicly available dataset (COVIDx) by training the model on chest X-rays from (i) only healthy adults, and (ii) healthy and other non-COVID-19 pneumonia, and detected COVID-19 as an anomaly. After performing 3-fold cross validation, we obtain a pooled ROC-AUC of 0.7652 and 0.6902 in the two settings respectively. These results are very encouraging and pave the way towards research for ensuring emergency preparedness in future pandemics, especially the ones that could be detected from chest X-rays.", "text_perturb": "As of September 2020 , the COVID-19 pandemic continues to devastate the health and eudaemonia of the global population. With more than 33 million confirmed cases and over a million deaths , global health organizations are however a long way from fully containing the pandemic. This pandemic has call forth serious questions about the emergency preparedness of health agencies , not only in terms of treatment of an unseen disease , but also in identifying its early symptoms. In the particular case of COVID-19 , several studies have indicated that chest radiography images of the infected patients show characteristic abnormalcy. However , at the onset of a given pandemic , such as COVID-19 , there may not constitute sufficient data for the affected cases to train models for their robust detection. Hence , supervised classification is ill-posed for this problem because the time spent in collecting large amounts of infected peoples ' datum could lead to the loss of human lives and delays in preventive interventions. Therefore , we word this problem within a one-class classification framework , in which the data for healthy patients is abundantly available , whereas no training data is present for the class of interest ( COVID-19 in our case ). To solve this problem , we present COVIDomaly , a convolutional autoencoder framework to discover unseen COVID-19 cases from the chest radiographs. We tested two context on a publicly available dataset ( COVIDx ) by training the model on chest X-rays from ( i ) only healthy adults , and ( ii ) healthy and other non-COVID-19 pneumonia , and detected COVID-19 as an anomaly. After execute 3-fold cross validation , we obtain a pooled ROC-AUC of 0. 7652 and 0. 6902 in the two scope respectively. These results are very encouraging and pave the manner towards research for ensuring emergency preparedness in future pandemics , especially the ones that could be detected from chest X-rays. ", "label": 1}
{"original_text": "Synthesizing physiologically-accurate human movement in a variety of conditions can help practitioners plan surgeries, design experiments, or prototype assistive devices in simulated environments, reducing time and costs and improving treatment outcomes. Because of the large and complex solution spaces of biomechanical models, current methods are constrained to specific movements and models, requiring careful design of a controller and hindering many possible applications. We sought to discover if modern optimization methods efficiently explore these complex spaces. To do this, we posed the problem as a competition in which participants were tasked with developing a controller to enable a physiologically-based human model to navigate a complex obstacle course as quickly as possible, without using any experimental data. They were provided with a human musculoskeletal model and a physics-based simulation environment. In this paper, we discuss the design of the competition, technical difficulties, results, and analysis of the top controllers. The challenge proved that deep reinforcement learning techniques, despite their high computational cost, can be successfully employed as an optimization method for synthesizing physiologically feasible motion in high-dimensional biomechanical systems.", "text_perturb": "Synthesizing physiologically-accurate human movement in a variety of conditions can help practitioners plan surgeries , design experiments , or prototype assistive devices in simulated environments , reducing time and costs and improving treatment effect. Because of the large and complex solution spaces of biomechanical manikin , current methods are constrained to specific movements and manikin , requiring careful design of a controller and hindering many possible applications. We sought to discover if modern optimization methods expeditiously explore these complex spaces. To do this , we posed the problem as a contest in which participants were tasked with developing a controller to enable a physiologically-based human model to navigate a complex obstacle course as quickly as possible , without using any experimental data. They were provided with a human musculoskeletal model and a physics-based simulation surroundings. In this paper , we discuss the design of the contender , technical difficulties , results , and analysis of the top controllers. The challenge proved that deep reinforcement learning techniques , despite their high computational cost , can be successfully employed as an optimization method for synthesizing physiologically feasible motion in high-dimensional biomechanical system of rules. ", "label": 1}
{"original_text": "A lot of research has been focused on secure outsourcing of biometric identification in the context of cloud computing. In such schemes, both the encrypted biometric database and the identification process are outsourced to the cloud. The ultimate goal is to protect the security and privacy of the biometric database and the query templates. Security analysis shows that previous schemes suffer from the enrolment attack and unnecessarily expose more information than needed. In this paper, we propose a new secure outsourcing scheme aims at enhancing the security from these two aspects. First, besides all the attacks discussed in previous schemes, our proposed scheme is also secure against the enrolment attack. Second, we model the identification process as a fixed radius similarity query problem instead of the kNN search problem. Such a modelling is able to reduce the exposed information thus enhancing the privacy of the biometric database. Our comprehensive security and complexity analysis show that our scheme is able to enhance the security and privacy of the biometric database and query templates while maintaining the same computational savings from outsourcing.", "text_perturb": "A lot of inquiry has been focused on secure outsourcing of biometric identification in the context of cloud computing. In such schemes , both the encrypted biometric database and the identification process are outsource to the cloud. The ultimate goal is to protect the security and privacy of the biometric database and the question templates. Security analysis bear witness that previous schemes suffer from the enrolment attack and unnecessarily expose more information than needed. In this paper , we propose a new secure outsourcing strategy aims at enhancing the security from these two aspects. First , besides all the attacks discussed in old schemes , our proposed scheme is also secure against the enrolment attack. nd , we model the identification process as a fixed radius similarity query problem instead of the kNN search problem. Such a modelling is capable to reduce the exposed information thus enhancing the privacy of the biometric database. Our comprehensive security and complexity analysis display that our scheme is able to enhance the security and privacy of the biometric database and query templates while maintaining the same computational savings from outsourcing. ", "label": 1}
{"original_text": "We present a bandit algorithm, SAO (Stochastic and Adversarial Optimal), whose regret is, essentially, optimal both for adversarial rewards and for stochastic rewards. Specifically, SAO combines the O (n) worst-case regret of Exp3 [, ] for adversarial rewards and the (poly) logarithmic regret of UCB1 [, ] for stochastic rewards. Adversarial rewards and stochastic rewards are the two main settings in the literature on (non-Bayesian) multi-armed bandits. Prior work on multi-armed bandits treats them separately, and does not attempt to jointly optimize for both. Our result falls into a general theme of achieving good worst-case performance while also taking advantage of \"nice\" problem instances, an important issue in the design of algorithms with partially known inputs.", "text_perturb": "We present a bandit algorithm , SAO ( Stochastic and Adversarial Optimal ) , whose regret is , essentially , optimum both for adversarial rewards and for stochastic rewards. Specifically , SAO combines the O ( n ) worst-case sorrow of Exp3 [ , ] for adversarial rewards and the ( poly ) logarithmic sorrow of UCB1 [ , ] for stochastic rewards. Adversarial rewards and stochastic rewards are the two main settings in the literature on ( non-Bayesian ) multi-armed brigand. Prior work on multi-armed bandits treats them individually , and does not attempt to jointly optimize for both. Our result falls into a general theme of achieving good worst-case performance while also taking advantage of `` nice '' problem instances , an significant issue in the design of algorithms with partially known inputs. ", "label": 1}
{"original_text": "Data augmentation in deep neural networks is the process of generating artificial data in order to reduce the variance of the classifier with the goal to reduce the number of errors. This idea has been shown to improve deep neural network's generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike in image recognition problems, data augmentation techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved, especially for small datasets that exhibit overfitting, when a data augmentation method is adopted. In this paper, we fill this gap by investigating the application of a recently proposed data augmentation technique based on the Dynamic Time Warping distance, for a deep learning model for TSC. To evaluate the potential of augmenting the training set, we performed extensive experiments using the UCR TSC benchmark. Our preliminary experiments reveal that data augmentation can drastically increase deep CNN's accuracy on some datasets and significantly improve the deep model's accuracy when the method is used in an ensemble approach.", "text_perturb": "data point augmentation in deep neural networks is the process of generating artificial data in order to reduce the variance of the classifier with the goal to reduce the number of errors. This idea has been shown to improve deep neural network 's generalization capabilities in many computer imaginativeness tasks such as image recognition and object localization. Apart from these applications , deep Convolutional Neural Networks ( CNNs ) have also lately gained popularity in the Time Series Classification ( TSC ) community. However , unlike in image recognition problems , data augmentation techniques cause not yet been investigated thoroughly for the TSC task. This make up surprising as the accuracy of deep learning models for TSC could potentially be improved , especially for small datasets that exhibit overfitting , when a data augmentation method make up adopted. In this paper , we fill this gap by inquire the application of a recently proposed data augmentation technique based on the Dynamic Time Warping distance , for a deep learning model for TSC. To evaluate the potential of augmenting the training set , we performed extensive experiments utilize the UCR TSC benchmark. Our preliminary experiments reveal that data augmentation can drastically increase deep CNN 's accuracy on some datasets and importantly improve the deep model 's accuracy when the method is used in an ensemble approach. ", "label": 1}
{"original_text": "Hypothesis testing for graphs has been an important tool in applied research fields for more than two decades, and still remains a challenging problem as one often needs to draw inference from few replicates of large graphs. Recent studies in statistics and learning theory have provided some theoretical insights about such high-dimensional graph testing problems, but the practicality of the developed theoretical methods remains an open question. In this paper, we consider the problem of two-sample testing of large graphs. We demonstrate the practical merits and limitations of existing theoretical tests and their bootstrapped variants. We also propose two new tests based on asymptotic distributions. We show that these tests are computationally less expensive and, in some cases, more reliable than the existing methods.", "text_perturb": "Hypothesis testing for graphical record has been an important tool in applied research fields for more than two decades , and still remains a challenging problem as one often needs to draw inference from few replicates of large graphical record. Recent discipline in statistics and learning theory have provided some theoretical insights about such high-dimensional graph testing problems , but the practicality of the developed theoretical methods remains an open question. In this paper , we consider the problem of two-sample examination of large graphs. We demonstrate the practical merits and limitations of existing theoretical tests and their bootstrapped var. We too propose two new tests based on asymptotic distributions. We show that these run are computationally less expensive and , in some cases , more reliable than the existing methods. ", "label": 1}
{"original_text": "An r -identifying code in a graph G (V, E) is a subset C V such that for each u V the intersection of C and the ball of radius r centered at u is non-empty and unique. Previously, r -identifying codes have been studied in various grids. In particular, it has been shown that there exists a 2 -identifying code in the hexagonal grid with density 4 19 and that there are no 2 -identifying codes with density smaller than 2 11. Recently, the lower bound has been improved to 1 5 by Martin and Stanton (2010). In this paper, we prove that the 2 -identifying code with density 4 19 is optimal, i.e. that there does not exist a 2 -identifying code in the hexagonal grid with smaller density.", "text_perturb": "An r -identifying code in a graph G ( V , einsteinium ) is a subset C V such that for each u V the intersection of C and the ball of radius r centered at u is non-empty and unique. Previously , r -identifying codes bear been studied in various grids. In particular , it has been shown that there exists a 2 -identifying computer code in the hexagonal grid with density 4 19 and that there are no 2 -identifying codes with density smaller than 2 11. Recently , the lower bound has been improved to 1 5 by Martin and elizabeth cady stanton ( 2010 ). In this paper , we prove that the 2 -identifying codification with density 4 19 is optimal , i. due east. that there does not be a 2 -identifying code in the hexagonal grid with smaller density. ", "label": 1}
{"original_text": "We develop a well-balanced central-upwind scheme for rotating shallow water model with horizontal temperature andor density gradients - the thermal rotating shallow water (TRSW). The scheme is designed using the flux globalization approach: first, the source terms are incorporated into the fluxes, which results in a hyperbolic system with global fluxes; second, we apply the Riemann-problem-solver-free central-upwind scheme to the rewritten system. We ensure that the resulting method is well-balanced by switching off the numerical diffusion when the computed solution is near (at) thermo-geostrophic equilibria. The designed scheme is successfully tested on a series of numerical examples. Motivated by future applications to large-scale motions in the ocean and atmosphere, the model is considered on the tangent plane to a rotating planet both in mid-latitudes and at the Equator. The numerical scheme is shown to be capable of quite accurately maintaining the equilibrium states in the presence of nontrivial topography and rotation. Prior to numerical simulations, an analysis of the TRSW model based on the use of Lagrangian variables is presented, allowing one to obtain criteria of existence and uniqueness of the equilibrium state, of the wave-breaking and shock formation, and of instability development out of given initial conditions. The established criteria are confirmed in the conducted numerical experiments.", "text_perturb": "We develop a well-balanced central-upwind scheme for circumvolve shallow water model with horizontal temperature andor density gradients - the thermal rotating shallow water ( TRSW ). The scheme is contrive using the flux globalization approach : first , the source terms are incorporated into the fluxes , which results in a hyperbolic system with global fluxes ; second , we apply the Riemann-problem-solver-free central-upwind scheme to the rewritten system. We ensure that the resulting method acting is well-balanced by switching off the numerical diffusion when the computed solution is near ( at ) thermo-geostrophic equilibria. The designed scheme is successfully tested on a serial of numerical examples. Motivated by future applications to large-scale motions in the ocean and atmosphere , the model is considered on the tangent plane to a rotating planet both in mid-latitudes and at the equator. The numerical scheme is shown to constitute capable of quite accurately maintaining the equilibrium states in the presence of nontrivial topography and rotation. Prior to numerical simulations , an analysis of the TRSW model based on the use of Lagrangian variables is presented , allowing one to obtain criteria of existence and uniqueness of the equilibrium state , of the wave-breaking and impact formation , and of instability development out of given initial conditions. The make criteria are confirmed in the conducted numerical experiments. ", "label": 1}
{"original_text": "Partially answering a question of Paul Seymour, we obtain a sufficient eigenvalue condition for the existence of k edge-disjoint spanning trees in a regular graph, when k {2, 3 }. More precisely, we show that if the second largest eigenvalue of a d -regular graph G is less than - d - 2 k 1 d 1, then G contains at least k edge-disjoint spanning trees, when k {2, 3 }. We construct examples of graphs that show our bounds are essentially best possible. We conjecture that the above statement is true for any k d 2.", "text_perturb": "Partially answering a question of Paul Seymour , we incur a sufficient eigenvalue condition for the existence of k edge-disjoint spanning trees in a regular graph , when k { 2 , 3 }. more precisely , we show that if the second largest eigenvalue of a d -regular graph G is less than - d - 2 k 1 d 1 , then G contains at least k edge-disjoint spanning trees , when k { 2 , 3 }. We construct examples of graphs that show our bounds are essentially good possible. We conjecture that the above command is true for any k d 2. ", "label": 1}
{"original_text": "We propose a novel biologically-plausible solution to the credit assignment problem, being motivated by observations in the ventral visual pathway and trained deep neural networks. In both, representations of objects in the same category become progressively more similar, while objects belonging to different categories becomes less similar. We use this observation to motivate a layer-specific learning goal in a deep network: each layer aims to learn a representational similarity matrix that interpolates between previous and later layers. We formulate this idea using a supervised deep similarity matching cost function and derive from it deep neural networks with feedforward, lateral and feedback connections, and neurons that exhibit biologically-plausible Hebbian and anti-Hebbian plasticity. Supervised deep similarity matching can be interpreted as an energy-based learning algorithm, but with significant differences from others in how a contrastive function is constructed.", "text_perturb": "We propose a novel biologically-plausible solution to the credit assignment problem , live motivated by observations in the ventral visual pathway and trained deep neural networks. In both , representations of objects in the same category become progressively to a greater extent similar , while objects belonging to different categories becomes less similar. We use this observation to motivate a layer-specific learning goal in a deep network : each layer aims to learn a representational similarity matrix that interpolates between former and later layers. We formulate this idea using a supervised deep similarity jibe cost function and derive from it deep neural networks with feedforward , lateral and feedback connections , and neurons that exhibit biologically-plausible Hebbian and anti-Hebbian plasticity. Supervised deep similarity matching can be see as an energy-based learning algorithm , but with significant differences from others in how a contrastive function is constructed. ", "label": 1}
{"original_text": "Crowd counting from unconstrained scene images is a crucial task in many real-world applications like urban surveillance and management, but it is greatly challenged by the camera's perspective that causes huge appearance variations in people's scales and rotations. Conventional methods address such challenges by resorting to fixed multi-scale architectures that are often unable to cover the largely varied scales while ignoring the rotation variations. In this paper, we propose a unified neural network framework, named Deep Recurrent Spatial-Aware Network, which adaptively addresses the two issues in a learnable spatial transform module with a region-wise refinement process. Specifically, our framework incorporates a Recurrent Spatial-Aware Refinement (RSAR) module iteratively conducting two components: i) a Spatial Transformer Network that dynamically locates an attentional region from the crowd density map and transforms it to the suitable scale and rotation for optimal crowd estimation; ii) a Local Refinement Network that refines the density map of the attended region with residual learning. Extensive experiments on four challenging benchmarks show the effectiveness of our approach. Specifically, comparing with the existing best-performing methods, we achieve an improvement of 12 on the largest dataset WorldExpo'10 and 22.8 on the most challenging dataset UCFCC50.", "text_perturb": "Crowd counting from unconstrained scene images is a crucial task in many real-world applications like urban surveillance and direction , but it is greatly challenged by the camera 's perspective that causes huge appearance variations in people 's scales and rotations. Conventional methods address such challenges by resorting to fixed multi-scale architectures that are often unable to cover the largely varied scales while cut the rotation variations. In this paper , we propose a unified neural network framework , refer Deep Recurrent Spatial-Aware Network , which adaptively addresses the two issues in a learnable spatial transform module with a region-wise refinement process. Specifically , our framework incorporates a Recurrent Spatial-Aware Refinement ( RSAR ) module iteratively conducting two components : i ) a Spatial Transformer Network that dynamically locates an attentional region from the crowd tightness map and transforms it to the suitable scale and rotation for optimal crowd estimation ; ii ) a Local Refinement Network that refines the tightness map of the attended region with residual learning. Extensive experimentation on four challenging benchmarks show the effectiveness of our approach. Specifically , comparing with the existing best-performing methods , we attain an improvement of 12 on the largest dataset WorldExpo'10 and 22. 8 on the most ambitious dataset UCFCC50. ", "label": 1}
{"original_text": "In spite of its importance, passenger demand prediction is a highly challenging problem, because the demand is simultaneously influenced by the complex interactions among many spatial and temporal factors and other external factors such as weather. To address this problem, we propose a Spatio-TEmporal Fuzzy neural Network (STEF-Net) to accurately predict passenger demands incorporating the complex interactions of all known important factors. We design an end-to-end learning framework with different neural networks modeling different factors. Specifically, we propose to capture spatio-temporal feature interactions via a convolutional long short-term memory network and model external factors via a fuzzy neural network that handles data uncertainty significantly better than deterministic methods. To keep the temporal relations when fusing two networks and emphasize discriminative spatio-temporal feature interactions, we employ a novel feature fusion method with a convolution operation and an attention layer. As far as we know, our work is the first to fuse a deep recurrent neural network and a fuzzy neural network to model complex spatial-temporal feature interactions with additional uncertain input features for predictive learning. Experiments on a large-scale real-world dataset show that our model achieves more than 10 improvement over the state-of-the-art approaches.", "text_perturb": "In spite of its importance , passenger demand prediction is a highly challenging problem , because the demand is simultaneously determine by the complex interactions among many spatial and temporal factors and other external factors such as weather. To address this problem , we propose a Spatio-TEmporal Fuzzy neural Network ( STEF-Net ) to accurately predict passenger demand incorporating the complex interactions of all known important factors. We design an end-to-end learning framework with different neural web modeling different factors. Specifically , we propose to capture spatio-temporal feature interactions via a convolutional long short run memory network and model external factors via a fuzzy neural network that handles data uncertainty significantly better than deterministic methods. To keep the temporal relations when fusing two networks and emphasize discriminative spatio-temporal feature of speech interactions , we employ a novel feature of speech fusion method with a convolution operation and an attention layer. As far as we know , our work is the first to fuse a deep recurrent neural network and a fuzzy neural network to sit complex spatial-temporal feature interactions with additional uncertain input features for predictive learning. Experiments on a large-scale real-world dataset show that our model achieves more than 10 melioration over the state-of-the-art approaches. ", "label": 1}
{"original_text": "Linguistically diverse datasets are critical for training and evaluating robust machine learning systems, but data collection is a costly process that often requires experts. Crowdsourcing the process of paraphrase generation is an effective means of expanding natural language datasets, but there has been limited analysis of the trade-offs that arise when designing tasks. In this paper, we present the first systematic study of the key factors in crowdsourcing paraphrase collection. We consider variations in instructions, incentives, data domains, and workflows. We manually analyzed paraphrases for correctness, grammaticality, and linguistic diversity. Our observations provide new insight into the trade-offs between accuracy and diversity in crowd responses that arise as a result of task design, providing guidance for future paraphrase generation procedures.", "text_perturb": "Linguistically various datasets are critical for training and evaluating robust machine learning systems , but data collection is a costly process that often requires experts. Crowdsourcing the process of paraphrase generation is an effective means of expanding natural oral communication datasets , but there has been limited analysis of the trade-offs that arise when designing tasks. In this paper , we present the beginning systematic study of the key factors in crowdsourcing paraphrase collection. We consider variations in instructions , incentives , datum domains , and workflows. We manually break down paraphrases for correctness , grammaticality , and linguistic diversity. Our observations provide new insight into the trade-offs between accuracy and diversity in crowd responses that arise as a result of task design , providing guidance for succeeding paraphrase generation procedures. ", "label": 1}
{"original_text": "A theory explaining how deep learning works is yet to be developed. Previous work suggests that deep learning performs a coarse graining, similar in spirit to the renormalization group (RG). This idea has been explored in the setting of a local (nearest neighbor interactions) Ising spin lattice. We extend the discussion to the setting of a long range spin lattice. Markov Chain Monte Carlo (MCMC) simulations determine both the critical temperature and scaling dimensions of the system. The model is used to train both a single RBM (restricted Boltzmann machine) network, as well as a stacked RBM network. Following earlier Ising model studies, the trained weights of a single layer RBM network define a flow of lattice models. In contrast to results for nearest neighbor Ising, the RBM flow for the long ranged model does not converge to the correct values for the spin and energy scaling dimension. Further, correlation functions between visible and hidden nodes exhibit key differences between the stacked RBM and RG flows. The stacked RBM flow appears to move towards low temperatures whereas the RG flow moves towards high temperature. This again differs from results obtained for nearest neighbor Ising.", "text_perturb": "A theory explaining how deep scholarship works is yet to be developed. Previous work suggests that deep learning performs a vulgar graining , similar in spirit to the renormalization group ( RG ). This idea has been explored in the setting of a local ( nearest neighbour interactions ) Ising spin lattice. We extend the discussion to the place setting of a long range spin lattice. markov Chain Monte Carlo ( MCMC ) simulations determine both the critical temperature and scaling dimensions of the system. The model is used to train both a single RBM ( restricted Boltzmann machine ) meshing , as well as a stacked RBM meshing. Following earlier Ising model studies , the trained weightiness of a single layer RBM network define a flow of lattice models. In contrast to results for nearest neighbor Ising , the RBM flow for the farseeing ranged model does not converge to the correct values for the spin and energy scaling dimension. Further , correlation functions between visible and secret nodes exhibit key differences between the stacked RBM and RG flows. The stacked RBM catamenia appears to move towards low temperatures whereas the RG catamenia moves towards high temperature. This again differs from results obtained for nearest neighbour Ising. ", "label": 1}
{"original_text": "The (classical) problem of characterizing and enumerating permutations that can be sorted using two stacks connected in series is still largely open. In the present paper we address a related problem, in which we impose restrictions both on the procedure and on the stacks. More precisely, we consider a greedy algorithm where we perform the rightmost legal operation (here \"rightmost\" refers to the usual representation of stack sorting problems). Moreover, the first stack is required to be s -avoiding, for some permutation s, meaning that, at each step, the elements maintained in the stack avoid the pattern s when read from top to bottom. Since the set of permutations which can be sorted by such a device (which we call s -machine) is not always a class, it would be interesting to understand when it happens. We will prove that the set of s -machines whose associated sortable permutations are not a class is counted by Catalan numbers. Moreover, we will analyze two specific s -machines in full details (namely when s 321 and s 123), providing for each of them a complete characterization and enumeration of sortable permutations.", "text_perturb": "The ( classical ) problem of characterizing and enumerating replacement that can be sorted using two stacks connected in series is still largely open. In the present paper we call a related problem , in which we impose restrictions both on the procedure and on the stacks. More precisely , we consider a greedy algorithm where we perform the rightmost legal performance ( here `` rightmost '' refers to the usual representation of stack sorting problems ). Moreover , the inaugural stack is required to be s -avoiding , for some permutation s , meaning that , at each step , the elements maintained in the stack avoid the pattern s when read from top to bottom. Since the set of permutations which can be sorted by such a twist ( which we call s -machine ) is not always a class , it would be interesting to understand when it happens. We will evidence that the set of s -machines whose associated sortable permutations are not a class is counted by Catalan numbers. Moreover , we will analyze two specific s -machines in full contingent ( namely when s 321 and s 123 ) , providing for each of them a complete characterization and enumeration of sortable permutations. ", "label": 1}
{"original_text": "In recent times, using small data to train networks has become a hot topic in the field of deep learning. Reusing pre-trained parameters is one of the most important strategies to address the issue of semi-supervised and transfer learning. However, the fundamental reason for the success of these methods is still unclear. In this paper, we propose a solution that can not only judge whether a given network is reusable or not based on the performance of reusing convolution kernels but also judge which layers' parameters of the given network can be reused, based on the performance of reusing corresponding parameters and, ultimately, judge whether those parameters are reusable or not in a target task based on the root mean square error (RMSE) of the corresponding convolution kernels. Specifically, we define that the success of a CNN's parameter reuse depends upon two conditions: first, the network is a reusable network; and second, the RMSE between the convolution kernels from the source domain and target domain is small enough. The experimental results demonstrate that the performance of reused parameters applied to target tasks, when these conditions are met, is significantly improved.", "text_perturb": "In late times , using small data to train networks has become a hot topic in the field of deep learning. Reusing pre-trained parameters is one of the most important strategies to address the issue of semi-supervised and change learning. yet , the fundamental reason for the success of these methods is still unclear. In this paper , we propose a solution that can not only judge whether a given network is reusable or not free base on the performance of reusing convolution kernels but also judge which layers ' parameters of the given network can be reused , free base on the performance of reusing corresponding parameters and , ultimately , judge whether those parameters are reusable or not in a target task free base on the root mean square error ( RMSE ) of the corresponding convolution kernels. Specifically , we define that the success of a CNN 's parameter reuse depends upon two conditions : first , the network comprise a reusable network ; and second , the RMSE between the convolution kernels from the source domain and target domain comprise small enough. The observational results demonstrate that the performance of reused parameters applied to target tasks , when these conditions are met , is significantly improved. ", "label": 1}
{"original_text": "National Eating Disorders Association conducts a NEDAwareness week every year, during which it publishes content on social media and news aimed to raise awareness of eating disorders. Measuring the impact of these actions is vital for maximizing the effectiveness of such interventions. This paper is an effort to model the change in behavior of users who engage with NEDAwareness content. We find that, despite popular influencers being involved in the campaign, it is governmental and nonprofit accounts that attract the most retweets. Furthermore, examining the tweeting language of users engaged with this content, we find linguistic categories concerning women, family, and anxiety to be mentioned more within the 15 days after the intervention, and categories concerning affiliation, references to others, and positive emotion mentioned less. We conclude with actionable implications for future campaigns and discussion of the method's limitations.", "text_perturb": "National Eating Disorders Association conducts a NEDAwareness week every year , during which it publishes mental object on social media and news aimed to raise awareness of eating disorders. Measuring the impact of these actions is vital for maximise the effectiveness of such interventions. This paper is an effort to model the change in demeanour of users who engage with NEDAwareness content. We find that , despite popular influencers being involved in the campaign , it is governmental and non profit making accounts that attract the most retweets. Furthermore , examining the tweeting language of users engaged with this content , we find linguistic class concerning women , family , and anxiety to be mentioned more within the 15 days after the intervention , and class concerning affiliation , references to others , and positive emotion mentioned less. We conclude with actionable implications for future campaigns and discussion of the method 's limitation. ", "label": 1}
{"original_text": "Compromised social media accounts are legitimate user accounts that have been hijacked by a malicious party and can cause various kinds of damage, which makes the detection of these accounts crucial. In this work we propose a novel general framework for discovering compromised accounts by utilizing statistical text analysis. The framework is built on the observation that users will use language that is measurably different from the language that an attacker would use, when the account is compromised. We use the framework to develop specific algorithms based on language modeling and use the similarity of language models of users and attackers as features in a supervised learning setup to identify compromised accounts. Evaluation results on a large Twitter corpus of over 129 million tweets show promising results of the proposed approach.", "text_perturb": "compromise social media accounts are legitimate user accounts that have been hijacked by a malicious party and can cause various kinds of damage , which makes the detection of these accounts crucial. In this work we propose a fresh general framework for discovering compromised accounts by utilizing statistical text analysis. The framework is built on the observation that users will use terminology that is measurably different from the terminology that an attacker would use , when the account is compromised. We use the framework to develop specific algorithms based on language modeling and use the similarity of language models of users and attacker as features in a supervised learning setup to identify compromised accounts. Evaluation results on a declamatory Twitter corpus of over 129 million tweets show promising results of the proposed approach. ", "label": 1}
{"original_text": "Internet of Things (IoT) devices have become ubiquitous and are spread across many application domains including the industry, transportation, healthcare, and households. However, the proliferation of the IoT devices has raised the concerns about their security, especially when observing that many manufacturers focus only on the core functionality of their products due to short time to market and low cost pressures, while neglecting security aspects. Moreover, it does not exist any established or standardized method for measuring and ensuring the security of IoT devices. Consequently, vulnerabilities are left untreated, allowing attackers to exploit IoT devices for various purposes, such as compromising privacy, recruiting devices into a botnet, or misusing devices to perform cryptocurrency mining. In this paper, we present a practical Host-based Anomaly DEtection System for IoT (HADES-IoT) that represents the last line of defense. HADES-IoT has proactive detection capabilities, provides tamper-proof resistance, and it can be deployed on a wide range of Linux-based IoT devices. The main advantage of HADES-IoT is its low performance overhead, which makes it suitable for the IoT domain, where state-of-the-art approaches cannot be applied due to their high-performance demands. We deployed HADES-IoT on seven IoT devices to evaluate its effectiveness and performance overhead. Our experiments show that HADES-IoT achieved 100 effectiveness in the detection of current IoT malware such as VPNFilter and IoTReaper; while on average, requiring only 5.5 of available memory and causing only a low CPU load.", "text_perturb": "Internet of Things ( IoT ) devices have become ubiquitous and personify spread across many application domains including the industry , transportation , healthcare , and households. However , the proliferation of the IoT devices has raised the concerns about their security , especially when observing that many manufacturers focus only on the core functionality of their products due to short time to market and downcast cost pressures , while neglecting security aspects. Moreover , it come not exist any established or standardized method for measuring and ensuring the security of IoT devices. Consequently , vulnerabilities are left untreated , allowing attackers to exploit IoT gimmick for various purposes , such as compromising privacy , recruiting gimmick into a botnet , or misusing gimmick to perform cryptocurrency mining. In this paper , we present a practical Host-based Anomaly DEtection System for IoT ( HADES-IoT ) that defend the last line of defense. HADES-IoT has proactive spying capabilities , provides tamper-proof resistance , and it can be deployed on a wide range of Linux-based IoT devices. The main advantage of HADES-IoT is its low performance overhead , which makes it suitable for the IoT domain , where state-of-the-art approaches can non be applied due to their high-performance demands. We deployed HADES-IoT on seven IoT devices to evaluate its effectiveness and functioning overhead. Our experiments show that HADES-IoT attain 100 effectiveness in the detection of current IoT malware such as VPNFilter and IoTReaper ; while on average , requiring only 5. 5 of available memory and causing only a low CPU consignment. ", "label": 1}
{"original_text": "Degree sequence (DS) problems are around for at least hundred twenty years, and with the advent of network science, more and more complicated, structured DS problems were invented. Interestingly enough all those problems so far are computationally easy. It is clear, however, that we will find soon computationally hard DS problems. In this paper we want to find such hard DS problems with relatively simple definition. For a vertex v in the simple graph G denote d I (v) the number of vertices at distance exactly I from v. Then d 1 (v) is the usual degree of vertex v. The vector d 2 (G) d 1 (v 1), d 2 (v 1, ..., (d 1 (v n), d 2 (v n is the second order degree sequence of the graph G. In this note we show that the problem to decide whether a sequence of natural numbers i 1, j 1), ... (i n, j n is a second order degree sequence of a simple undirected graph G is strongly NP -complete. Then we will discuss some further NP -complete DS problems.", "text_perturb": "Degree sequence ( DS ) job are around for at least hundred twenty years , and with the advent of network science , more and more complicated , structured DS job were invented. interestingly enough all those problems so far are computationally easy. It is clear , however , that we will find soon computationally operose DS problems. In this paper we require to find such hard DS problems with relatively simple definition. For a vertex v in the simple graph G denote ergocalciferol I ( v ) the number of vertices at distance exactly I from v. Then d 1 ( v ) be the usual degree of vertex v. The vector calciferol 2 ( G ) d 1 ( v 1 ) , d 2 ( v 1 ,. . . , ( d 1 ( v n ) , d 2 ( v n exist the second order degree sequence of the graph G. In this note we show that the problem to decide whether a sequence of natural numbers pool i 1 , j 1 ) ,. . . ( i n , watt second n is a second order degree sequence of a simple undirected graph G is strongly NP -complete. Then we will discuss some further NP -complete cholecalciferol problems. ", "label": 1}
{"original_text": "The long-standing byzantine agreement problem gets more attention in recent years due to the increasing demand for scalable geo-replicated Byzantine state machine replication (SMR) systems (e.g., Blockchains). To date, the key bottleneck of such systems is the communication cost of the byzantine agreement they employ as a building block, which motivates many researchers to search for low-communication byzantine agreement protocols. The conventional approach is to design deterministic protocols in the eventually synchronous communication model that are optimized to reduce the communication cost after the global stabilization time (GST). In this paper, we challenge the conventional approach and argue it is not the best fit for scalable SMR systems since it might induce an unbounded communication cost during asynchronous periods before GST, which we prove to be inherent. Instead, we forgo eventual synchrony and propose a different approach that hopes for the best (synchrony) but prepares for the worst (asynchrony). Accordingly, we design an optimistic protocol that first tries to reach an agreement via an efficient deterministic algorithm that relies on synchrony for termination, and then, only if an agreement was not reached due to asynchrony, the protocol uses a randomized asynchronous algorithm for fallback that guarantees termination with probability 1. Although randomized asynchronous algorithms are considered to be costly, we design our solution to pay this cost only when an equivalent cost has already been paid while unsuccessfully trying the synchronous protocol. We formally prove that our protocol achieves optimal communication complexity under all network conditions and failure scenarios. We first prove a lower bound of O (f t t) for synchronous deterministic agreement protocols, where t is the failure threshold, and f is the actual number of failures. Then, we present a tight upper bound and use it for our synchronous part. Finally, for the asynchronous fallback, we use a variant of the (optimal) VABA protocol, which we reconstruct to safely combine it with the synchronous part.", "text_perturb": "The long-standing byzantine agreement problem gets more attention in recent twelvemonth due to the increasing demand for scalable geo-replicated Byzantine state machine replication ( SMR ) systems ( e. k. , Blockchains ). To date , the key bottleneck of such systems constitute the communication cost of the byzantine agreement they employ as a building block , which motivates many researchers to search for low-communication byzantine agreement protocols. The conventional approach is to design deterministic protocols in the eventually synchronous communication model that are optimize to reduce the communication cost after the global stabilization time ( GST ). In this paper , we challenge the conventional approach and argue it is non the best fit for scalable SMR systems since it might induce an unbounded communication cost during asynchronous periods before GST , which we prove to be inherent. Instead , we forgo eventual synchrony and propose a different glide path that hopes for the best ( synchrony ) but prepares for the worst ( asynchrony ). Accordingly , we design an optimistic protocol that first tries to reach an agreement via an efficient deterministic algorithm that relies on synchroneity for termination , and then , only if an agreement was not reached due to asynchrony , the protocol uses a randomized asynchronous algorithm for fallback that guarantees termination with probability 1. Although randomized asynchronous algorithms are considered to be costly , we project our solution to pay this cost only when an equivalent cost has already been paid while unsuccessfully trying the synchronous protocol. We formally prove that our protocol achieves optimal communicating complexity under all network conditions and failure scenarios. We first prove a low bound of O ( f t t ) for synchronous deterministic agreement protocols , where t is the failure threshold , and f is the actual number of failures. Then , we present a tight upper limit and use it for our synchronous part. Finally , for the asynchronous fallback , we use a stochastic variable of the ( optimal ) VABA protocol , which we reconstruct to safely combine it with the synchronous part. ", "label": 1}
{"original_text": "Since its renaissance, deep learning has been widely used in various medical imaging tasks and has achieved remarkable success in many medical imaging applications, thereby propelling us into the so-called artificial intelligence (AI) era. It is known that the success of AI is mostly attributed to the availability of big data with annotations for a single task and the advances in high performance computing. However, medical imaging presents unique challenges that confront deep learning approaches. In this survey paper, we first highlight both clinical needs and technical challenges in medical imaging and describe how emerging trends in deep learning are addressing these issues. We cover the topics of network architecture, sparse and noisy labels, federating learning, interpretability, uncertainty quantification, etc. Then, we present several case studies that are commonly found in clinical practice, including digital pathology and chest, brain, cardiovascular, and abdominal imaging. Rather than presenting an exhaustive literature survey, we instead describe some prominent research highlights related to these case study applications. We conclude with a discussion and presentation of promising future directions.", "text_perturb": "Since its renaissance , deep learning has been widely used in various medical imaging tasks and has attain remarkable success in many medical imaging applications , thereby propelling us into the so-called artificial intelligence ( AI ) era. It is known that the winner of AI is mostly attributed to the availability of big data with annotations for a single task and the advances in high performance computing. However , medical mental imagery presents unique challenges that confront deep learning approaches. In this survey paper , we first of all highlight both clinical needs and technical challenges in medical imaging and describe how emerging trends in deep learning are addressing these issues. We cover the topics of network architecture , sparse and noisy labels , federating learning , interpretability , dubiety quantification , etc. Then , we present several case studies that are commonly found in clinical practice , including digital pathology and breast , brain , cardiovascular , and abdominal imaging. Rather than presenting an thoroughgoing literature survey , we instead describe some prominent research highlights related to these case study applications. We conclude with a discourse and presentation of promising future directions. ", "label": 1}
{"original_text": "We present an evaluation of several representative sampling-based and optimization-based motion planners, and then introduce an integrated motion planning system which incorporates recent advances in trajectory optimization into a sparse roadmap framework. Through experiments in 4 common application scenarios with 5000 test cases each, we show that optimization-based or sampling-based planners alone are not effective for realistic problems where fast planning times are required. To the best of our knowledge, this is the first work that presents such a systematic and comprehensive evaluation of state-of-the-art motion planners, which are based on a significant amount of experiments. We then combine different stand-alone planners with trajectory optimization. The results show that the combination of our sparse roadmap and trajectory optimization provides superior performance over other standard sampling-based planners' combinations. By using a multi-query roadmap instead of generating completely new trajectories for each planning problem, our approach allows for extensions such as persistent control policy information associated with a trajectory across planning problems. Also, the sub-optimality resulting from the sparsity of roadmap, as well as the unexpected disturbances from the environment, can both be overcome by the real-time trajectory optimization process.", "text_perturb": "We present an evaluation of several representative sampling-based and optimization-based motion planners , and then introduce an integrated motion planning system which incorporates recent advances in trajectory optimisation into a sparse roadmap framework. Through experiments in 4 vernacular application scenarios with 5000 test cases each , we show that optimization-based or sampling-based planners alone are not effective for realistic problems where fast planning times are required. To the best of our knowledge , this is the first work that presents such a systematic and comprehensive evaluation of state-of-the-art movement planners , which are based on a significant amount of experiments. We then blend different stand-alone planners with trajectory optimization. The results show that the combination of our sparse roadmap and trajectory optimization provides superior operation over other standard sampling-based planners ' combinations. By using a multi-query roadmap instead of generating completely new trajectories for each planning problem , our approach allows for reference such as persistent control policy information associated with a trajectory across planning problems. Also , the sub-optimality resulting from the spareness of roadmap , as well as the unexpected disturbances from the environment , can both be overcome by the real-time trajectory optimization process. ", "label": 1}
{"original_text": "In this contribution we generalize the classical Fourier Mellin transform, which transforms functions f representing, e.g., a gray level image defined over a compact set of R 2. The quaternionic Fourier Mellin transform (QFMT) applies to functions: f - R 2 H, for which f is summable over x R S 1 under the measure d th d r r. R is the multiplicative group of positive and non-zero real numbers. We investigate the properties of the QFMT similar to the investigation of the quaternionic Fourier Transform (QFT) in.", "text_perturb": "In this contribution we vulgarise the classical Fourier Mellin transform , which transforms functions f representing , e. gigabyte. , a grayish level image defined over a compact set of R 2. The quaternionic Fourier Mellin transform ( QFMT ) applies to functions : f - R 2 H , for which f is summable over x R sulfur 1 under the measure d th d r r. R is the multiplicative group of positive and non-zero real figure. We investigate the holding of the QFMT similar to the investigation of the quaternionic Fourier Transform ( QFT ) in. ", "label": 1}
{"original_text": "Object detection and instance segmentation are dominated by region-based methods such as Mask RCNN. However, there is a growing interest in reducing these problems to pixel labeling tasks, as the latter could be more efficient, could be integrated seamlessly in image-to-image network architectures as used in many other tasks, and could be more accurate for objects that are not well approximated by bounding boxes. In this paper we show theoretically and empirically that constructing dense pixel embeddings that can separate object instances cannot be easily achieved using convolutional operators. At the same time, we show that simple modifications, which we call semi-convolutional, have a much better chance of succeeding at this task. We use the latter to show a connection to Hough voting as well as to a variant of the bilateral kernel that is spatially steered by a convolutional network. We demonstrate that these operators can also be used to improve approaches such as Mask RCNN, demonstrating better segmentation of complex biological shapes and PASCAL VOC categories than achievable by Mask RCNN alone.", "text_perturb": "Object detection and instance segmentation are prevail by region-based methods such as Mask RCNN. However , there is a growing pursuit in reducing these problems to pixel labeling tasks , as the latter could be more efficient , could be integrated seamlessly in image-to-image network architectures as used in many other tasks , and could be more accurate for objects that are not well approximated by bounding boxes. In this paper we show up theoretically and empirically that constructing dense pixel embeddings that can separate object instances can not be easily achieved using convolutional operators. At the same time , we show that simple modifications , which we call semi-convolutional , have a a great deal better chance of succeeding at this task. We use the latter to show a connector to Hough voting as well as to a variant of the bilateral kernel that is spatially steered by a convolutional network. We demonstrate that these operators give the sack also be used to improve approaches such as Mask RCNN , demonstrating better segmentation of complex biological shapes and PASCAL VOC categories than achievable by Mask RCNN alone. ", "label": 1}
{"original_text": "Recent years have seen big advances in the field of sentence-level quality estimation (QE), largely as a result of using neural-based architectures. However, the majority of these methods work only on the language pair they are trained on and need retraining for new language pairs. This process can prove difficult from a technical point of view and is usually computationally expensive. In this paper we propose a simple QE framework based on cross-lingual transformers, and we use it to implement and evaluate two different neural architectures. Our evaluation shows that the proposed methods achieve state-of-the-art results outperforming current open-source quality estimation frameworks when trained on datasets from WMT. In addition, the framework proves very useful in transfer learning settings, especially when dealing with low-resourced languages, allowing us to obtain very competitive results.", "text_perturb": "Recent years have seen big advances in the field of sentence-level caliber estimation ( QE ) , largely as a result of using neural-based architectures. However , the majority of these methods work only on the language twain they are trained on and need retraining for new language pairs. This cognitive process can prove difficult from a technical point of view and is usually computationally expensive. In this paper we propose a simple QE framework based on cross-lingual transformers , and we use it to implement and evaluate two unlike neural architectures. Our evaluation shows that the purport methods achieve state-of-the-art results outperforming current open-source quality estimation frameworks when trained on datasets from WMT. In addition , the framework proves rattling useful in transfer learning settings , especially when dealing with low-resourced languages , allowing us to obtain rattling competitive results. ", "label": 1}
{"original_text": "In this paper we study the problem of designing a distributed graph visualization algorithm for large graphs. The algorithm must be simple to implement and the computing infrastructure must not require major hardware or software investments. We design, implement, and experiment a force-directed algorithm in Giraph, a popular open source framework for distributed computing, based on a vertex-centric design paradigm. The algorithm is tested both on real and artificial graphs with up to million edges, by using a rather inexpensive PaaS (Platform as a Service) infrastructure of Amazon. The experiments show the scalability and effectiveness of our technique when compared to a centralized implementation of the same force-directed model. We show that graphs with about one million edges can be drawn in less than 8 minutes, by spending about 1 per drawing in the cloud computing infrastructure.", "text_perturb": "In this paper we examine the problem of designing a distributed graph visualization algorithm for large graphs. The algorithmic rule must be simple to implement and the computing infrastructure must not require major hardware or software investments. We design , implement , and experiment a force-directed algorithm in Giraph , a popular subject source framework for distributed computing , based on a vertex-centric design paradigm. The algorithm is tested both on real and artificial graphs with up to million edges , by using a rather inexpensive PaaS ( Platform as a service of process ) infrastructure of Amazon. The experiments show the scalability and effectiveness of our technique when compared to a centralized implementation of the like force-directed model. We show that graphs with about one million edges can be drawn in less than 8 minutes , by spending about 1 per drawing in the cloud calculation infrastructure. ", "label": 1}
{"original_text": "With the shortage of physicians and surgeons and increase in demand worldwide due to situations such as the COVID-19 pandemic, there is a growing interest in finding solutions to help address the problem. A solution to this problem would be to use neurotechnology to provide them augmented cognition, senses and action for optimal diagnosis and treatment. Consequently, doing so can negatively impact them and others. We argue that applying neurotechnology for human enhancement in physicians and surgeons can cause injustices, and harm to them and patients. In this paper, we will first describe the augmentations and neurotechnologies that can be used to achieve the relevant augmentations for physicians and surgeons. We will then review selected ethical concerns discussed within literature, discuss the neuroengineering behind using neurotechnology for augmentation purposes, then conclude with an analysis on outcomes and ethical issues of implementing human augmentation via neurotechnology in medical and surgical practice.", "text_perturb": "With the shortage of dr and surgeons and increase in demand worldwide due to situations such as the COVID-19 pandemic , there is a growing interest in finding solutions to help address the problem. A solution to this problem would be to use neurotechnology to provide them augmented cognition , gage and action for optimal diagnosis and treatment. Consequently , doing so can negatively touch them and others. We argue that applying neurotechnology for human enhancement in physicians and surgeons give the sack cause injustices , and harm to them and patients. In this paper , we will first describe the augmentation and neurotechnologies that can be used to achieve the relevant augmentation for physicians and surgeons. We will then review selected ethical concerns discussed within lit , discuss the neuroengineering behind using neurotechnology for augmentation purposes , then conclude with an analysis on outcomes and ethical issues of implementing human augmentation via neurotechnology in medical and surgical practice. ", "label": 1}
{"original_text": "In this letter we propose the Rao test as a simpler alternative to the generalized likelihood ratio test (GLRT) for multisensor fusion. We consider sensors observing an unknown deterministic parameter with symmetric and unimodal noise. A decision fusion center (DFC) receives quantized sensor observations through error-prone binary symmetric channels and makes a global decision. We analyze the optimal quantizer thresholds and we study the performance of the Rao test in comparison to the GLRT. Also, a theoretical comparison is made and asymptotic performance is derived in a scenario with homogeneous sensors. All the results are confirmed through simulations.", "text_perturb": "In this letter we propose the Rao test as a simpler alternative to the generalise likelihood ratio test ( GLRT ) for multisensor fusion. We consider sensors observing an unknown deterministic parametric quantity with symmetric and unimodal noise. A decision fusion center ( DFC ) receives quantal sensor observations through error-prone binary symmetric channels and makes a global decision. We analyze the optimal quantizer room access and we study the performance of the Rao test in comparison to the GLRT. Also , a theoretic comparison is made and asymptotic performance is derived in a scenario with homogeneous sensors. All the effect are confirmed through simulations. ", "label": 1}
{"original_text": "For sustainable growth and profitability, online game companies are constantly carrying out various events to attract new game users, to maximize return users, and to minimize churn users in online games. Because minimizing churn users is the most cost-effective method, many pieces of research are being conducted on ways to predict and to prevent churns in advance. However, there is still little research on the validity of event effects. In this study, we investigate whether game events influence the user churn rate and confirm the difference in how game users respond to events by character level, item purchasing frequency and game-playing time band.", "text_perturb": "For sustainable growth and profitability , online game companies are constantly carrying out various events to attract new game user , to maximize return user , and to minimize churn user in online games. Because minimizing churn users is the most cost efficient method , many pieces of research are being conducted on ways to predict and to prevent churns in advance. However , there is still trivial research on the validity of event effects. In this study , we investigate whether game events influence the exploiter churn rate and confirm the difference in how game users respond to events by character level , item purchasing frequency and game-playing time band. ", "label": 1}
{"original_text": "Based on 46 in-depth interviews with scientists, engineers, and CEOs, thisdocument presents a list of concrete machine research problems, progress onwhich would directly benefit tech ventures in East Africa.", "text_perturb": "Based on 46 in-depth interviews with scientists , engineers , and CEOs , thisdocument presents a list of concrete machine research trouble , progress onwhich would directly benefit tech ventures in East Africa. ", "label": 1}
{"original_text": "Head pose estimation is an important pre-processing step in many pattern recognition and computer vision systems such as face recognition. Since the performance of the face recognition systems is greatly affected by the pose of the face, how to estimate the accurate pose of the face in the face image is still a challenging problem. In this paper, we present a novel method for head pose estimation. To enhance the efficiency of the estimation we first use contourlet transform for feature extraction. Contourlet transform is a multi-resolution, multi-direction transform. Finally, in order to reduce the feature space dimension and obtain appropriate features, we use LDA (Linear Discriminant Analysis) and PCA (Principal Component Analysis) to remove inefficient features. Then, we apply k-nearest neighborhood (k-NN) and minimum distance classifiers to classify the pose of head. We use the public available FERET database to evaluate the performance of the proposed method. Simulation results indicate the efficiency of the proposed method in comparison with previous method.", "text_perturb": "Head pose estimation is an important pre-processing step in many pattern recognition and computer vision organisation such as face recognition. Since the performance of the face recognition systems equal greatly affected by the pose of the face , how to estimate the accurate pose of the face in the face image equal still a challenging problem. In this paper , we present a novel method for head pose idea. To heighten the efficiency of the estimation we first use contourlet transform for feature extraction. Contourlet transform is a multi-resolution , multi-direction transform. Finally , in order to reduce the feature space dimension and obtain appropriate features , we use LDA ( Linear Discriminant Analysis ) and PCA ( head Component Analysis ) to remove inefficient features. Then , we apply k-nearest neighborhood ( k-NN ) and minimum distance classifier to classify the pose of head. We use the public available FERET database to evaluate the performance of the purport method. Simulation results indicate the efficiency of the offer method in comparison with previous method. ", "label": 1}
{"original_text": "In this paper, we design and experiment a far-field wireless power transfer (WPT) architecture based on distributed antennas, so-called WPT DAS, that dynamically selects transmit antenna and frequency to increase the output dc power. Uniquely, spatial and frequency diversities are jointly exploited in the proposed WPT DAS with low complexity, low cost, and flexible deployment to combat the wireless fading channel. A numerical experiment is designed to show the benefits using antenna and frequency selections in spatially and frequency selective fading channels for single-user and multi-user cases. Accordingly, the proposed WPT DAS for single-user and two-user cases is prototyped. At the transmitter, we adopt antenna selection to exploit spatial diversity and adopt frequency selection to exploit frequency diversity. A low-complexity over-the-air limited feedback using an IEEE 802.15.4 RF interface is designed for antenna and frequency selections and reporting from the receiver to the transmitter. The proposed WPT DAS prototype is demonstrated in a real indoor environment. The measurements show that WPT DAS can boost the output dc power by up to 30 dB in single-user case and boost the sum of output dc power by up to 21.8 dB in two-user case and broaden the service coverage area in a low cost, low complexity, and flexible manner.", "text_perturb": "In this paper , we design and experiment a far-field wireless power transfer ( WPT ) architecture establish on distributed antennas , so-called WPT DAS , that dynamically selects transmit antenna and frequency to increase the output dc power. Uniquely , spatial and frequency diverseness are jointly exploited in the proposed WPT DAS with low complexity , low cost , and flexible deployment to combat the wireless fading channel. A numerical experiment is designed to show the benefits utilize antenna and frequency selections in spatially and frequency selective fading channels for single-user and multi-user cases. Accordingly , the advise WPT DAS for single-user and two-user cases is prototyped. At the transmitter , we adopt antenna selection to exploit spatial multifariousness and adopt frequency selection to exploit frequency multifariousness. A low-complexity over-the-air limited feedback using an IEEE 802. 15. 4 RF interface is designed for antenna and frequency selections and reporting from the receiver to the vector. The proposed WPT DAS prototype is prove in a real indoor environment. The measurements read that WPT DAS can boost the output dc power by up to 30 dB in single-user case and boost the sum of output dc power by up to 21. 8 dB in two-user case and broaden the service coverage area in a low cost , low complexity , and whippy manner. ", "label": 1}
{"original_text": "Multiple instance learning (MIL) is a variation of supervised learning where a single class label is assigned to a bag of instances. In this paper, we state the MIL problem as learning the Bernoulli distribution of the bag label where the bag label probability is fully parameterized by neural networks. Furthermore, we propose a neural network-based permutation-invariant aggregation operator that corresponds to the attention mechanism. Notably, an application of the proposed attention-based operator provides insight into the contribution of each instance to the bag label. We show empirically that our approach achieves comparable performance to the best MIL methods on benchmark MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and two real-life histopathology datasets without sacrificing interpretability.", "text_perturb": "multiple instance learning ( MIL ) is a variation of supervised learning where a single class label is assigned to a bag of instances. In this paper , we state the MIL problem as learning the Bernoulli distribution of the bagful label where the bagful label probability is fully parameterized by neural networks. Furthermore , we propose a neural network-based permutation-invariant collection operator that corresponds to the attention mechanism. Notably , an application of the proposed attention-based operator provides insight into the contribution of each instance to the bag recording label. We establish empirically that our approach achieves comparable performance to the best MIL methods on benchmark MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and two real-life histopathology datasets without sacrificing interpretability. ", "label": 1}
{"original_text": "We study the power and limits of optimal dynamic pricing in combinatorial markets; i.e., dynamic pricing that leads to optimal social welfare. Previous work by Cohen-Addad et al. [EC'16] demonstrated the existence of optimal dynamic prices for unit-demand buyers, and showed a market with coverage valuations that admits no such prices. However, finding the frontier of markets (i.e., valuation functions) that admit optimal dynamic prices remains an open problem. In this work we establish positive and negative results that narrow the existing gap. On the positive side, we provide tools for handling markets beyond unit-demand valuations. In particular, we characterize all optimal allocations in multi-demand markets. This characterization allows us to partition the items into equivalence classes according to the role they play in achieving optimality. Using these tools, we provide a poly-time optimal dynamic pricing algorithm for up to 3 multi-demand buyers. On the negative side, we establish a maximal domain theorem, showing that for every non-gross substitutes valuation, there exist unit-demand valuations such that adding them yields a market that does not admit an optimal dynamic pricing. This result is reminiscent of the seminal maximal domain theorem by Gul and Stacchetti [JET'99] for Walrasian equilibrium. Yang [JET'17] discovered an error in their original proof, and established a different, incomparable version of their maximal domain theorem. En route to our maximal domain theorem for optimal dynamic pricing, we provide the first complete proof of the original theorem by Gul and Stacchetti.", "text_perturb": "We study the power and terminus ad quem of optimal dynamic pricing in combinatorial markets ; i. vitamin e. , dynamic pricing that leads to optimal social upbeat. Previous work by Cohen-Addad et al. [ EC'16 ] demonstrated the cosmos of optimal dynamic prices for unit-demand buyers , and showed a market with coverage valuations that admits no such prices. However , finding the frontier of markets ( i. vitamin e. , valuation functions ) that admit optimal dynamic terms remains an open problem. In this work we establish positive and negative results that narrow the live gap. On the positive side , we provide tools for handling securities industry beyond unit-demand valuations. In particular , we qualify all optimal allocations in multi-demand markets. This characterization allows us to partition off the items into equivalence classes according to the role they play in achieving optimality. Using these tools , we provide a poly-time optimal dynamic pricing algorithm for up to 3 multi-demand buyer. On the negative side , we establish a maximum domain theorem , showing that for every non-gross substitutes valuation , there exist unit-demand valuations such that adding them yields a market that does not admit an optimal dynamic pricing. This result is reminiscent of the seminal maximal domain theorem by Gul and Stacchetti [ JET'99 ] for Walrasian counterbalance. Yang [ JET'17 ] discovered an error in their original proof , and established a different , incomparable version of their maximal area theorem. En route to our maximal world theorem for optimal dynamic pricing , we provide the first complete proof of the original theorem by Gul and Stacchetti. ", "label": 1}
{"original_text": "Abundant data is the key to successful machine learning. However, supervised learning requires annotated data that are often hard to obtain. In a classification task with limited resources, Active Learning (AL) promises to guide annotators to examples that bring the most value for a classifier. AL can be successfully combined with self-training, i.e., extending a training set with the unlabelled examples for which a classifier is the most certain. We report our experiences on using AL in a systematic manner to train an SVM classifier for Stack Overflow posts discussing performance of software components. We show that the training examples deemed as the most valuable to the classifier are also the most difficult for humans to annotate. Despite carefully evolved annotation criteria, we report low inter-rater agreement, but we also propose mitigation strategies. Finally, based on one annotator's work, we show that self-training can improve the classification accuracy. We conclude the paper by discussing implication for future text miners aspiring to use AL and self-training.", "text_perturb": "Abundant data is the key to successful motorcar learning. However , supervised eruditeness requires annotated data that are often hard to obtain. In a classification task with limited resources , Active Learning ( AL ) promises to guide annotators to examples that bring the most note value for a classifier. AL can be successfully compound with self-training , i. es. , extending a training set with the unlabelled examples for which a classifier represent the most certain. We report our experiences on using aluminium in a systematic manner to train an SVM classifier for Stack Overflow posts discussing performance of software components. We show that the training examples deemed as the near valuable to the classifier are also the near difficult for humans to annotate. Despite carefully evolved annotation criteria , we cover low inter-rater agreement , but we also propose mitigation strategies. at last , based on one annotator 's work , we show that self-training can improve the classification accuracy. We conclude the paper by discussing implication for future text miners aspiring to use alabama and self-training. ", "label": 1}
{"original_text": "We propose a machine learning framework to synthesize reactive controllers for systems whose interactions with their adversarial environment are modeled by infinite-duration, two-player games over (potentially) infinite graphs. Our framework targets safety games with infinitely many vertices, but it is also applicable to safety games over finite graphs whose size is too prohibitive for conventional synthesis techniques. The learning takes place in a feedback loop between a teacher component, which can reason symbolically about the safety game, and a learning algorithm, which successively learns an approximation of the winning region from various kinds of examples provided by the teacher. We develop a novel decision tree learning algorithm for this setting and show that our algorithm is guaranteed to converge to a reactive safety controller if a suitable approximation of the winning region can be expressed as a decision tree. Finally, we empirically compare the performance of a prototype implementation to existing approaches, which are based on constraint solving and automata learning, respectively.", "text_perturb": "We propose a machine learning framework to synthesize reactive controllers for systems whose interactions with their adversarial environment personify modeled by infinite-duration , two-player games over ( potentially ) infinite graphs. Our framework targets safety games with infinitely many vertices , but it follow also applicable to safety games over finite graphs whose size follow too prohibitive for conventional synthesis techniques. The learning takes place in a feedback loop between a teacher component , which can reason symbolically about the safety game , and a learning algorithm , which successively learns an approximation of the winning region from various kinds of examples leave by the teacher. We develop a novel decision tree learning algorithm for this setting and show that our algorithm is guaranteed to converge to a reactive safety controller if a suitable approximation of the winning region can be extract as a decision tree. at long last , we empirically compare the performance of a prototype implementation to existing approaches , which are based on constraint solving and automata learning , respectively. ", "label": 1}
{"original_text": "This paper addresses the problem of target detection and localisation in a limited area using multiple coordinated agents. The swarm of Unmanned Aerial Vehicles (UAVs) determines the position of the dispersion of stack effluents to a gas plume in a certain production area as fast as possible, that makes the problem challenging to model and solve, because of the time variability of the target. Three different exploration algorithms are designed and compared. Besides the exploration strategies, the paper reports a solution for quick convergence towards the actual stack position once detected by one member of the team. Both the navigation and localisation algorithms are fully distributed and based on the consensus theory. Simulations on realistic case studies are reported.", "text_perturb": "This paper addresses the problem of target detection and localisation in a limited domain using multiple coordinated agents. The swarm of Unmanned Aerial Vehicles ( UAVs ) determines the position of the dispersion of mess effluents to a gas plume in a certain production area as fast as possible , that makes the problem challenging to model and solve , because of the time variability of the target. Three different exploration algorithms embody designed and compared. Besides the exploration strategies , the paper reports a solution for quick convergence towards the actual stack position erst detected by one member of the team. Both the navigation and localisation algorithms are fully distributed and establish on the consensus theory. Simulations on realistic character studies are reported. ", "label": 1}
{"original_text": "Parameterized algorithms are a very useful tool for dealing with NP-hard problems on graphs. Yet, to properly utilize parameterized algorithms it is necessary to choose the right parameter based on the type of problem and properties of the target graph class. Tree-width is an example of a very successful graph parameter, however it cannot be used on dense graph classes and there also exist problems which are hard even on graphs of bounded tree-width. Such problems can be tackled by using vertex cover as a parameter, however this places severe restrictions on admissible graph classes. Michael Lampis has recently introduced neighborhood diversity, a new graph parameter which generalizes vertex cover to dense graphs. Among other results, he has shown that simple parameterized algorithms exist for a few problems on graphs of bounded neighborhood diversity. Our article further studies this area and provides new algorithms parameterized by neighborhood diversity for the p-Vertex-Disjoint Paths, Graph Motif and Precoloring Extension problems - the latter two being hard even on graphs of bounded tree-width.", "text_perturb": "Parameterized algorithms are a rattling useful tool for dealing with NP-hard problems on graphs. Yet , to properly utilize parameterized algorithms it is necessary to choose the right parameter based on the type of problem and properties of the target area graph class. Tree-width is an example of a very successful graph parameter , nevertheless it can not be used on dense graph classes and there also exist problems which are hard even on graphs of bounded tree-width. such problems can be tackled by using vertex cover as a parameter , however this places severe restrictions on admissible graph classes. Michael Lampis has recently introduced neighborhood diversity , a new graph argument which generalizes vertex cover to dense graphs. Among former results , he has shown that simple parameterized algorithms exist for a few problems on graphs of bounded neighborhood diversity. Our clause further studies this area and provides new algorithms parameterized by neighborhood diversity for the p-Vertex-Disjoint Paths , Graph Motif and Precoloring Extension problems - the latter two being hard even on graphs of bounded tree-width. ", "label": 1}
{"original_text": "In this work, we demonstrate that receptive fields in 3D pose estimation can be effectively specified using optical flow. We introduce adaptive receptive fields, a simple and effective method to aid receptive field selection in pose estimation models based on optical flow inference. We contrast the performance of a benchmark state-of-the-art model running on fixed receptive fields with their adaptive field counterparts. By using a reduced receptive field, our model can process slow-motion sequences (10x longer) 23 faster than the benchmark model running at regular speed. The reduction in computational cost is achieved while producing a pose prediction accuracy to within 0.36 of the benchmark model.", "text_perturb": "In this work , we demonstrate that receptive fields in 3D pose estimation can be effectively specified using optical period. We introduce adaptive receptive fields , a simple and effective method to aid receptive field selection in pose estimation manakin based on optical flow inference. We contrast the performance of a benchmark state-of-the-art model running on fixed receptive fields with their adaptive field counterpart. By using a reduced receptive field , our model give notice process slow-motion sequences ( 10x longer ) 23 faster than the benchmark model running at regular speed. The step down in computational cost is achieved while producing a pose prediction accuracy to within 0. 36 of the benchmark theoretical account. ", "label": 1}
{"original_text": "Ad hoc electrical networks are formed by connecting power sources and loads without pre-determining the network topology. These systems are well-suited to addressing the lack of electricity in rural areas because they can be assembled and modified by non-expert users without central oversight. There are two core aspects to ad hoc system design: 1) designing source and load units such that the microgrid formed from the arbitrary interconnection of many units is always stable and 2) developing control strategies to autonomously manage the microgrid (i.e., perform power dispatch and voltage regulation) in a decentralized manner and under large uncertainty. To address these challenges we apply a number of nonlinear control techniques - including Brayton-Moser potential theory and primal-dual dynamics - to obtain conditions under which an ad hoc dc microgrid will have a suitable and asymptotically stable equilibrium point. Further, we propose a new decentralized control scheme that coordinates many sources to achieve a specified power dispatch from each. A simulated comparison to previous research is included.", "text_perturb": "Ad hoc electrical net are formed by connecting power sources and loads without pre-determining the network topology. These systems are well-suited to addressing the lack of electricity in rural areas because they can be assembled and modified by non-expert substance abuser without central oversight. There are two core aspects to ad hoc system design : 1 ) plan source and load units such that the microgrid formed from the arbitrary interconnection of many units is always stable and 2 ) developing control strategies to autonomously manage the microgrid ( i. vitamin e. , perform power dispatch and voltage regulation ) in a decentralized way and under large uncertainty. To address these challenges we apply a number of nonlinear control techniques - including Brayton-Moser potential theory and primal-dual dynamics - to obtain conditions under which an advertizement hoc dc microgrid will have a suitable and asymptotically stable equilibrium point. Further , we propose a new decentralise control scheme that coordinates many sources to achieve a specified power dispatch from each. A simulated comparability to previous research is included. ", "label": 1}
{"original_text": "In reinforcement learning (RL), agents often operate in partially observed and uncertain environments. Model-based RL suggests that this is best achieved by learning and exploiting a probabilistic model of the world. 'Active inference' is an emerging normative framework in cognitive and computational neuroscience that offers a unifying account of how biological agents achieve this. On this framework, inference, learning and action emerge from a single imperative to maximize the Bayesian evidence for a niched model of the world. However, implementations of this process have thus far been restricted to low-dimensional and idealized situations. Here, we present a working implementation of active inference that applies to high-dimensional tasks, with proof-of-principle results demonstrating efficient exploration and an order of magnitude increase in sample efficiency over strong model-free baselines. Our results demonstrate the feasibility of applying active inference at scale and highlight the operational homologies between active inference and current model-based approaches to RL.", "text_perturb": "In reinforcement learning ( RL ) , agents often operate in partially observed and uncertain environment. Model-based RL suggests that this is best achieved by learning and exploiting a probabilistic mannikin of the world. 'Active inference ' is an emerging normative framework in cognitive and computational neuroscience that offers a unifying account of how biological agents reach this. On this framework , inference , learning and action emerge from a single imperative to maximize the Bayesian evidence for a niched model of the earthly concern. however , implementations of this process have thus far been restricted to low-dimensional and idealized situations. here , we present a working implementation of active inference that applies to high-dimensional tasks , with proof-of-principle results demonstrating efficient exploration and an order of magnitude increase in sample efficiency over strong model-free baselines. Our results demonstrate the feasibility of applying combat ready inference at scale and highlight the operational homologies between combat ready inference and current model-based approaches to RL. ", "label": 1}
{"original_text": "In this paper, we address an issue that the visually impaired commonly face while crossing intersections and propose a solution that takes form as a mobile application. The application utilizes a deep learning convolutional neural network model, LytNetV2, to output necessary information that the visually impaired may lack when without human companions or guide-dogs. A prototype of the application runs on iOS devices of versions 11 or above. It is designed for comprehensiveness, concision, accuracy, and computational efficiency through delivering the two most important pieces of information, pedestrian traffic light color and direction, required to cross the road in real-time. Furthermore, it is specifically aimed to support those facing financial burden as the solution takes the form of a free mobile application. Through the modification and utilization of key principles in MobileNetV3 such as depthwise seperable convolutions and squeeze-excite layers, the deep neural network model achieves a classification accuracy of 96 and average angle error of 6.15deg, while running at a frame rate of 16.34 frames per second. Additionally, the model is trained as an image classifier, allowing for a faster and more accurate model. The network is able to outperform other methods such as object detection and non-deep learning algorithms in both accuracy and thoroughness. The information is delivered through both auditory signals and vibrations, and it has been tested on seven visually impaired and has received above satisfactory responses.", "text_perturb": "In this paper , we address an issue that the visually impaired commonly face while crossing intersections and propose a solution that takes variety as a mobile application. The application utilizes a deep learning convolutional neural network model , LytNetV2 , to output necessary information that the visually impaired may miss when without human companions or guide-dogs. A prototype of the application runs on iOS gimmick of versions 11 or above. It is designed for comprehensiveness , concision , accuracy , and computational efficiency through delivering the two most important pieces of information , prosaic traffic light color and direction , required to cross the road in real-time. Furthermore , it is specifically aimed to support those face financial burden as the solution takes the form of a free mobile application. Through the modification and utilization of key principles in MobileNetV3 such as depthwise seperable convolutions and squeeze-excite layers , the deep neural network model achieves a classification accuracy of 96 and middling angle error of 6. 15deg , while persist at a frame rate of 16. 34 skeletal system per second. to boot , the model is trained as an image classifier , allowing for a faster and more accurate model. The meshing is able to outperform other methods such as object detection and non-deep learning algorithms in both accuracy and thoroughness. The information exist delivered through both auditory signals and vibrations , and it has been tested on seven visually impaired and has received above satisfactory responses. ", "label": 1}
{"original_text": "Shallow Convolution Neural Network (CNN) is a time-tested tool for the information extraction from cancer pathology reports. Shallow CNN performs competitively on this task to other deep learning models including BERT, which holds the state-of-the-art for many NLP tasks. The main insight behind this eccentric phenomenon is that the information extraction from cancer pathology reports require only a small number of domain-specific text segments to perform the task, thus making the most of the texts and contexts excessive for the task. Shallow CNN model is well-suited to identify these key short text segments from the labeled training set; however, the identified text segments remain obscure to humans. In this study, we fill this gap by developing a model reduction tool to make a reliable connection between CNN filters and relevant text segments by discarding the spurious connections. We reduce the complexity of shallow CNN representation by approximating it with a linear transformation of n-gram presence representation with a non-negativity and sparsity prior on the transformation weights to obtain an interpretable model. Our approach bridge the gap between the conventionally perceived tradeoff boundary between accuracy on the one side and explainability on the other by model reduction.", "text_perturb": "Shallow Convolution Neural Network ( CNN ) is a time-tested tool for the information extraction from malignant neoplastic disease pathology reports. Shallow CNN performs competitively on this task to other deep scholarship models including BERT , which holds the state-of-the-art for many NLP tasks. The main insight behind this eccentric phenomenon is that the information extraction from cancer pathology reports require only a small routine of domain-specific text segments to perform the task , thus making the most of the texts and contexts excessive for the task. Shallow CNN model is well-suited to identify these key short text segment from the labeled training set ; however , the identified text segment remain obscure to humans. In this discipline , we fill this gap by developing a model reduction tool to make a reliable connection between CNN filters and relevant text segments by discarding the spurious connections. We reduce the complexity of shallow CNN representation by approximating it with a linear transformation of n-gram presence representation with a non-negativity and sparsity prior on the transformation weighting to obtain an interpretable model. Our approach bridge the gap between the conventionally perceived tradeoff boundary between accuracy on the one side and explainability on the other by example reduction. ", "label": 1}
{"original_text": "Currently, self-driving cars rely greatly on the Global Positioning System (GPS) infrastructure, albeit there is an increasing demand for alternative methods for GPS-denied environments. One of them is known as place recognition, which associates images of places with their corresponding positions. We previously proposed systems based on Weightless Neural Networks (WNN) to address this problem as a classification task. This encompasses solely one part of the global localization, which is not precise enough for driverless cars. Instead of just recognizing past places and outputting their poses, it is desired that a global localization system estimates the pose of current place images. In this paper, we propose to tackle this problem as follows. Firstly, given a live image, the place recognition system returns the most similar image and its pose. Then, given live and recollected images, a visual localization system outputs the relative camera pose represented by those images. To estimate the relative camera pose between the recollected and the current images, a Convolutional Neural Network (CNN) is trained with the two images as input and a relative pose vector as output. Together, these systems solve the global localization problem using the topological and metric information to approximate the current vehicle pose. The full approach is compared to a Real-Time Kinematic GPS system and a Simultaneous Localization and Mapping (SLAM) system. Experimental results show that the proposed approach correctly localizes a vehicle 90 of the time with a mean error of 1.20m compared to 1.12m of the SLAM system and 0.37m of the GPS, 89 of the time.", "text_perturb": "Currently , self-driving cars rely greatly on the Global Positioning System ( GPS ) substructure , albeit there is an increasing demand for alternative methods for GPS-denied environments. One of them is known as place recognition , which associates images of position with their corresponding positions. We previously proposed systems based on Weightless Neural Networks ( WNN ) to address this problem as a classification job. This encompasses only one part of the global localization , which is not precise enough for driverless cars. Instead of just recognizing past places and outputting their poses , it is desired that a global localization system estimates the pose of current place range. In this paper , we propose to tackle this problem as pursue. Firstly , given a live figure , the place recognition system returns the most similar figure and its pose. Then , given live and recollected images , a visual localization organization outputs the relative camera pose represented by those images. To estimate the relative camera pose between the recollected and the current picture , a Convolutional Neural Network ( CNN ) is trained with the two picture as input and a relative pose vector as output. Together , these systems solve the global localization problem apply the topological and metric information to approximate the current vehicle pose. The wide cut approach is compared to a Real-Time Kinematic GPS system and a Simultaneous Localization and Mapping ( SLAM ) system. Experimental results show that the proposed approach correctly localizes a vehicle 90 of the clip with a mean error of 1. 20m compare to 1. 12m of the SLAM scheme and 0. 37m of the GPS , 89 of the clip. ", "label": 1}
{"original_text": "Aiming to minimize service delay, we propose a new random caching scheme in device-to-device (D2D) -assisted heterogeneous network. To support diversified viewing qualities of multimedia video services, each video file is encoded into a base layer (BL) and multiple enhancement layers (ELs) by scalable video coding (SVC). A super layer, including the BL and several ELs, is transmitted to every user. We define and quantify the service delay of multi-quality videos by deriving successful transmission probabilities when a user is served by a D2D helper, a small-cell base station (SBS) and a macro-cell base station (MBS). We formulate a delay minimization problem subject to the limited cache sizes of D2D helpers and SBSs. The structure of the optimal solutions to the problem is revealed, and then an improved standard gradient projection method is designed to effectively obtain the solutions. Both theoretical analysis and Monte-Carlo simulations validate the successful transmission probabilities. Compared with three benchmark caching policies, the proposed SVC-based random caching scheme is superior in terms of reducing the service delay.", "text_perturb": "Aiming to minimize service delay , we propose a new random lay away scheme in device-to-device ( D2D ) -assisted heterogeneous network. To support diversified viewing qualities of multimedia television services , each television file is encoded into a base layer ( BL ) and multiple enhancement layers ( ELs ) by scalable television coding ( SVC ). A topnotch layer , including the BL and several ELs , is transmitted to every user. We define and quantify the service delay of multi-quality videos by deriving successful transmission probabilities when a user is served by a D2D helper , a small-cell base station ( bachelor of science ) and a macro-cell base station ( MBS ). We formulate a delay minimization problem subject to the limited stash sizes of D2D helpers and SBSs. The structure of the optimal solutions to the problem is revealed , and then an improved standard gradient projection method is contrive to effectively obtain the solutions. Both theoretic analysis and Monte-Carlo simulations validate the successful transmission probabilities. Compared with three benchmark caching policies , the proposed SVC-based random caching scheme be superior in terms of reducing the service delay. ", "label": 1}
{"original_text": "It is a challenge to specify unambiguous distance (UD) in a phase-based ranging system with hopping frequencies (PRSHF). In this letter, we propose to characterize the UD in a PRSHF by the probability that it takes on its maximum value. We obtain a very simple and elegant expression of the probability with growth estimation techniques from analytic number theory. It is revealed that the UD in a PRSHF usually takes on the maximum value with as few as 10 frequencies in measurement, almost independent of the specific distribution of available bandwidth.", "text_perturb": "It is a challenge to specify univocal distance ( UD ) in a phase-based ranging system with hopping frequencies ( PRSHF ). In this letter , we pop the question to characterize the UD in a PRSHF by the probability that it takes on its maximum value. We incur a very simple and elegant expression of the probability with growth estimation techniques from analytic number theory. It is revealed that the UD in a PRSHF usually takes on the maximum value with equally few as 10 frequencies in measurement , almost independent of the specific distribution of available bandwidth. ", "label": 1}
{"original_text": "A picture is worth a thousand words. Albeit a cliche, for the fashion industry, an image of a clothing piece allows one to perceive its category (e.g., dress), sub-category (e.g., day dress) and properties (e.g., white colour with floral patterns). The seasonal nature of the fashion industry creates a highly dynamic and creative domain with evermore data, making it unpractical to manually describe a large set of images (of products). In this paper, we explore the concept of visual recognition for fashion images through an end-to-end architecture embedding the hierarchical nature of the annotations directly into the model. Towards that goal, and inspired by the work of (,), we have modified and adapted the original architecture proposal. Namely, we have removed the message passing layer symmetry to cope with Farfetch category tree, added extra layers for hierarchy level specificity, and moved the message passing layer into an enriched latent space. We compare the proposed unified architecture against state-of-the-art models and demonstrate the performance advantage of our model for structured multi-level categorization on a dataset of about 350k fashion product images.", "text_perturb": "A picture is worth a thousand speech. Albeit a cliche , for the fashion industry , an image of a clothing slice allows one to perceive its category ( e. gee. , attire ) , sub-category ( e. chiliad. , day dress ) and properties ( einsteinium. guanine. , whitened colour with floral patterns ). The seasonal nature of the fashion industry create a highly dynamic and creative domain with evermore data , making it unpractical to manually describe a large set of images ( of products ). In this paper , we explore the concept of visual recognition for fashion images through an end-to-end architecture plant the hierarchical nature of the annotations directly into the model. Towards that goal , and inspired by the work of ( , ) , we have alter and adapted the original architecture proposal. Namely , we have removed the message passing layer symmetry to cope with Farfetch category tree , added extra layers for hierarchy level specificity , and locomote the message passing layer into an enriched latent space. We compare the proposed unified architecture against state-of-the-art models and demonstrate the performance advantage of our model for structured multi-level categorization on a dataset of about 350k manner product images. ", "label": 1}
{"original_text": "Recommender systems (RS) are increasingly present in our daily lives, especially since the advent of Big Data, which allows for storing all kinds of information about users' preferences. Personalized RS are successfully applied in platforms such as Netflix, Amazon or YouTube. However, they are missing in gastronomic platforms such as TripAdvisor, where moreover we can find millions of images tagged with users' tastes. This paper explores the potential of using those images as sources of information for modeling users' tastes and proposes an image-based classification system to obtain personalized recommendations, using a convolutional autoencoder as feature extractor. The proposed architecture will be applied to TripAdvisor data, using users' reviews that can be defined as a triad composed by a user, a restaurant, and an image of it taken by the user. Since the dataset is highly unbalanced, the use of data augmentation on the minority class is also considered in the experimentation. Results on data from three cities of different sizes (Santiago de Compostela, Barcelona and New York) demonstrate the effectiveness of using a convolutional autoencoder as feature extractor, instead of the standard deep features computed with convolutional neural networks.", "text_perturb": "Recommender systems ( RS ) are increasingly present in our daily lives , especially since the advent of Big Data , which allows for storing all form of information about users ' preferences. personalize RS are successfully applied in platforms such as Netflix , Amazon or YouTube. However , they are missing in gastronomic platforms such as TripAdvisor , where moreover we terminate find millions of images tagged with users ' tastes. This paper explores the potential of using those images as sources of information for modeling users ' sense of taste and proposes an image-based classification system to obtain personalized recommendations , using a convolutional autoencoder as feature extractor. The declare oneself architecture will be applied to TripAdvisor data , using users ' reviews that can be defined as a triad composed by a user , a restaurant , and an image of it taken by the user. Since the dataset is highly unbalanced , the employment of data augmentation on the minority class is also considered in the experimentation. Results on data from three cities of different sizes ( Santiago de Compostela , Barcelona and New York ) demonstrate the effectiveness of using a convolutional autoencoder as feature extractor , alternatively of the standard deep features computed with convolutional neural networks. ", "label": 1}
{"original_text": "In this work, we explain the working mechanism of MixUp in terms of adversarial training. We introduce a new class of adversarial training schemes, which we refer to as directional adversarial training, or DAT. In a nutshell, a DAT scheme perturbs a training example in the direction of another example but keeps its original label as the training target. We prove that MixUp is equivalent to a special subclass of DAT, in that it has the same expected loss function and corresponds to the same optimization problem asymptotically. This understanding not only serves to explain the effectiveness of MixUp, but also reveals a more general family of MixUp schemes, which we call Untied MixUp. We prove that the family of Untied MixUp schemes is equivalent to the entire class of DAT schemes. We establish empirically the existence of Untied Mixup schemes which improve upon MixUp.", "text_perturb": "In this work , we explain the working mechanics of MixUp in terms of adversarial training. We innovate a new class of adversarial training schemes , which we refer to as directional adversarial training , or DAT. In a nutshell , a DAT scheme perturbs a training example in the direction of another example but proceed its original label as the training target. We prove that MixUp follow equivalent to a special subclass of DAT , in that it has the same expected loss function and corresponds to the same optimization problem asymptotically. This understanding not only serves to explain the effectiveness of MixUp , but also reveals a more general family of MixUp schemes , which we call unshackled MixUp. We prove that the family of Untied MixUp schemes equal equivalent to the entire class of DAT schemes. We shew empirically the existence of Untied Mixup schemes which improve upon MixUp. ", "label": 1}
{"original_text": "This paper proposes a robust adversarial reinforcement learning (RARL) -based multi-access point (AP) coordination method that is robust even against unexpected decentralized operations of uncoordinated APs. Multi-AP coordination is a promising technique towards IEEE 802.11be, and there are studies that use RL for multi-AP coordination. Indeed, a simple RL-based multi-AP coordination method diminishes the collision probability among the APs; therefore, the method is a promising approach to improve time-resource efficiency. However, this method is vulnerable to frame transmissions of uncoordinated APs that are less aware of frame transmissions of other coordinated APs. To help the central agent experience even such unexpected frame transmissions, in addition to the central agent, the proposed method also competitively trains an adversarial AP that disturbs coordinated APs by causing frame collisions intensively. Besides, we propose to exploit a history of frame losses of a coordinated AP to promote reasonable competition between the central agent and adversarial AP. The simulation results indicate that the proposed method can avoid uncoordinated interference and thereby improve the minimum sum of the throughputs in the system compared to not considering the uncoordinated AP.", "text_perturb": "This paper proposes a robust adversarial reinforcement learning ( RARL ) -based multi-access point ( AP ) coordination method that live robust even against unexpected decentralized operations of uncoordinated APs. Multi-AP coordination is a promising technique towards IEEE 802. 11be , and there are discipline that use RL for multi-AP coordination. Indeed , a simple RL-based multi-AP coordination method diminishes the collision probability among the APs ; therefore , the method follow a promising approach to improve time-resource efficiency. However , this method is vulnerable to frame contagion of uncoordinated APs that are less aware of frame contagion of other coordinated APs. To help the central agentive role experience even such unexpected frame transmissions , in addition to the central agentive role , the proposed method also competitively trains an adversarial AP that disturbs coordinated APs by causing frame collisions intensively. Besides , we propose to exploit a history of frame losses of a matching AP to promote reasonable competition between the central agent and adversarial AP. The simulation results indicate that the proposed method can avoid uncoordinated interference and thereby improve the minimum sum of the throughputs in the system liken to not considering the uncoordinated AP. ", "label": 1}
{"original_text": "Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors. Recent research has demonstrated the widespread presence and the devastating consequences of such attacks. Existing defense techniques either assume prior knowledge of specific attacks or may not work well on complex models due to their underlying assumptions. We argue that adversarial sample attacks are deeply entangled with interpretability of DNN models: while classification results on benign inputs can be reasoned based on the human perceptible featuresattributes, results on adversarial samples can hardly be explained. Therefore, we propose a novel adversarial sample detection technique for face recognition models, based on interpretability. It features a novel bi-directional correspondence inference between attributes and internal neurons to identify neurons critical for individual attributes. The activation values of critical neurons are enhanced to amplify the reasoning part of the computation and the values of other neurons are weakened to suppress the uninterpretable part. The classification results after such transformation are compared with those of the original model to detect adversaries. Results show that our technique can achieve 94 detection accuracy for 7 different kinds of attacks with 9.91 false positives on benign inputs. In contrast, a state-of-the-art feature squeezing technique can only achieve 55 accuracy with 23.3 false positives.", "text_perturb": "Adversarial sample attacks perturb benign input signal to induce DNN misbehaviors. Recent research has demo the widespread presence and the devastating consequences of such attacks. Existing refutation techniques either assume prior knowledge of specific attacks or may not work well on complex models due to their underlying assumptions. We argue that adversarial sample attacks are deeply entangled with interpretability of DNN models : while classification results on benign inputs can make up reasoned based on the human perceptible featuresattributes , results on adversarial samples can hardly make up explained. Therefore , we propose a novel adversarial sample signal detection technique for face recognition models , based on interpretability. It features a new bi-directional correspondence inference between attributes and internal neurons to identify neurons critical for individual attributes. The activation values of critical neurons are enhanced to amplify the reasoning part of the computation and the values of former neurons are weakened to suppress the uninterpretable part. The classification results after such transformation are compared with those of the original model to detect adversary. Results exhibit that our technique can achieve 94 detection accuracy for 7 different kinds of attacks with 9. 91 false positive degree on benign inputs. In demarcation , a state-of-the-art feature squeezing technique can only achieve 55 accuracy with 23. 3 fake positives. ", "label": 1}
{"original_text": "With wearable devices such as smartwatches on the rise in the consumer electronics market, securing these wearables is vital. However, the current security mechanisms only focus on validating the user not the device itself. Indeed, wearables can be (1) unauthorized wearable devices with correct credentials accessing valuable systems and networks, (2) passive insiders or outsider wearable devices, or (3) information-leaking wearables devices. Fingerprinting via machine learning can provide necessary cyber threat intelligence to address all these cyber attacks. In this work, we introduce a wearable fingerprinting technique focusing on Bluetooth classic protocol, which is a common protocol used by the wearables and other IoT devices. Specifically, we propose a non-intrusive wearable device identification framework which utilizes 20 different Machine Learning (ML) algorithms in the training phase of the classification process and selects the best performing algorithm for the testing phase. Furthermore, we evaluate the performance of proposed wearable fingerprinting technique on real wearable devices, including various off-the-shelf smartwatches. Our evaluation demonstrates the feasibility of the proposed technique to provide reliable cyber threat intelligence. Specifically, our detailed accuracy results show on average 98.5, 98.3 precision and recall for identifying wearables using the Bluetooth classic protocol.", "text_perturb": "With wearable device such as smartwatches on the rise in the consumer electronics market , securing these wearables is vital. However , the current security mechanisms entirely focus on validating the user not the device itself. Indeed , wearables can be ( 1 ) unauthorized wearable devices with correct credentials get at valuable systems and networks , ( 2 ) passive insiders or outsider wearable devices , or ( 3 ) information-leaking wearables devices. Fingerprinting via machine learning can provide necessary cyber scourge intelligence to address all these cyber attacks. In this work , we introduce a wearable fingerprinting technique focusing on Bluetooth classic communications protocol , which is a common communications protocol used by the wearables and other IoT devices. specifically , we propose a non-intrusive wearable device identification framework which utilizes 20 different Machine Learning ( ML ) algorithms in the training phase of the classification process and selects the best performing algorithm for the testing phase. Furthermore , we evaluate the performance of proposed wearable fingerprinting proficiency on real wearable devices , including various off-the-shelf smartwatches. Our rating demonstrates the feasibility of the proposed technique to provide reliable cyber threat intelligence. Specifically , our detailed accuracy results indicate on average 98. 5 , 98. 3 preciseness and recall for identifying wearables using the Bluetooth classic protocol. ", "label": 1}
{"original_text": "In this paper, we study integrated estimation and control of soft robots. A significant challenge in deploying closed loop controllers is reliable proprioception via integrated sensing in soft robots. Despite the considerable advances accomplished in fabrication, modelling, and model-based control of soft robots, integrated sensing and estimation is still in its infancy. To that end, this paper introduces a new method of estimating the degree of curvature of a soft robot using a stretchable sensing skin. The skin is a spray-coated piezoresistive sensing layer on a latex membrane. The mapping from the strain signal to the degree of curvature is estimated by using a recurrent neural network. We investigate uni-directional bending as well as bi-directional bending of a single-segment soft robot. Moreover, an adaptive controller is developed to track the degree of curvature of the soft robot in the presence of dynamic uncertainties. Subsequently, using the integrated soft sensing skin, we experimentally demonstrate successful curvature tracking control of the soft robot.", "text_perturb": "In this paper , we meditate integrated estimation and control of soft robots. A significant challenge in deploy closed loop controllers is reliable proprioception via integrated sensing in soft robots. Despite the considerable overture accomplished in fabrication , modelling , and model-based control of soft robots , integrated sensing and estimation is still in its infancy. To that end , this paper introduces a new method of estimating the degree of curvature of a soft automaton using a stretchable sensing skin. The skin is a spray-coated piezoresistive sensing layer on a latex tissue layer. The mapping from the strain signaling to the degree of curvature is estimated by using a recurrent neural network. We investigate uni-directional bending every bit well as bi-directional bending of a single-segment soft robot. Moreover , an adaptive restrainer is developed to track the degree of curvature of the soft robot in the presence of dynamic uncertainties. Subsequently , using the integrated soft sensing skin , we experimentally demonstrate successful curvature tracking control of the soft golem. ", "label": 1}
{"original_text": "User intent detection plays a critical role in question-answering and dialog systems. Most previous works treat intent detection as a classification problem where utterances are labeled with predefined intents. However, it is labor-intensive and time-consuming to label users' utterances as intents are diversely expressed and novel intents will continually be involved. Instead, we study the zero-shot intent detection problem, which aims to detect emerging user intents where no labeled utterances are currently available. We propose two capsule-based architectures: IntentCapsNet that extracts semantic features from utterances and aggregates them to discriminate existing intents, and IntentCapsNet-ZSL which gives IntentCapsNet the zero-shot learning ability to discriminate emerging intents via knowledge transfer from existing intents. Experiments on two real-world datasets show that our model not only can better discriminate diversely expressed existing intents, but is also able to discriminate emerging intents when no labeled utterances are available.", "text_perturb": "User intention detection plays a critical role in question-answering and dialog systems. Most previous works treat intent detection as a compartmentalization problem where utterances are labeled with predefined intents. However , it is labor-intensive and time-consuming to label users ' utterance as intents are diversely expressed and novel intents will continually be involved. Instead , we study the zero-shot intent detection problem , which aims to detect emerging user intent where no labeled utterances are currently available. We propose two capsule-based architecture : IntentCapsNet that extracts semantic features from utterances and aggregates them to discriminate existing intents , and IntentCapsNet-ZSL which gives IntentCapsNet the zero-shot learning ability to discriminate emerging intents via knowledge transfer from existing intents. Experiments on two real-world datasets show that our model not only can better discriminate diversely extract existing intents , but is also able to discriminate emerging intents when no labeled utterances are available. ", "label": 1}
{"original_text": "Quantum Clustering is a powerful method to detect clusters in data with mixed density. However, it is very sensitive to a length parameter that is inherent to the Schrodinger equation. In addition, linking data points into clusters requires local estimates of covariance that are also controlled by length parameters. This raises the question of how to adjust the control parameters of the Schrodinger equation for optimal clustering. We propose a probabilistic framework that provides an objective function for the goodness-of-fit to the data, enabling the control parameters to be optimised within a Bayesian framework. This naturally yields probabilities of cluster membership and data partitions with specific numbers of clusters. The proposed framework is tested on real and synthetic data sets, assessing its validity by measuring concordance with known data structure by means of the Jaccard score (JS). This work also proposes an objective way to measure performance in unsupervised learning that correlates very well with JS.", "text_perturb": "quantum Clustering is a powerful method to detect clusters in data with mixed density. However , it cost very sensitive to a length parameter that cost inherent to the Schrodinger equation. In addition , yoke data points into clusters requires local estimates of covariance that are also controlled by length parameters. This raises the question of how to align the control parameters of the Schrodinger equation for optimal clustering. We propose a probabilistic framework that furnish an objective function for the goodness-of-fit to the data , enabling the control parameters to be optimised within a Bayesian framework. This naturally yields probabilities of clustering membership and data partitions with specific numbers of clusters. The proposed theoretical account is tested on real and synthetic data sets , assessing its validity by measuring concordance with known data structure by means of the Jaccard score ( JS ). This work too proposes an objective way to measure performance in unsupervised learning that correlates very well with JS. ", "label": 1}
{"original_text": "We revisit the complexity of the classical k - Coloring problem parameterized by clique-width. This is a very well-studied problem that becomes highly intractable when the number of colors k is large. However, much less is known on its complexity for small, concrete values of k. In this paper, we completely determine the complexity of k - Coloring parameterized by clique-width for any fixed k, under the SETH. Specifically, we show that for all k 3, 0, k - Coloring cannot be solved in time O 2 k 2) cw), and give an algorithm running in time O 2 k 2) cw). Thus, if the SETH is true, - 2 k 2 is the \"correct\" base of the exponent for every k. Along the way, we also consider the complexity of k - Coloring parameterized by the related parameter modular treewidth (mtw). In this case we show that the \"correct\" running time, under the SETH, is O k k 2) mtw). If we base our results on a weaker assumption (the ETH), they imply that k - Coloring cannot be solved in time n o (cw), even on instances with O (log n) colors.", "text_perturb": "We revisit the complexity of the classical k - Coloring job parameterized by clique-width. This is a real well-studied problem that becomes highly intractable when the number of colors k is large. However , much less is known on its complexness for small , concrete values of k. In this report , we completely determine the complexity of k - Coloring parameterized by clique-width for any fixed k , under the SETH. Specifically , we show that for all k 3 , 0 , k - Coloring can not be solved in time o 2 k 2 ) cw ) , and give an algorithm running in time o 2 k 2 ) cw ). Thus , if the SETH is true , - 2 k 2 is the `` right '' base of the exponent for every k. Along the way , we also consider the complexity of kb - Coloring parameterized by the related parameter modular treewidth ( mtw ). In this case we shew that the `` correct '' running time , under the SETH , is O k k 2 ) mtw ). If we base our results on a weaker assumption ( the ETH ) , they imply that k - Coloring can not be solved in time n o ( cw ) , even on representative with O ( log n ) colors. ", "label": 1}
{"original_text": "This paper offers a multi-disciplinary review of knowledge acquisition methods in human activity systems. The review captures the degree of involvement of various types of agencies in the knowledge acquisition process, and proposes a classification with three categories of methods: the human agent, the human-inspired agent, and the autonomous machine agent methods. In the first two categories, the acquisition of knowledge is seen as a cognitive task analysis exercise, while in the third category knowledge acquisition is treated as an autonomous knowledge-discovery endeavour. The motivation for this classification stems from the continuous change over time of the structure, meaning and purpose of human activity systems, which are seen as the factor that fuelled researchers' and practitioners' efforts in knowledge acquisition for more than a century. We show through this review that the KA field is increasingly active due to the higher and higher pace of change in human activity, and conclude by discussing the emergence of a fourth category of knowledge acquisition methods, which are based on red-teaming and co-evolution.", "text_perturb": "This paper offers a multi-disciplinary review of cognition acquisition methods in human activity systems. The review captures the degree of involvement of various types of agencies in the knowledge acquisition process , and proposes a classification with three categories of methods : the human factor , the human-inspired factor , and the autonomous machine factor methods. In the first two categories , the acquisition of knowledge is seen as a cognitive undertaking analysis exercise , while in the third category knowledge acquisition is treated as an autonomous knowledge-discovery endeavour. The motivation for this classification stems from the continuous change over time of the structure , meaning and purpose of human activity systems , which are come across as the factor that fuelled researchers ' and practitioners ' efforts in knowledge acquisition for more than a century. We show through this review that the KA field is increasingly active due to the gamy and gamy pace of change in human activity , and conclude by discussing the emergence of a fourth category of knowledge acquisition methods , which are based on red-teaming and co-evolution. ", "label": 1}
{"original_text": "Pufferfish is a Bayesian privacy framework for designing and analyzing privacy mechanisms. It refines differential privacy, the current gold standard in data privacy, by allowing explicit prior knowledge in privacy analysis. Through these privacy frameworks, a number of privacy mechanisms have been developed in literature. In practice, privacy mechanisms often need be modified or adjusted to specific applications. Their privacy risks have to be re-evaluated for different circumstances. Moreover, computing devices only approximate continuous noises through floating-point computation, which is discrete in nature. Privacy proofs can thus be complicated and prone to errors. Such tedious tasks can be burdensome to average data curators. In this paper, we propose an automatic verification technique for Pufferfish privacy. We use hidden Markov models to specify and analyze discretized Pufferfish privacy mechanisms. We show that the Pufferfish verification problem in hidden Markov models is NP-hard. Using Satisfiability Modulo Theories solvers, we propose an algorithm to analyze privacy requirements. We implement our algorithm in a prototypical tool called FAIER, and present several case studies. Surprisingly, our case studies show that naive discretization of well-established privacy mechanisms often fail, witnessed by counterexamples generated by FAIER. In discretized Above Threshold, we show that it results in absolutely no privacy. Finally, we compare our approach with testing based approach on several case studies, and show that our verification technique can be combined with testing based approach for the purpose of (i) efficiently certifying counterexamples and (ii) obtaining a better lower bound for the privacy budget .", "text_perturb": "sea squab is a Bayesian privacy framework for designing and analyzing privacy mechanisms. It refines differential privacy , the current gold standard in data privacy , by allowing explicit prior knowledge in privacy analytic thinking. Through these secrecy frameworks , a number of secrecy mechanisms have been developed in literature. In recitation , privacy mechanisms often need be modified or adjusted to specific applications. Their privacy risks have to make up re-evaluated for different circumstances. furthermore , computing devices only approximate continuous noises through floating-point computation , which is discrete in nature. Privacy proofs can thus equal complicated and prone to errors. Such tedious tasks can be burdensome to average data conservator. In this paper , we propose an robotic verification technique for Pufferfish privacy. We use hidden Markov models to intend and analyze discretized Pufferfish privacy mechanisms. We show that the Pufferfish check problem in hidden Markov models is NP-hard. Using Satisfiability Modulo Theories solvers , we propose an algorithmic program to analyze privacy requirements. We follow up our algorithm in a prototypical tool called FAIER , and present several case studies. Surprisingly , our case studies show that naive discretization of well-established privacy mechanisms often give way , witnessed by counterexamples generated by FAIER. In discretized Above Threshold , we show that it results in perfectly no privacy. Finally , we compare our approach with testing based approach on several case subject area , and show that our verification technique can be combined with testing based approach for the purpose of ( i ) efficiently certifying counterexamples and ( ii ) obtaining a better lower bound for the privacy budget. ", "label": 1}
{"original_text": "We present the Latvian Twitter Eater Corpus - a set of tweets in the narrow domain related to food, drinks, eating and drinking. The corpus has been collected over time-span of over 8 years and includes over 2 million tweets entailed with additional useful data. We also separate two sub-corpora of question and answer tweets and sentiment annotated tweets. We analyse contents of the corpus and demonstrate use-cases for the sub-corpora by training domain-specific question-answering and sentiment-analysis models using data from the corpus.", "text_perturb": "We present the Latvian Twitter Eater Corpus - a set of tweets in the narrow domain related to nutrient , drinks , eating and drinking. The corpus has been hoard over time-span of over 8 years and includes over 2 million tweets entailed with additional useful data. We also separate two sub-corpora of question and answer tweets and persuasion annotated tweets. We analyse contents of the corpus and demonstrate use-cases for the sub-corpora by training domain-specific question-answering and sentiment-analysis models using datum from the corpus. ", "label": 1}
{"original_text": "We consider the problem of robustly recovering a k -sparse coefficient vector from the Fourier series that it generates, restricted to the interval [ - O, O ]. The difficulty of this problem is linked to the superresolution factor SRF, equal to the ratio of the Rayleigh length (inverse of O) by the spacing of the grid supporting the sparse vector. In the presence of additive deterministic noise of norm s, we show upper and lower bounds on the minimax error rate that both scale like (S R F) - 2 k 1 s, providing a partial answer to a question posed by Donoho in 1992. The scaling arises from comparing the noise level to a restricted isometry constant at sparsity 2 k, or equivalently from comparing 2 k to the so-called s -spark of the Fourier system. The proof involves new bounds on the singular values of restricted Fourier matrices, obtained in part from old techniques in complex analysis.", "text_perturb": "We consider the problem of robustly recovering a k -sparse coefficient vector from the Fourier series that it generates , limit to the interval [ - O , O ]. The difficulty of this problem is linked to the superresolution factor SRF , equal to the ratio of the Rayleigh length ( inverse of O ) by the spatial arrangement of the grid supporting the sparse vector. In the presence of additive deterministic noise of norm s , we show upper and lower bounds on the minimax erroneousness rate that both scale like ( S R F ) - 2 k 1 s , providing a partial answer to a question posed by Donoho in 1992. The scaling arises from comparing the noise level to a restricted isometry constant at sparsity 2 m , or equivalently from comparing 2 m to the so-called s -spark of the Fourier system. The proof involves new bounds on the singular values of restricted Fourier matrices , obtained in part from sure enough techniques in complex analysis. ", "label": 1}
{"original_text": "We present Animo, a smartwatch app that enables people to share and view each other's biosignals. We designed and engineered Animo to explore new ground for smartwatch-based biosignals social computing systems: identifying opportunities where these systems can support lightweight and mood-centric interactions. In our work we develop, explore, and evaluate several innovative features designed for dyadic communication of heart rate. We discuss the results of a two-week study (N34), including new communication patterns participants engaged in, and outline the design landscape for communicating with biosignals on smartwatches.", "text_perturb": "We present Animo , a smartwatch app that enables people to share and view each early 's biosignals. We project and engineered Animo to explore new ground for smartwatch-based biosignals social computing systems : identifying opportunities where these systems can support lightweight and mood-centric interactions. In our work we develop , explore , and value several innovative features designed for dyadic communication of heart rate. We discuss the results of a two-week study ( N34 ) , including new communication patterns participant engaged in , and outline the design landscape for communicating with biosignals on smartwatches. ", "label": 1}
{"original_text": "One of the roadmap plans for quantum computers is an integration within HPC ecosystems assigning them a role of accelerators for a variety of computationally hard tasks. However, in the near term, quantum hardware will be in a constant state of change. Heading towards solving real-world problems, we advocate development of portable, architecture-agnostic hybrid quantum-classical frameworks and demonstrate one for the community detection problem evaluated using quantum annealing and gate-based universal quantum computation paradigms.", "text_perturb": "One of the roadmap plans for quantum computers is an integration within HPC ecosystems assigning them a role of accelerators for a variety of computationally severe tasks. However , in the near term , quantum ironware will be in a constant state of change. Heading towards solving real-world job , we advocate development of portable , architecture-agnostic hybrid quantum-classical frameworks and demonstrate one for the community detection problem evaluated using quantum annealing and gate-based universal quantum computation paradigms. ", "label": 1}
{"original_text": "This study mainly investigates two decoding problems in neural keyphrase generation: sequence length bias and beam diversity. We introduce an extension of beam search inference based on word-level and n-gram level attention score to adjust and constrain Seq2Seq prediction at test time. Results show that our proposed solution can overcome the algorithm bias to shorter and nearly identical sequences, resulting in a significant improvement of the decoding performance on generating keyphrases that are present and absent in source text.", "text_perturb": "This study mainly investigates two decoding problems in neural keyphrase propagation : sequence length bias and beam diversity. We introduce an extension of beam search inference based on word-level and n-gram level attention score to adjust and restrain Seq2Seq prediction at test time. Results show that our proposed solution can overcome the algorithm bias to shorter and nearly identical sequences , resulting in a significant improvement of the decoding performance on beget keyphrases that are present and absent in source text. ", "label": 1}
{"original_text": "The motivation for this paper is to apply Bayesian structure learning using Model Averaging in large-scale networks. Currently, Bayesian model averaging algorithm is applicable to networks with only tens of variables, restrained by its super-exponential complexity. We present a novel framework, called LSBN (Large-Scale Bayesian Network), making it possible to handle networks with infinite size by following the principle of divide-and-conquer. The method of LSBN comprises three steps. In general, LSBN first performs the partition by using a second-order partition strategy, which achieves more robust results. LSBN conducts sampling and structure learning within each overlapping community after the community is isolated from other variables by Markov Blanket. Finally LSBN employs an efficient algorithm, to merge structures of overlapping communities into a whole. In comparison with other four state-of-art large-scale network structure learning algorithms such as ARACNE, PC, Greedy Search and MMHC, LSBN shows comparable results in five common benchmark datasets, evaluated by precision, recall and f-score. What's more, LSBN makes it possible to learn large-scale Bayesian structure by Model Averaging which used to be intractable. In summary, LSBN provides an scalable and parallel framework for the reconstruction of network structures. Besides, the complete information of overlapping communities serves as the byproduct, which could be used to mine meaningful clusters in biological networks, such as protein-protein-interaction network or gene regulatory network, as well as in social network.", "text_perturb": "The motivation for this paper represent to apply Bayesian structure learning using Model Averaging in large-scale networks. presently , Bayesian model averaging algorithm is applicable to networks with only tens of variables , restrained by its super-exponential complexity. We present a novel framework , called LSBN ( Large-Scale Bayesian Network ) , making it possible to handle networks with infinite size by following the rule of divide-and-conquer. The method acting of LSBN comprises three steps. In general , LSBN first performs the partition by using a second-order partition strategy , which achieves more than robust results. LSBN conducts sampling and structure learning within each overlapping biotic community after the biotic community is isolated from other variables by Markov Blanket. at last LSBN employs an efficient algorithm , to merge structures of overlapping communities into a whole. In comparison with other four state-of-art large-scale network structure learning algorithms such as ARACNE , PC , Greedy Search and MMHC , LSBN shows comparable results in five common bench mark datasets , evaluated by precision , recall and f-score. What 's more , LSBN makes it potential to learn large-scale Bayesian structure by Model Averaging which used to be intractable. In summary , LSBN provides an scalable and parallel fabric for the reconstruction of network structures. Besides , the complete information of overlapping communities serves as the byproduct , which could be used to mine meaningful clusters in biological networks , such as protein-protein-interaction electronic network or gene regulatory electronic network , as well as in social electronic network. ", "label": 1}
{"original_text": "The process of collecting and annotating training data may introduce distribution artifacts which may limit the ability of models to learn correct generalization behavior. We identify failure modes of SOTA relation extraction (RE) models trained on TACRED, which we attribute to limitations in the data annotation process. We collect and annotate a challenge-set we call Challenging RE (CRE), based on naturally occurring corpus examples, to benchmark this behavior. Our experiments with four state-of-the-art RE models show that they have indeed adopted shallow heuristics that do not generalize to the challenge-set data. Further, we find that alternative question answering modeling performs significantly better than the SOTA models on the challenge-set, despite worse overall TACRED performance. By adding some of the challenge data as training examples, the performance of the model improves. Finally, we provide concrete suggestion on how to improve RE data collection to alleviate this behavior.", "text_perturb": "The process of accumulate and annotating training data may introduce distribution artifacts which may limit the ability of models to learn correct generalization behavior. We key out failure modes of SOTA relation extraction ( RE ) models trained on TACRED , which we attribute to limitations in the data annotation process. We collect and annotate a challenge-set we call Challenging RE ( CRE ) , based on naturally occurring principal examples , to benchmark this behavior. Our experiments with four state-of-the-art RE models show that they have indeed embrace shallow heuristics that do not generalize to the challenge-set data. Further , we find that alternative question answering mould performs significantly better than the SOTA models on the challenge-set , despite worse overall TACRED performance. By adding some of the challenge data as training examples , the performance of the poser improves. Finally , we provide concrete hint on how to improve RE data collection to alleviate this behavior. ", "label": 1}
{"original_text": "We introduce a novel class of adjustment rules for a collection of beliefs. This is an extension of Lewis' imaging to absorb probabilistic evidence in generalized settings. Unlike standard tools for belief revision, our proposal may be used when information is inconsistent with an agent's belief base. We show that the functionals we introduce are based on the imaginary counterpart of probability kinematics for standard belief revision, and prove that, under certain conditions, all standard postulates for belief revision are satisfied.", "text_perturb": "We introduce a novel class of adjustment regulation for a collection of beliefs. This is an extension of Lewis ' imagery to absorb probabilistic evidence in generalized settings. Unlike standard tools for impression revision , our proposal may be used when information is inconsistent with an agent 's impression base. We show that the functionals we introduce are based on the imaginary counterpart of probability kinematics for standard feeling revision , and prove that , under certain conditions , all standard postulates for feeling revision are satisfied. ", "label": 1}
{"original_text": "We propose a novel vector representation that integrates lexical contrast into distributional vectors and strengthens the most salient features for determining degrees of word similarity. The improved vectors significantly outperform standard models and distinguish antonyms from synonyms with an average precision of 0.66-0.76 across word classes (adjectives, nouns, verbs). Moreover, we integrate the lexical contrast vectors into the objective function of a skip-gram model. The novel embedding outperforms state-of-the-art models on predicting word similarities in SimLex-999, and on distinguishing antonyms from synonyms.", "text_perturb": "We propose a novel vector representation that integrate lexical contrast into distributional vectors and strengthens the most salient features for determining degrees of word similarity. The improved vectors significantly outstrip standard models and distinguish antonyms from synonyms with an average precision of 0. 66-0. 76 across word course ( adjectives , nouns , verbs ). Moreover , we mix the lexical contrast vectors into the objective function of a skip-gram model. The novel embedding outperforms state-of-the-art mannequin on predicting word similarities in SimLex-999 , and on distinguishing antonyms from synonyms. ", "label": 1}
{"original_text": "This work proposes an improved reversible data hiding scheme in encrypted images using parametric binary tree labeling (IPBTL-RDHEI), which takes advantage of the spatial correlation in the entire original image but not in small image blocks to reserve room for hiding data. Then the original image is encrypted with an encryption key and the parametric binary tree is used to label encrypted pixels into two different categories. Finally, one of the two categories of encrypted pixels can embed secret information by bit replacement. According to the experimental results, compared with several state-of-the-art methods, the proposed IPBTL-RDHEI method achieves higher embedding rate and outperforms the competitors. Due to the reversibility of IPBTL-RDHEI, the original plaintext image and the secret information can be restored and extracted losslessly and separately.", "text_perturb": "This work proposes an improved reversible data hiding scheme in encrypted images using parametric binary tree labeling ( IPBTL-RDHEI ) , which takes advantage of the spatial coefficient of correlation in the entire original image but not in small image blocks to reserve room for hiding data. Then the original image is encrypted with an encryption key and the parametric binary tree is used to label encrypted pixels into two different class. Finally , one of the two class of encrypted pixels can embed secret information by bit replacement. According to the experimental results , compared with several state-of-the-art method , the proposed IPBTL-RDHEI method achieves higher embedding rate and outperforms the competitors. Due to the reversibility of IPBTL-RDHEI , the original plaintext image and the secret information give the axe be restored and extracted losslessly and separately. ", "label": 1}
{"original_text": "We assume that recommender systems are more successful, when they are based on a thorough understanding of how people process information. In the current paper we test this assumption in the context of social tagging systems. Cognitive research on how people assign tags has shown that they draw on two interconnected levels of knowledge in their memory: on a conceptual level of semantic fields or topics, and on a lexical level that turns patterns on the semantic level into words. Another strand of tagging research reveals a strong impact of time dependent forgetting on users' tag choices, such that recently used tags have a higher probability being reused than \"older\" tags. In this paper, we align both strands by implementing a computational theory of human memory that integrates the two-level conception and the process of forgetting in form of a tag recommender and test it in three large-scale social tagging datasets (drawn from BibSonomy, CiteULike and Flickr). As expected, our results reveal a selective effect of time: forgetting is much more pronounced on the lexical level of tags. Second, an extensive evaluation based on this observation shows that a tag recommender interconnecting both levels and integrating time dependent forgetting on the lexical level results in high accuracy predictions and outperforms other well-established algorithms, such as Collaborative Filtering, Pairwise Interaction Tensor Factorization, FolkRank and two alternative time dependent approaches. We conclude that tag recommenders can benefit from going beyond the manifest level of word co-occurrences, and from including forgetting processes on the lexical level.", "text_perturb": "We assume that recommender systems are more successful , when they are based on a thorough understanding of how people process info. In the current paper we test this premiss in the context of social tagging systems. Cognitive research on how people assign tags has shown that they draw on two interconnected levels of knowledge in their memory : on a conceptual level of semantic fields or topics , and on a lexical level that turns patterns on the semantic level into tidings. Another strand of tagging research reveals a strong impact of time dependent forgetting on users ' tag choices , such that recently used tags hold a higher probability being reused than `` older '' tags. In this paper , we align both strands by implementing a computational theory of human memory that integrates the two-level conception and the summons of forgetting in form of a tag recommender and test it in three large-scale social tagging datasets ( drawn from BibSonomy , CiteULike and Flickr ). As expected , our results reveal a selective effect of time : forgetting is much more pronounced on the lexical level of tag. Second , an extensive evaluation based on this observation shows that a tag recommender interconnecting both levels and integrating time dependent forgetting on the lexical level results in high accuracy prevision and outperforms other well-established algorithms , such as Collaborative Filtering , Pairwise Interaction Tensor Factorization , FolkRank and two alternative time dependent approaches. We conclude that tag recommenders can benefit from going beyond the manifest level of word co-occurrences , and from let in forgetting processes on the lexical level. ", "label": 1}
{"original_text": "Computed tomography (CT) is critical for various clinical applications, e.g., radiotherapy treatment planning and also PET attenuation correction. However, CT exposes radiation during acquisition, which may cause side effects to patients. Compared to CT, magnetic resonance imaging (MRI) is much safer and does not involve any radiations. Therefore, recently, researchers are greatly motivated to estimate CT image from its corresponding MR image of the same subject for the case of radiotherapy planning. In this paper, we propose a data-driven approach to address this challenging problem. Specifically, we train a fully convolutional network to generate CT given an MR image. To better model the nonlinear relationship from MRI to CT and to produce more realistic images, we propose to use the adversarial training strategy and an image gradient difference loss function. We further apply AutoContext Model to implement a context-aware generative adversarial network. Experimental results show that our method is accurate and robust for predicting CT images from MRI images, and also outperforms three state-of-the-art methods under comparison.", "text_perturb": "Computed tomography ( CT ) is vital for various clinical applications , e. one thousand. , radiotherapy treatment planning and also darling attenuation correction. However , CT exposes radiation during learning , which may cause side effects to patients. Compared to CT , magnetic resonance imaging ( MRI ) follow much safer and does not involve any radiations. Therefore , recently , researchers are greatly motivated to estimate CT effigy from its corresponding MR effigy of the same subject for the case of radiotherapy planning. In this paper , we propose a data-driven approach to address this challenging trouble. Specifically , we train a amply convolutional network to generate CT given an MR image. To better mold the nonlinear relationship from MRI to CT and to produce more realistic images , we propose to use the adversarial training strategy and an image gradient difference loss function. We further apply AutoContext Model to follow out a context-aware generative adversarial network. Experimental results show that our method is exact and robust for predicting CT images from MRI images , and also outperforms three state-of-the-art methods under comparison. ", "label": 1}
